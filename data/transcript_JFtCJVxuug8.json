{"video_id": "JFtCJVxuug8", "title": "Oxide and Friends 12/1/2025 -- Death by Uptime", "link": "https://www.youtube.com/watch?v=JFtCJVxuug8", "published": "2025-12-08T15:00:38+00:00", "summary": "We hit a new (and disturbing!) failure mode recently when a production rack that had been up for several months saw every (!) compute sled's service processor become simultaneously unresponsive. Bryan and Adam were joined by the members of the Oxide team who debugged the vexing issue -- and reached its surprising root cause.\n\nContext: https://github.com/oxidecomputer/hubris/issues/2304\nNotes: https://github.com/oxidecomputer/oxide-and-friends/blob/master/2025_12_01.md", "transcript_html": "<p><strong>[00:00]</strong></p>\n<p>Full enough house. >> Full enough house. Uh yeah, that this was a this was a wild one. This was a really wild one. So, I'm going to give you my uh if you don't mind, I I'm going to give you kind of my introduction to this problem, Adam, and then will maybe we can back up and get your introduction to this problem and kind of go forward from there. Um because my intro to the problem was I come into the office and I think on a meeting and Robert came up to me Robert of holistic engineer fame. So</p>\n<p>we can we can ring the chime even though people on YouTube >> the much the much loved chime >> the much loved chime. We we will be we we we've heard your comment on YouTube and we'll be ringing the chime a lot. We will be making as many possible references to previous episodes. But um Robert of host engineer fame uh came up to me with a wild look in his eyes and I mean Adam you have known Robert for a very long time. >> Yeah. W a wild look in the eyes is not</p>\n<p>common from Robert. I mean that like that alone is enough to I mean recall just to just to get that chime really working um during when we had the data center reboot when we rebooted the data center. Robert was the one who was actually like healing the water. Cool. I was one that I thought I thought I was going to pass out and or vomit on my keyboard. I bet. But Robert was actually like the cool head in the room. >> No, if Robert's panicking, it's because the fire station itself has burned down. >> That's right. That's right. So, Robert comes up to me with a wild look in his</p>\n<p>eyes and like I'm like I was clearly on a call, but it was like so okay. I mean, obviously, yes, Robert, what is it? And Robert says, \"If I attempt to write to a device address via MDU minus KW, do you think it'll let me?\" [snorts] And I'm like, \"Oh, where where are we right now?\" It is. Do you ever watch Quantum Leap? That show? >> Yes. I couldn't quote, you know, chapter and verse from it, but yeah. >> I mean, I can Matt, have you ever Matt, I'm sorry to to As a as a token</p>\n<p>millennial, can you just does quantum leap ring any bells? Um, as we've learned in previous episodes, uh, if it wasn't featured on Spongebob, uh, it might not have left the generational chasm. I I can't imagine that it would. >> We had >> Yeah. >> Okay. So, good cliff. You You've seen you've heard of Quantum Leap. >> I'm familiar with it. Yeah, we had reruns on satellite. >> Yeah. There you go. Okay. So the quantum leap was a pretty like interesting show because the guy would travel into someone else's body and part of the like in the beginning of the show he's trying</p>\n<p>to figure out like where am I? Like I've arrived in a new body and I've got no idea like I clearly this body knows something that's going. I felt like that I had that feeling of like okay I've obvious I've been transported into the middle of this problem where where we are asking if if writing to device memory is going v. So what Robert is asking is that I do a a a write via the</p>\n<p><strong>[03:00]</strong></p>\n<p>kernel debugger. MB minus KW and MDB is is our debugger. MD minus K is running it such as it's debugging the kernel. The W flag denotes I want to actually write to memory which is obviously like wait a minute is that like is this a debugger or is this a destroyer? It's like well line gets blurry. >> That's right. But but any any idea that is like MDB minus KW it's like all it raises raises certain goosebumps right like that >> what's the craziest thing you've done MD minus KW Adam</p>\n<p>>> uh I have um changed locking primitives so that uh everyone gets a lock that's [laughter] the I've just changed it so that like it doesn't just like whoever wants for a lock wants a lock gets a lock. Uh, no. This was not on a production system. One assumes. [laughter] >> No, no, no. What is the craziest thing you've done on a production system? >> Uh, probably changed an instruction to like um, you know, uh, to like bounce over a like, you know, a condition</p>\n<p>basically. Uh but that felt very it feels very sticky because you're like if I have computed this instruction incorrectly, we are going to we're going to bounce into outer space. >> That's right. Um I for me it was I changed the branch displacement to uh to I changed a particular um or I call displacement actually. Um I change to change a CV broadcast into a CV signal. >> That's exciting. Oh, it was super</p>\n<p>exciting and this was on a definitely a hot customer system where the customer was upset. This is back in Sundays and you remember you remember Jesse, our our our dear friend that we'd worked with and uh this was a customer that he'd been working with >> and Jesse got very nervous when I started asking him permission for what I was about to do. He's like, \"Wait, why are you asking like what why are you asking why are you so uncertain about what you're about to do? Like here's the the surgeon is not supposed to be asking me these kinds of questions. Why is the surgeon asking me permission in this</p>\n<p>regard? Like is >> just to roll it back. You're like I'm seeing this thundering herd. >> So what if instead of waking up everybody we just wake up somebody >> and Yeah. Yeah. >> And like that'll probably that could be fine. >> Assuming I did all all this correctly. assuming [laughter] I I turned this CV broadcast into a call the CV signal and not a call into the middle of of an illegal instruction and or anything else that I could turn >> and you're probably like well if it does wedge up the system I could probably turn it back and maybe the system will</p>\n<p>unwedge too. >> Um [laughter] I I did not really have no know I I kind of knew that there was no insurance policy this was going to be kind of a one-way trip. Uh, and I did start asking Jesse, \"What are the consequences of this? If this system were to reboot right now, what would be the consequences?\" And Jesse's like, \"Not good.\" Like, \"Why are you ask why are you asking me that?\" That's a weird question to ask me. It's like, you know, it's like your surgeon asking you just like, \"Oh, you know, are your your</p>\n<p><strong>[06:01]</strong></p>\n<p>affairs are in order?\" So, like you do have a will, right? I mean, obviously, I mean, obviously you got a will. Me, my god, you you clearly done the most basic adult things. You're like, um, >> feel like it's more like your dentist asking that, but yeah, >> it's like your dentist asking [laughter] why. Uh, this is a super. Do you ask this for No, no. Just like this is a pretty I don't know. This is a little adventurous this one. This root canal is a little more adventurous than the ones I've done. And I just want to make sure just asking you your fair share or you've got like you know you don't want you don't want your you want your kids to be able to you know they're already</p>\n<p>going to be devastated enough having lost a parent. You don't want them to be financially ruined. Um you're like what? Um no. So I it worked. I'd like to say it all worked and uh I was relieved and then maybe too relieved. Jesse thought I was a little too relieved and realized that like I should not have allowed you to do that. Okay, so Robert is asking me if he can write to device memory via MV minus KW. And I'm like if it did allow you to do that that would be that itself would be a bug. Like we don't that is like what do you want to do? And what Robert quickly explained and will this</p>\n<p>is where we're going to jump to you to get more context is like he said so this is a customer system. We have lost contact with all service processors. And I'm like, what do you mean all? It's like every compute sled, we cannot talk to the service processor on any compute sled. Hosts are up, but all service processors are at this point like I can say, yeah, wildlook is definitely merited. And so what Robert like what Robert wanted to do, so what the first</p>\n<p>thing what we needed to figure out and again we'll go to you to get more context on all this. Um, and I know Matt you jumped in here early too. We want to determine, you know, how dead is the service processor actually and how can we get what we can tell because the service processor is connected to the network and what we know is we can't reach it over to the network. Um but we or seemingly um we also know the service processor is in charge of certain basic maintenance of the system. Uh the</p>\n<p>service processor among other things uh has the thermal loop which Matt wrote. Um, and we know if the service processor goes out to lunch completely, uh, the fans will all crank up. Um, so >> just for a little context, the service processor may be obvious here, but it's the computer within the computer. It's the computer that is is driving the basic kind of autonomic functions of of the of the server uh, as and including things like being able to reboot it or the or the fans as you're saying. >> Yeah, that's right. And I mean, this is</p>\n<p>the this is our answer to the baseboard management controller. So we we we do not have a traditional baseboard management controller for a bunch of good reasons. Um and what we have instead is a service processor. So the u but that the SP is definitely important. So and the SP and we'll go into this in detail has been designed with an operating system that Cliff led the charge on Hubris that is designed to be very robust and it is really not</p>\n<p><strong>[09:04]</strong></p>\n<p>designed to disappear. It was very unusual that it would disappear. And so, uh, the the the reason for the wild look is that what Robert Robert's kind of bonkers idea was so requires a little bit of backstory, but the, um, so, uh, we, um, when we boot the, the service processor talks to the DIMs on the on the box. So there's there is an I squared C bus that the DIMs the the</p>\n<p>memory is connected to and there are there's there's some identifying information in those DIMs and it's the service processor that is connected to that bus and gets that information. But the host CPU ultimately needs to get that information in order to train memory. It's got its own I squared C initiator and it when it thinks it's talking to the DIMs, it's actually talking to the service processor. Okay. >> So Okay. So this but this only happens when you boot the host CPU. Once it's</p>\n<p>booted, the I squed C controller is like not really used. And one of the things that Robert has discovered over the last I'm not sure when he made this discovery but one of the things he's gotten working over the last couple of months is like so this I square C initiator is hidden from you know we we we talked about uh and um the the kind of the various other uh chips the hidden cores on the die um and we uh and all the</p>\n<p>those kind of like the hidden things that we don't see that I C controller is controlled by one of those hidden cores. And what Robert realized is like actually the I squed C controller for that thing is actually mapped into our address space and we the host operating system can actually manipulate that I squed C controller. So we can initiate I squed C. And I'm not even sure like this kind of defies metaphor. I don't even know like we're kind of like borrowing its underwear. I don't know. I mean, I'm not even sure what the So, what Robert wanted to do was uh Robert's like,</p>\n<p>actually, what I think we can go do is I can hit this memory mapped region for the I squ C controller and I can force this thing because the host CPU is up. I can force this thing to initiate I squed C transactions and see if the SP can respond to these I squared C transactions um to identify like memory which >> the I was like wow that okay we are really desperate um and uh we and even Robert is like yeah this this feels a</p>\n<p>little too adventurous I'm like that definitely like my my CD broadcast a CB signal can just sit If you're going to do this, [laughter] this is definitely next level. Uh so um the but that was coming into this while it was already kind of evolved. So Will, I think you were among the first on scene on this to discover that the service processors were were were down.</p>\n<p><strong>[12:05]</strong></p>\n<p>What was kind of the the and you were attempting to do uh were kind of supporting another issue and you all noticed that like oh my god these things are all down. Uh how did the kind of things proceed from there? Um, do you want me to give us some context on like what the customer is seeing first? >> Yeah, sure. That'd be great. Yeah, that'd be great. >> Yeah. So, the customer reached out to us because they were they were trying to stop an instance via the CLI and the request was timing out. Um, which typically means that one of the the sleds is down and like isn't able to respond and so the the the request within the rack times out and so the the client times out. Um, so we ask for permission to to connect to the the rack</p>\n<p>and they let us let us in. Um, and then we know we list all the hosts and we can see that sled 23 is down. Um, and then at that point we list all the SPs just kind like a matter of course just to like validate that the SP for that sled is there. And then as you said all of the the sleds are gone. We still have the SPS for the two PowerShell controllers um and the two switches but the other um 16 SPS are just completely missing. Uh >> so so like the list like you're able to</p>\n<p>list them and it's like yeah I have these two or three that's what you're looking for right >> yeah there's four right [laughter] >> yeah so um so the tool we use to list SPS is called pilot and that has like a streaming feature where you can just like show me all the discoveries you have and so we use that next and we can see it's it's only discovering the the four that we see in the list which makes sense um so we look at the MGS or management gateway service logs next and we can see that you know the we're reaching out So all these SPs and it's timing after 20 seconds and five</p>\n<p>attempts. Um so at that point, you know, we we reach out in the the channel and say we don't see any SPS on this this rack. And um you know, Matt and a number of other people hop in from that point to to start to troubleshoot more. And Matt, I'm sure you were like, you can't see you've lost all of them. I the I mean it definitely reminds me of that Far Side cartoon where it's like we paid you to look after the children and you cooked and ate them both when they are coming home to a wicked witch. I mean it feels like you've we've lost all of the SPs that must have been this is not a</p>\n<p>failure mode that we've really uh this really shouldn't be possible. >> Yeah. I mean to lose one SP could be seen as careless. To lose 27 of them that's really [laughter] really impressive. Yeah. So, at this point, I get pinged and I'm like, \"Oh, it's another quote unquote management network bug.\" Uh, which is never the management network's fault, but you know, I got to go in and prove that to my satisfaction. Uh, and so I, you know, pop into the system and we have pretty good counters and visibility to like what's going on in the management network where I guess the the context here is the management</p>\n<p>network is the separate switch which has all of the SP traffic and then it has a bridge up to the main network. Uh, so we can use this. This is running before the main switch is running. it runs when the system is mostly powered off. And so we start looking at the counters and sure enough we see that we have packet counters for all of the SPS and the packet counters are going up for the</p>\n<p><strong>[15:06]</strong></p>\n<p>two side cars and the PSC and they are not going up for any of the SPs. So we're like oh well that's a bad sign. Uh that means that no packets are leaving the SP. this like this all checks out, right? Because the the whole point of the broad the way the discovery works is that the SPs are periodically broadcasting a message saying, \"Hello, I'm an SP.\" And if we don't see that message, then it doesn't get through. So, the fact that the packet counters aren't going up, is like, okay, that's understandable, but not great. So, I actually, let me just see. I pulled out, unfortunately, this is in a</p>\n<p>customer support ticket, so it's a private repo, but I pulled out my long list of things that we did. >> Oh, yeah. I love that that you were saying that I actually was coming into this several hours of bad ideas in. So I I cannot wait to hear some of the other ideas. >> Yeah, Robert's like, \"Let's cut off our own hands was like that was the best idea.\" [laughter] >> That was exactly that was after several other ideas. >> So one other thing we try is running there's a command called IPCC which talks to the SP over the serial port in the system. Uh so that is like not using the network stack at all obviously and</p>\n<p>so we tried using that to talk to the SPs on these stucks sleds and sure enough they didn't talk over IPCC the serial line either. So at this point we're like I'm like okay something has gone wrong and like the kernel has hung in all of these SPS and maybe it's like a timer that has gone wrong or something like that. And I think Robert is like well can we just try to ping the SPS just to see if that works? Uh, and I'm like, \"Sure, sure, but that's not going to work.\" Like the whole system is hung. Uh, and so we, you know, figure out the IP address and we try to ping one of the</p>\n<p>SPs and the SP answers on ping. And we see the packet counters go up for like the the two packets that it takes to do uh, ICMP discovery and echo and we're like, \"Oh, the SP is still running. This is weirder than we thought.\" >> Yeah. Totally weird, right? Because we I mean >> Yeah. >> Yeah. Go ahead. No, no, I was going to say that I mean I I think because the expectation there is like when we are dead that the whole that we are the SP is actually dead. The colonel is panicked or something as as so the fact that this or that the networking task is</p>\n<p>like totally dead. So the fact that this thing can actually respond to ICMP echoes is kind of wild. Something very weird is going on. The SPs are alive enough to answer pings but dead enough that they can't seem to do anything else. And one thing we know about pings is that pings are actually handled within the net task itself. So it doesn't do dispatch to a different task. And what it seems like now is that like every task below priority five, which is the priority of the net task, is not</p>\n<p>running for some reason. And we're not sure why this is happening. I point out that if the net task was always runnable for mysterious reasons, then it would always be selected and that would cause the behavior we saw. But this is still in the like mysterious reasons category. Uh we then I think will do you want to talk a little bit about the like thermal current debugging that we tried to do as well?</p>\n<p><strong>[18:06]</strong></p>\n<p>>> Sure. Uh yeah so the the SPS will um collect um metrics on on current for the the sleds and then we also have and also from the power shelf controller. So we uh we did this two different ways. Um and we can we can query the metrics um with within the you know kind of like the management system of the rack using uh OMDb which is kind of internal tool. So it's really easy to to run metrics queries. Um so the first thing we did is we just queried for um hardware current um from one of the the deadl SPS just to see uh</p>\n<p>like when when did this stop and we could see that it stopped you know roughly 25 days previously. Um and then we just repeated that for all the other sleds. Um just and we can see they'd all failed within the space of I think roughly a day. Um, and then we also like and I guess uh I and we also checked uh for the the PSC um or uh hardware metrics or uh current metrics just to see like when the SPS died, did we see</p>\n<p>an increase in current indicating that the fans were kicking off and it looks like we did see an increase in draw which was suggestive of that. I don't know if we ever conclusively determined that though. Yeah, we so we ended up seeing like a moderate increase in current. So not enough that the fans were like at 100%. So it was like mixed results. Like we saw something change in current, but it was not strong evidence for exactly what was going on. At one point we're also considering asking the customer to go down to the actual data center and like car talk style like describe the noise</p>\n<p>the server is making. Is it more of a woo or is it more of a woo? [laughter] Uh we didn't actually end up asking the customer to do that though. [laughter] Um, but maybe we should, you know, even in hindsight, we've got this thing completely debugged, why not actually just like, you know, I think Matt, as long as you ask them in exactly that way. I feel we should uh I like the various kinds of apes that we're trying to determine which one we're seeing. >> The other uh the other thing we did at this point was take the number like 188.5, which was the rough up time, and</p>\n<p>like look at it in milliseconds, and try to turn it into an even power of two, cuz we're like, \"Oh, maybe something is rolling over at this point.\" And it turns out you cannot turn 188.5 days into like anything that looks like power of two unfortunately. >> Yeah. So we've got uh and then we and but the host is up right. So we also don't want to like well yeah I mean we don't actually we don't have the ability to extract any more state other than we know we and we don't need to do um or</p>\n<p>were there other bad ideas that um before Robert wanted to write to device memory to use the what were some of the other things? >> We kind of backed off the the device memory once we saw the ping working because we're like okay like the the SP is actually alive which was what we were trying to prove by showing that it responded over SPD. >> Um I think the other thing that we</p>\n<p><strong>[21:08]</strong></p>\n<p>hadn't done at this point is like we had not proven that the SPS would come back >> which was concerning. Uh yeah, the uh in terms of like we don't know if the SPS are actually dead dead. >> Yes. Although by by the time we saw them responding ping, we were maybe feeling a little bit better on that front, but we were still like if we power cycle one of these sleds like and the SP doesn't come back, then someone is flying off to a certain location with a debugger and not going to have a good week.</p>\n<p>>> Yeah, that's a very dark thought. I I I guess I came into this after that I did that dark thought had not occurred to me that we had managed to actually like electrically destroy every one of the SPs. That would be uh that's dark. Yeah, that that that's definely dark. Fortunately, so um we and I think we did end up resetting Will, you ended up resetting the sled that was the cause of the investigation to begin with and that thing did come back up. Is that correct? >> Yeah, that's right. The next day um we</p>\n<p>got had access to the rack again and um power cycled and it came the host and the people both came right right up. So that was a relief. That's a relief. Okay. So now we have got really just the symptoms of this problem. Um it's obviously a very bad problem. We really rely on that SP being up. Um, and but so we we're kind of we we're kind of reduced to we I think Matt we've kind of</p>\n<p>exhausted the information we can get out of the running system. Um or maybe there were some other ideas on other information we could get out but um we're kind of reduced to like all right we're going to need to kind of go from first principles and try to reproduce elements of this problem. Um you had the thought that I think a lot of folks had is like could this be time related? um definitely reminds Adam of the Elbolt problem, the the famous Unix Elbolt problem where after with Elbolt is a 32-bit value. Um it and at its defbolt</p>\n<p>is the lightning bolt variable that dates back to like sixth edition. Um yeah, they they took very like odd poetic license or poetic license at very odd times like >> drop the E off of Cat and uh and Elbolt as lightning bolt. But so this thing fires 100 times a second. This is the system clock at 100 hertz. Um you will that that value will become signed uh after 248 days. Um and kind of famously Unix systems of a certain vintage could</p>\n<p>not stay up for longer than 248 days. And I mean they would be up after 248 days. It's just that it would be absolute madness of people thinking that that their timeouts that were in the future were in fact in the past and and a bunch of stuff would break. That was all this is all like in the 90s and actually one of the first things I don't I the first thing I actually did at Sun was actually fixed that. Um yeah that it</p>\n<p><strong>[24:09]</strong></p>\n<p>was kind of the I I someone else had kind of already started that work and was kind of handed to me. >> It's like a classic job to like send to the new guy too cuz you're like how hard like this doesn't seem that hard and I'm sure then like your phone was ringing for years or whatever uh on this critical code path. Uh, you know, it was funny actually on that in particular like the the that work had already been uh had already been broadly done >> and they also wanted to allow the hertz value to be to be tuned uh to be</p>\n<p>configured and they had decided that they senior engineers had decided that the values that were acceptable were 100 and a thousand. So 100 Hz and a th000 Hz. I'm like, why not like why not just allow it to be configured to any value? Like, well, that'll be kind of unsupportable. Like, that feels like that should be supportable. So, I just like crank the values higher. So, what I would do is like I'm just going to crank the value until the machine no longer boots because it's just running the clock interrupt all the time, which was super satisfying strangely to do that. It was like I don't know. I think that</p>\n<p>there's something there there's something sadistic in software engineers where we kind of enjoy computers that are in pain at some level. So, um, and I in particular remember that on Sun4C, this is Campus, this is a an old old machine at this point. Um, I don't know what the clock rate was on that thing. Um, I could get it to 26,000 and it hung at 2,600 hertz. Um, and I came back the next morning and I was very satisfied that it hung and I hit the the the carriage return and verified that it had</p>\n<p>hung. Um, I guess I did that the night before because I came in back the next morning and it was actually making progress. It was executing like some very small number of instructions at a time. Um, and then the machine immediately panicked. Uh, and it panicked on what ultimately was a chip bug that we found. >> Wow. >> Yeah. It was just crazy. Um and the uh as it turns out uh there when you set the processor interrupt level um there was a two instruction window immediately after that where you could take in the interrupt at a level lower than you just</p>\n<p>set the interrupt level to. Um and that was a chip bug as it turns out was a chip bug in every Spark microp processor they had made up before Ultra Spark. So um yeah it was and it was it was actually it was it was kind of an interesting lesson in a whole bunch of ways. one that like the the consequences of just time in general, the these problems that you have that you only see with uptime, right, that are really hard to test for. Um because how do you like you have to just like wait um and obviously there are ways to do this and</p>\n<p>there are ways to kind of jump start time. I mean, Matt, that was one idea you had was around time. And did you end up doing the experiment of trying to accelerate time um closer to this value that of course is not even power of two to see if anything breaks? >> No, we had talked about just like booting the system with the clock set to 188 days, but didn't actually get around to that. >> Get around. Yeah. So, we're this kind of a you know, this is a high priority</p>\n<p><strong>[27:10]</strong></p>\n<p>issue, but we're kind of noodling around on how to like I got what to do. Um, and then Cliff, you uh you picked this up. It's like, well, this seems like a high priority issue obviously. Uh, what was your approach in terms of like because this is this is a tough one to kind of go from first principles on? >> Yeah. Um, so I had been out for a chunk of this dealing with family stuff. And so I get in and I have text messages waiting from a bunch of these folks being like, \"Hey, so there's a weird thing. Hey, there's a weird thing. we'd</p>\n<p>really like you to look at the weird thing. Oh my god, could you please look at the So anyway, uh but fortunately by the time I got in, a lot of this prep work had already been done and the the stuff that Matt and folks investigated really narrowed down the potential failure space. So by the time I showed up, what we knew was essentially machine goes unresponsive to everything except ICMP ping, which as Matt mentioned is handled on a fast path inside the network stack. So that can keep working sort of like a brain stem</p>\n<p>reflex like a chicken with its head cut off long after the rest of the computer is doing something else. And Matt also mentioned earlier the the possibility of the net task like being really busy or doing something in a loop. And so that was sort of the leading hypothesis, but we didn't know what would cause that or why it would be doing a lot of work in a loop. So, Cubris has some interesting properties and tools here that actually came in really handy. And this sort of we need to model the operation of the system in</p>\n<p>our heads because we can't get information in or out of the computer because it's that borked is the sort of situation that guided the design of a lot of the system and tooling. So what we had was uh from the build system we could get a graph showing the priority relationships of all of the IPCs between all of the tasks. Uh and from that we could clearly see that like the IPCC handling the serial port to the host was a lower priority than the network stack as are all of the</p>\n<p>clients of the network stack by design. Uh the hubris network stack is a little weird, but it's a separate task rather than being in the kernel. And tasks that want to offer a network service are lower priority than the network stack, which means whenever the network stack has an opportunity to run, it wins. It will take the CPU away from any of its clients as a fairness thing mostly. But in this case, uh the IPCC was also lower than the network stack. So if the network stack were running with wild</p>\n<p>abandon, it could explain why all of these interfaces are down except for ping. Uh the other thing that seemed plausible at the time though was one of the ways a task in hubris can burn lots of CPU is to crash a lot because our default response, >> yeah, >> generally it's an system is to restart the task. Now, Matt recently actually added a um</p>\n<p><strong>[30:13]</strong></p>\n<p>sort of smart timeout to give a waiting a cool down period whenever a task crashes before it gets restarted. But I believe that uh this customer was on an older release and I wasn't confident that that code was there. So, so that wasn't a possibility was that it was just falling over a lot. So, we had to sort of rewind. And the good news is is like thinking about this after the fact, there's a bunch of problems we didn't have to chase that would have been wild goose chases that we might have had to do on earlier systems I've supported. Like this was probably not a wild pointer</p>\n<p>misuse in a different task because we're pretty confident the memory isolation between the tasks works at this point. Um it's probably not a scheduler bug because theuler is super super simple. So >> I had to Yeah. And just on that, a good especially on the wild pointer cliff because I think this is so important because when you have the possibility of kind of arbitrary corruption from arbitrary things, >> right? >> You've got this kind of like well magic</p>\n<p>happens and sometimes there's bad magic in this system and we don't understand why and therefore like certain things are unknowable. Um, and >> yeah, supporting complex C firmware for a long time is the reason why I know what it looks like in a hack dump. If a pointer has been replaced by an IE E floating point number, [laughter] that's the sort of thing that happens, >> right? Oh, so having this that is a I mean not only do we have the solace that that</p>\n<p>doesn't happen, but that also gives us a kind of resolve that like this is like there's something else going on like we we we can't just chalk it up to bad magic due to due to something having a straight pointer. >> Well, as you say, data corruption is almost is not is almost undebugable. That is to say, you're separated at such a distance. We talked about this last week and the ramifications are almost arbitrary. So it does give you some license to feel like giving up is an option. >> Totally.</p>\n<p>>> Yeah. And and data corruption is sort of like the well I guess it was ghosts of software engineering. >> Exactly. Exactly. [laughter] >> Very un for better or worse don't really get to reach for that one. Um, so we instead stepped through everything sort of rigorously and I started with the kernel looking for potential bugs, but theuler is really simple and we didn't find anything there. So I started looking for things that might cause the network stack to crash because if it's crashing, it must be crashing for a reason. It's probably a panic cuz it's</p>\n<p>Rust. Like that's basically how we crash. And the number of actual panics in the network stack code is pretty low. Although I did run off on a couple of tangents chasing ghosts that wound up not bearing any fruit, but we pretty quickly narrowed it down to the idea that um the network task was probably failing to correctly acknowledge an</p>\n<p><strong>[33:13]</strong></p>\n<p>interrupt. So hardware peripherals on on machines like this on these microcontrollers indicate some condition to software by signaling an interrupt which causes an interrupt handler. It basically interrupts the flow of instructions through the computer and in our case uh a small routine runs in the kernel to handle the interrupt and pass it off to a task outside of the kernel for further processing in this case the network stack. So if the stack were getting an interrupt from the network controller and was failing to like clear the</p>\n<p>condition, then as soon as it tried to go back to sleep, the kernel would receive another interrupt and would flap the network stack again. And you'd wind up in this cycle where the network stack basically receives all userland cycles instead of the computer ever idling. But it wasn't clear what could be causing that because we've had this Ethernet driver for years and it's generally been pretty reliable and it's there weren't any obvious interrupt sources we wouldn't be clearing. So I had to go read the manual again and buried in the manual in an unexpected</p>\n<p>location of the um let me just double check the page here. >> And can I just ask you something about your methodology here when you say I'm going to go read the manual again. So, >> the manual for the microcontroller >> is thousands of pages long. >> I just looked it up. It's 3,294 pages, >> which is a good thing to be clear. We've and I I believe >> I believe in our episode on transparency and hardware software interfaces, I've called out ST as a model in this regard.</p>\n<p>So, love having this much documentation, but when you say I'm going to go back and read the manual, are you Um, and and clearly the documentation on Ethernet controller is is slimmer, but it's like I mean it's probably hundreds of pages, is it not? I mean, it's got to be >> Yeah, the Ethernet chapter is is only 300 pages long. And >> oh my god, I think the other problem with the Ethernet chapter is that >> there are several interrupts which are listed as enabled when the chip is</p>\n<p>reset. And that is just straight up a lie. Like we were going through this and we found, oh, it says these interrupts are enabled. These interrupts are enabled and they're not enabled when the chip is reset. >> Yeah, the chapter is effectively crying wolf. There are three or four different interrupts where it asserts in plain English this is enabled by default. But it's not. But it turns out turns out one of those four actually is enabled by default. But the only way to confirm this is with this diagram that's hidden on page I don't know 2000 in</p>\n<p>mumble that um I posted on the GitHub issue that uh shows that this one interrupt source for every other interrupt has this and gate that like masks it if an interrupt enable isn't on. This one interrupt source instead has an orgate that doesn't allow you to mask it ever.</p>\n<p><strong>[36:14]</strong></p>\n<p>So uh >> uh what is I mean do I may I are we taking questions at this time? [laughter] Why? >> Why? >> Yeah. So that I mean that that was just confusing to you that this would be we'd have this this particular interable. >> That's pretty bonkers. I mean so normally the sort of convention on an armed microcontroller like this is that the center central standard interrupt controller has enabled bits for every</p>\n<p>interrupt source and sometimes something like an Ethernet controller will combine a bunch of sources internally into a a single bit that goes to the central interrupt controller. So in our case from the CPU's perspective Ethernet produces one interrupt but it's a combination of like two dozen possible event sources. So, the nice thing to do is to have bits in the peripheral that let you turn those individual interrupt sources on and off. The next nicer thing to do if you have some of them that can't be turned off is to have them</p>\n<p>connected to some somehow optional and maybe a function that has to be turned on. So, there were actually two stanzas in the interrupt handler and the Ethernet uh driver in Hubris that said, you know, basically had a todo, we don't enable this interrupt, we don't need to handle this, which >> which is which is half true. It's >> true. So, well, actually, so it turns out to be all the way true. Folk folks had flagged that as a as an OSHA thing</p>\n<p>we need to look into, which is valid, but it turns out those interrupt sources actually aren't enabled by default despite what the book says. So, those two are fine. There was a third that we didn't know about that was not listed in the Ethernet interrupt section of the manual that turns out to be the thing that's actually on by default. And it's the uh if I can jump to the spoiler, it's the management counters interface on the network interface controller. So,</p>\n<p>it's this block of things which we skipped over because we're like, \"Oh, management counters that'd be cool someday.\" Like, but it's probably fine, right? Counters, that doesn't sound dangerous. What would go wrong with a counter if we don't do anything? [laughter] Yeah. So, the answer is is there's a one of the counters is responsible for counting packets in and out. And by default, when that counter reaches its halfway value, it lets you know it's going to overflow by causing an interrupt. There's there's no way to turn this off. Actually, there it did turn out there's</p>\n<p>a way to turn it off, but it's really hidden in a different register. Yeah. And I mean I I guess like thanks for letting me know that I thanks for thanks for killing me by letting me know that this is like a fire breathing canary. I'm trying to figure out like again what the metaphor is for this. But the uh and so it fires the interrupt when it you're when the the counter is</p>\n<p><strong>[39:15]</strong></p>\n<p>halfway at at its halfway mark which also feels like pretty aggressive. >> Anakin, come on man. Like you're halfway there. You're halfway there. >> I mean, the glass is like, isn't isn't the counter literally half empty? Like, why are you you're you're complaining that it's half full. >> So, Cliff, can you walk me through the So, then you get the interrupt >> and then what happens? >> So, in this case, because there was no software to handle the interrupt, what happens is the kernel interrupt handler runs as usual. The kernel notices that it's from the Ethernet controller, sends</p>\n<p>a notification to the Ethernet handling task, the net stack. The net stack wakes from sleep uh looks at its notifications and says, \"Oh, I've got an interrupt. Great. Let me go run my interrupt processing code.\" Doop doop doop. So, it goes through a whole series of reading device registers and looking at bits in them and trying to figure out what actual hardware event caused this interrupt. And it runs off the end of the code because it didn't think to check the one register for this thing we hadn't turned on. [clears throat]</p>\n<p>>> Uh so then it says, \"Great, I've handled the interrupt. This must have been spurious cuz that does happen. Uh, I'll just reenable the interrupt, which it does. Go back to sleep. And as soon as it goes back to sleep, the colonel says, \"Hey, you got an interrupt.\" And then the whole thing is right over. So the the failure was interesting because what we basically had was a network activated time bomb in every service processor and actually in</p>\n<p>in the other in the switch in the sidecar switch and the the power shelf. All of them had this time bomb lurking, but we never seen it kind of because we usually the machines before they hit this counter, but we in hindsight, we had had a couple of infrequently used dog food systems that would mysteriously fall off the network and we never really knew why, but I think now we know why. Um, >> yeah,</p>\n<p>>> it's also fair. Is it fair to say that this this feels like it could be lurking in every consumer of this, right? Like the this counter is so buried, the documentation does not make it clear. In some cases, it's wrong. >> The pathology waits for a gajillion packets or whatever or half a gajillion, excuse me. [laughter] Right? Like could this be lurking in like everybody who thought they've properly implemented something on top of this? >> Right? I'm not accusing this construct</p>\n<p>of being enemy action, but if it were enemy action, what would it look like? [laughter] >> Yeah. So, I actually was wondering that, too. So, I went and checked every open source driver I could find for the Ethernet block on this microcontroller. And it's not a super popular microcontroller, but it's kind of popular. So, there were several code bases I could check. And in general, every codebase I found tended to have a commit</p>\n<p><strong>[42:16]</strong></p>\n<p>usually months after the original version of the code >> that sheishly went in and turned these bits off. >> So people are hitting this in practice, but they're hitting it faster than us, which then sent me down a whole like why why are we so late to the party here? Like why are we getting bit with this at a customer site when other people like the the rust embedded how driver for this Ethernet controller actually fixed this in 2022 I think so >> oh interesting >> yeah and I think I think the reasons are kind of a side effect of the system</p>\n<p>robustness if we get a failure like this the only symptom is that like oh wow it dropped off the network uh in a normal system having an interrupt storm like this means the entire computer locks up all interface has stopped working, you have a brick. And it's a lot more obvious when you're having this class of system failure. And with our systems, it's just like, huh, well, I don't know, maybe the cable to this one PSC is flaky. We should probably receat the cable uh and move on. And</p>\n<p>>> yeah, and then you reboot it and receat the cable and the problem's gone. >> Yep. for you. >> I also could I also do wonder if the other folks using this mic controller because if you're you I mean we don't see this is not like a network device you you know what I mean like yes we we obviously the network's important here but we are not like pounding the network all the time like if we were making if we were using this microcontroller >> for you can imagine use cases that would hit this much faster than than we hit it. The management network on the rack is completely separate from the customer</p>\n<p>data network and the amount of traffic flowing over it is relatively low and it's very controlled. It's all just our things talking to our things. It's also small packets. It's all UDP. It's very lightweight. So our packet frequency on that network is lower than probably your home Wi-Fi network. So we can we'll get to [clears throat] 202 to the 31st power packets sent a lot later than most people. >> Uh yeah 166 days later apparently I from our 186 days. Sorry Matt the number was</p>\n<p>>> Yeah. >> Um so okay so but we've got this uh really interesting thing in the data sheet that you've discovered. Um, what's next in terms of like how can we go explore this hypothesis? >> Oh, yeah. So, I think I posted in chat saying I may have found a thing that that we're not handling, but I need to look into this more um because I don't know, I tend to be habitually uncertain about things. But uh</p>\n<p>I went digging in the data sheet and I found a test register in the Ethernet block which lets you force the hardware to set the counters just below overflow. So there's actually >> in the controller for testing the overflow behavior without waiting for two to the 31st packets. So once I saw</p>\n<p><strong>[45:20]</strong></p>\n<p>that, it was like I was worried I was going to have to run the thing overnight spamming it with packets, but no, I I just went in with a debugger. And I mean, I know it sounds like and the colonel debugger, you would consider this a bug, but I I used the debugger to write a device register to uh force this bid on uh and the and then pinged it 16 times and the thing hung up with exactly the behavior we would expect in production or we were seeing in production. So that was a strong indicator. And then if you do humility tasks at that point, you can see the all the running tasks and net is always</p>\n<p>marked as running. Idle never runs. So it's it's not yielding the CPU. >> Yeah. And I mean the great thing is that you've now you've reproduced this cuz when we are in a comput sled certainly in a customer site but even a comput sled that's just in a rack we don't have a debugger plugged into that thing like they we the header's populated but we don't actually there's not a a so when the network is actually our only way to understand what's going on inside that uh that service processor. You have now reproduced this on the bench where we you actually have a debugger attached to</p>\n<p>it. So we can use the serial wire debug interface in and we can actually understand heaven and earth about what this thing is actually doing. >> We can ask it arbitrary questions even though it's network interfaces down because the nice thing about these embedded debugging interfaces like JTAG and serial wire debug is that they're not cooperative. They will work even if the computer doesn't want them to. It's >> also why we don't have them plugged in at a customer site because that would be rude and give us lots of weird powers over their computer. uh on the benches</p>\n<p>>> as it has died. I and I can't remember if we've mentioned it here before or not, but I do feel like one of the one of the things I I love that we have done is that we have use the serial wire debug and in this incredible robustness of it. It really is a very robust mechanism and as you say it's like it's not an opt-in mechanism. Um this is how the root of trust can control the service processor on our machine. The root of trust actually has that squid line and it can actually control the service processor and uh force it to attest to itself and do all sorts of</p>\n<p>other things which is extremely useful. >> Yeah. On boot the root of trust actually stops the service processor um like alters the contents of its RAM, forces programs into it and makes them run and verifies that they ran in a way that the hardware cannot lie about. So that that that was Rick's idea a long time ago and boy has it been a delightful hack. It's it's really quite powerful. >> It's a damn good Yeah, it's a damn good idea and it's been really really robust. But it all goes to this I mean and I've certainly understanding Cortex</p>\n<p>microcontrollers was a first for me at Oxide and really appreciating the robustness of that of that SWID interface. Um it it's very very helpful to have something that's so robust there. So, all right. So, so you've now reproduced it. We've got the symptoms and then so uh so what's the fix? I</p>\n<p><strong>[48:20]</strong></p>\n<p>mean, it feels like what actually what is did we do? We just uh actually let this interrupt know that we're actually not No, I guess we can't we can't mask it. So, we've got to actually deal with it. >> Yeah. So, once you once this interrupt goes off, you have to figure out which of about a dozen different bits in different registers you would have to set to make it stop happening. There's a whole tree process you have to follow of like read the top level register and see which bit is set and then go read a different register depending on what bit is set and then like da da da da da da and we could do that but it also turns</p>\n<p>out that there are bits you can set in a control register to just turn this feature off. We don't use the >> but the code I added is about 30 lines of comments and like two lines of rust uh basically like >> so this is actually on by default and here is the bit here's the here are the bits we have to set and here's the code to set them and now the interrupt shouldn't occur. >> Amazing. Um, and uh, and I mean I think</p>\n<p>that we I mean on the one hand and Cliff I mean as as one would I mean you said look we we we can't say conclusively we found the issue but boy we found an issue that matches everything symptomatically. It does feel like we've got a high degree of confidence that this is the issue that we saw in production. >> Yeah. Like the the simultaneous failure is really my I mean okay I'm a little bit of a ghoul. So [laughter] I one of my favorite parts about this failure is the fact that it was simultaneous</p>\n<p>because if it had totally one sled we probably wouldn't have had this focus and we wouldn't have been able to rule out really simple basic things. But the fact that it was an approximately simultaneous failure of every machine in this class of machines in Iraq was a big wakeup call of like it's either a bad packet on the network or it's power supply issue or it's something something across all of them. And what it actually turned out to be is just the fact that a lot of our management traffic is</p>\n<p>multiccast. A lot of our access patterns over the management network to these compute sleds are uniform, which means if they all start up at about the same time, their packet counters have about the same value. >> And in fact, we did the math on this afterwards where we were seeing, you know, somewhere between 100 and 150 packets per second multiplied by 188 days. This is a case where it actually does line up with the nice round power of two. So that was another confidence builder that this was the right</p>\n<p>diagnosis, >> right? There was just a conversion that we had to discover to convert between seconds and number of packets sent. And then it's a nice power of two. >> Yeah, that that is absolutely wild. And I mean this is one of those and I feel we've had this you know many many many times where you've got these symptoms there's like there's somehow we are</p>\n<p><strong>[51:21]</strong></p>\n<p>going to explain these symptoms and the the simultaneity is like god there's something that's going to explain that um you know what could it possibly be and I mean cliff I don't I mean I thought this was very surprising I mean ultimately I mean of course it makes complete sense but it was also not I mean we we really got there from Gdonkan experiment and then careful reading of the data sheet, not thinking like, oh, there's probably some network encounter that's that's interrupting in incessantly somewhere. Um, I mean, it's uh it it was I don't know, maybe you were you were less surprised, but I</p>\n<p>thought it was it was definitely surprising. >> I was honestly mostly focused on the fact one that originally missed the existence of this interrupt when I was writing the Ethernet driver. So, you know, it's sort of a bug I created several years ago without realizing it. Well, they're all I mean, are they all? But I also feel that like it's um and this is where we because we have not used the uh the kind of vendor source code for this stuff. We don't use the embedded house. We we have gone our own way which does require us to own this</p>\n<p>stuff at a deeper level. Um >> but I I don't know it. Yeah, >> one of the things I suggested in chat when I was sort of self-posting this was the it probably makes sense for us to periodically go take a look at the other open source drivers for our peripherals because for a bunch of technical reasons we can't use the vendor drivers. We can't use net hell or most of the Rust ecosystem drivers. And it's simply that they generally don't assume they're</p>\n<p>running on a protected mode operating system. They don't assume that their interrupts go through an IPC system. They don't there's a bunch of assumptions they make that are valid for 99% of users but are not valid for us. So in the absence of being able to just share the bug fixes, we need some kind of communication channel to make sure we at least hear about them. Yeah. Um you and how Yeah. Uh so there's a question in the chat. Have we notified ST that the docs are wrong? Um no. We</p>\n<p>probably should do that. Um, ST's been it's pretty I mean again pretty as these things go pretty receptive. I view ST as kind of a model for for pretty good transparency here and and in generally pretty good documentation. I mean I know that it's uh in this case it was misleading >> or wrong. >> So the the answer here is a little complicated because ST to their credit tends to release very comprehensive docs on their microcontrollers. They also never update them. Uh unless I</p>\n<p>don't know I don't know what you have to do to get them to update them. They will release erata sheets that explain that oh by that way that feature we're still advertising isn't implemented. But um what they won't do is a release an erata sheet for a thing that just kind of sounds misleading. So it's it's actually not clear that ST has a policy that would result in this</p>\n<p><strong>[54:23]</strong></p>\n<p>getting changed. Um they've this has been reported to them by I I posted this on Masttodon and several people reached out saying like, \"Oh yeah, that bug. Yeah, man. I remember that bug. [laughter] >> That sucked.\" And uh they all reached out to ST. ST is aware, but like ST's position is, \"Hey man, we described this in the manual and like yeah, maybe you don't find the pros as accessible as you'd like, but it's not a bug per se and you know, you do keep buying our chips.\" So, um, so I'm I'm maybe a little, uh, cynical there, but I I don't</p>\n<p>think that there's an obvious pathway to getting the manual updated. What we can do, though, is publish this in as many forms as we can, which is part of why I took a bunch of the notes and wrote up that public hubris GitHub issue in addition to >> Yeah. And and if anyone wants to point us to other podcast episodes from other companies talking about their firmware bugs, we will gladly listen to absolutely all of them to make sure that we uh because I I do think that this stuff is uh extremely valuable information to to to share. Um, and I think it it also just underscores the</p>\n<p>importance of having open source having because in a in a closed proprietary world and we do work with vendors where like all of the source the where the documentation is proprietary um and so it makes it a lot harder to find problems like this or to go validate them. So the transparency here is is a win and is helpful um just not totally sufficient in this case. Um, well, this is uh this is awesome.</p>\n<p>Actually, I do love the fact that we were [laughter] we were talking about this. Megan was asking this morning, he's like, \"Do we need to like should we like issue a patch for a previous release on this?\" Like, well, no, because we're going to we're know that it actually is going to take a while to hit this. So, um, by the time they hit this, they're going to we'll we'll have them updated to the most recent version. So, uh, it's actually very helpful to this. >> Sorry. Go ahead.</p>\n<p>>> Yeah. If a customer doesn't want to upgrade for another half a year, then we may want to push out a patch, but we don't think anybody's really, you know, insisting on that. So, >> yeah. Yeah. >> Um, and and then the uh the mystery of Sled 23, which is what kind of caused all this, that's going to be a future podcast episode, so you know, stay tuned. We don't have, you know, we've been we we've we've been on a bender recently of of oversharing uh fascinating bugs, but we just seem to be hitting more and more content</p>\n<p>generation. Um well, this is great. I Cliff, again, extraordinary work on this. um when uh and because for all I mean this uh I'm I'm not sure if you were there was some hidden work here, but you actually debugged this remarkably quickly once you hit the data sheet. Um felt like you</p>\n<p><strong>[57:23]</strong></p>\n<p>was >> I mean it took a few hours of of concerted work, but I just I want to emphasize that like I was just knocking the pens down that Matt and Laura and Will and the other people that were working on this before I got there had set up. And uh well you once again I think this has been a theme on these other bugs too. We got the kind of the baton being passed. So uh everyone taking their turn with the baton. Um and uh this was this was another good one. Um and really terrific work. Very exciting to get this this fix in. Um I Adam I for one would</p>\n<p>like slightly less content generation even though this [laughter] is is terrific content. Like we can we can ease up. I feel like, you know, we if the gods are listening, you know, um >> on one hand, debilitating bug, on the other hand, podcast episode solved. But, uh solved, >> but we're we're going to be off for a couple of weeks, so we can just uh pause on some of the debilitating bugs. >> We can we we can pause on some of those. So, we uh and actually speaking of upcoming weeks, so we've got we're I'm</p>\n<p>out next week. Uh but then the week after is going to be our last episode of the year. So, um that's wrap-up time. We're gonna do our our our wrap-up episode. So, that's going to be uh that's gonna be exciting. >> Yeah. >> Um we which means we will be doing a title and image review. So, [laughter] just one that's right. >> Um you know, not too much pressure on anybody. Um but >> I assume that episode's just going to be chime sounds the whole time. [laughter]</p>\n<p>>> Yeah. You know, you know, so that is actually a bit of an over question. Like I feel like it is an act of cruelty to have it just uh non-stop chimes, but yeah, it will be a lot of chimes, I think. Or maybe maybe no chimes. >> Maybe it'll get them all in at the beginning or something. >> Exactly. We're not actually we don't actually hate the listener even though sometimes our audio behavior is in is >> No, no, it's a much more complicated ambivalence. [laughter] Yes, >> it's a much more complicated relationship. >> Exactly. Well, again, uh, terrific work, uh, Will, Matt, and Cliff, and and I</p>\n<p>said other folks that have worked on this problem and Robert and others, but, um, really Justin, uh, a lot of great work all around. And, uh, uh, fun to have another podcast episode, but we don't need to have any more world gods, you can actually, it's okay. Things can actually work now. Um, now that we've deal between between future lock and our data corruption episode and I also like to see we kind of like hit on all like why am I about to say this? Why am I like literally tempting the gods with the other um Yeah, I'm just going to shut up now. We know the gods</p>\n<p>are listeners. So, >> were you about to say like we never seen a bug in this sub? >> No, no, no, I wasn't. I wasn't. I sure wasn't. So, awesome. Well, uh, Cliff, thank you very much especially for joining us and great work debugging this. Um and uh we'll get get the word out there for other folks that may have this part. Um and let us know if if there are other issues that we should be aware of. Please let us know. So thanks</p>\n<p><strong>[60:26]</strong></p>\n<p>everybody and uh we will see you next time. So in two weeks um and uh bring some of your your year highlights. We'll be doing our year wrap-up. See you next time.</p>", "cleanup_applied": false, "cleanup_reason": "legacy_or_disabled"}