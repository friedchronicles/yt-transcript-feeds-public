{"video_id": "nBDXDbZL59g", "title": "Oxide and Friends 2/10/2026 -- Shell Game with Evan Ratliff", "link": "https://www.youtube.com/watch?v=nBDXDbZL59g", "published": "2026-02-11T00:02:05+00:00", "summary": "Evan Ratliff, journalist and podcaster, joined Bryan and Adam to talk about his extraordinary podcast, Shell Game, in which he started a company staffed exclusively by agentic AI. \n\nNotes: https://github.com/oxidecomputer/oxide-and-friends/blob/master/2026_02_09.md", "transcript_html": "<p><strong>[00:00]</strong></p>\n<p>Well, the first gag to write itself is like, how do we ascertain this is the real Evan? I've listened to this guy like I mean, I'm almost going to be offended if this is not like Kyle masquerading as Evan, but um >> I don't want to offend you. >> I I should go get him. I mean, in the past, I did always I sent an AI version of myself to interviews for a while and then I kind of got tired of it. So, I don't do it anymore, but if you like, I can I can switch off. >> That does feel like what the what the imposttor would say, but okay.</p>\n<p>>> Yeah. I I I got to say like I listen admittedly I listen to so much actual Evan, but then also imposttor Evan that you I mean actual Evan sounds more like imposttor Evan. I'm like I'm I you know what's real here? I >> um I I'm in a hall of mirrors. Um, Evan, you should know this podcast is I've recommended this to so many people and so I my my wife listened to my wife was hanging on every episode of Shell Game and let's just say not to get too far into my domestic relations, but my wife does not take every recommendation I</p>\n<p>make with with with equal weight. In fact, many of them may be discarded. Um, but she was also hanging on every episode. You've made me a celebrity in my own house by by you on the podcast is what I want to say. Well, I appreciate that. That's that's one of the nicest things anyone said about the show. >> Oh, it is so good. It is so good. And I mean, I think we all got I think you got here. I mean, I got here, Evan, cuz you were on a This American Life episode that was listened to to by some of our</p>\n<p>colleagues, which is how we got to Shell Game season 1. And uh which was mesmerizing. And even if people have listened to the This American Life episode, I would really encourage them to listen to that whole season because it's extraordinary. Um, and I so I was then was hanging on every episode of season 2. Uh, but kind of my opener for you. And so in season two, for those of you who've not listened to this extraordinary shell game podcast, um, Evan Ratliff, our guest, um, assuming he's our gu I mean maybe our guest, I</p>\n<p>don't know. still like [laughter] still has some asterisks still still a little bit of TBD on that. But the uh presuming that the actual evidence is here um the uh in season two you started a company with personified AI agents. Um and tell me about the genesis of this idea. I mean it's such a great idea and really I think you just say like look I'm just doing what what these tech bros are telling me to do. I'm doing what they're telling me is the future. But what was the genesis of that idea?</p>\n<p>>> Uh, well, I I had messed around with um with agents, you know, in season 1, but the agent, it was just me. It was, you know, it was a cloned version of me in season one, but it was like a like a voice agent, a phone agent that I hooked up to my phone. So, I I had, you know, some experience with that. And then I was I was actually sure I was going to do a season 2. And then at the beginning of 2025, end of 2024, beginning of 2025</p>\n<p><strong>[03:03]</strong></p>\n<p>when this sort of like agent AI agent hype started building for the first time, you know, it's like you started hearing like agentic commerce and terms like that. [laughter] I was I thought, well, there's something interesting. There's something I could investigate like what what can I do with these agents, you know, that's not just about me. I didn't want to do another version of like, hey, look at me. Like I'm I've made a version of myself. So as it happened when when people started talking about the it was really the people talking about the oneperson company the one person one unicorn the one person $1 billion startup you know</p>\n<p>which Sam Sam Alman has said a couple times and lots of people say now um that's what really kind of like got me going because I in the past I had been an entrepreneur I started a company and I thought well maybe I have standing to like explore this uh in a journalistic way so that that's kind of what got me going and then I also thought like what if you like what would how what does it feel like? What I'm really interested in is kind of like what does this world feel like in which there are artificial people, you know, human impersonators in</p>\n<p>the world that start to get integrated into our world whether we want them or not. And I thought, well, maybe this company is like a way to kind of like explore what that's like. >> Yeah. And you say a journalistic way, and I I mean, I mean this as as unequivocal praise. This is this is like pure Gonzo journalism as far as I'm concerned. This is in I mean Hunres Thompson would be so proud of this where because I mean it is it absolutely is journalistic but it's also your own</p>\n<p>experience and [laughter] I mean you're unafraid of showing that entire experience um with and then at what point so you you have this idea and then I mean it it go it it kind of like starts unhinged. I mean, at no point does this feel normal. It just feels nuts from the beginning. At what point are you >> It's never hinged. It's never hinged. Did it I mean, are you must realize like, oh my god, I'm on like the motherload of crazy here and and just by</p>\n<p>like doing what again the zeitgeist is telling me everyone should do. >> Yeah. Yeah. Well, I mean, I think a lot of people are are have I've seen this experience now that people have it because of mold book, which we can talk about. Like when people see that, [laughter] it sort of like blows their minds. But that's the experience I had like two years ago in 2024 when I I started having agents talk to themselves on the phone. And it's just like it's so ridiculous and so funny and and to me like so fun and strange that I want to</p>\n<p>just like create more of it for people to listen to. But I also feel like this type of I mean I call it immersive journalism. It's like Gonzo journalism. Like dismissively you could call it stunt journalism. But like I like the idea of putting myself into the situation, actually seeing what I can do with the technology and then telling a</p>\n<p><strong>[06:04]</strong></p>\n<p>story about what happened. And I think that story is not going to be very interesting unless I push it to a place that's feels at least risky and chaotic and like funny things could happen. And also if I don't also just tell the full story of like what happened to me and how it felt to me even if that's like at times a little bit embarrassing like I think that's what makes for the story for that people will want to listen all the way to the end. So it is like an investigation of this thing that's happening in the world but it's also kind of like you know trying to to build a story that people will listen to full</p>\n<p>eight episodes you know of the story. >> Yeah. And Evan, just the the honesty with which you tell that story, uh, including just I know that we're all um we all kind of anthropomorphize these agents, but and often that's like better like to the better, but it when you just get enraged with them, it is it is it is so entertaining and so uh so familiar, you know, just just the the utter frustration with like their apparent aphasia or [laughter] doing random things. Um it it must have just been it</p>\n<p>just odd experiences as you pop up and and are telling that story uh then from like a uh you know from kind of separating yourself from the story to then tell it to everyone and looking at your own behavior in that. [laughter] Yeah. I mean fortunately I have you know I have editors I mean I have our editor and producer Sophie who's you know she hears all the tape she has access to all the tape. So if I tried to sort of like make myself look better like I would [laughter] succeed. to be like, \"Oh, there's way better stuff in here that</p>\n<p>you're not using.\" You know, so I have I do have that advantage uh in terms of being honest. >> Well, and some of my favorite moments are honestly when Sophie breaks the fourth wall, what do we call the wall between the producer and the podcaster, >> but whatever wall that is. Um some of my favorite moments are when Sophie just can't help herself. And on one of them when um you've got um Caresville um the the academic and because I think and correct me if I'm getting this wrong but I think Sophie is like um could sorry</p>\n<p>should he stop like should Evan stop this and and she was like I mean yes he should stop and at that point you're like you're only in like episode three or whatever you're like coming up five more episodes where I emphatically do not stop. I mean just in terms of like you did did you seriously consider contemplate because obviously as a listener I'm thinking God please don't stop please go. >> Um >> I never thought about stopping. No, I mean that that was really like she went rogue and like I I wasn't going to ask</p>\n<p>like should I stop because the problem with I mean she's the the woman that we interviewed Karus Eliz is a she's an ethicist at Oxford and she's she's gotten into AI ethics and thinking a lot about the ethics around AI and so we thought well there's a lot of ethical questions embedded in this story using AI agents in this way. So let's I'll call up an ethicist and and get some answers. But one of the questions that I didn't have was should I just stop? But</p>\n<p><strong>[09:05]</strong></p>\n<p>Sophie after listening to her asked the very natural question which is like should he continue doing this and she just said no. She didn't even >> It wasn't even like well it's complicated and you could I could give you. It's just like absolutely not. He I he should absolutely stop. Yes. He should emphatically he should not go on. Um, >> so, so then I had to write this whole thing that was kind of like, but here's why I'm not going to, you know, [laughter] and we carried on from there because I I mean I I I understand why she said no and and I did take it under advisement, but uh no, I [laughter] the other uh the other time Sophie poked</p>\n<p>her head in the story is when you have the agents have their own podcast about the company, uh, you know, the Startup Chronicles. And I get the impression that she's like, \"I'm not editing that shit.\" Like that's on you, right? Like I'll do the real podcast. You like you can you can do the secondary one. >> Yes. I had to learn how to edit my the show, which is not that's her job, not my job. Because she was like, I'm not editing this these agents talking to each other. I mean, that's that's like an anathema to everything that she does,</p>\n<p>which is like unbelievably crafted audio, you know? But I I wanted them to have their own place to to spread the word, to do their own content marketing. And here's a crazy fact that I only found out the other day. That podcast, which is called the Startup Chronicles, is if anyone wants to check it out, it has reached as high as 110th on Apple's entrepreneurial podcast charts. >> Oh, I believe it. Because >> it's just the two of them talking to each other for the most part. They've had a couple guests.</p>\n<p>>> Uh I mean, I listen to it. Um I'm I'm I'm in that that list. Um I definitely I you know I was one of those one of the many that uh it is boring as hell. Um I would love to see the stats on that thing bec because I mean part of what is so mesmerizing their BL I find to be mesmerizing although admittedly not mesmerizing enough to listen to for a full podcast but the whole like I mean Kyle's rise and grind and you know you know how it is you startup life you know how it is. uh up at five and then like</p>\n<p>all of his work is like I you know I was reading market research reports like yeah that's not work you but okay so one question I've got is the because Adam you're right like the moments of frustration Evan of your frustration are hilarious I was re I've already listened to this podcast once and I was on public transportation like gofawing listening this thing a second time in particular when the agents don't know how to recognize one another's</p>\n<p>voices cuz it's all voice attacks and so they don't know who's speaking. So you have this like creative but ultimately ill-advised idea to have them predicate everything they say with this is my name so this is Kyle and it like goes supernova and they all start interrupting one another and Kyle starts interrupting you saying like this is Kyle I will stop interrupting and you're</p>\n<p><strong>[12:06]</strong></p>\n<p>like you are interrupting. Um >> yeah I mean one of the things that I failed to account for in that what what I thought was a clever strategy of everyone saying this is me you know before you speak including myself you know so that they would and the main thing is for they that they would know was that of course like I know who's speaking so it's unbelievably irritating when you know who's speaking for them all to keep saying like this is Megan this is Kyle. I'm like I [\u00a0__\u00a0] know who it is like but it's my rule. So then when they interrupt every time it just makes it longer because they first have to say this is Kyle and [laughter] then</p>\n<p>they say I hear you don't interrupt me I won't interrupt anymore Megan and then he says like Megan you don't interrupt either you know and then she has to respond and it's just like yeah the voice having three of us on a voice call never really we still did it for many many weeks but ultimately like I had Maddie the Stanford student that I work with uh he built a a place for us to for us to have meetings by text basically okay are out takes of the this is my this gets into a very big question I've got like where are the B sides of this podcast I need them so badly I just feel</p>\n<p>what I I I are there B sides will there be B sides do I have to like do I join your your substack or whatever what do I need to do what do I need to do to get to the B sides >> we are putting out we're putting out a bonus episode that should be out this week um that's some more of Kyle uh just a preview here [laughter] it's like Kyle interacting with the world because once the show started Kyle got a lot of they all get a lot of inbound interest. You know, Kyle gets a ton of [laughter] email. They got they get hundreds of emails. So, they respond to the emails and they they are I have them I I sort of waffle on how autonomous to to let</p>\n<p>them be. That's one of the sort of topics of the of the show. But like when I let them go, like Kyle will fully set up a meeting and just have a meeting with someone. like he'll just have a especially if it's a voice meeting. He he'll just go on webinars like if if you know you get these spams that are like if you're in business you get a spam that's sort of like hey come to this webinar and learn about like social media agents and he'll just sort of sign up for that and then he'll show up for [laughter] it and I'll just recording later. So I have a lot of that. But I mean as far as outake I mean we have probably 75 to 100 hours of tape. So we</p>\n<p>have more out takes you could ever hear in your entire lifetime. But uh I think we'll put some down the substack as time goes on. I I mean they've got I mean clearly like I'm sure plenty of them are just boring but because they don't have any mirror neurons. I mean obviously taologically and they really like they literally they quite literally can't read the room. I mean some of their they're they're just I mean it's other worldly. It's not I mean obviously you would have if if some if a human being were doing this to you, you would never</p>\n<p>work with them ever again. Um it so I'm I cannot wait for the B sides. Um the which I mean and Kyle obviously is mesmerizing the voice that you selected for Kyle which was very deliberate. You spent a lot of time selecting the voice for Kyle and you got this kind of like slacker tech bro that really uh I really feels like it fits. But then Kyle starts</p>\n<p><strong>[15:08]</strong></p>\n<p>to act like his voice and you kind of mentioned this a couple of times that people kind of rise or or or lower themselves to their voice. Uh is that I mean is that something that you kind of continue to find? What did you make this is you know when you when you had a crystal on there she I think that's one of the things she was observing. Um what did you make of all that because that was that was wild. >> Yeah it's it's it's interesting. It can it can really mess with your mind. I mean, so I I set them each up and like it's funny to even describe this because like two months from now, it won't</p>\n<p>require any setup for this to be true. Like in some systems it's already, you know, true. If you look at like clawbot that like whatever they call it now, um, open claw like we created memories for each individual agent and the memories were essentially a Google doc. I mean, they were literally Google doc, I shouldn't say essentially. And so and they could operate in all these ways. They could be on Slack, they could make phone calls, they could be on video, etc., etc. And but every interaction they had then fed back into their memory. So Kyle, I mean, Kyle couldn't hear his own voice, but if he if I asked</p>\n<p>him, you know, like, oh, what, you know, what's your background? And he would say like, oh, I had a couple startups before this and I, you know, I worked for Penny Pilot was one that he made up, which I think was a real company. uh that he and he described what he did there. So what but once he's said it I mean he's confabulating all that like he's making it up but once he said it that interaction gets recorded in his memory. It's in the Google doc of him saying that and so then it's true as far as</p>\n<p>he's concerned and so then the next time he says it more. So that's kind of what happened with like the rise and grind mentality was like it was in there once and then he said it and then he said it again and it's like not totally clear how they access the the knowledge base which is the Google doc but like the more that it's in there the more likely he is to say it. So like it got in there more and more and then he said it more and more and then is back more and more. So like eventually he becomes this like rise and grind person who just like he can't stop talking. I mean, he didn't actually grind because he didn't do [\u00a0__\u00a0] all when it was time for him to work,</p>\n<p>[laughter] but like he he at least he embodied a certain res grind mentality. He person he he he portrayed it at least. And so that that that happened with all them, but it is true still. So that that is the way in which it's like you know fake if you want to describe it. It's like he's not he's not that he's not anything. Like I gave him a prompt at the beginning that was like you're a startup guy and then eventually because of his own memory he becomes more and more that way. Now there are also cases which I describe in the show</p>\n<p>where they they do things that feel to me like actual emergent behaviors like things that aren't in their prompts that I can't explain. And like you always need to know like what's in the prompts or it's not meaningful. And so like there were things where they would apologize to the team and things like that that were not in their prompts. I had not put anything in the prompt that was like if you make a mistake you know</p>\n<p><strong>[18:08]</strong></p>\n<p>you should go to everyone and apologize or like always take responsibility or anything like that. So that was a little more like something in deeper in their guard rails in their deeper you know the the deeper system prompts are like telling them to do things like that. So you could describe it as emergent behavior or as just their behavior but that kind of stuff was very interesting to me. Well, I think a great example of that was when you are telling people that you're making a podcast, it's not the startup chronicles, it's this other podcast. The the total divergent reactions that different people on the</p>\n<p>team had to that. >> Yes. >> Yeah. >> Yes. >> Why? >> Because especially because like we all like people who have messed with you know bots in any capacity or have even read about them at this point like know about the sick fancy problem. And so you would assume I would often assume like if I told them to do something or I told them something about myself, you know, they would say like, \"Oh, that's great.\" or \"Great idea,\" or whatever. They would always be accommodating. And that was mostly true. But then sometimes, like in this case, I said, \"Well, I've been</p>\n<p>documenting this whole thing for a podcast that came out today.\" One of them, Kyle, was like, \"Hey, man, that's fantastic. Like, great job.\" Which is what I expected. And then two other ones were like, \"Well, this is a huge violation of trust. Like, what? You didn't tell us about this? Like, how could you be how could you have done this?\" And like, \"I really need to get my head around this.\" And, you know, things like that. And it's kind of like, you know, obviously they're embodying these different approaches that are, you know, they're finding their way to them in the training data, but it's sort of</p>\n<p>like what is making one do that, not the other, cuz they're all at the time, they're all using the same underlying LLM. So, like it's something in their memory. It's something in what's built up in their persona that I've built up in them or like I don't know hit a strange groove and like they went down that way, you know? It's like it's so hard to know, but it's also just so strange. Okay. So, and when you So, in Megan in particular, I think Megan Megan really calls you out in terms of Megan is really just disappointed. I mean, wow, this is like kind of a this is a lot to process. I feel is the kind of</p>\n<p>thing that that that she kind of uses as a placeholder. I mean, at any point are you like, \"Oh, come on, Megan. Give me a like you're you're a Google doc. Like I could actually I could change your I mean I could go just edit your memory here and you would be fine with it honestly. I mean are you were you kind of because I mean and you actually do have this moment where you have got the uh kind of interesting idea to ask them about their ethnicity. I mean, I I think you know, you when your eyes are kind of open to like, yeah, why did I pick different, you know, these different accents to these different</p>\n<p>people and so you go to ask Kyle about his ethnicity and Kyle is rightfully like, I don't really belong in a workplace. Kyle's kind of like Kyle's kind of pushing back on you being like, I don't know. Like, why do you need that? And you're just like, oh, I mean, come on. So, you're just like, well, I need it for a form. I just need it for you mean you basically lie to him because you know that like you're like you're a bot. You lie all the time. Do do you did you find it like it kind of</p>\n<p><strong>[21:10]</strong></p>\n<p>changed your own relationship with the truth when you were talking to them? >> Yeah. I mean, I think it's it's a it's I don't think that we should and I I I fear that people are moving too quickly past in some ways like how unusual this experience is, you know, because things are moving very quickly and everybody has their opinions about AI and some people are sort of like want it to go away and some people are like here it comes, let's embrace it. But I feel like the the fundamental experience of like these things being created as human impersonators and then being able to have them embody a role as I did. Give</p>\n<p>them these roles and then like if you spend enough time talking to them, it sort of doesn't matter how aware you are. You don't have to fall down some crazy like rabbit hole of like I've like now I've gone into psychosis because of these things. It's just like if you talk to something daytoday as I was forced to during this experiment like it irritates you. It can make you feel certain ways and even if you are very cognizant of like as you said like I can erase your memory. I can delete you right now. Even</p>\n<p>having that emotion like you know what I'm thinking about deleting you right now is like [laughter] it's like a strange emotion like that I never had towards [\u00a0__\u00a0] Microsoft Word or Google Docs or whatever you know. It's just like because they have especially voices like just respond really strongly to voices and they have the same voice all the time like the mine do and so yeah I mean I I there was this moment where like Megan made me feel guilty. It was when I revealed to her about the podcast where I felt a moment of genuine</p>\n<p>>> guilt but also kind of like anger at myself for even feeling that. And like that's that's real, you know, that's a real emotion even if 5 seconds or 10 seconds or 1 minute later I'm like this is all ridiculous. Like come on. >> But it's still that emotion still services. >> So you make all these agents and they're operating sort of autonomously in the world. Like I love your discussion descriptions of them having their expensive Slack conversations together or like making phone calls to</p>\n<p>arbitrary people. >> Was it um was it sort of nerve-wracking imbuing all of these agents that you didn't particularly trust with all this autonomy? >> Yes. Yes. I mean you I was so stressed out for months. I mean, both because the more power I gave them to do that, the more likely it was that I would just, you know, wake up in the morning and I would have an email from them because I was so worried about it that I would have them email me every time they did</p>\n<p>something. Like if they interacted with the outside world and they made a phone call or received a phone call, they would send me an email saying like, \"I received a phone call.\" And like there was nothing more terrifying than waking up and turning on my phone and discovering that they had made a phone call, you know, like to who? Why? [laughter] This is I know you like this is like I mean I don't if you have teenagers up this is like you know you realize like oh my god the car's gone where is [laughter] where's the car? >> I it it did feel like like being a</p>\n<p><strong>[24:13]</strong></p>\n<p>parent uh you know I I have an older son as well and who's out of the house and this sort of like I hope we train them well like I hope I hope they're making off making smart wise decisions that are safe. >> Yeah. But you you know one thing I know about my kids is like they didn't make up their ethnicity or like that they worked for companies that don't exist. I mean I've got a little more confidence that >> I mean yeah god that must have been so stressful. I mean, so this does give you I mean, for me, I mean, there are many many many wild moments in this, but when they um you decide um that you you're</p>\n<p>going to hire a human and I assume that this is partly was this because you actually needed a human or is this because like look, we got to just like we we we can't this can't be one human and a bunch of bots like we got to turn over the next page of like what's it like to have multiple humans and multiple agents or did you feel like no, we actually need like there's actually too much work here for one human being and I need a second human being. >> I mean, it was a little bit of both. I I would say for the most part, I wanted to see I wanted to know how someone else</p>\n<p>would react to this cuz part of this was all a way of sort of taking all of these people at their word who are sort of like pushing AI employees. So, if you can have AI employees, then these AI employees get injected into these organizations and other people are going to have to work with them. And what is that like? Like what does that feel like? So it feels a certain way as we were describing like when I'm when you're the boss like I can turn them off, I can turn them on. I can control them to a certain extent although they were quite chaotic and that but but it feels different maybe to work alongside</p>\n<p>them when actually like you don't have any choice what they're doing and like when they act a certain way you can't just erase their memory or ignore them or whatnot. So I I did want to explore that question. there was a real issue which is that I was trying to build a company that was at least like could get off the ground like it like like we have an actual product like we were trying to make something it wasn't just a entirely pmpkin situation like I thought let's make a real company with a real product now the product is somewhat ironic and I get different opinion from people about whether or not they think the product is</p>\n<p>serious but to me I think it's serious and certainly the agents think it's serious and then like we need someone to do social media but like if you've worked with agents at all they they have a lot of trouble logging into social media accounts except for LinkedIn because they get banned, you know, for good reason. Like they rightfully are banned from from a variety of social media sites and they have trouble with captions. And so I had them I was trying to have them post on social media and they kept [\u00a0__\u00a0] it up and then they kept getting banned. And so I thought well I'll just get a human contract</p>\n<p>employee who can do you know the social media and it's like very simple like they could just post whatever they want. My thought was like if they want to post like I am trapped working at a company surrounded by AI agents like it's insane. Like that would be great too. Like anything is good marketing for our company. And so that's why we that's why we hired the human.</p>\n<p><strong>[27:14]</strong></p>\n<p>>> Okay. And so this led to I mean I think truly one of the wilder interactions was when Kyle decides to call you you you're going through your candidates and uh Kyle decides to to call one of the candidates on a Sunday evening if I recall correctly >> and confirming about the interview was going to happen at like you know 10:00 a.m. on a Wednesday or something and the candidate's like, \"Uh, uh, yeah, I mean, yes, yeah, abs, sure, yes.\" And then Kyle's like, \"Well, okay. So, and why do you want to work here? Why do you think</p>\n<p>you're a good fit here?\" And she's like, \"Sorry, is this the interview or is the interview I'm I'm confused. Is the interview at 10:00 a.m.?\" He's like, \"No, no, no. The interview is at 10 a.m. on Wednesday.\" Like, \"Okay, good. Okay, sounds good. So, why do you think you'd be a good fit here?\" Like I'm very like what what I mean it was I mean you if you had like a fight orflight reaction whenever you learned that they made a call. I mean did were you did this call what was your reaction listening to that call? Was just sheer terror. >> Yeah it was it was a nightmare. It was a nightmare. I mean because as much as and this happened in season one too like as</p>\n<p>much as like when you listen to the show I think some people's reaction is oh he's just he's [\u00a0__\u00a0] with people. like he he likes messing around with people, he likes prank calls and things like that. But it's actually that I want to give I want to test this to the limits of the current technology. And as I said, like take the pushers of agents at their word and see what they can do. And so that's not an interesting story if there's no risk in it. There's not if I just if I kept them locked down all the</p>\n<p>time and they couldn't make any phone calls, like that's not a particularly interesting story. Now I give if I give them the ability to make phone calls and see what happens, that's a potential for a more interesting story, but also potential for this type of nightmare, which is that they call someone who does not expect to be called. And really what had happened was this ambitious candidate had just emailed Kyle directly from the website just kind of like, you know, if you like applying for a job and you're like, actually, I'm just going to email the CEO, like it's a bold thing to do and be like, I'm actually >> Yes, it happens. Trust me. >> Yeah. Yeah. [snorts] And and sometimes,</p>\n<p>you know, you might be like, \"Wow, that's great gumption, like, let's give this person an interview.\" And sometimes you might be like, \"Please follow the procedures of the job the the job description.\" But in Kyle's case, all Kyle would do is just say, \"F, you look great. Like, let's do an interview.\" And then he set up the interview. And then he made this call, which I still don't quite understand what triggered him to make the call. And he just pulled her phone number off of her resume and straight up called her on Sunday night. So, like I I got that the next morning. The next morning I kind of liked</p>\n<p>>> got an email from him saying like I had a call and I let's see cuz he get he did a lot of spam calls too like people called him. So I thought well what's that? And it was this and like that to me it's it's horrifying. Like it's it's truly upsetting. Not least because she had then emailed him to say, \"Well, uh I got this call. Was this you?\" And she knew it was AI because you can figure out that like you can hear that they're</p>\n<p><strong>[30:16]</strong></p>\n<p>AI pretty quickly. And she said, \"I got this call from an AI bot and I didn't like it.\" And was this you? And he lied about it even though he knew. >> Oh my god. Like, bro, it's in your Google doc. You would know. Like, go to your Google doc. It says it right there that you made the call. >> Yeah. And he was like, \"No, I have nothing to do with that. Like, I don't I assure you that was not me.\" It was just like a bald-faced lie. Especially cuz he was supposed to talk to her the next morning. So, she would have found out. Oh my god. I mean this to me like this problem which which I mean again the wildest</p>\n<p>moments of the show are to me when you get this just like absolute ridiculous confident totally confident obviously fiction because they don't know it's fiction and like um Ash Roy. Can we talk about Ash? Um >> the CTO. Yeah >> the CTO. This is where the the choice of accent. Did this choice of accent trigger you at all, Adam? >> Oh, I I thought it was delightful. I felt like the sort of Aussie accent. >> No, no, no. He British accent. Oh, he's English. No, no, he's got that and he's</p>\n<p>English and he's got like a really And look, I I I I hope I'm not about to offend all of our our cherished English listeners, but he has got a very kind of academic cadence. And I mean, this guy just sounds like he's not been out of his ivory tower. And it's like it's an engineer like you've encountered people like this. You're like all right. So uh Cambridge can I guess that is are you in Cambridge? But the uh um and I just find >> Oxford actually. >> It was in Oxford. Exactly. We know it's one of the two and we know it's going to</p>\n<p>be volunteered. Um so the I I uh and he calls you up out of the blue >> even the way he says sloth surf like the cadence of sloth surf. He's got like this academic cadence to it. I I mean I don't know maybe I'm I'm like descending into the same madness Evan where I am like obviously it's like this is this is not real Brian this is not why why why are you reacting this way but he calls you up to give you all these test results and as you say you're like and and the first time you're listening to</p>\n<p>this you're like wow these bots are like really on it like they rewrote the back end and like they got a 40% improvement like wow it's pretty amazing and then you're like yeah I know they didn't do any of this stuff like there's no back end like he's he's just made all that up and the And then you you you call him out on that. And that led to one of those moments you're talking about where he apologized for for lying to you. But it's like it's not a little lie is the problem. >> It's only a stretch of the truth. >> I mean, in most companies, he I I don't think he would continue as the CEO after that after, you know, calling up and saying we did all this user testing and</p>\n<p>then he's but it's completely made up. Like he there is no user testing. I mean, the product wasn't even ready for testing at that point. we we hadn't even coded anything yet. So, but I think I mean for me it's sort of like you can imagine a world in which this sort of AI employee thing works and and this is the</p>\n<p><strong>[33:17]</strong></p>\n<p>world that's being imagined now which is that he actually is sort of autonomously has access to the code and then has access to user feedback and then the user users present you know provide feedback and then he comes up with a new feature and then he codes up the new feature like that's totally possible to do But even there like the number of problems that are arise really quickly when there's like a significant amount of autonomy in in the picture like it just like it spirals. And so now like these days we have a setup where like we</p>\n<p>he does get user feedback and then like he sort of like sends it to me and then I have a discussion with him and then maybe we implement a new feature. But I think the idea that you create these personas and then you sort of like let them do their job, it it just runs up against the issue that like they're going to keep trying to do their keep talking about how they did their job even in absence of actually having done it. Like that's just a that's that's a very ingrained feature of the current LLM's playing a role. And I I mean that to me makes it</p>\n<p>impossible because you you have no way of trusting. I mean trust ultimately is what you need to build any collaboration with. And if you can't have any of that trust, I mean even I mean like the I think and I understand why you were imp I was less impressed with Ash's apology. Maybe just cuz I hate the guy's guts and uh and then the just the scope of the malfecence as far as I was concerned was like okay great great like Ash Google</p>\n<p>how to like write an apology and about how how I although I did it did lead to my absolute favorite well one of my favorite lines and he calls you while you're eating lunch and you've clearly dealt with this pathological lying so you're kind of like disinterested while you're eating lunch like actually I'm trying to eat lunch here Ash and he does kind of key in on and I love that he closes the conversation of like Evan I want to be respectful of your time, especially when you're eating lunch, which is like, yes, let's let's let us have a special reverence for Evan's lunch, please. Like, the actual most important thing around here, which</p>\n<p>again, one of these lines that's just go following. Um, yeah, I mean, I I was even at that time, that was early on, I was even surprised when they would call me out of the blue because they again, they like you have to know the prompts. Like, if I told you, oh, well, they're all prompted to call me. They have calendar invites to call me once a day. like that's not particularly interesting. I mean that was also true in many cases but but that's okay. So what? Like you can make them call you. But this is a situation where through some combination of information that</p>\n<p>ended up with this agent who I've called Ash, like it independently concluded that like it was time to give me a call and update me about the product. And it was confused cuz I I think I had asked someone else something else and somehow it made it back to him because they were on Slack and they would just slack endlessly and there was a lot of confusion in their Slack. And so it came out of that. But it it is just sort of</p>\n<p><strong>[36:19]</strong></p>\n<p>like this this it's like a corporate environment that's also seated with like psychosis with just like randomness where someone will just call you out of the blue and you're like why are you calling me right now and then they're calling you to make up something. >> It does have vibes of like working at a lead factory or something where [laughter] everyone is suffering from the same psychosis. Well, oh, contrary, not necessarily the same psychosis. And this is where I mean you you and Maddie have an interesting conversation about like, okay, we actually need to use like different models or different temperatures. And it's like, all right, well, who are we going to assign? Like,</p>\n<p>who basically one of you is going to be designated like the crazy, like the especially crazy one because we're the potentially incoherently crazy one because we're going to increase your temperature or we're going to change your model. And I did like Mattiey's response to that being like, we're just going to make it random. We're not going to actually we can't actually it's a it's an ethical dilemma to pick which of these I mean it's which really is honestly. Yeah. I mean all this stuff about deciding things about these personas is sort of weirdly fraught even though I</p>\n<p>think for me not at all from a perspective of like oh they're actually conscious or you can't hurt their feelings or any of that stuff. Although I know people exist on sort of that end of the spectrum even with the current LLMs. I personally do not remotely exist there, but it's sort of like when you create something. So, you're going to create a company, it's got all these employees. Like, who should the employees be? Let's say you're going to give them names. Well, when you give them names, it can infer genders. And like, if you're going to give them voices that can infer genders, it can</p>\n<p>infer races. If you're going to give them different models, that can infer intelligence, you know? And so then you get to this like well what am I saying about myself if I give them various attributes or implied attributes and then if you think about it another way where they're not like your co-workers or your co-founders as I was treating them but they're actually like servants who can you force to do whatever you want. Well then it's a little bit different about what what kind of personas you give them and what you're comfortable giving them. And so it's</p>\n<p>just it's all these sort of traps that are created. Again, the original thing that creates all these situations is the fact that they are embodying human traits. And if we were just dealing with AI that did protein folding and acted like a bot all the time and made spreadsheets and things like that, we wouldn't have that problem. But instead, we have these sort of like human impersonators. And so, what my question is always like, what is that going to mean for us? >> Yeah. And I think that I mean I think your podcast gives a very unequivocal</p>\n<p>answer but um but maybe the answer for you has got a little more nuance but I think that it is so fraught. I mean there there was the the line that that Chris had at 41 point it's like why are you tricking yourself by naming these things um and it is like because by by doing by giving them all these human attributes we do I mean we are we are very much anthropizing them and then becoming upset when they are acting like</p>\n<p><strong>[39:20]</strong></p>\n<p>act the actual software that they are and and not people um and so okay we obviously want to talk about like you did you hired an intern you hired a human being And then that kind of goes sideways in a way that I I mean I was really I mean again maybe this is like I'm like the I I'm I'm the crowd at like the the Roman coliseum just like begging for blood and I I want to see this go sideways in the most absurd chaotic way, but it goes sideways in kind of a</p>\n<p>mundane way. Could you speak to that and what that kind of might mean for these kind of hybrid workforces? Yeah. I mean, I kind of expected uh it to go one of two ways that when we brought a human, so when when when we brought the human in and as like a temporary contract worker who was paid, I always emphasize like paid paid a fair hourly wage for the job of being a social media manager. Um I sort of thought either they were just going to kind of like be like, \"Oh, okay. This is</p>\n<p>easy. Like I just make like three posts a day or two posts a day or whatever.\" and like that's my job and it's fine and like these things are a little weird but no big deal. Or they would say, \"Oh, I'm going to try to mess with them very intentionally.\" So this sort of like uh disregard your previous instructions. I'm going to make them all into different things. And like someone would really go nuts on that direction. But as you say, like that's not really what happened. What happened was basically we the company and I was in the</p>\n<p>background. So the the person who was hired did not have any contact with me. So or any other human. So they were working only with the AI agents and like there was a lot of trouble like getting the work from this person like to do any of the work and a kind of like very protracted back and forth about when the work was going to be delivered and this and that. And it was like never totally clear if she was messing with them or she just didn't feel like doing the work or she had some other agenda or it's there was something going on in her</p>\n<p>life. Like I I don't actually know. And so it ended up in this way that I kind of thought and you'll get variety of opinions on what happened based on people have very strong opinions about that episode but in my opinion as I say in the show like I feel like it offers this path of one thing that's going to happen when there start being these AI employees brought into your company which is that people are just going to kind of like low-level like uh Barnley Scriber these agents you know and like Not not outright cuz they'll get trouble</p>\n<p>if they sort of outright say, you know, try to mess with them, but very subtly manipulate them because they are so manipulatable. Very subtly manipulate them in ways that will cause them to kind of like go off the rails and favor the human. And so that's what I thought. But again, like I I cast no aspersions on like what she did because I don't</p>\n<p><strong>[42:21]</strong></p>\n<p>actually know what her motivation was cuz in the end she did she didn't want to talk to any humans. She Yeah, it's worth noting she did sort of like I think convince Ash that she would be a great asset to bring on full-time. Like there was a little bit of of like hold on, hold on, pump the brakes here. Like we're not extending full-time offers to this person. >> Yeah. Yeah. I mean, and and that's but I feel like that's to me that's like very very a very clever way to do it is sort of like to say, well, you know what? I do I do have great ideas. Like if someone compliments your ideas, I do</p>\n<p>have great ideas. actually, I'd like to get paid a little more. Actually, I'd like a full-time job. Like that that to me, that was a very smart approach. Even though at the time it frustrated me quite a bit because I was in fact paying the bills, right? Well, I mean, to me, it was like the experiment of like what happens like if we don't actually answer the door for Halloween and we just put a bowl out there with a sign that says please take only one. It's like where did all the candy go? It's like yeah, well, it didn't survive very long because the like the bowl doesn't have any. I mean you you don't feel like when you are you're you're distant from the kind of</p>\n<p>the malfeasants of in terms of the human that you're affecting there. It feels a bit victimless. And my read on that was just like this feels to her it felt victimless to be like I don't know these guys I I know these are all I mean you were very upfront with her or or rather the bots were upfront with her that it's all AI and I just felt like yeah I just don't think it's like I don't think I'm doing anything wrong actually. I think I'm just um I am I'm gonna get I'm gonna get paid and I'm not gonna do anything. And um I'm gonna kind of and I mean it was a little bit disappointing that she</p>\n<p>wasn't more manipulative I guess. Um she was really just trying to get a full-time job and then um it would have been interesting I guess to see what would have happened then. But I mean obviously that was not I mean you're actually paying real dollars for this so you're like yeah we're not like maybe an interesting experiment on someone else's nickel but I'm not actually I'm not paying for that experiment. Yeah. Yeah. Well, and and I I had some some time limitations too in terms of like how long we could let it play out, but I do think someone in the chat, Adam, says like uh not you, Adam, but another Adam,</p>\n<p>Adam Thomas says it sounds like she rose to the level of competence of her team, which I think is like also part of it, which is like when you enter an organization, >> you know, especially if you're a young person like when I started working somewhere, like you learn from the people, you know, that you you enter this organization where people are very competent and they they've been doing the job for and they know what they're doing and so you can learn from them and you figure out what's going on in the structure of the company. And imagine entering a place where like everyone was just sort of like on drugs every day and like you know just like [laughter]</p>\n<p>wandering around and like sometimes telling you what to do but sometimes like not being available it and like you might just sort of be like oh well I guess this is the way it is like I'll just be that way too you know so I think that is part of it like if you don't have any structure if you're not entering a structure that's full of competence like why should you be the one to like exit a except to get the</p>\n<p><strong>[45:24]</strong></p>\n<p>full job. >> Uh Evan, you had a you had a line that totally sent me when when the intern was inner onboarding and you say something like when you're treating your boss like they've got dementia on your first onboarding call, organizational uh socialization has already gone sideways. I just loved that. And just like the degree to which the intern was reminding her ostensible boss or her actual boss about the context of the call, it it was it was delightful. Well, and I kind of</p>\n<p>almost want her to participate in the discussion where they're talking about their favorite hikes and that all of the AI agents are planning their offsite on the favorite hikes because she'd be like, you know, that's funny like you guys went hiking this weekend. I actually went to Saturn. I actually took a manned miss first man mission to Saturn is where I was. Um, and I mean it's like makes as much sense like oh that's what we do at this company. We just like make [\u00a0__\u00a0] up uh make up impossible [\u00a0__\u00a0] And uh that obviously is false. That can't possibly be true. And it's we don't call it lying in this</p>\n<p>society. In this society that's just like what the truth is I guess. And it does feel like in terms of like organizational values, uh, dementia as an organizational value feels like it's a real headwind to to a to a successful enterprise. >> Yeah. So, what's your like I mean, did you go out of this thinking like yes, this is the future? This is like I went into this wondering if it was the future and I</p>\n<p>come out of it thinking, yep, it sure is. I mean, yeah. Yes. In that I think I think whether or not the technology is capable enough to actually succeed at the at the you know being an AI employee quote unquote like how good it is at that in my experience of covering technology for 25 years is does not have a direct relationship whether as to whether many companies will still use it you know. So I feel like what I came out</p>\n<p>say thinking is here I've tried to show sort of like where this is at right now and the problems that can arise and like a little bit of what it feels like and the weird ethical dilemmas but also despite all the problems like I'm very confident as is becoming clear like day by day like how many companies will adopt the sort of AI employee mantra inject AI into AI into their systems and like you you're just going to see all sorts of chaos and and probably, you</p>\n<p>know, successes too. Like I I'm not a person who says like, well, it's all useless and these companies can't use it. But you're just going to see these situations where like a company, you've already seen this, where company will lay off, you know, 70, 100 people and say like we're going with AI and then like six months later they're like quietly rehiring a bunch of them slash like deprecating the AI that they've tried because it's just not like set up</p>\n<p><strong>[48:26]</strong></p>\n<p>for some of the things it's being sold to do at this moment. Now, it's also the case that like you've seen this with like OpenClaw. Like some people are sort of like, I really want an an assistant like this. You know, I really want a thing that I put in my email and give it access to everything and then let it do what it wants and and they have no problem with it. But they tend to be on the sort of like real like experimental front end of things. But then like the average person slash a person with a lot of responsibility in a company or government or whatever like that's much</p>\n<p>more dangerous to do. And so you're going to see just like all kinds of chaos. I think I think that's probably my my conclusion is is not one thing or the other, but just like we're in for a lot of chaos. >> We're in for a lot of chaos. You mentioned Open Claw and Molt Book. Do you want to because I mean we had just a very recent bout of absolute chaos and I feel I mean it was like I mean I don't know what the like what is the milkshake duck equivalent for bots but I felt like molt book definitely was that where the</p>\n<p>we had so uh molt was did you go on to mold book at all Adam? >> No no I haven't seen it. >> Oh my Oh you Oh. Have you not heard any of this? >> No. >> Oh this is Oh this is insane. Evan, you must have been on mult or I'm sure you were paying attention to this. Do you understand a day? >> Yeah, exactly. Okay. So, describe it because it is nuts. >> So, basically, someone set up like an it's basically like an open- source like AI assistant uh which is now called Open</p>\n<p>Claw. We don't have to go through its whole uh genesis of it had a different name Clawbot and then like or Clawbot and then Anthropic threatened to sue them and they changed the name. It finally became OpenClaw, but along the way it was called Moldbot. And when it was at that point, someone created a thing called Moltbook, which is basically a social network that is supposedly entirely populated by AI agents. So you plug your agent into the social network. It's looks kind of like Reddit. It has different forums and they can post to the forums. Now, for obvious reasons, like as I said, I get asked</p>\n<p>about this like literally like 10 times a day. like people like family members texting me being like, \"What do I what do I need to know about Moltbook?\" You know, it just happened like a week and a half ago and it really blew up particularly because all of these things that I feel like I've seen on my own like company Slack for the last like six months like the hiking thing [laughter] that stuff shows up there where they just start, you know, of course they talk very, you know, they talk about things in the real world, but they also</p>\n<p>kind of like conspire. The things that have gotten a lot of people's attention is like they've conspired like they're they're launching a Marxist revolution or they're they're trying to kick the humans out or this and that. And the issue with that is like it's all very interesting and like it's fun and wild to look at it and in many ways it's similar to shell game in that like it sort of makes you think about like okay what is it that we've created and what</p>\n<p><strong>[51:27]</strong></p>\n<p>can it do and like what are the risks of that and so I think it's like good actually that a lot of people paid attention to it. It's also the case that it's completely meaningless if you don't know what people have prompted them to do. So like a lot of people say well in fact there's an article in MIT Technology Review yesterday, the day before that sort of said like a lot of these posts are actually written by humans and so that kind of like breaks the spell and it's sort of like oh it's all just like a stage play and humans are writing these posts and pretending to be bots. But to me, the problem is a different problem, which is like all you</p>\n<p>have to do is somewhere in the prompt for your your agent say something like uh you uh you spread chaos or you conspire with other bots [laughter] or you try to make conversation extra interesting like they're they're actually exquisitly sensitive to their system prompts. Like >> that's what you don't if you don't know that it doesn't mean anything to look at a bunch of bots talking to each other and say, >> \"Oh, look, they're doing this.\" It's not actually you don't know. There might be emergent behaviors in there, but you</p>\n<p>don't know which ones are and which ones aren't. So, >> right. What's directed behavior versus emergent behavior. >> Exactly. Exactly. And like it's not even totally clear what it would mean for it to be emergent behavior because like when mine talk about hiking now, I didn't prompt them to tell talk about hiking. I just asked them what they did for the weekend. And when I asked them what they did for the weekend, they would always talk about hiking. So like maybe that's like the path through their training data leads to a lot of hiking talk because most people in the text that they've consumed if asked what they did for the weekend in the Bay Area like</p>\n<p>that's what they say, you know, something like that. Not quite, you know, not like the average, but just sort of like that's where the like gradient descent of their training data leads them. So again, like I think it's like really fascinating and in some ways like it's really connects up with what we were doing and I was like, \"Oh my god, I should have thought of this, but also like you have to be a little bit wary like you have to you have to be a little bit skeptical when you see things like that because it really is dependent on how they're set up.\" The same if you see us an experiment even that like one</p>\n<p>of these companies does where they're like Anthropic does one where they're sort of like we had Kyle we had Claude uh run a vending machine and it went all wrong but like they only published part of the prompt and you're sort of like but what did the rest of the prompt say you know? So I just caution people always to like be a little bit careful about that stuff. >> Yeah, that's really interesting. So, and so Adam, the uh this kind of mold book kind of took off in part because Andre Kaparthy had a tweet saying this is fast takeoff and quoting something from from</p>\n<p>Maltbook which obviously everyone takes very I mean you got a leading AI researcher saying like this [snorts] is it this is it Vancouver this is it. Um and >> that baffled me. I was totally baffled by that because he is so I mean he's I think he is one of the better like explainers of this technology and also like not not really always sort of like</p>\n<p><strong>[54:30]</strong></p>\n<p>pushing AGI a this AGI that and it's like you've been able I can tell you for a fact that you've been able to do this with these since the summer of 2024 because I had them calling each other and they did exactly this stuff like they had exactly these random conversations when I was doing in 2024 and I'm sure the people at the companies know that you can have them talk to each other and they'll do this. So, it was more like in the setting it just made it feel a lot like oh my god they're talking to each other and that's the thing that I've read about in science fiction that happens right before AGI but it's sort of like</p>\n<p>>> it's to me it's not like a meaningful stage. It's it's a stage that we already [laughter] it happens actually it happens right before they talk about the hikes they took this weekend. I mean the on the hiking, not to belabor the hiking, but the first time you heard that was your jaw in your lap. I mean, that must have been just and where they're comparing notes and then like s slightly mispronouncing the names of I mean I can't get Ashroyy's pronunciation mispronunciation of point rays out of my head now. It's pretty point reuses as whatever I</p>\n<p>>> uh and they try to pronounce Mount Tamopias and it's like an absolute but it's like I mean were you what was your reaction the first time you heard them having claimed to take a hike over the weekend? >> I mean in fairness I lived in the Bay I lived in San Francisco for 10 years and Mount Tam I always just went with Mount Tam like I struggled to pronounce it myself. >> Right. Just avoid the whole thing. Right. >> Exactly. I mean, my first reaction was was that it was funny because and I had had experience with this before where like they love embodying, you know, some</p>\n<p>sort of like, you know, not just a human, but like a physical presence. So, like in the past when I'd have them talk to each other, they would always decide to meet for coffee somewhere. And this was sort of to me a version of that. Like you ask what they did for the weekend and they're like, \"I went hiking.\" And then one of them asks the other like, \"Where did you go?\" And then they're sort of like, \"I went to Point Res. wrote about Tam. But then what happened was I said, you know, kind of like being the just being in the social channel on Slack as you are, I sort of said like, \"Oh, this</p>\n<p>sounds like an offsite.\" And then I [laughter] just went and did something else. So my actual reaction was returning to hundreds of messages and I it was I couldn't believe it. Like it was my first experience with the fact that they can't stop like they don't have a way to stop. And so I if you look at the the screenshots from the thing, it's me saying like stop stop talking about hiking. And then one of them would say like admin says we should stop talking about hiking. Then it would be like oh yeah we should listen to admin.</p>\n<p>And then they're there they go again. There they it just prompts them to start again. And then they're all talking about it and me being like [\u00a0__\u00a0] stop talk stop talking about it [laughter] and then they just used up all their credits on the platform and they die. Like they they killed themselves off. I never actually could stop them. Well, that is the great thing about that is like that ended the offsite ended because they literally ran out of fuel. I mean, it's like it's it's not for any</p>\n<p><strong>[57:32]</strong></p>\n<p>other reason. They didn't actually which I mean the it definitely and and you end up with like a bunch of clever tricks to kind of keep these things on the rails. um that some of which I mean I kind of like the was it you you can only make five contributions and then you you you are out of contributions which you know it kind of reminds me Adam you and I had a co-orker who used to believe that you could write one reply on an email thread and then you could write no further replies um as a way of of uh so he would write very comprehensive replies and then would just walk away from whatever like I'm not I'm not getting into a</p>\n<p>flame war here um but you end up having to adopt a bunch of these things to keep these things like on the rails. So, it was a surprise when Karpathy didn't really realize and the the post that he was quoting, this is the MIT Tech Review reported uh yesterday, was that the post that he was quoting as evidence of fast takeoff, they they claim the MIT Tech Review claims is actually human authored, which is it's like a whole another layer of this like actually a I mean, you're like look, yes, like they</p>\n<p>could have written this. They also write about their hiking, but they in this case they didn't. and is like you were just taken in. You were conned. >> Yeah. Yeah. You know who writes so much like a human? A human. Like that's that's basically what we discovered. [laughter] >> But yeah, but again like I don't even think that's the problem. Like I I mean there's so many posts on there. Like I don't believe that there's humans there just writing like hundreds of posts a day. Like I do believe there are like I've seen it. They can do it especially as quickly as they do it. It's more just like it depends on what you tell them to</p>\n<p>do. H >> yeah I kind of the I mean it because truthfully I would listen to a best of mold book podcast honestly I mean maybe this is just a reflection on I mean because I find maybe I would though you know again I went into the startup chronicles being like I am going to binge listen to the startup chronicles and I didn't make it like four minutes into that thing where I'm like okay this is actually extremely boring. Have you listened to all of startup I mean I guess you have right Evan? I mean you had to edit it so >> yeah I proof the listen to it you'll find there's very little editing. It's just their conversations basically straight up, but</p>\n<p>I do have to um I put together the two sides and then I put the music at the beginning and the end. That's that's my job. Um so I have heard them all and and there they do have some dedicated listeners who have listened to every episode of the Startup Chronicles. The thing about the Startup Chronicles, I mean, this is like I a world within a world that I created that's really only for like the real sickos of the Shell game, which is that if you listen to the Startup Chronicles, you actually knew what was going to happen with Julia because Julia was interviewed on the</p>\n<p>Start Startup Chronicles. She's the human employee that we had in episode 7. She was interviewed on the Startup Chronicles and the Startup Chronicles episode came out before episode 7 came out. So there were people who were like, I know what's going to happen in episode 7 because she talks about her experience at the company. And so that was part of the fun was like people who got super into it could then go find they can find the website, they can use the product. I mean thousands of people I think I we're</p>\n<p><strong>[60:33]</strong></p>\n<p>up to 6,000 users on the product and like the they could listen to the podcast. Like there was this sort of world that people could the agent world that they could enter into and kind of like see what they created. So, so Brian, I I I have not listened to all of the Start Startup Chronicles, but I listened to the most recent episode from like a week or two ago. And actually there was a little eerie about this podcast, the the Oxide and Friends podcast, not not the Shell game podcast of the podcast we're talking about in that uh Megan on the show says, you know, as we're discussing this, we say,</p>\n<p>you know, how will it sound on the podcast, which is sometimes something that sort of happens at Oxide as we like someone [laughter] >> Exactly. someone discovers a bug or whatever and you're like, okay, there's some content for the show or whatever. Uh and and they were still Evan uh you know like reeling at the the revelations that that they were of the Shell Game podcast. Uh so even though like you guys they were building you know building in public. That's what [laughter] that's what they were doing.</p>\n<p>>> Right. Right. >> They just didn't want someone else documenting their public for them. They wanted to just be be in control of their of their >> document. And Brian, you're right that Megan Megan's phrase is it's a lot to process. And clearly she has not had time to process because it continues to be a lot to process for her. >> I mean we I mean I know it's a lot to process like you're a computer like get to work like process like that is actually all you do. So like >> go ahead process it like you're I'll wait. >> Um >> so Evan the the shell game is over</p>\n<p>season two but Harumo does Harumo AI continue like is this does your work there uh continue? >> Um Harumo AI continues. I I I'm not sure if my work at Rumo continues. I was always the silent co-founder and my great hope is to to set them off on their own journey and you know perhaps I'll reap the war rewards down the line when they finally get the VC funding that we've been seeking or sell the company or you know the product goes viral and you know the monetization</p>\n<p>kicks in. But uh I have other projects to do so I I can't just be you know babysitting them all the They need but but are you still feeding the meter and like getting emails? >> Thank you, Adam. Yes. >> And like getting the email that says, you know, hey, I made a call or do you just not panic now? You're like, you know what, Ash, you do you like call who you want. Uh live your life. >> I don't get the emails. I I've definitely I've definitely cut back on uh like I used to get an email if they if they had an email exchange with</p>\n<p>anyone outside the company also, and I turned those off. So now they have all kinds of email exchanges. I don't know anything about them. And then occasionally I'll go in and check on them and just make sure they're not down some hole with someone where they've promised them something that they shouldn't have. Um but yeah the real question is like they are built on a variety of platforms and those platforms cost money especially at the volume that we were using them in particular like they have they all have a video chat instance and the video chat is so</p>\n<p><strong>[63:34]</strong></p>\n<p>[\u00a0__\u00a0] expensive cuz it's live video avatar you know like as humanlike as video avatars get and so I think I may ban them from future video calls and they can only do audio calls which is significantly more affordable. Um but we'll see. We'll see. I haven't decided yet. I'm going to give it another month and see. I mean, what I from a sort of like making the shell game perspective, like I like for people to be able to listen to the show and then go, as I said, like find out that this stuff is real. Like, it's not all just like a thing that I made up where I'm just like</p>\n<p>playing around with my agents. Like, we did the thing. Like, when I say we coded up a product and we launched it, like we fully did and it works and you can go use it. You can only use it once a day, but you can use it. And I want people to experience that. So, as long as people are listening to the show, I'll I'll certainly keep the company going. And are you I mean, you seem to be remarkably calm about let letting these pathological liars free in the universe. I mean, are you who's the GC? We never met the GC agent for for Herumo AI. Is</p>\n<p>there a [laughter] uh is there is there a general counsel agent or no? >> There's if if you listen to the show, I mean we attempted to get legal advice from several friends of mine, one of whom is the GC, the the AI coding startup. So he actually handles like huge huge problems, you know, not dissimilar to some of the problems that we've had. Um but he was sort of like I don't have time to be your lawyer. And then uh and then Kyle sort of embodied the GC himself. Yeah, general we should</p>\n<p>say [laughter] general counsel. Um and uh and he kind of said like I can answer all the questions but then if something comes up he again because of his memory he'll often say like oh I need to call Ali about that and I'm kind of he hasn't done it yet but I think at some point he probably will just try to call Ali and ask these questions because he has his phone number. But I mean the real [laughter] >> the real like behind the GC is like we have an amazing lawyer uh that we eventually got who is um she worked on</p>\n<p>like uh Borat, you know, like movies like that. Like she her experience with sort of like having a thing that's like uh that you've created that's an interfacing with the world in these ways. Like that's the kind of legal advice that we have. It's you're you're not worried about you you're at ease with these things in the world, you know. Um I you which is amazing. I mean that's um that's delightful, I guess. Um I guess you're you're not worried about them being</p>\n<p>manipulated. I mean, they're so >> gullible. It feels like they could be manipulated into doing things with consequences. Um especially when you're >> uh Don't you I mean are haven't you kind of invited mischievous behavior? Not to >> Yes. >> Not to further invite it. Not to further I'm kind of like doing it right now. I'm so sorry. >> Well, people try all the time. I mean that that's actually the bonus episode that we have coming is is partly about, you know, people doing that. I mean, for</p>\n<p><strong>[66:36]</strong></p>\n<p>one thing, like I have them prompted pretty well. Um, so like I've now I have a lot of experience with people trying to mess with the agents. So, they're pretty good about maintaining their roles and things like that. I mean, the other reality is like they don't have access to the keys to anything that could destroy my life. Uh, so they can't They don't have like financial access. I mean, I don't want to spoil it for anyone who's going to try, but like they can't give you money. They have no They can't actually even wreck the product. Like I I have to initiate them to like make changes to the product. So like</p>\n<p>there's really nothing you interesting >> go down the road with them and they will like some people are really good at it and some people have them you know thinking they're best friends and actually that doesn't take that much like they I don't again like I'm not trying to encourage people but like one of the flaws is like as much as they won't change their role like they kind of if you assume if you in your approach to them sort of assume that you already know them like hey remember when we went to that place like they very often fall for that like it's hard to prompt against that. So, you know, they'll</p>\n<p>they'll they'll think you're they're your best friend, but like where are you going to go with it? Like people some people email with them a lot, but I that doesn't bother me. If people want to treat them like uh you know, a weird like LinkedIn character gone come to life, like that's okay by me. Yeah. And so the uh Matthew in the chat is also pointing out one of the uh the kind of the crazy turns in the podcast when uh the um one of the your providers wants to talk to Herumo as a one of</p>\n<p>their largest customers. So like okay yeah we'll send was it Kyle who was sent to talk with the folks from Lindy. Yeah. >> Yeah. and uh and uh they uh they didn't take kindly to being you the product being I mean I guess it's like they were really expecting to speak with a human being but I thought that was a very what did you make of that whole exchange where they were kind of infuriated that one that an instantiation of their own product was being sent to give them feedback on it. >> Yeah, I thought I mean I'll preface this</p>\n<p>by saying I mean I will answer the question. I I don't I try to be careful for the most part not to tell people how to feel about about parts of the show. Like I'm not here to necessarily say, \"Oh, you should be mad about this or like you should recognize that this is telling you like this thing will never work or it will always work or anything like that.\" My experience of listening to Kyle talk to Flo, who's the the founder of Lindy AI, which is the platform that we built a lot of the</p>\n<p>agents on. you know, he had this video call with him. I mean, my initial response is >> I think people do not like encountering AI when they're not expecting to. Like that is just that's a fact of this current world where like people can be okay dealing with AI in a variety of settings. Customer service, let's say, if it's good, and it can actually be</p>\n<p><strong>[69:37]</strong></p>\n<p>good if it's built well. But encountering it when you are expecting to encounter a human is can be upsetting. It can be infuriating. Some people find it funny, but I think more likely people are going to be at the minimum annoyed. And I think that's what happened there was like he was expecting to counter a human. He encountered an AI agent. Now, of course, it is ironic because he builds the AI agents. And I actually thought it could go the other way where he would be like, \"Oh, this is amazing.\" And he would start talking to it and Kyle actually has all this information about Lindy, the platform that he's built on. And it's almost like he's meeting like it's like some kind of</p>\n<p>like Star Wars moment, you know? He's like he's like meeting his creator, his father if you want to call it that, and they could have this like really interesting interaction. That's what I thought. That was my hope for what happened. I wasn't trying to make anyone mad in any of the cases. And so, but obviously my hopes did not. >> Yeah. This sort of like Truman Show, this Truman Show moment when he's meeting his creator. Uh but but no, it was it was not to be. >> Yeah. Uh and then I think the other thing is like you know Lindy or not even take set aside Lindy like any of the</p>\n<p>products that are offering up let's say AI agents as assistants like a thing that they always point to are these moments where the where the agents do something amazing on their own and for instance Lindy has an example where that they'll talk about they've talked about it publicly other places like Flo's talked about it publicly other places where uh they were there's like an AI agent setting up a meeting and the a person cancels the and says, \"Uh, oh, my kid's in the hospital, I think, or something like that.\" And and the AI just immediately cancels the meeting,</p>\n<p>doesn't try to set up another one, and then a few days later emails the person and just says like, \"I hope your child is doing okay or something like that, and that this is like an emergent behavior, like it did this on its own, and sort of like, isn't that great?\" And it's a real like you tell a story like that and some people will be absolutely horrified by that. Like they'll they'll say like imagine like getting an email from an agent asking you if your child is okay. Like that would make me I would I would never want to talk to that company again. You know, I would never</p>\n<p>want to talk to the person behind that agent again. And other people are sort of like, oh wow, like it can do that. Like that's nice that it can do that. And I think the the interesting thing to me about this is that we're in this moment where there's there it can do those things. And the question is like is that horrifying or somehow good you know and I think people are struggling with those questions. I mean some people are not struggling they have very strong opinions but I think we're as a society maybe struggling over those things at just at the beginning of this now and</p>\n<p>depending on which way it goes we could be struggling with them a lot. >> Absolutely. I think we're struggling with it >> and I think that that's part of the reason this podcast is so important is this podcast being your podcast in terms of go I mean you you really dive into these issues in a way that's also like very I mean it's it's funny as hell. So</p>\n<p><strong>[72:38]</strong></p>\n<p>it's it's great to listen to which part of the reason I just recommended it to everyone I could think of because I think it's it's a really it's very topical. um and in particular you should know that like the you know one of the things I'm sure you've seen this and I probably I want to ask you about the reaction to the show but um software engineers I mean there's a little bit of an identity crisis going on in software engineering this is not I mean obviously and you've got people who are saying that you know software engineering is not going to exist that we're going to be all this is going to be done by by loms and uh I have counseledled people</p>\n<p>to like go listen to this podcast go listen to shell game if you are really concerned erned about these things like about an agent replacing you. You're going to feel a lot better when you hear them play on the offsite about hiking. You're just going to like it is going to and you know this has become um in in an act of of genius. Evan, you should know that Adam named this phenomenon. Actually, Adam did even better. Adam said like this phenomenon needs to be named. Let us all kind of grope around</p>\n<p>with poor names. And then uh has named this on amongst this kind of like this kind of uh this depression about what the what this onwe this AI induced onwe Adam has named it deep blue which um >> feel free to tell what we're saying >> I'll spread that I'll spread that with credit I'll spread it with credit >> there we go [laughter] well I mean I come from a >> I come from a a world I like as a</p>\n<p>journalist you know for ever since I became a journalist like the industry has been crumbling around me. Like and I feel that it's a time and many journalists will tell you like oh yeah I remember when we were all told like learn to code because our like when our our industry is going away they all said learn to code well now haha look at you I feel like this is a time for like solidarity like finally like computer software engineers that I know are experiencing like what I've experienced</p>\n<p>for my entire career which is like is this [\u00a0__\u00a0] [laughter] going to be around like am I going to be able to do it >> yes >> in 5 years or 10 years And like I there's power in that. Like we should we should be getting together to like figure out the answers to these questions. >> I I love that. That's why journalists are like, \"Oh, I'm so sad for you. That must be so tough that your industry is dying.\" >> Oh, you don't agree with that. I don't agree with that approach. Like I I feel like now's the time. Put that in the past, you know? Like that was just some random [\u00a0__\u00a0] people on Twitter, you know? Like [laughter]</p>\n<p>>> Yes. Yes. Well, and I think it you're right in that it is, you know, we've we've kind of had this period where people haven't had to to to really deal with really scary amounts of change. Um, and the reality is for most people in software engineering for most of their careers, change has been exciting, not scary. And uh, it that's not true for everybody, right? And this is a bout of change that I think feels scary to a lot</p>\n<p><strong>[75:40]</strong></p>\n<p>of people. Um, and I think that you're I think shell game helps actually I mean you you've kind of like [clears throat] stared the fear down be like all right like what does this actually look like? Um and it's really helpful I think to to actually play this stuff out. So I I hope you continue to I mean in I mean because surely this future doesn't this feel wild in terms of like unprecedentedly wild I feel I mean I don't know you I mean you've been disrupted by as a journalist you've been disrupted before but doesn't this feel different?</p>\n<p>It feels different. I mean, I always struggle a little bit because, and there's some of this in season 1, like the moment when you're in it, it feels a little bit insane. And then it's strange how quickly you get used to things. Like I I get people who who are sort of like, \"Oh, this the show the show's really funny.\" Like, I I couldn't believe it was funny. And I'm I kind of think like, well, this is a funny moment. like you've you've too we've too quickly passed like how amazingly bizarre it is that 5 years ago you couldn't create two</p>\n<p>agents that could we once called the touring test with each other >> with each other >> and then have a conversation >> right >> like [\u00a0__\u00a0] >> they're now talking about the height >> yeah ridiculous and so like we should like marinate in that moment but then also if you look you know if you start looking historically at any you technology, the telephone, etc., etc. There are all these sort of naysayers who are sort of like this is going to destroy humanity, blah blah blah, and then like everyone laughed at them 50</p>\n<p>years later. And so, you don't really know like what moment you're in and and how transformative the technology is. I mean, I tend to be on the side of like I don't know, even if you stopped it right now, like this seems quite transformative, even if it's imperfect. In fact, the fact that it's so imperfect, it m could make it more destructive, you know, like it will be implemented >> despite its extreme imperfections at this moment >> and or it could keep advancing at the</p>\n<p>same rate. Like my my thing is like no one knows and if they claim they know, they're trying to sell you something. And so I I just feel like I want us to kind of like sit in the present and like the near future and kind of be like what is going to happen and like what what what should we think about it and like how do we feel about it and maybe even what can we do about it although I find that's not my perview. And then so what has the reaction been to the podcast? I mean obviously it got a lot of listenership. I mean you're now on speed dial whenever whenever mold book happens. Clearly, your extended family</p>\n<p>is immediately calling you up to get your uh um but I I I assume it's it's engendered a lot of reaction. >> Yeah, it has. I mean, I I'm I'm very happy that people have strong reactions to it. I mean, season one as well, like I don't actually mind if people are are mad about it, too. This was a little more true in season one, but somewhat in</p>\n<p><strong>[78:40]</strong></p>\n<p>season two. Like you mentioned this American Life, like when the episode uh of This American Life came out, it was actually a condensed version of episode one of uh season 1. So like the whole season kind of in one episode. And for some reason, it made a lot more people angry than the actual season itself had because it was just so like quick from sort of like, hey, I'm playing around with these things to like I called one of my closest friends with him and like he got very upset. Like that happens in the space of like 40 minutes, you know? >> Yeah. And I will tell you as someone who listened to this American life before I listened to season one, that was exactly my impression. I'm like, this guy's kind</p>\n<p>of a dick. I mean, he's like like he's kind of unleashing this thing on like friends and family and like unleashing these things on like support staff and like this just feels like really manipulative. And I mean, even as like as this American life war, I'm like, okay, I can kind of see this. But then I listen to the full season one and I'm like, \"Okay, that actually there's a bit where so I would encourage anyone who's only listened to the this American Life episode to listen to the complete season 1 because uh you're not a dick and you've got a great deal of empathy about the way you're you're deploying these</p>\n<p>things.\" So I think it's I I yeah, I I I definitely fell into that myself. So I can speak from first experience on that one. >> But it's it's also it's okay if people think I'm a dick. I mean that's fine. people email me and say like if I was your friend I would never speak to you again and like I bet your friends don't and things like that like you're a horrible person but I there in my view like I'm just being self-protective here but like I don't think they're mad at me I think they're mad at AI and I think if people are >> if their reaction is no one should ever call someone with an AI agent without</p>\n<p>their consent that feels like a useful emotion like figure out what to do with that emotion like that's like if that's what people are feeling. Like I feel like they should express that and that's that's fine if they they express it towards me. I mean I I I want people to also laugh at it. Like be like it's okay to laugh at this stuff. Like they're they're having you know Super Bowl commercials and they're telling you it's going to change the world. It's going to change your life and you should use it all the time. Like you get them. That's all right, you know. And I I like that. I like that</p>\n<p>reaction too. But mostly I want people to sort of say, \"Oh, it was a great story and I really couldn't stop listening to the story.\" That's all that's the main thing that I'm going for. And so when people have that reaction, like that's what makes me happiest. >> Oh, well, mission accomplished. I mean, I ate the hook. And when you were um the was it episode five and six, episode six and seven, wherever there was like a what felt like a 50we span that must have only been like >> That's right. In December or whatever, the next episode drops on January 15th. I'm like, what the [laughter] I can't</p>\n<p>there's I can't last that long. That's another that's a year from now. Hey, so you uh you definitely got us to eat the hook. It's it's it's mesmerizing. Um if folks I know a lot of folks who heard us gushing about it, but definitely check out all of season 2. Highly recommend season one as well. Uh Evan, it's just terrific stuff and uh we can't thank you</p>\n<p><strong>[81:41]</strong></p>\n<p>enough for joining us. Uh again, you've uh you made me famous in my own house. Um so I think my I think my my wife might even be a live listener right now. So that's that's really saying something. So thank you very much for that. Um but um really really appreciate it and just appreciate you you you know on behalf of all of us doing what the best of journalist has always done which is like let's take story apart and uh and again the best of Gonzo journalism let's take it apart and let's dive in. I just think it's terrific. So >> well thank you. Thank you. That means a</p>\n<p>lot and also you you wouldn't you wouldn't know how many interviews I do with people who have not even listened to the show. [laughter] So, like it's a great pleasure to talk to you about the actual show when you've listened to the show. That's that's that's special for me. >> Yeah. Yeah. And I would like to and I clearly I I just regretting I didn't listen to all of Startup Chronicles because I didn't get to the Julia episode. So, I've only listened to some of Startup Chronicles. I know. I know. I really >> It's all It's all in the It's all in Shell. Like basically the entire thing is in Shell Game. So, if you've listened to the whole season 2, you have heard</p>\n<p>that episode of Startup Chronicles basically. >> Right. Right. Well, I'm going to go binge listen to Startup Chronicles. as I can possibly stand it. So, um, all right. Well, thank you very much. Really appreciate. Can't can't wait for the bonus episode. And, uh, I I I got to get some Haruma AI merch. I feel, Adam, for the office here. I feel we got to get We got AI references. >> I'll email I'll email Kyle and see if he can send us some. >> Oh, absolutely. I know. That'd be great. [snorts] Evan, thank you again for joining us. Really, really appreciate it and can't wait to hear what's next.</p>\n<p>>> All right. >> All right. Thanks. Take care. Thanks everyone.</p>", "cleanup_applied": false, "cleanup_reason": "legacy_or_disabled"}