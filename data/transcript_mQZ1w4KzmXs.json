{"video_id": "mQZ1w4KzmXs", "title": "Dangerous Question: Has AI Been A Disappointment So Far? | Cal Newport", "link": "https://www.youtube.com/watch?v=mQZ1w4KzmXs", "published": "2026-01-29T11:00:00+00:00", "summary": "Cal Newport examines if AI has been a disappointment so far in this clip from a recent episode of the Deep Questions podcast.\n\nBuy Cal Newport's latest book, \u201cSlow Productivity\u201d at www.calnewport.com/slow \n\nDownload my FREE Deep Life Guide HERE: https://bit.ly/3QBIcug\n\nListen to Episode Here:  https://www.thedeeplife.com/listen/\n\nGet your questions answered by Cal! Here\u2019s the link: https://bit.ly/3U3sTvo\n\n0:00 Is AI a disappointment?\n3:20 Pattern finding\n6:10 AI and customer support\n8:50 Corporate trade secrets\n\nConnect with Cal Newport:\n\n\ud83d\udd34Visit Cal's BLOG and website:             https://calnewport.com/blog/\n\ud83d\udd34Check out Cal's books:                         https://calnewport.com/writing/\n\ud83d\udd34Check out The Deep Life:                     https://thedeeplife.com\n\nAbout Cal Newport:\nCal Newport is a computer science professor at Georgetown University. In addition to his academic research, he writes about the intersection of digital technology and culture. Cal's particularly interested in our struggle to deploy these tools in ways that support instead of subvert the things we care about in both our personal and professional lives.\n\nCal is a New York Times bestselling author of seven books, including, most recently, A World Without Email, Digital Minimalism, and Deep Work. He's also the creator of The Time-Block Planner.\n\nThe videos are considered to be used under the \"Fair Use Doctrine\" of United States Copyright Law, Title 17 U.S. Code Sections 107-118. Videos are used for editorial and educational purposes only and I do not claim ownership of any original video content. I don't use said video clips in advertisements, marketing or for direct financial gain. All video content in each clip is considered owned by the individual broadcast companies.\n\n#CalNewport #DeepWork #DeepLife #DeepQuestions #TimeblockPlanner\n#WorldWithoutEmail #DeepQuestionsPodcast", "transcript_html": "<p><strong>[00:04]</strong></p>\n<p>Clearly, a huge amount of money is being invested into new generative AI tools built on large language models such as chatbots. And it's just goes without saying this has been massively disruptive. Most of the conversation is about how do we deal with the disruption that has been caused by this new technology. But think about this question for a second. What actually are the things that this massive investment in generative AI through language models, what actually are the things that this has changed? Because if you ask people, they don't</p>\n<p>always have an immediate answer to offer up. Is that possible? Well, I want to investigate this. So, here's the way I'm going to do this. Um, I found a Reddit thread that was from three months ago. I'll put this on the screen here for people who are watching. It says the same question. with all the billions or trillions going into it, what has AI actually done other than as a search engine and funny pictures. So, this is a thread where people from all over the internet are going to write in and do their best to explain all the various</p>\n<p>things that we've gotten from this massive investment in new AI technologies. So, whatever these benefits are, you would think they're in this very popular thread. So, what we're going to do is I want to go through this Reddit thread to try to come up with uh a list of the things that this recent massive invest in AI has produced. Now, a couple ground rules to this. I'm not going to include things uh AI applications. I'm not going to include AI applications that are based um aren't</p>\n<p>based primarily on the new large language models that have received the bulk of this investment. So the type of models that OpenAI and Enthropic have been producing there's a lot of existing machine learning driven AI tools that we've been working on for year after year and and over the time those have made progress. I'm going to separate that because that's not that's just the standard progress in AI and it's not connected to anything new that has happened. I also want to separate into its own category the one obvious place where we hear most often about language models making an impact which is</p>\n<p>computer programming. Computer programming is like a best case scenario for gender of AI. It's a highly structured language and we have a huge amount of very uh relevant data on which to train these. So we know it's been really uh impactful there. So we'll kind of keep that as its own column. What I'm looking for as we go through here then what I'm actually going to write down as we go through here is examples that depend on the generative AI models that we put billions of dollars in the last three or four years. But it's not computer programming because clearly if this has really changed our world that list should be really long. All right. So I'm going to</p>\n<p>load this back up again. Um, and I'm going to go through I this is a very long thread, so I'm just going to pull do the best I can to go through this. All right, so the first thing we see here is assisting medical and scientific research and translating ancient documents written in dead languages. Um, none of the neither of those are really from generative AI assisting medical and scientific research. I mean, there are a lot of tools that we're using in for</p>\n<p><strong>[03:04]</strong></p>\n<p>medical research. We're building AI tools, but that's using existing technology that that's been around pre uh the Gen AI boom. Um translation documents, that's also machine learning tools have been around. We've been getting better at them, but that's not directly related to the recent boom. All right, let's keep going here. Um AI as a tool is incredible at very specific things, mostly things human finds to be incredibly mind-numbing and meticulous. Uh its best use by far is pattern finding in wide data sets that are hard to pick up by hand. So, I'm going to put that down. Pattern finding. I'm just writing this on paper here. So, pattern</p>\n<p>finding. I I've heard this. You can give some data to a chatbot and it can perhaps find you some patterns. Um, let's keep going. Alphafold protein structure database. Uh, Alphafold is not based off of directly based off of the recent investments in Generative AI. They've been working on that model for well before the LLM breakthrough when it uses um its own technologies that have it has some new versions have some overlap with transformer attention ideas but that is sort of a separate trajectory that's not a result of the billions and billions that have been</p>\n<p>invested in large language models. So um I'm going to put that to the side. All right. Next thing it speeds up a lot of menial computer task. I had it make a PowerPoint from six MSWordsiz document pages for me. It made 60 slides like a minute. Would have taken me an hour to do the same thing. I'm going to write that down. Like I I'll put down slide production. Uh it's more generally it can produce slides. Uh I've seen that in PowerPoint. That's a good that required the investments that have happened. So we'll put that down. Um let's see. It's incredible tool for programming. Okay,</p>\n<p>so we're putting that aside. There's an argument about that. Someone else says it's a lot of bad code and then all the cloud code people come out with their their torches and get mad at them. Um here's a different one. I mean, it really is useful for quickly disseminating a large volume of boring info into bite-sized pieces and identifying points of interest. I think this is right. So, I'm going to put down summarizing text. So, we've seen this a lot. Like, you can take a a bunch of notes like a meeting transcript and say, let's let's give me the give me the main points here. Summarize this in the bullet points. Um,</p>\n<p>language is very good at that. All right, let's keep rolling here. Translation of any language to another. That's not primarily a language model based thing. We've been doing that for a while. It's being used to help detect cancer earlier than humans detect it. All of that sort of medical prediction model research is not those are not underlying it language models. That's something people have been working on for decades and we keep getting a little bit better at it. But that's sort of unrelated to the billions being invested in large language models. So I'll put that aside. Um discussion discussion mapped every protein. We talked about</p>\n<p>that. That's not large language models. Let's uh keep moving here. Someone else described a bunch of stuff and then a response to that said most of the stuff you're describing isn't breakthroughs from the last three years a slow incremental process over the last 20 or more years. Um that's right. So he was pointing out a whole long example of things that uh was not actually</p>\n<p><strong>[06:06]</strong></p>\n<p>generative AI. Someone says take customer support. Call centers are already so heavily scripted they might as well be AI. Make AI good enough to hold a rudimentary guided conversation and it can replace basically every first level support person. That's some speculation into the future, but I will put down uh customer support agents because there are more of those. I don't think it's necessarily replacing the industry as quickly as people predicted, but there are better sort of firstline chat agents that language models in particular made those good enough to deploy in a way that they wouldn't have</p>\n<p>been before. All right, let's go here. Um, a teacher in my family uses it to create a live avatar of himself that speaks fluently in multiple different languages as it records him teach in his native language. He's been able to teach multiple classes in multiple countries at the same time. I guess that's partially language models are probably involved in that. Uh, the language translation is something we've been doing from before. In the medical field, AI does a decent job transcribing notes. It's not really a generative AI</p>\n<p>breakthrough though OpenAI has been working on voice to text. They have a special model for that, their sort of whisper model which they then have on the front end of chat GPT. So like if you talk to your phone into the chat GPT act app, you really have a separate smaller model that's been trained. It's a different type of architecture than a language model that converts that to text and then the text is submitted to the large language model. So that's cool, but again that is not a result of the billions invested in large language models. We were already doing that. Um then someone came along, this is</p>\n<p>interesting, and said you can do things like tell it read this congressional bill and note anything that seems illegal, unconstitutional, or would adversely affect separation of powers, checks and balances or civil liberties ranked by risk and describe the worst case scenario, the worst possible abuse of the change considering an executive branch intent on consolidating power for itself. And the guy's like, \"Oh, that's the type of thing you could you could ask GPT5 to do.\" But then someone else wrote back and said, \"LMs can't actually do that, though, right? There's no reason, no imagination. they can't create and explore scenarios in the way you're explaining. They're not going to give you good advice. So, I'm not going</p>\n<p>to write anything down. Someone else said, \"Check this year's Nobel Prize in Chemistry.\" Well, that was given to Deep Mind for AlphaFold, which again is non- language model technology that predates the billions invested. Someone else says, \"It can make pretty good uh hint.\" And someone else said, \"Actually, it's slop.\" So, I guess I won't write that down. Someone else said, \"Write the answers to my stupid quarterly self-review questions.\" That is true, right? boring text. Yeah. So, it is really good for that. Like, oh my god, no one cares about this. I have to write a self-re.</p>\n<p>It'll write boring, you know, good enough text that covers what you want. It's very good at that. All right. Uh, let's just do a couple more because I think we're seeing some patterns here. Someone else says there's thousands of AI projects you don't hear about because they're corporate trade secrets. That's not true. Uh, there's a lot of that push of like, no, there's all these amazing things you just don't know about yet. They're coming. Let me tell you, as someone who's studied this for the last five years, they've we've always been</p>\n<p><strong>[09:07]</strong></p>\n<p>quote unquote three months away from learning about the amazing thing that Open AAI or Anthropic or Google or Microsoft are doing behind the scenes. I have a lot of sources at these places. There aren't magic projects. There isn't. I mean, we heard this two years ago that OpenAI had AI was now doing all their programming and within a few months they're going to start like leaping ahead in models completely made by AI. That was just made up. It's just not true. They're using the same coding agents that anyone else is using. So, uh, I get that. Um, we'll do one or two more small QL improvements for businesses, automatically sending text messages to</p>\n<p>confirm appointments a few days prior, things like that. Sure, you can call it AI, but none of that has to do with advances in language models that have taken all these billions of uh, investments. And then someone says, uh, fake videos and influencers pushing fascism. There is a lot of fake videos. That's not a good thing though. That's a bad thing. Um, and then I saw something else in here. I'll just write this down because I can't quite find it, but basically someone was talking about it's good for pulling out or summarizing complicated information and they talked</p>\n<p>about taking the municipal parking rules for where they lived and then chat GPT could kind of summarize them into something that's easier. So, make sense of complicated text. All right, whatever. We've been going for a while here, right? Let me look at this list I just wrote. So this is, you know, AI is a the world is going to be unrecognizable. It's the biggest thing that's ever happened to us. How why are our kids even going to college? Like this is where we are now. Here is the list of things from this open discussion on the internet. Anyone</p>\n<p>who can come and tell us how the billions invested recently AI have changed the world. Here is the the total list of non-computer programming uh ideas that came out of this pattern finding, producing slides, summarizing text in the bullet points, customer service agents, writing uh boring text automatically, and helping to make sense of complicated text. Those are cool, Jesse. But if I just if I five years ago said, imagine a tool</p>\n<p>that could do those six things. you weren't going to like Simpson style crash out of the window and then like jump on the back of a horse and ride off. It's like oh that's yeah it sounds like that good. I'm glad we're making progress on that. So it's kind of interesting and look I don't want to go too far here and be like this revolution doesn't matter. But when you put aside the computer programming stuff which is a discussion for another time it's complicated more complicated than people make it out to be but that's a discussion for another time. And when you put aside other AI stuff that's unrelated to all these billions we</p>\n<p>invested, what we are getting right now out of the whatever it is $500 billion that have been invested uh into Generative AI, there's not a ton of home runs yet. And I think this is an a difficult point for AI boosters is why there's a lot of like what is going to happen next year? And we've done this five years in a row now almost. what is going to happen next year is where the conversation goes</p>\n<p><strong>[12:08]</strong></p>\n<p>because I think it's hard not to admit the real concrete things are coming a little slower than we think. Now there we we see these amazing demos. We see these things do great on benchmarks and we have all these scary scenarios which are real like look at these fake videos. What's going to happen to truth or students can produce their papers on these things? But if we really think about it, the stuff that like what's changing your mind, people are using this like a better version of Google and then they're very narrow right now. Now, this doesn't mean much bigger changes aren't coming, but I thought this was an interesting sort of experiment to do</p>\n<p>that when we actually look at what has already come specifically from investing all of this money into gener. hard not to conclude that like so far um it's not massive yet. Hey, if you like this video, I think you'll really like this one as well. Check it out.</p>"}