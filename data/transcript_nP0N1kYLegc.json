{"video_id": "nP0N1kYLegc", "title": "\ud83d\udd2cGenerating Molecules, Not Just Models", "link": "https://www.youtube.com/watch?v=nP0N1kYLegc", "published": "2026-02-12T02:05:23+00:00", "summary": "This episode traces the remarkable journey from AlphaFold2\u2019s landmark achievement in protein structure prediction to the broader landscape of molecular interaction modeling and protein design. The problem AlphaFold2 addressed\u2014predicting the structure of single-chain proteins\u2014was long considered intractable due to its perceived NP-hard nature. The breakthrough came not only from advances in machine learning but also from leveraging evolutionary data to infer co-evolution of amino acids, providing powerful hints about spatial proximity in protein structures. Yet, as the guests explain, the field quickly moved beyond this milestone toward more complex questions, like how proteins interact, how they fold dynamically, and how to model these interactions with small molecules, RNA, and DNA.\n\nAlphaFold3 marks a critical shift in this evolution, moving from static structure prediction to modeling heterogeneous molecular interactions. Rather than treating these interactions as isolated problems, AlphaFold3 unifies them within a single model trained across modalities. This progress also reflects a broader trend in machine learning: the shift from regression-style prediction to generative models capable of expressing uncertainty and capturing system dynamics. By sampling from a distribution of plausible structures and interactions, these models allow researchers to better understand the flexibility and variability of biological systems. However, such models also introduce new challenges, particularly around validation and ranking of generated outputs.\n\nEnter Boltz and its suite of tools, which aim to democratize access to these cutting-edge capabilities. Boltz builds on open-source principles and a strong community foundation to deliver models that are both state-of-the-art and accessible, with a focus on usability, extensibility, and real-world validation. Boltz2 and BoltzGen combine structure prediction, affinity estimation, and generative design in one pipeline, enabling users to design new proteins and small molecules with high confidence. Notably, Boltz emphasizes the importance of experimental validation, collaborating with partners across academia and industry to test new designs in the lab. This feedback loop is essential to the iterative improvement of models and benchmarks.\n\nBoltzLab, the newly launched platform, encapsulates this vision by providing a cloud-based interface for running large-scale protein and molecule design campaigns. With support for both computational and experimental scientists, BoltzLab offers APIs, collaboration tools, and automated agentic workflows to make advanced molecular modeling accessible to users with varying levels of computational expertise. It embodies the shift from abstract model development to practical deployment, where infrastructure, cost-efficient compute, and user-friendly interfaces make a meaningful difference. As the guests emphasize, the real progress lies in enabling scientists to use these tools creatively and collaboratively to accelerate discovery in biology and medicine.\n\nTimestamps\n\n00:00 Introduction to Benchmarking and the \u201cSolved\u201d Protein Problem\n06:48 Evolutionary Hints and Co-evolution in Structure Prediction\n10:00 The Importance of Protein Function and Disease States\n15:31 Transitioning from AlphaFold 2 to AlphaFold 3 Capabilities\n19:48 Generative Modeling vs. Regression in Structural Biology\n25:00 The \u201cBitter Lesson\u201d and Specialized AI Architectures\n29:14 Development Anecdotes: Training Boltz-1 on a Budget\n32:00 Validation Strategies and the Protein Data Bank (PDB)\n37:26 The Mission of Boltz: Democratizing Access and Open Source\n41:43 Building a Self-Sustaining Research Community\n44:40 Boltz-2 Advancements: Affinity Prediction and Design\n51:03 BoltzGen: Merging Structure and Sequence Prediction\n55:18 Large-Scale Wet Lab Validation Results\n01:02:44 Boltz Lab Product Launch: Agents and Infrastructure\n01:13:06 Future Directions: Developpability and the \u201cVirtual Cell\u201d\n01:17:35 Interacting with Skeptical Medicinal Chemists", "transcript_html": "<p><strong>[00:00]</strong></p>\n<p>Actually, we only trained the big model once. Uh that's how much compute we had. We could only train it once. And so, like while the model was training, we were like finding bugs left and right. Uh a lot of them that I wrote. >> And like I would I remember like us like sort of like you know doing like surgery in the middle like stopping the run, making the fix, like relaunching and um yeah, we never actually went back to the start. We just like kept training it with like the bug fixes along the way. Uh which was >> impossible to reproduce now. Yeah. Yeah. No, that model is like has gone through such a curriculum that you</p>\n<p>know it's learned some weird stuff. Uh but uh yeah, somehow a miracle it worked out. >> It's a pleasure to have with us today Gabriella Corso and Jeremy Vulvin. They are they recently founded Boltz, a company trying to democratize and bring art, structure prediction and biology to you know the masses. uh they were both uh recent PhD grads from MIT and have been working on all sorts of foundational papers in like generative biology. Um anyway, uh pleasure to have you here. Thanks for coming.</p>\n<p>>> Thank you. >> Thank you. >> Thank you. >> Uh I guess we're maybe what 6 years post Alphold 2 right now, which was like kind of a big moment. >> Um is that right? Yeah. >> I think was it 2021? >> So yeah, on going on 5 years. >> 5 years. 5 years. Yeah. Um, yeah. So maybe for the audience like can can let's go back to that moment in time and explain like what was this big moment and why was it interesting? Why was everyone so excited and I think you two were probably quite excited. So why were</p>\n<p>you personally excited? >> I would start on kind of why that was interesting kind of you know from a scientific standpoint. So Alpha so maybe first as a kind of introduction for uh the ones in the audience and not structural biologists. So the idea of structural biology is that you know we want to try to understand how you know proteins and other molecules take shape inside our cells and you know how they interact and structural biology is sort of this beautiful discipline uh</p>\n<p>where we are somehow able to understand this minuscule structure at know kind of atomic details using uh these incredibly um complex methods like you X-ray crystalallography and you know the the dream has always been of computational biology. Can we understand kind of the structures without having to you know resolve this crystal you know shoot X-rays and so on. And so Alphafold um was a real breakthrough in this problem</p>\n<p>of protein folding which is trying to understand the structure of a single uh protein. And to me it was exciting across kind of many dimensions. One I was a computer scientist. I was working a lot on machine learning. And I saw kind of the impact that kind of the work similar somewhat similar to what I was</p>\n<p><strong>[03:00]</strong></p>\n<p>doing could have on like a longstanding scientific problem. And on the second perspective from a more you know personal side, the seeing kind of the structures coming out of these models where you know you see kind of this beautiful you know um creation of life is something that was was very inspiring to me and so that was kind of one of the things that led me to start uh working on uh structural biology and in particular with machine learning. >> Were you a structural biologist before</p>\n<p>Alpha Flood came out? I mean did you you did machine learning but it was not in structural biology so that actually shifted your career quite dramatically. >> Yeah very dramatically. I was I was working on some pretty kind of theoretical methodological things and I was starting to see kind of you know some of the challenges in you know kind of doing somewhat theoretical or methodological work and you know seeing kind of the potential impact of you know doing excellent you know alpha fold was really a machine learning breakthrough</p>\n<p>but you know and applied machine learning and so that led me to uh want to start working in applied ML. our our group at the time was um working a lot on like small molecules already and um I think alpha is kind of what triggered I think this shift to like working on on biologics um and at the time I think it like opened as many questions you know as it answered in a sense like we um the immediate follow-ups were okay like can we do this on other things than proteins can we do um you know interactions of</p>\n<p>small molecules with proteins nucleic acid with proteins Can we model more complex protein systems? And I think yeah very rapidly I think after alpha fold uh people realized I think that there was you know machine learning could have a could really yeah sort of target this problem very differently than you know than previous methodologies >> clarification. So what what does small molecule mean? What does protein mean? What is you know the terms that you just mentioned?</p>\n<p>>> Yeah maybe we can start with protein. Um, so you know, protein is is maybe the most fundamental one. It's what gets decoded out of our DNA. >> Um, it's uh essentially a sequence of uh amino acids. Each amino acid you can kind of consider as a we call a small molecule. Um, and there's 20 of them in the at least in the human body. Um, and you know any compositions of these 20 amino acids in a sequence um you know creates a different form of a protein. Um and so you know obviously they are a</p>\n<p>very large number of those sequences that you can create. Um small molecules are sort of you know following the name um typically considered to be um you know a much smaller number of atoms. Um and the atoms that compose them I think are also generally a bit more diverse right amino acids have um you know this composition and it's always the same. uh</p>\n<p><strong>[06:03]</strong></p>\n<p>with small molecule you know there's a larger set of possible atoms that also we have to consider that also make the problem uh pretty challenging and then we have nucleic acids so DNA and RNA uh which are also very interesting to model the structure for and those a little bit more similar to proteins you know they're sort of composed of four um nucleic acids and you form sequences from them and um any uh codon which is like three uh nucleic acid um translates into a specific amino acid. Um so yeah, different forms of molecules at the end</p>\n<p>of the day just a bunch of atoms uh you know that are bonded together uh that we try to understand the interaction of. >> Going back to the alpha fold 2 moment like um I remember this very well. I was at uh Nurifs when I guess the results of this famous competition came out. So um you can you want to talk about CASP and like what it is and why it is it was so interesting and exciting. >> Yeah, I think every so um every couple years um and the goal has always been to</p>\n<p>you know find u protein structures that are a little bit different from what's known. So CASSP over the years has like you know put in a lot of effort to like gather structures from you know academic groups and uh even industry groups uh to try to create sort of a test set that would be um difficult um for uh different methods and CASP uh 14 was when uh Alpha 2 really you know blew everything out of the water. Um and the</p>\n<p>the improvement was so large over you know the previous previous method and also over the previous competitions. Um and now CASP continues you know we've had CAS 15 we have CAT 16 and you know sort of what's happened now is that it's really expanding to also all these other modalities like I was mentioning like protein small molecule nucleic acid and u but the goal remains to like you know really challenge the models like how well do these models generalize and you know we've seen in some of the latest GAS competitions like while we're become</p>\n<p>really really good at proteins basically monomeic proteins um you know Adamal is remain pretty difficult. So it's really essential you know in the field that there are like these efforts to um you know to to to gather um you know benchmarks that that are challenging so keeps us in line you know about what the models can do or not. >> Yeah. >> It's interesting you say that like in some sense cast you know at cast 14 a problem was solved and like pretty comprehensively right but at the same</p>\n<p>time it was really only the beginning. So can you explain like what was the specific problem you would argue was solved and then like you know what is remaining which is probably quite open. >> I think I think we'll we'll steer away from the term solved because we have many friends in community who get pretty upset at that word and I think you know</p>\n<p><strong>[09:04]</strong></p>\n<p>fairly so. Um uh but the the problem that was um you know that a lot of progress was made on um was the ability to predict the structure of single chain proteins. So proteins can like be composed of many chains and single chain proteins are you know just a single sequence of amino acids and uh one of the reason that we've been able to make such progress is also because um we take a lot of uh hints from evolution. So the way the models work is that you know</p>\n<p>they sort of decode a lot of hints um that that comes from evolutionary landscapes. So if you have like you know some protein in an animal and you go find the uh similar protein across like you know different organisms uh you might find different mutations um in them. And as it turns out if you uh take a lot of these sequences together and you analyze them you see that uh some positions in the sequence tend to evolve um at the same time as other positions of the sequence. sort of this like uh correlation between different positions</p>\n<p>and um in it turns out that that is typically a hint that these two positions are close in three dimension. So part of the you know part of the breakthrough has been like our ability to also decode that very very effectively. uh but what it implies also is that you know in absence of that co-evolutionary landscape the models don't quite perform as well and so you know I think when that information is available maybe one could say you know the the problem is like somewhat solved</p>\n<p>from the perspective of structure prediction >> when it isn't it's it's much more challenging and I think it's also worth also differentiating the um sometime we confound a little bit structure prediction and folding folding is the more complex process of actually understanding like how it goes from like this disordered state into like a structured like state and that I don't think we've made that much progress on but the idea of like yeah going straight to the answer uh we've become uh pretty good at. So there's this protein that is like just a long chain and it folds up.</p>\n<p>Yeah. And and so we're good at getting from that long chain in whatever form it was originally to >> the thing, but we don't know how it necessarily gets to that state and there might be intermediate states that it's in sometimes that we're not aware of. >> That's right. And and that relates also to like you know our general ability to um model like the different you know proteins are not static. they move, they take different uh shapes based on their energy states. And I think we are also not that good at understanding the</p>\n<p>different states that the protein can be in and at what frequency, what probability. >> Um so I think the two problems are quite related in some ways. Um so yeah, still still a lot to solve. Um but I think the it was yeah I think I think it was very surprising at the time you know that uh</p>\n<p><strong>[12:05]</strong></p>\n<p>even with these evolutionary hints that we were able to you know to make such such dramatic progress. >> So I want to ask why does the you know sort of like intermediate states matter but first I kind of want to understand why do we care what proteins are shaped like? Yeah, I mean the proteins are kind of the machines of uh our body. You know the way that all the processes that we have in our cells, you know, work is typically through proteins, sometimes other molecules sort</p>\n<p>of intermediate, you know, interactions and through that interactions, we have all sorts of cell functions. And so when we try to understand you know a lot of biolog how our body works how disease work we often try to boil it down to okay what is going right in case of you know our fun normal biological function and what is going wrong uh in case of the disease state and we boil it down to kind of you know proteins and kind of</p>\n<p>other molecules and their interaction. And so when we uh we try predicting the structure of proteins, it's critical to you know have an understanding of kind of those those interaction. It's a bit like um seeing the difference between having kind of a list of parts that you would put it uh in a car and seeing kind of the car uh in its final form. You know, seeing the car really helps you uh kind of understand what it does. Yeah. >> Uh on the other hand, kind of going to</p>\n<p>your question of you know why do we care about you know um how the protein folds or you know how the car is made uh to some extent is that you know sometimes when it something goes wrong you know there are you know cases of you know proteins misfolding in some diseases and so on. Um if we don't understand uh this folding process we don't really know how to uh intervene. >> Okay. And so do proteins when they're in the body, do they are they typically in</p>\n<p>that folded state or are they kind of just like you know doing whatever until they're in a location where they need to interact with something? That's a great question. Uh and it really depends on the protein. Uh it depends on basically the stability of the protein. There are some proteins that are very stable and so once they are produced you know from the ribosome they sort of fold in this shape then more or less they keep that shape with a minor variations. >> The ribosome is the part of the cell that actually translates and and turns</p>\n<p>DNA to RNA to proteins. >> RNA to proteins that final part of RNA to proteins. >> And so once they come out they're pretty stable. Uh but then on the other hand there are some that you know for example have multiple states that they switch to depending on their environment. You know uh the bi biologists really figure out</p>\n<p><strong>[15:06]</strong></p>\n<p>some incredible machines. Uh there are machines where you know proteins where you know depending on whether for example another molecule is present not they will take different shapes and that different shape will give it a different function. And so we have this you know so-called fault switching uh proteins that take multiple and we have some proteins that are completely disordered and these disorder proteins are actually pretty important in kind of many diseases and those are kind of ones of the ones that we have you know the least</p>\n<p>understanding of >> there's this nice line in the um I think it's in the full 2 manuscript where they sort of discuss also like why we even hopeful that we can target the in the first place. And then this this notion that like um well four proteins that fold um the folding process is almost instantaneous which is a strong like you know signal that like yeah like we we might be able to um you know predict that this very like constrained uh thing that that the protein does so</p>\n<p>quickly. Um, and of course that's not the case for, you know, for for all proteins and there's a lot of like really interesting mechanisms in the cells, but um, yeah, I remember reading that I thought, yeah, that's somewhat of an insightful insightful point. Um, yeah, >> I think one of the interesting things about the protein folding problem is that it used to be actually studied and part of the reason why people thought it was impossible, it used to be studied as kind of like a classical example of like an MP problem. uh like there are so many</p>\n<p>different you know type of you know shapes that you know this amino acid could take and so uh this grows combinatorily with the size of the sequence and so there used to be kind of a lot of actually kind of more theoretical computer science thinking about and studying pro problem protein folding as an MP problem and so it was very surprising also from that perspective kind of seeing machine learning So clear there is some you know</p>\n<p>signal in those sequences uh through evolution but also through kind of other things that you know us as humans we're probably not really able to uh to understand but that this uh models have have learned. Yeah. So and Andrew White we were talking to him a few weeks ago and he said that he was following the development of this and that there were actually uh AS6 that were developed just to solve this problem. So um yeah that like and that there were many many many</p>\n<p>many millions of computational hours spent trying to solve this problem before alpha fold. And just to be clear um one thing that you mentioned was that uh there's this kind of co-evolution of um mutations and that you see this again and again in different species. So explain why does that give us a good hint that they're close by to each other? >> Yeah. um like think of it this way that you know if I have you know some amino</p>\n<p><strong>[18:07]</strong></p>\n<p>acid that mutates um it's going to impact everything around it right in three dimensions and so it's almost like the protein you know through several probably you know random mutations in evolution like um you know ends up sort of figuring out that this other amino acid needs to change as well for the structure to be conserved. Uh so this whole principle is that the structure is probably largely conserved you know because there's this function associated with it. Um and so it's really sort of like different yeah different different</p>\n<p>positions compensating for for each other. >> I see. So the the those hints in aggregate kind of give us a lot of information about what is close to each other and then you can start to look at what kinds of folds are possible given the structure and then what where where what is the end state and therefore you can make a lot of inferences about what the actual total shape is. >> Yeah, that's right. It's almost like, you know, you have this big like three-dimensional valley, you know, where you're sort of trying to find like</p>\n<p>these like low energy states and um there's so much to search through that's almost overwhelming. Um but these hints, they sort of maybe put you in an area of the space that's already like kind of close to the solution, maybe not quite there yet. And and there's always this question of like how much physics are these models learning, you know, versus like just pure like statistics. And like I think one of the thing at least I believe is that um once you're in that sort of approximate you know area of the solution space then the models have like</p>\n<p>some understanding you know of how to get you to like you know the low energy uh low energy state and so maybe you have some some light understanding of of of physics but maybe not quite enough you know to to know how to like navigate the whole space well. So we need to give it these hints to like >> get it into the right valley and then it finds the the minimum or something. Yeah. >> One interesting uh explanation about how free works that I think it's quite insightful of of course doesn't cover kind of the entirety of of what does</p>\n<p>that is um that I'm going to borrow from uh Sergey Chico at MIT. And so he sees kind of alphaold and the interesting thing about Alphaold is got this very peculiar architecture that we have since you know um used and this architecture operates on this you know pair-wise context between amino acids and so the idea is that probably the MSA gives you this first hint about what potential uh amino acids are close to each other. >> MSA is m</p>\n<p>>> multiple sequence alignment. Exactly. This evolutionary exactly this evolutionary information >> and you know from this evolutionary information about potential contacts then is almost as if the model is sort of running some kind of you know da algorithm where it's sort of decoding okay these have to be closed okay then if these are closed and this is connected to this then this has to be somewhat close and so you decode uh this</p>\n<p><strong>[21:08]</strong></p>\n<p>that becomes basically a pair-wise kind of distance matrix and then from this rough pair-wise distance matrix. You decode kind of the actual potential structure. >> Interesting. So there's kind of two different things going on in the the kind of coarse grain and then the fine grain optimizations. Interesting. Yeah. >> Very cool. >> Yeah. You mentioned Alpha Fold 3. So maybe good time to move on to that. So the Alpha Flow 2 came out and it was like I think fairly groundbreaking for this field. Everyone got very excited. A few years later, Alpha Fold 3 came out</p>\n<p>and um maybe for some more history like what was the difference between Alpha what were the advancements in Alpha Fold 3 and then I think maybe we'll after that we'll talk a bit about the uh sort of how it connects to bolts but anyway yeah so after Alphaold 2 came out I mean um you know Jeremy and I got into the field and with many others you know the clear problem that you know uh was you know obvious after that was okay now we can do individual chains can we do interactions, interaction different proteins, proteins with small molecules,</p>\n<p>proteins with other other molecules and so >> so quick why why are interactions important? >> Interactions are important because to some extent that's kind of the way that you know these machines that you know these proteins have a function. You know the function comes by the way that uh they interact with other uh with other proteins and other molecules. actually in the first place you know uh the machines the individual machines are often as Jeremy was mentioning not made of a single chain but they're made of multiple</p>\n<p>chains and then these multiple chains interact uh with other molecules to give uh the function to uh those and on the other hand you know when we try to intervene of these interactions think about like a disease think about like a bio sensor or many other ways we are trying to design a molecules or proteins that interact in a particular way with what we would call a target protein or target. Um and so you know this problem after 2, you know, became clear kind of the the</p>\n<p>big uh one of the biggest problems in the field to to solve. uh many groups including kind of ours and others you know started making some kind of contributions uh to this problem of trying to model these interactions and Alpha 3 was um you know put a was significant advancement on the problem of modeling interactions and one of the interesting thing that uh they were able to do while you know some of the rest of the field that really tried to try to model different interactions separately</p>\n<p>ly you know how protein interacts with small molecules, how protein interacts other proteins, how RNA or DNA um have their structure. They put everything together and you know train a very large models with a lot of advances including kind of changing kind of some of the key uh architectural choices and managed to</p>\n<p><strong>[24:08]</strong></p>\n<p>get a single model that was able to set a new state-of-the-art performance across u all of these different kind of modalities whether that was protein small molecules is critical to developing kind of new drugs protein protein understanding you know interactions of you know proteins with RNA A and DNA and so on. >> So just uh to satisfy the AI engineers and in the audience, what were some of the key architectural and data changes that made that possible? >> Yeah. So one uh critical one that was not necessarily just unique to Alphaold</p>\n<p>3, but there were actually um a few other teams including ours in the field that proposed this was moving from you know modeling structure prediction as a regression problem. So where there is a single answer and you're trying to shoot for that answer to a generative modeling problem where you have a posterior distribution of possible structures and you're trying to sample uh this distribution and this achieves two things. one is starts to allow us to try to model um more dynamic systems as we</p>\n<p>said you know some of these structures can actually take multiple um multiple structures uh and so you know you can now you know model that you know through kind of modeling the entire distribution but on the second hand from more kind of core modeling questions when you move from a regression problem to a generative modeling uh problem you are really tackling the way that you think about uncertainty in the model in a different way. So if you think about,</p>\n<p>you know, I'm undecided between different answers, what's going to happen in a regression model is that, you know, I'm going to try to make an average of those different kind of answers that I had in mind. And uh when you have a generative model, what you're going to do is you know sample all these different answers and then maybe use a separate models to analyze those different answers and pick out um the best. So that was kind of one of the uh critical improvement. The other</p>\n<p>improvement is that they significantly simplified to some extent the architecture especially of the um final model that takes kind of those pair wise representations and turns them uh into an actual structure and that's now looks a lot more like a more traditional transformer than you know like a very um specialized equivariant architecture that it was uh in Alpha 4. So this is a bitter lesson a little bit. >> There is some aspect of a bitter lesson</p>\n<p>but the interesting thing is that it's very far from you know being like a simple transformer. I think one of um this field is one of the uh I would argue very few fields in uh applied machine learning where we still have kind of architecture that are very specialized and you know there are many people that have tried to replace these</p>\n<p><strong>[27:08]</strong></p>\n<p>architectures with you know simple transformers and you know there's a lot of debate in the field but I think kind of the uh most of the consensus is that you know the performance that we get from the specialized architecture is faster ly superior than what we get through a single transformer. >> Yeah. >> Can can you talk a bit about that like specialized architecture? Um I assume you're referring to triangle layers probably as the core idea or >> there's something uh maybe it's probably quite fundamental about the fact that we sort of model this in like a you know</p>\n<p>second order. So like instead of just the sequence we model every single pair and then to update every pair then we need to have these like sort of triangular type operations and um I think what's interesting about it is is is is a couple of things like one I think it relates a little bit to what the input is you know we talked about these multiple sequence alignments before and kind of this notion that like um you know we need to look at pairs of residues to try to understand you know</p>\n<p>maybe this initial like distance matrix like Gabri was talking about um and that's something that is very natural right to to model um in 2D um and and I think also there's something about the output as well I think where I think supervising you know over these pairs I think is also quite powerful you know it's this idea of telling the model hey like these two things are close to one another these two things are not um And doing that I think in in 3D is is maybe</p>\n<p>a bit more challenging. Um you know when I say 3D sorry I mean like so it's like 1D where we model the coordinates in three dimensions but doing that in like one dimension I think is probably more challenging for the model and and yeah I think to it's it's really survived the test of time. I mean you know this thing came out in 2021 and it's largely the same. I mean there's been this change to the the structure module that's been like largely simplified but where the a lot of the magic happens you know I think it's still it's still in the same place um with these like large like pair-wise interaction modeling</p>\n<p>>> um that's maybe like the most differentiated portion the other part I think that's in off three uh is sort of this moving away from modeling just at the amino acid level to actually sort of having um the model sort of alternate between um you know sort of atomic resolution modeling and then more like it's called token level which is like at the amino acid level that's also something that was introduced um that I think you know was particularly helpful in like you know modeling these other modalities like small molecule etc and like this idea of like coarse grain like</p>\n<p>um finer grain is I think that's actually quite popular I think in other areas as well so that's maybe like not too surprising but yeah I think this the fact that you for some reason you you know the models that have so much more inductive bias when you when you go you know into this 2D representation I think</p>\n<p><strong>[30:08]</strong></p>\n<p>is is is very interesting. >> So you you mentioned coarse and fine grain and that brings to mind the sort of ribbony diagrams of proteins that I've that everyone has probably seen. Can you actually pull up a like a molecule and kind of talk about what >> you know what the different components of that protein are we're looking at like with the spiral and the arrows and all those what components and those like what what level of uh granularity are we looking at h like how do we think about</p>\n<p>that how does a model think about that >> yeah so um there's actually a little image of our of our own bull platform. Um I have a protein here. Um and you actually like sort of see both uh the coarse grain and the finer grain here. So we have the sort of ribbon like structure here that is um you know representing these these different amino acids in the protein. But then like when we zoom in over this like interaction with the small molecule um then you see like sort of this at the atomic level</p>\n<p>like how these things like you know interact with one another. There's even like the actual like bond interactions uh here that are like shown. Um and yeah like you know we we go from like this very abstract representation of these things you know like the the sequence the graph of the molecule and and the goal is like every single atom should have a coordinate and um and you know ends up looking like something like this. It's actually pretty pretty elegant. I think this is like something that's nice really nice that this field has done is like it's made really beautiful visualizations of stuff which is like really nice to look at and yeah</p>\n<p>I mean this is this is this is one example >> and so the there's like okay um the there's like ribbons there there's like the coily ribbons there's arrows there's like some sort of like not coily ribbons like what do those mean how does someone think about those >> yeah so um we can zoom into a few different areas of the protein this one's actually a good example because there's a few different secondary structures here. So, um here you have, you know, we call an alpha helix. Um there essentially like sort of three</p>\n<p>categories. There's the alpha helyses. Um this is where it takes a little bit of like this like ribbon uh shape. Um there's here what we call a better sheet. Um which actually, you know, as the name says, uh sort of like ribbon going like this forming forming a bit of a of a sheet. And then you have um these more like loopy regions uh which look like more unstructured and those are you know the parts of the protein that are most flexible. they are super important. Uh you know maybe like one of the most</p>\n<p>like canonical you know drug modalities are antibodies and antibodies have like you know six of these loops that are like largely flexible but when they interact you know kind of come into this like fixed structure when interacting with the um you know with with its target. Um so harder to model and really critical to interactions. Um, and yeah,</p>\n<p><strong>[33:10]</strong></p>\n<p>those are largely the three sort of big families. >> Okay. And and as a, you know, as a structural biologist or just a biologist, when you look at that, so you you're basically looking, okay, here's the the sheet part. Here's the and then you're you're kind of saying, okay, that so that'll be bendy and then I have like these coils those like what what do those mean to you when you look at them? >> Yeah, I mean, you know, I I should say I am not a structural biologist by any any way, shape or form. Um but you know there's certain types of interactions that are more canonically associated with these different types of</p>\n<p>structures. Yeah. >> Um I think uh a more well-versed structural biologist you know could give you a more thorough answer than that. I don't know if you know anything more than I do but yeah um yeah and and and you know like we've seen for example this this maybe related to that point like we've seen um you know some of the early successes of protein design um being able to design a binder you know to to any any target um a lot of the early success was like these like very you know alpha helix centric type peptides which I think are um almost</p>\n<p>like bricks you know um and the models had like a pretty good understanding of those like kind of interactions and so like there was like good success with that and then took a little bit of time to like go from that to like you know more exotic uh binders and and things like that and so um yeah there's certainly a lot of um yeah a lot of important um interaction behaviors associated with with these structures. Yeah, >> another interesting thing that I think on the staying on the modeling machine learning side which I think is somewhat</p>\n<p>counterintuitive seeing some of the other kind of uh fields and applications is that scaling hasn't really worked kind of the same uh in this field. Um now you know models like alpha 2 and alpha 3 uh are you know still very large models but at the same time they in terms of parameters they're actually not very big. they are definitely below a billion parameters. You know, if you hear these days in LLM space, you know, a model with less than a billion</p>\n<p>parameters, you would think can do anything. But on the other hand, when you look at the computational cost of running these models, they are actually a lot more expensive than uh it is to run a language models because as Jeremy was saying, we go from instead of having sort of like quadratic operations, we now a cubic operation and and so it's interesting how right now in the field and and this is maybe related to you know having kind of less data or you know needing more inactive biases but we</p>\n<p>have um this ratio of you know amount of computation to parameters that is much much higher than in other in other places. >> Yeah, if I recall Alpha 2 was like what 70 million parameters something like that. >> Um yeah it's it's something like that. It's quite yeah it's quite small around 100 or so. Yeah. >> So like these these decisions of</p>\n<p><strong>[36:11]</strong></p>\n<p>triangle layers and like these for alpha 2 this like interesting equavarian architecture like really were priors that it baked in a lot of the physics of the system and also co-evolution data is I think people have argued that is kind of like almost like a database lookup of some sorts. It also sort of so that provides in some sense more parameters as well. Yeah, I mean it's uh it's more definitely the amount of like you know pure like compute flops, right? Is is very high and it's almost like more yeah more almost more like reasoning based</p>\n<p>maybe than like more just like information extraction. You know, I think one of the things that the part of the reason the LMS are so large isn't just because of their reasoning capability, but also because of like like the sheer quantity of information that they store. And I think here there's a little bit less of that, you know, and I think it's more about like, you know, decoding this input rather than maybe like memorizing as much of it. >> So is there like a loop in the architecture that allows it to compute more for per parameter? Like how does that work? Part of it is just you know exclusively this fact that instead of you know having operations that operate</p>\n<p>on the uh on the single chain they operate on the pair wise and so you instead of having like quadratic number of kind of interactions you have a cubic number of interactions and so that on its own you know leads you to have you know smaller kind of representation sizes but more representation that leads to more flops but fewer parameters. On the other hand, you know, there is actually also this idea of, you know, they somewhat similar to to reasoning where you recycle kind of this operation. from Alpha 4 2 but also kind</p>\n<p>of Alpha 4 3. They have this interesting framework where you know you start we as we were discussing kind of the input to the model is sort of like this initial understanding of the interactions either from the evolution of the multiple sequence but also potentially from what we call templates that are basically database lookup of similar structures. And so how the model works is that you know it decodes these and tries to understand a good you know potential rough structure of the pair wise</p>\n<p>interaction and then what you can do is basically do this recycling where you feed this uh kind of understanding back to the input of the model and then try to decode it again and people do this you know three or four times and you know in some cases you know I've even tried to do it uh tens of times and so you can see it as a very very early version of kind of reasoning uh or you know trying to uh to get. >> Yeah. So you you know uh Alpha 2 really cool, Alpha 3 really cool. Um but Alpha</p>\n<p>3 came with a catch and I think this catch was important for the development of you know bolts and so on. So >> yeah the catch was that it was an amazing paper nature uh paper but unfortunately they uh decided not to release the model. uh you know Alpha Fall 2 uh was open source and since then was was used I think the the reported</p>\n<p><strong>[39:12]</strong></p>\n<p>numbers is you know more than a million scientists. Alpha for free for you know commercial reasons that you know um did mine has since spin-off as a morphic lab that is now trying to become sort of like a new pharmaceutical company uh and decided to keep this model internal and and only use internally and now uh both you know we were in the field and you know building on top of models like Alphafold and so now we no longer add you know kind of the base starting point uh to build on top but even more importantly everyone in uh both kind of</p>\n<p>academic research and in industry no longer had access to these incredible models that you know was you know really useful to try to understand um kind of biologies but also try to develop new therapeutics. And so we um decided that you know to to take the the matter in our own hands and decided to kind of um try to obtain a model that was of similar accuracy. And so largely also you know using a lot of you know the uh</p>\n<p>information that was in the alpha free manuscript we went ahead and built boltzswan which was um the first fully open source kind of model to approach the the level of accuracy of of our fault 3 and you know along the way and and you know uh we can talk about it more but you know we realized that you know it was probably too ambitions to have you know to see this as a an academic project and you know there are a lot of things that were kind of missing and so um we decided to also</p>\n<p>start a public benefit company to push kind of this this mission of you know democratizing access to these models that we started with bolts one >> quick interjection I mean I remember this it was actually shocking how fast you got bolts one out like it was just like two or three months right >> I think we started in late May and it came in November if I remember correctly. So slightly longer but yeah. Yeah, it was relatively quick. I mean</p>\n<p>for what it's worth like >> you know we were working on some of the some similar ideas at the time. I think like we you know for example this idea of like having a diffusion model on top of um this like more this pair wise strong was something that we were we were exploring independently. Um now when the paper came out it was like really clear like especially for example on the data pipelines there was like so much that we were like not really doing and so um there was a lot to like catch up on. Um but we were already in a place I think where we had you know some</p>\n<p>experience working in you know with with the data and working with these type of models and I think that put us already in like a good place to you know to to produce it quickly and you know and I would I would even say like I think we could have done it quicker. The problem was like for a while we didn't really have the compute and so we couldn't really train the model and actually we only trained the big model once. Uh</p>\n<p><strong>[42:13]</strong></p>\n<p>that's how much compute we had. We could only train it once and so like while the model was training we were like finding bugs left and right. Uh a lot of them that I wrote and like I would I remember like us like sort of like you know doing like surgery in the middle like stopping the run, making the fix like relaunching and um yeah we never actually went back to the start. We just like kept training it with like the bug fixes along the way. Uh which was >> impossible to reproduce now. >> Yeah. Yeah. No, that model is like has gone through such a curriculum that you know it's learned some weird stuff. Uh</p>\n<p>but uh yeah, somehow by miracle it worked out. >> The other uh funny thing is that the way that we were training most of that model was through uh a cluster from the department of energy, but that's sort of like a share cluster that many groups use. And so we were basically training the model for 2 days and then it would go back into the queue and stay a week in the queue. And so it was it was it was pretty painful. And so we actually kind of towards the end um I caught up with with Deon the CEO of of Genesis and</p>\n<p>and basically I was telling him a bit a bit about the project and you know kind of telling him about this frustration with the computer. And so luckily, you know, uh he offered to kind of help and so we uh we got the help from Genesis to, you know, finish up the um the model otherwise it probably would have taken a couple of extra weeks of weeks. >> Yeah. >> Yeah. Bolt one. How did that compare to Alpha Fold 3? And then and then there's some progression from there.</p>\n<p>>> Yeah. So I would say kind of the bolts one but also kind of these other kind of set of models that came um around the same time were kind of approaching were a big leap from you know kind of the previous kind of open source models uh and you know kind of uh really kind of approaching the level of alpha 3. But I would say still say that you know even to this day there are you know some specific instances where uh alpha 3 uh works better. I think one one common</p>\n<p>examples is antibbody antigen uh prediction where you know alpha fold 3 still seems to have an edge uh in in many situations. Obviously these are somewhat different models. They are you know you run them you obtain different results. So it's it's not always the case that one model is better than the other but kind of in aggregate we still uh especially at the time so 3 is you know still having a bit of an edge we should talk about this more when we talk about volt but like how do you know one</p>\n<p>is one model is better than the other like so you I make a prediction you make a prediction like how do you know >> yeah so the easily you know the the great thing about kind of structure prediction and you know once we're going to go into the design space of designing new small molecule new proteins this becomes It's a lot more complex. But a great thing about structure prediction is that a bit uh like you know CASP was doing basically the way that you can evaluate</p>\n<p><strong>[45:14]</strong></p>\n<p>them is that you know you train uh the model on a structure that was you know released across the field up until a certain time. And you know one of the things that we didn't talk about that was really critical in all this development is the uh PDB which is the protein data bank is this um common resources basically common database where every uh biologist and uh publishes their structures and so we can you know train on you know all the structures that were put in the PTB until a certain date and then we</p>\n<p>basically look for recent structures. Okay, which structures look pretty different from anything that was published before? Because we really want to try to understand generalization and on this new structure we evaluate all these different models. >> So you just know when alpha 4 was three three was trained, you know when you're you intentionally train to the same date or something like that. >> Exactly. >> Right. Yeah. >> And so this is kind of the way that you can somewhat easily kind of compare these models. Obviously that assumes</p>\n<p>that you know the the training set >> you've always been very passionate about validation. I remember like diff doc and then there was like diff do l and dogen like you you really thought you've thought very carefully about this in the past like um yeah I mean actually I think dogen is like a really funny story that I think um I don't know I don't know if you want to talk about that it's an interesting like uh >> yeah I think one of the amazing things about putting things open source is that you know it um we get a ton of feedback from from the</p>\n<p>field and you know sometimes we get kind of great feedback of people really liking the model. But honestly, most of the times and you know to be honest that's also maybe the most useful feedback is you know people sharing about where it doesn't work. And so you know at the end of the day it's critical and this is you know also something you know across other fields of of machine learning it's always critical to set uh to do progress in machine learning set clear uh benchmarks and you know as you know you start you know doing progress</p>\n<p>of certain benchmarks then you know you need to improve the benchmarks and make them harder and harder and this is kind of the progression of you know how the field operates and so you know the example of of uh doctrine was you know we um published this initial uh model called diff do um in my first year PhD which was sort of like you know one of the early um models to try to predict uh bio kind of interactions between proteins small molecules um that we</p>\n<p>about a year after alpha 2 was published and now on the one end you know on these benchmarks that we were using at the I am uh diff was doing uh really well kind of you know uh outperforming kind of some of the traditional physics based methods but on the other hand you know when we started you know kind of giving these uh tools to kind of many</p>\n<p><strong>[48:17]</strong></p>\n<p>biologists and uh one example was uh that we collaborated with was the group of Nick Pitzy at Harvard. uh we not started noticing that there was this clear pattern where for proteins that were very different from the ones that we're trained on uh the models was was struggling. And so you know that seemed clear that you know this is probably kind of where we should you know put our focus on. And so we first developed you know with uh Nick and his group a new benchmark and then you know went after</p>\n<p>and said okay what can we change and kind of about the current architecture to improve this uh pattern and generalization and this is the same that you know we uh we're still doing today you know uh kind of where does the model not work you know and then you know once we have that benchmark you know let's try to uh throw everything we uh any ideas that we have at the pro >> and there's a lot of like healthy skepticism in the field which I think you know is is is great and I think you know it's very clear that there's a ton of things the models don't really work</p>\n<p>well on but I think one thing that's probably you know undeniable is just like the pace of pace of progress you know and how how much better we're getting you know every year and so I think if you you know if you assume you know any constant you know rate of progress moving forward I think you know um things are going to look pretty cool at some point in future was only 3 years ago >> yeah I mean it's wild like >> what? >> Yeah. Yeah. Yeah. It's one of those things like even being in the field, you don't see it coming, you know, and like I think Yeah. Um hopefully we'll, you know, we'll we'll continue to have as</p>\n<p>much as we've had the past few years. >> So, this is maybe an an aside, but I I'm really curious. You get this great feedback from the from the community, right, by being open source. Um my question is partly like okay yeah if you open source then everyone can copy what you did but it's also maybe balancing priorities right where you like all my customers are saying I want this like there's all these problems with the model yeah yeah yeah but that like my customers don't care right so like how</p>\n<p>do you how do you think about that >> yeah so I would say a couple of things one is you know part of uh our goal with bolts and you know this is also kind of established as kind of the mission of the public benefit company that we started is to democratize the access to these tools. But one of the reason why we realized that Boltz needed to be a company it couldn't just be an academic project is that putting a model on GitHub is definitely not enough to get you know chemists and biologists you</p>\n<p>know across you know uh both academia, biotech and and pharma to use your model to uh in their therapeutic programs. And so a lot of what we think about you know at Bolts beyond kind of the just the models is thinking about all the layers that come on top of the models to get you know from you know those models to something that can really uh enable</p>\n<p><strong>[51:19]</strong></p>\n<p>scientists uh in the industry. And so that goes you know into building kind of the right kind of uh workflows that take in kind of for example the data and try to answer kind of directly that those problems that you know the chemists and the biologists are asking and then also kind of building the infrastructure. And so this to say that you know even with kind of you know models fully open you know we see kind of a ton of um potential for you know um you know products in the space and um the</p>\n<p>critical part about a product is that even you know for example with an open source model you know running the model is not free you know as we were saying these are pretty expensive model and especially and maybe we'll get uh into this you know these is we're seeing kind of pretty dramatic inference time scaling uh of of these models where you know the more you run them the better the results are. Uh but there you know you start getting into a point that compute and compute cost becomes a critical factor and so putting a lot of</p>\n<p>work into building the right kind of infrastructure building the optimizations and so on really allows us to provide you know a much better service potentially to the open source models. But that to say you know even though you know with a product we can provide a much better service. I do still think and we will continue to put a lot of our models open source because the um the critical kind of role I think of open source models is you know helping kind of the community progress on the research and you know from which</p>\n<p>we we all benefit and so you know we'll continue to on the one end you know put some of our kind of base models open source so that the field can can build on top of it and you know as we discussed earlier we learn a ton from you know the way that the field uses and builds on top of our models but then you know try to build a product that gives the best experience possible to scientists um so that you know like a chemist or a biologist doesn't need to you know spin off a GPU and you know set</p>\n<p>up you know our open source model in a particular way but can just you know uh a bit like you know I even though I am a computer scientist machine learning scientist I don't necessarily you know take a open-source LLM and try to kind of spin it off. But, you know, I just maybe open um the Chipy app or CL code and just use it as an amazing product. Uh we kind of want to give the same experience to scientists around the world. >> I heard a good analogy yesterday that a surgeon doesn't want the hospital to</p>\n<p>design a scalpel, >> right? So, just buy the scalpel. You wouldn't believe like the number of people even like in my short time um you know between a full three coming out and and the end of the PhD like the um number of people that would like reach out just for like us to like run off a full three for them >> you know or things like that just because like um or bolts in our case</p>\n<p><strong>[54:21]</strong></p>\n<p>>> you know just because it's like not that easy you know to do that you know if you're not a computational person and I think like part of the goal here is also that you know We continue to obviously build an interface with competitional folks but that you know the models are also accessible to like a larger broader audience and and then that comes from like you know good interfaces and stuff like that. >> I think one like really interesting thing about Bolt is that with the release of it you didn't just release a model but you created a community. >> Yeah. >> Did that community it grew very quickly. Did that surprise you and like what is then the evolution of that community and</p>\n<p>how is that fed into Bolts? >> If you look at its growth, it's it's like very much like when we release a new model, it's like there's a big uh big jump. Um but yeah, it's I mean it's been great. You know, we have a Slack community that has like thousands of people on it. Um and it's actually like self-sustaining now, which is like the really nice part because, you know, it's it's almost overwhelming, I think. you know, to be able to like answer everyone's questions and help. It's really difficult, you know, with the the few people that we were, but it ended up that like, you know, people would answer</p>\n<p>each other's questions and like sort of like, you know, help one another. And so, the the the Slack, you know, has been like kind of yeah, self self sustaining and that's been that's been really cool to see. Um, and um, you know, that's that's for like the Slack bar, but then also obviously on GitHub as well. We've had like a nice nice community. Um you know I think we also aspire to be even more active on it you know than we've been in the past 6 months which been like a bit challenging you know for us but um yeah the the community has been has been really great and you know there's a lot of papers</p>\n<p>also that have come out with like new evolutions on top of bolts and um it's surprised us to some degree because like there's a lot of models out there and I think like you know sort of people converging on that was was really cool and you know I think it speaks also I think to the importance of like you know when when you put code out like to try to put a lot of emphasis in like making it like as easy to use as possible and something we thought a lot about when we released the the codebase um you know it's far from perfect but you know >> do you think that that was one of the factors that caused your community to</p>\n<p>grow is just the focus on easy to use make it accessible >> I think so yeah and we we've we've heard it from a few people over over the over the years now and um you know and some people still think it should be a lot nicer and and they're right >> uh and they're right but um Yeah, I think it was, you know, at the time maybe a little bit easier than than other things. The other I think part that I think led to to the community and to some extent I think you know like the somewhat the trust in the community and kind of what we what we put out is the fact that you know it's not really been</p>\n<p>kind of you know one model but and maybe we'll talk about it you know after bolts one you know there were maybe another couple of models kind of released you know uh or open source kind of soon after we kind of continued kind of that open source journey release bolts too where we are not only improving kind the structure prediction but also starting to do affinity prediction. So understanding kind of the strength of the interactions between these different</p>\n<p><strong>[57:22]</strong></p>\n<p>models which is this critical component critical property that you often want to optimize uh in discovery programs and then you know more recently also kind of protein design model. And so we've sort of been building this suite of of models that come together interact with one another where you know kind of there is almost an expectation that you know we we take very at heart of you know always having kind of you know across kind of the entire suite of different task the best or across the best model uh out there. So that it's sort of like uh our</p>\n<p>open source tool can be kind of the go-to uh model for everybody in the in the industry. >> I really want to talk about bold gen. But before that one last question in this direction. Was there anything about the community which surprised you? Were there any like someone was doing something and you're like why would you do that? That's crazy. Or that's actually genius and I never would have thought about that. >> I mean we've had you know many contributions. I think like some of the interesting ones like I mean we had you</p>\n<p>know this one individual who like wrote like a complex GPU kernel you know for part of the architecture um on on a piece of the funny thing is like that piece of the architecture had been there since Alpha 2 and I don't know why it took bolts for this you know office person to you to decide to do it but that was like a really great contribution we've had a bunch of others There's like you know people figuring out like ways to you know hack the model to do cyclic peptides like you know</p>\n<p>there's I don't know if there's any other interesting one cool one and and this was you know something that initially was uh proposed as you know as a message in the slack channel by by Tim O'Donnell was basically he was you know there are some cases especially for example we discussed you know antibody antigen interactions where the models don't necessarily kind of uh get the right answer what he noticed is that you the models were somewhat stuck into predicting kind of the the antibbody to interact with a part of the antigen that</p>\n<p>was incorrect. And so he basically um run the experiments. In this model, you can condition uh basically you can give hints. And so he basically gave uh you know random hints uh to the model basically. Okay, you should bind to this residue uh you should bind to the first residue or you should bind to the 11th residue or you should bind to the 21st residue. you know basically every 10 residue scanning the entire antigen and >> residues are the the >> the amino acids amino acid so the first amino acids the 11 amino acids and so</p>\n<p>on. So it's sort of like doing a scan and then you know conditioning the model to predict all of them and then looking at the confidence of the model in each of those cases and taking the top and so it's sort of like a very somewhat crude way of doing kind of inference time search but surprisingly you know for for antibbody antigen prediction actually kind of helped quite a bit and so there's some you know interesting ideas</p>\n<p><strong>[60:23]</strong></p>\n<p>that you know as a um obviously as kind of developing the model you say kind of you know wow this is why would the model you know, be so dumb. But, you know, it's it's very interesting and and that, you know, leads you to also kind of, you know, start thinking about, okay, how do I can I do this, you know, not, you know, with this brute force, but, you know, in a in a smarter way. And so, we've also done a lot of work on that direction. >> And that speaks to like the, you know, the power of scoring. Uh we're seeing that a lot. I'm sure we'll talk about it more when we talk about bulls gen. But um you know, our ability to like take a</p>\n<p>structure and determine that that structure is like good, >> you know, like somewhat accurate. uh whether that's a single chain or like an interaction is a really powerful you know way of improving you know the the models like sort of like you know if you can sample a ton and you assume that like you know if you sample enough you're likely to have like you know the good structure then it really just becomes a ranking problem. Um, and you know, now we're, you know, part of the inference time scaling that Gabri was talking about is is very much that it's</p>\n<p>like, you know, the more we sample, the more we like, you know, the ranking model ends up finding something it really likes. Um, and so I think our ability to get better at ranking, I think is also what's going to enable sort of the next, you know, next big big breakthroughs. >> Interesting. But I guess there's a my understanding there's a diffusion model and you generate some stuff and then you I guess it's just what you said, right? Then you rank it using a score and then you finally um and so like can you talk about those different parts?</p>\n<p>>> Yeah. So first of all like the one of the critical kind of you know beliefs that we had you know also when we started working on pulse one was sort of like the structure prediction models are somewhat you know our field version of some foundation models you know learning about kind of how proteins and other molecules interact and and then we can leverage that learning to do also to other things and so with Bolu we leverage that learning to do things uh affinity prediction So understanding</p>\n<p>kind of you know if I give you this protein these small molecules how tightly is the interaction uh for bolshen what we did was taking kind of that kind of foundation models and then fine-tune it to predict kind of entire new proteins and so the way basically that that works is sort of like instead of uh for the protein that you're designing instead of feeding in an actual sequence you feed in a set of blank tokens and you train the models to you know predict both the structure of</p>\n<p>kind of that protein and with the structure also what the different amino acids uh of um that proteins are. And so basically the way that uh bolt chain operates is that you feed a this a target a protein that you may want to kind of bind to or you know another DNA RNA and then you feed um the highle kind</p>\n<p><strong>[63:26]</strong></p>\n<p>of design specification of you know what you want your new protein uh to be for example it could be like an antibbody with a particular framework could be a peptide could be many other things >> and that's with natural lang language or >> and that's you know basically you know prompting and we have kind of this sort of like spec that you you specify >> and you know you feed kind of this this spec to the model and then the model translate this into you know a set of you know uh tokens a set of conditioning to the model a set of you know blank</p>\n<p>tokens and and then you know basically decodes as part of the um diffusion models decodes a new structure and a new sequence for your your protein and you know basically and then we take that and as Jeremy was saying you know trying to score it and you know how good of you know a binder it is to that original target that you you're using both basically bolts to to predict the folding and the affinity to that molecule. So and then</p>\n<p>that is your that kind of gives you a score. Is that >> exactly? So you you use this model to predict the structure and then you do two things. One is that you predict the structure >> and with something like bolts do and then you basically compare that structure with what the model uh predicted what bolshion predicted um and this is sort of like in the field calls consistency. It's basically you want to make sure that you know the structure that you're predicting is actually what you're trying to design and that gives</p>\n<p>you a much better confidence that you know that's a good design. And so that's the the first filtering and the second filtering that we did as part of kind of the the Bolshion pipeline um that was released is uh that we look at the confidence that the model has in the structure. Now unfortunately kind of going to your your question of you know predicting affinity unfortunately confidence is not a very good predictor of affinity um and so one of the things</p>\n<p>that we've actually done a ton of progress you know since uh we released Bolchen and kind of we have some uh new results that we are going to kind of announce soon is kind of you know the ability to get much better rates when instead of you know trying to rely on confidence of the model we are actually directly trying to predict the affinity uh of that interaction. >> Okay, just backing up a minute. So your diffusion model actually predicts not</p>\n<p>only the protein sequence but also the folding of it. >> Exactly. And actually kind of the way one of the big um kind of different things that we did compared to uh other models in the space and you know there were some uh papers had already kind of done this before but we uh really scaled it up was you know basically</p>\n<p><strong>[66:27]</strong></p>\n<p>somewhat merging kind of the structure prediction and the sequence prediction into almost the same task. And so the way that Bolsten works uh is that you are basically the only thing that you're doing is predicting the structure. So the only sort of like supervision is we give you a supervision on the structure but because the structure is atomic and you know the different amino acids have a different atomic composition basically from the way that you place the atoms. We also understand not only kind of the</p>\n<p>structure that you wanted but also the identity of the amino acid that you know the models believed was there. And so we've basically instead of you know having these two supervision signals you know one discrete one continuous that somewhat you know don't interact well together we sort of like build kind of like an encoding of you know sequences in structures that allows us to basically use exactly the same supervision signal that we using to bolts 2 that you know uh you know largely similar to what Alpha 3 uh</p>\n<p>proposed which is very scalable and we we can use that to design new proteins. >> Oh, interesting. >> Maybe a quick shout out to Hannes uh Stark on our team who like did all this work. Um yeah. >> Yeah, it was a really cool idea. I mean like looking at the paper and there's just this like encoding where you just add a bunch of I guess kind of atoms which can be anything and then they get sort of rearranged and then basically plopped on top of each other so that and then that encodes what the amino acid is</p>\n<p>and there's sort of like a unique way of doing this. It was that was like such a really such a cool fun idea. Yeah, >> I think that idea was had existed before. Yeah, there were a couple of papers that had proposed this and and analysts really took it to um to the large scale. >> In the paper, a lot of the paper for both gen is dedicated to actually the validation of the model. In my opinion, we talk a all the people we basically talk about feel that this sort of like in the wet lab or whatever the appropriate you know sort of val like in</p>\n<p>real world validation is the whole problem or not the whole problem a big giant part of the problem. So can you talk a little bit about the highlights from there that really because to me uh the results are uh impressive both from a the perspective of the you know the model and also just the the effort that went into the validation by a large team. First of all, I think I should tr start saying is that both when we were at MIT and Thomas Yakolas and Regina</p>\n<p>Barcel's lab as well as at Bolts, you know, we are not a we're not a biolab and you know, we are not a therapeutic company. And so to some extent, you know, we were first forced to, you know, look outside of, you know, our group, our um team to do the experimental validation. And so one of the things</p>\n<p><strong>[69:29]</strong></p>\n<p>that um really honest uh in the team pioneer was the idea okay can we go not only to you know maybe a specific group and you know trying to find a specific system and you know maybe overfitit a bit to that system and and trying to validate but how can we test these models across a very wide variety of different settings so that you know anyone in uh in the field and you know printing design is you know such a kind of wide um task with all sorts of different applications from therapeutic to you</p>\n<p>know bio sensors and uh many others that you know so can we get a validation that is kind of goes across uh many different tasks and so he basically put together you know I think it was something like you know 25 different you know academic and industry labs that you know sort of like committed to you know testing uh some of designs from the model and some of this testing is is still ongoing. uh and you know giving uh results kind of uh back to us in exchange for you know</p>\n<p>hopefully getting some you know new se new great sequences for uh their task and and he was able to you know coordinate this you know very wide uh set of you know uh scientists and uh already in the paper I think we uh shared uh results from I think uh 8 to 10 different uh labs uh kind of showing results from you know designing peptides uh designing uh to target you know ordered proteins, peptides targeting</p>\n<p>disordered proteins. We show results you know of uh designing proteins that bind to small molecules. Uh we showed results of you know designing nanobodies and across a wide variety of different targets. And so that sort of like gave to the to the paper a lot of you know validation and to the model a lot of validation that was kind of uh wide uh >> just uh again um for our nonbiologist uh audience peptides nanoparticles what are these things that are being designed</p>\n<p>why like what is interesting about these particular things why are is there focus in them >> yeah so largely you know they're all proteins it's just different shape the proteins they peptides uh is is a small protein uh and is you know a relatively common type of of therapeutic the very common examples these days are the you know GLP1 ompic right >> ompic and so on they're all peptides formed by both canonical and</p>\n<p>non-cononical amino acids um the when we think about kind of larger proteins there also can take different shapes There is you know maybe one of we have this term called mini proteins which is like a very vague term to say kind of any sort of shape. Uh but then there are</p>\n<p><strong>[72:31]</strong></p>\n<p>some specific shapes that you know proteins can take and um so one very common one is antibodies and antibodies are uh particular type of protein in our body that is involved uh in our immune system and it's formed by um basically a set of you know four different um protein chains you know two uh two heavy call heavy which are longer and to light that come together and form kind of this interesting structure and</p>\n<p>those are you know very common type also of therapeutic because of you know the function that they have in our immune system and finally there are kind of what are called nanobodies that I mentioned that are sort of like the equivalent of antibodies but on specific in specific animals so there are some animals and I think some examples are >> llamas camels and sharks that instead of having kind of this more complex set of you know four proteins coming together, it's a single protein</p>\n<p>and and so recent in recent years has been also a relatively common type of therapeutic uh that people are trying to design. And so these are sort of like have a similar function to antibodies but are simpler in terms of uh structure. >> And so those would be therapeutics for those animals or they relevant to humans as well? they're relevant to humans as well. Obviously, you need to do some work into uh quote unquote humanizing them, making sure that you know they have the right characteristic to so</p>\n<p>they're not uh toxic to humans and so on. Uh but there are um some approved medicine in the uh in the market there are no >> there's a general pattern I think in like in trying to design things that are smaller, you know, like it's easier to manufacture. Um at the same time like that comes with like potentially other challenges like maybe a little bit less selectivity than like if you have something that has like more hands you know um but the yeah there's this big desire to you know try to yeah design</p>\n<p>many proteins nanobodies small peptides you know that just are just great drug modalities >> and that that's because they're more selective. >> No generally I think it's largely a manufacturing thing. >> Oh okay I see. So it's you know the bigger the bigger the protein the more complex essentially. Yeah, >> I put a pin in. I want to understand like how do you actually build a protein? Like I know you guys are not wet lab technicians, but >> I want to like hear more about the validations that you've done. >> Um I can try</p>\n<p>>> essentially like so we work with uh organizations to do the the lab evaluation. um we we don't do any of it ourselves and typically what we send those people is we send them you know the sequence of the target and the sequence of the binder in this case for example an antibbody it would be like a single single chain uh we have to order the DNA that's yet another company that produces that DNA sends it over and then</p>\n<p><strong>[75:33]</strong></p>\n<p>you have to like express the proteins so you have to like express the target you have to express the binders and by expressing what I mean is like you put you know the the DNA uh typically in like you know either uh some capsid or you put it in like a and then you express it in like a yeast for example or you can like do it in like sulfury systems now but um essentially you know you you use like typical biological mechanism um to >> you're kind of like hijacking the yeast to create >> yeah you give it the extra DNA and you're like okay like create this thing</p>\n<p>>> so so you want to this is like um you're amplifying the DNA in some way is that basically >> yeah yeah so there yeah so they're jumping some steps there's like a yeah amplifying the DNA there's all this stuff and then um but at the end of the day the you starts to produce a lot of this protein then you need to purify it because there's a lot of other stuff in there so typically you have like a tag on the protein and then like based on that tag you can sort of purify um once you have like your pure target your pure binder you can then like run your binding assay and then that's where my</p>\n<p>knowledge stops but there's various methods to do that uh you know you put things in a well and then you can measure um the you know the the binding strength um and then we get the results back um and we also get to know like you know whether it was a binder but also like how strong of a binder it was um and that's generally the the process >> right so so that you kind of you specify the molecule they create some DNA that can create the RNA they create some RNA</p>\n<p>from that that creates the >> uh the protein You take the protein and you use lab voodoo to measure the the binding strength of that or the two proteins or two molecules. >> Yeah. Okay. That's right. >> Okay. So, we were I think we were left off we were talking about >> validation in the lab and I was very excited about seeing like all the diverse validations that you've done. Can you</p>\n<p>>> Yeah. >> go into some more detail about them >> specific ones? Yeah, the nanobbody one I think we did what was it 15 targets is that correct 14 >> 14 targets um testing um so we typically the way this works is like we uh make a lot of designs all right on the order of like tens of thousands and then we like rank them and we pick like the top n uh in this case n was 15 right um for each target and then we like measure sort of like the success rates both on like how</p>\n<p>many targets we were ble to um to get a binder for and then also like more generally like out of all of the you know binders that we designed how many actually proved to be uh good binders. Some of the other ones I think involved like yeah like we had a a cool one where there was a small molecule or design a protein that uh you know binds to it. Um that has a lot of like interesting</p>\n<p><strong>[78:34]</strong></p>\n<p>applications you know for example like Gabby mentioned like biosensing and things like that uh which is pretty cool. Um we had we had a disordered protein I think you mentioned also. Um and yeah I think some of maybe some those were some of the the highlights. >> Yeah. So I would say that the way that we structure kind of some of those validations was on the one end we have validations across a whole set of different problems uh that you know the biologists that we're working uh with came to us with. So we are trying to uh</p>\n<p>for example in some of the experiments design peptides that would uh target rack C which is uh a target that is involved in metabolism. Um we had you know number of other uh applications where we were trying to design you know peptides or other modalities against some other therapeutic relevant targets. Um we designed some um proteins to bind small molecules and then some of the other uh testing that we did was really</p>\n<p>trying to get like a more broader sense of how does the model work especially when tested you know on somewhat generalization. So one of the things that you know we we found uh with the field was that a lot of the validation especially outside of the validation that was done on specific problems was done on targets that have a lot of you know known interactions in in the training data. And so it's a bit always a bit hard to understand, you know, how much are these models really just</p>\n<p>regurgitating kind of what they've seen or trying to imitate what they've seen in training data versus, you know, really be able to design uh new proteins. And so one of the experiments that we did was to uh take nine targets from um the PDB filter into things where there is no known interaction. uh in in the PDB. So basically the model has never seen kind of this particular</p>\n<p>protein bound or a similar protein bound to another protein. So there is no way that the model uh you know from its training set can sort of like say okay I'm just going to uh kind of >> tweak something >> tweak something and and just imitate this particular kind of interaction and and so we we took those nine proteins we worked with adaptive CRO and basically tested you know 15 mini proteins and 15 nanobodies against each one of them and the very cool thing that we saw was that</p>\n<p>on twothirds of those targets we were able to from these 15 designs uh get uh nanomolar uh binders. Nanomolar roughly speaking is just a measure of you know how strongly kind of the interaction is and roughly speaking kind of like a nanomolar binder is approximately the kind of binding strength of binding that you need for a therapeutic.</p>\n<p><strong>[81:36]</strong></p>\n<p>>> Okay. >> Yeah. So maybe switching uh directions a bit. Um so I I Boltz Lab was just announced um this week or was it last week? Yeah. >> Um uh this is like your first I guess product if if that's the if you want to call it that. Um can you talk about what Bolts Lab is and um yeah you know what you hope that people take away from this. Yeah, you know, as we mentioned like I think at the very beginning is the goal with the product has been to,</p>\n<p>you know, address what the models don't on their own. Um, and there's largely sort of two categories there. Um, you know, or let's say let's say I'll split it in three. Um, the first one is that you know it's one thing to predict you know a single interaction for example like a single structure. Um it's another to like you know very effectively uh search a space a design space you know to to produce something of value and you</p>\n<p>know what we've what we found like sort of building up this product is that there's a lot of steps involved you know in that that we sort of need to like you know accompany the user through. Um you know one of those steps for example is like you know the the creation of the target itself. you know, how do we make sure the model has like a good enough understanding of the target so we can like design something and there's all sorts of tricks, you know, that you can do uh to improve like a particular, you know, structure prediction. And so that's sort of like you know the first stage and then there's like this stage of like you know designing and searching</p>\n<p>the space efficiently you know for something like BSG for example like you you know you design many things and then you rank them for example for small molecule the process is a little bit more complicated. we actually need to also make sure that uh the molecules are synthesizable. And so the way we do that is that you know we have a generative model that um learns to use like appropriate building blocks such that you know it can design within a space that we know is like synthesizable. And so there's like you know this whole pipeline really of different models involved you know in being able to um to</p>\n<p>design a molecule. And so that's been sort of like the first thing we call them agents. We have a protein agent and we have a small molecule design agents. And that's really like at the core of like what powers, you know, the post platform. >> So these agents are are they like a language model wrapper or they're just like your models and you're just calling them agents because they they they sort of perform a function on behalf of >> they're more of like a you know a recipe if you wish and I think uh we use that term sort of because of you know sort of</p>\n<p>the complex pipelining and automation you know that goes into like all this plumbing. Um so so that's the first part of the product. Um the second part is the infrastructure. You know we need to be able to do this at very large scale for any one you know group that's doing a design campaign. Um you know let's say you're designing you know let's say a 100,000 possible candidates right to find the good one. Um that is you know a</p>\n<p><strong>[84:38]</strong></p>\n<p>very large amount of compute. Uh you know for small molecules it's on the order of like a few seconds per uh per design. for proteins can be a bit longer and so you know ideally you want to do that in parallel otherwise it's going to take you weeks um and so you know we've put a lot of effort into like you know our ability to have a GPU fleet that allows any one user you know to be able to do this kind of like large parallel search >> so you're amvertising the cost over your your users basically >> exactly and you know to some degree like it's whether you do uh you use 10,000 GPUs for like you know uh a minute is the same cost as using you know uh one</p>\n<p>GPUs for god knows how long, right? So, you might as well try to paralyze if you can. So, you know, a lot of work has gone has gone into that making it very robust, you know, so that we can have like a lot of people on the platform doing that at the same time. Um, and and the third one is is the interface and the interface comes in in two shapes. one is um in form of an API and that's you know um really suited for companies that want to integrate you know these pipelines these agents directly in existing you know workflows that they</p>\n<p>have or like existing user interfaces that they have and we're already like partnering with you know a few distributors you know that are going to integrate our API and then the second part is the the act the user interface and you know we we've put a lot of thoughts also into that and this is when I I mentioned earlier you know this idea of like broadening the audience that's kind of what the the user interface is about and we've built a lot of interesting features in it. You know, for example, for collaboration, um you know, when you have like potentially multiple medicine chemists are going through the results and trying to pick out, okay, like what are the molecules</p>\n<p>that we're going to go and test in the lab, it's powerful for them to be able to, you know, for example, each provide their own ranking and then do consensus building and um so there's a lot of features around, you know, launching these large job, but also around like collaborating on analyzing the results um that we try to solve, you know, with with that part of the platform. So, Boltz Lab is sort of combination of these three objectives into like one, you know, sort of cohesive platform. >> Who is this accessible to? >> Everyone. Uh, you do need to request access today. We're still like, you know, sort of ramping up the usage. Um, but anyone can request access. Um, if</p>\n<p>you are an academic in particular, uh, we uh, you know, we provide um, you know, a fair amount of free credit. So, you can like play with the platform. If you are a startup uh or a biotech, you may also, you know, reach out and we'll typically like actually hop on a call just to like understand what you're trying to do and um also provide a lot of free credit to to get started. Um and uh of course also with larger companies uh you know we uh we can deploy this this platform in a more like secure environment and so that's like more like custom you know uh deals that we make</p>\n<p>you know with with the partners. Um, so you know that and that's sort of that the ethos of Bolt. I think this idea of like uh servicing everyone and not necessarily like going after just you know the um the really large enterprises. Um and that starts from the open source but it's also you know main a key key design principle of of the</p>\n<p><strong>[87:38]</strong></p>\n<p>product itself. >> Yeah. >> One thing I was thinking about with regards to infrastructure like in the LLM space you know the cost of a token has gone down by I think a factor of a thousand or so over the last three years right. Yeah. >> And is it possible that like essentially you can exploit economies of scale and infrastructure that you can make it cheaper to run these things yourself than for any person to roll their own >> 100%. Yeah. I mean we're already there you know like running bolts on our platform especially on in a large screen is like considerably cheaper um than it would probably take anyone to put the open source model out there and run it.</p>\n<p>And you know on top of the infrastructure like one of the thing that we've been working on is is accelerating the models. So you know our our small molecule screening pipeline is 10x faster on bolts lab than it is in the open source. Um you know and that's that's also part of like you know building building a a product you know of something that that scales really well. Um and yeah uh we really wanted to get to a point where like you know we could keep prices uh very low um you know in in a way that it would be a no</p>\n<p>no-brainer you know to to use bolts through through our platform. How do you think about validation of your like agentic systems? Because you know as you saying earlier like we're alphafold style models are really good at let's say monomeic you know proteins where you have you know co-evolution data but now suddenly the whole point of this is to design something which doesn't have >> you know co-evolution data something which is really novel. So now you're basically leaving the the domain that you thought was you know that you you</p>\n<p>know you were good at. So like how do you validate that? >> Yeah. Um I mean I I like Gabri complete but there's um there's obviously you know a ton of computational metrics that we rely on but those are only take you so far. Um you really got to go to the lab you know and and test you know okay with this method A and this method B uh how much better are we you know how much better is my uh my hit rate? How stronger are my binders? Also it's not just about hit rate it's also about how how good the binders are. And there's really like no way no way around that.</p>\n<p>And I think, you know, we've really ramped up the amount of experimental validation um that we do so that we like really track progress, you know, as scientifically sound, you know, as as possible. um out of this I think. >> Yeah. Know I think you know one thing that is unique about us and maybe companies like us is that because we're not working on like maybe a couple of therapeutic uh pipelines where you know our validation would be focused on those. We when we do an experimental validation, we try to test it across</p>\n<p>tens of targets. And so that on the one end we can get a much more statistically significant um results and and really allows us to make progress from the methodological side without being you know steered by you know overfitting on any one particular system. And of course we choose you know we always try to choose uh targets and problems are sort</p>\n<p><strong>[90:41]</strong></p>\n<p>of like at the frontier of what's possible today. So you know you don't want something too easy you don't want something too hard otherwise you're not going to see progress. And so you know this is a somewhat evolving set of targets. We talked earlier about the targets that we looked at with with bolt and now we are even trying kind of you know even harder targets both for molecule and proteins. And so we try to keep oursel on the on the boundary uh of what's possible. >> So do you have like infrastructure or this is like you just have a lot of different partnerships with academic labs and you're just going to keep</p>\n<p>pushing on these and driving these? We do partially this through academic labs but more and more we do this through uh CRO just because of you know to some extent is also we need kind of replicability often kind of you know going after the same targets you know multiple times and you know to see the the progress from you know one month to the next >> and speed of execution. Yeah. >> And so what happens if you start getting a bunch of like really strong biters against therapeutic targets? What do you do? >> Um I miss them. Yeah.</p>\n<p>>> In open sort like >> Yeah. I mean, you know, I mean, when we say we have no interest in making dress, we're serious like you know, uh I mean when it when it was with the academic labs basically, you know, it was they keep it, they do whatever they want with it. And with the with the CRO so far, yeah, we've been we've been very Yeah. releasing releasing them. You know, I I will also say and and I think this is a bit been a bit of the issue that I I have with with some of kind of the things I've been said in the field is like when we say that we design new</p>\n<p>proteins or we say that we design new molecules, you know, uh that you know go and bind these particular targets, >> we should be very clear, you know, these are not drugs, you know, these are not things are ready to be put into into a human And there is still a lot of development that that goes with it. And so this is this is kind of to to us you know we see oursel as you know building tools for scientists. You know at the end of the day you know it really relies on the scientist having a great</p>\n<p>therapeutic appease and then pushing through kind of all the stages of development and you know we try to build tools that can accompany them uh in that journey. We It's not like a a magic box where, you know, uh you can just turn it and get >> get FDA approved drugs, >> FDA approved drugs, FDA approved drugs. Um, yeah. But but actually that brings up an interesting question that I have I've been wondering about is do you guys see yourself like staying in this like this for lack of a better way of saying</p>\n<p>it layer or do you think that you'll start to like either on the physical sense looking at different layers of the virtual cell so to speak or um also you know so there's the like the development process that goes you know sort of like design preclinical clinical approval and thinking about</p>\n<p><strong>[93:43]</strong></p>\n<p>like improving the performance throughout that process based on the designs. Is that a direction that you guys are pushing? >> Yeah. So one of the things as Jeremy said you know we are not a therapeutic company and we want to kind of stay not to be a therapeutic company always be at the service of you know all the different you know companies including therapeutic companies that we serve and you know that to some extent does mean you know that we need to try to you know go deeper and deeper in getting these models better and better. One of the</p>\n<p>things that we are doing across you know uh many other uh in the field is you know now that we already they're start to be good both for small molecule and for proteins to design kind of binders designed relatively tight binders is starting to look at all these other properties you know called developabilities or atme that you know we care about when developing a drug and trying can we uh design them from uh from get and the thing about those properties in some of them, you know, um</p>\n<p>you need to, you know, start having an understanding of of the cell and and so that's on the one hand kind of why we need that understanding, but also, you know, the way that we also think about kind of, you know, um all different and complex diseases is that these models and these tools that we're building have a good understanding of kind of, you know, biomolelecular interactions and kind of their interactions. Now at the same time every disease is often kind of unique and every therapeutic hypothesis is unique and so you maybe want to have</p>\n<p>something that um needs to uh hit the particular you know um let's say target uh in in a virus in a particular way but you don't maybe know exactly what uh way you want to do. And so maybe in the first set of designs, you're going to try to target different epitopes in different ways and then you're going to test them in the lab, maybe directly in vivo, and you're going to see which ones work and which one don't. And so then you need to bring those results back</p>\n<p>into the models. And then the models can start to have a more uh wider understanding you know not just of the biohysical of the uh antibodies interacting with that target but also how that is shaped within the entire uh the entire cell. And so first of all you know that means on the one end that we need you know kind of these loops and this is also partially how we we design the platform to be but that also means that we also need to start understanding more and more kind of higher level things and you know I wouldn't say that</p>\n<p>we're working in any way on like a virtual cell like others are but we're definitely thinking kind of very deeply about kind of you know how does you know kind of the way that we target um certain proteins interfere here interact with you know maybe pathways that are existing in the cell. >> One question that has come up is you talk a lot about user interface and so</p>\n<p><strong>[96:43]</strong></p>\n<p>on and I think this is really important but like my experience with dealing with medicinal chemists when you give them machine learning models is they are the most superstitious skeptical like pseudo religious people I've ever talked to when it comes to doing science. So sorry for the medicinal chemist. Yeah, they're they're amazing. Like they're absolutely I've worked with some spectacular medicinal chemists who just pull magic out of their hat again and again and I have no idea how they do it. But when you bring them a machine learning model, it is sometimes quite tricky to get them to deal with it. How how has your</p>\n<p>interaction been with this and how have you thought about like building Boltz Lab to work with the skeptics? One of the great value unlocks for us and for our product has been when we brought to the team um m chemist his name is Jeffrey. So I think kind of like on the one end you know day one you know he obviously had a lot of opinions on kind of a lot of the ways that we should uh change you know both kind of the way that the agents worked the way that the platform worked. Uh but it's been really amazing kind of you know once also we</p>\n<p>started kind of shaping kind of the platform uh in a better way with with this feedback how we went from you know some extent you know fair skepticism to him you know actually using a lot more compute than any of our computational uh folks in the team you know um at times that you know he's you know running you know he has all these sort of tur uh hyp hypothesis. Okay, maybe I can hit this protein this particular way. I can hit</p>\n<p>in that way. Actually, let me look at for this particular molecular space. Let me try to optimize for this particular interactions. So, he ends up, you know, running several screens in parallel, you know, using hundreds of GPUs, you know, on his own. And you know, so this has been, you know, pretty incredible to see kind of how, you know, maybe the way that I was more thinking about a problem, which is okay, you just trying to design a binder, a small molecule to a particular protein. The way that he thinks about it is, you know, much more deeply and, you know, trying all these</p>\n<p>different things, these different hypothesis. And then you know once he gets the results from the um from the model he doesn't just you know take the top 15 uh but he it really kind of looks over and you know kind of tries to understand you know the different things and then when we uh select you know maybe some designs to uh to bring forth you know he has you know something where you know both the models understand that something is good but all himself as well and that's why we also built kind of the platform to be uh an interface for you know this kind uh this kind of</p>\n<p>chemist and you know also like collaborative experience. I >> I think at the end of the day like you know for people to be convinced you have to show them something that they didn't think was possible and until you have that aha moment you know I think the skepticism will remain but then when you know every once in a while I think there's like a result that like really surprises people and then it's like oh</p>\n<p><strong>[99:44]</strong></p>\n<p>wow okay this actually I can do something with this. >> So you just get in their hands have them try it out and they'll be convinced. >> Yeah. or like at maybe once the lab results come back >> or their their friend Yeah. or maybe one of their colleagues is convinced and >> I think it it it takes going to the lab I think at some point there's no avoiding that you know as beautiful as the platform can be as nice as the molecules might look you know that the model predicted I think what really convinces people is like you know hits >> you see the results</p>\n<p>>> exactly yeah >> cool thank you for you know taking the time to chat with us >> yeah you know is there anything that you would like your audience to know >> I mean first of all you know uh we're just getting started, you know, uh continuing to to build a team. And so, uh definitely always looking for, uh great folks both on, you know, kind of, you know, software side, you know, machine learning side, but also scientists, uh to join the team and help us, you know, uh shape >> on the infrastructure side too.</p>\n<p>>> Indeed. >> If you if you think that if you want a new challenge because this is not just next token prediction, this is really a new engineering challenge. >> Exactly. If you if no matter you know how much experience you have with you know biologist and chemistry if you want to come you know help us you know shape what you know biology and chemistry hopefully will look like in 5 10 years um we'd love to hear from you and so um go to bold bio and you know come join the team. >> Cool. Thank you.</p>\n<p>>> Awesome. Thank you so much. Thank you.</p>"}