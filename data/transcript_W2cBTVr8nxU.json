{"video_id": "W2cBTVr8nxU", "title": "\u26a1\ufe0f Prism: OpenAI's LaTeX \"Cursor for Scientists\" \u2014 Kevin Weil & Victor Powell, OpenAI for Science", "link": "https://www.youtube.com/watch?v=W2cBTVr8nxU", "published": "2026-01-27T19:36:10+00:00", "summary": "\u201c2026 in AI for Science is going to look a lot like 2025 for Software Engineering\u201d \u2014 Kevin Weil\n\nFrom building *Crixet* in stealth (so stealthy Kevin had to hunt down Victor on Reddit to explore an acquisition) to launching *Prism (*https://openai.com/prism/) as OpenAI's free AI-native LaTeX editor, *Kevin Weil* (VP of OpenAI for Science) and *Victor Powell* (Product Lead on Prism) are embedding frontier reasoning models like GPT 5.2 directly into the scientific publishing workflow\u2014turning weeks of LaTeX wrestling into minutes of natural language instruction, and accelerating the path from research breakthrough to published paper.\nWe discuss:\n\n* What *Prism* is: a free AI-native LaTeX editor with *GPT-5.2 embedded directly into the workflow* (no copy-pasting between ChatGPT and Overleaf, the AI has full context on all your files)\n* The *origin story:* Kevin found Victor's stealth company Cricket on a Reddit forum, DMed him out of the blue, and brought the team into OpenAI to build the scientific collaboration layer for AI acceleration\n* *Live demo highlights:* proofreading an introduction paragraph-by-paragraph, converting a whiteboard commutative diagram photo into TikZ LaTeX code, generating 30 pages of general relativity lecture notes in seconds, and verifying complex symmetry equations in parallel chat sessions\n* Why *LaTeX is the bottleneck:* scientists spend hours aligning diagrams, formatting equations, and managing references\u2014time that should go to actual science, not typesetting\n* The *software engineering analogy:* just like 2025 was the year AI moved from \"early adopters only\" to \"you're falling behind if you're not using it\" for coding, 2026 will be that year for science\n* Why *collaboration is built-in:* unlimited collaborators for free (most LaTeX tools charge per seat), commenting, multi-line diff generation, and Monaco-based editor infrastructure\n* The *UI evolution thesis:* today your document is front and center with AI on the side, but as models improve and trust increases, the primary interface becomes your conversation with the AI (the document becomes secondary verification)\n* *OpenAI for Science's mission:* accelerate science by building frontier models _and_ embedding them into scientific workflows (not just better models, but AI in the right places at the right time)\n* The *progression from SAT to open problems:* two years ago GPT passed the SAT, then contest math, then graduate-level problems, then IMO Gold, and now it's solving open problems at the frontier of math, physics, and biology\n* Why *robotic labs are the next bottleneck:* as AI gets better at reasoning over the full literature and designing experiments, the constraint shifts from \"can we think of the right experiment\" to \"can we run 100 experiments in parallel while we sleep\"\n* The *in silico acceleration unlock:* nuclear fusion simulations, materials science, drug discovery\u2014fields where you can run thousands of simulations in parallel, feed results back to the reasoning model, and iterate before touching the real world\n* *Self-acceleration and the automated researcher:* Jakub's public goal of an intern-level AI researcher by September 2026 (eight months away), and why that unlocks faster model improvement and faster science\n* The vision: *not to win Nobel Prizes ourselves, but for 100 scientists to win Nobel Prizes using our technology*\u2014and to compress 25 years of science into five by making every scientist faster\n\n\u2014\nPrism\n\n* Try Prism: https://prism.openai.com (free, log in with your ChatGPT account)\n* OpenAI for Science: https://openai.com/science\n\n00:00:00 Introduction: OpenAI Prism Launch and the AI for Science Mission\n00:00:42 Why LaTeX Needs AI: The Scientific Writing Bottleneck\n00:03:13 The Cricket Acquisition Story: From Reddit to OpenAI\n00:05:50 Live Demo: AI-Powered LaTeX Editing with GPT-5.2\n00:17:13 Engineering Challenges: Monaco, WebAssembly, and Backend Rendering\n00:18:19 The Future of Scientific UIs: From Document-First to AI-First\n00:15:51 Collaboration Features and Notebooks: The Next Integration\n00:21:02 AI for Science: From SAT Tests to Open Research Problems\n00:23:32 The Wet Lab Bottleneck: Robotic Labs and Experimental Acceleration\n00:33:08 Self-Acceleration and the Automated AI Researcher by September 2026", "transcript_html": "<p><strong>[00:05]</strong></p>\n<p>Okay, we're here at OpenAI with some exciting news from the AI for science team. Uh with us is Kevin Wild from I guess your VP of AI for science. >> Open AI for science. Yeah, >> open for science and Victor Powell um who is the product lead on the new product that we're talking about today. Uh and with me is our new Yeah, for science host R.J. welcome. >> Uh so thanks for having >> us. Yeah, it's very good to be here. >> Yeah. uh thanks for hosting us as as well. It's always nice to come over to the office. Um what are we announcing today? >> So we're launching Prism, which is a an a free AI native [snorts] latte editor.</p>\n<p>What does all that mean? Because probably a lot of people on the the pod haven't worked with Latte in the past. Latte is a a language effectively for type setting mathematics, physics, and you know, science in general. So if you're uh a scientist writing a paper, you're probably not using Google Docs because you need to you have diagrams, you have equations, etc. But it's and it's been the standard for decades. But the the tools that that people use to to actually write latte, write their papers</p>\n<p>haven't changed in a long time. >> And uh in particular, AI can help with a lot of the tasks, right? Because you you spend your time doing the science, you need to write it up. That's an important part of communicating your work. But you want that to be fast and you you want that to be accelerated and AI can help in a ton of ways and we'll talk about some of those. But if you if you step back right is open AI for science. Our goal is to accelerate science and the surface area of science is very large. So we're we're trying to build tools and</p>\n<p>products that help every scientist move faster with AI. Some of that is obviously the work that we can do with the model, making the model able to solve really hard scientific frontier, you know, frontier kind of problems. Uh allowing it to think for a long time. But it's not only that, right? If if there was a lesson from what happened over the last year with software engineering, it's that part of the acceleration from uh in software engineering came from better</p>\n<p>models, but part of it also came from the fact that you now have uh AI embedded into the workflows into the products that you use as a software engineer. Right? It'd be one thing if we were going back and forth copying and pasting code between, you know, chat GPT and your IDE. that would be okay. That would be an acceleration. But the real acceleration came when you embedded AI into the actual workflow. And so that's what we're doing here. So OpenAI for science, it's it's both building great models for scientists and also speeding them up by bringing AI into the</p>\n<p>workflow. That's what we're doing with Prism. >> Yeah. I often say like every million copy and paste done in ChachiBT, there's probably some product to be built, >> right? Exactly. >> That's a good analogy. [laughter] Yeah, that's a good way to look at it. >> Especially with latte, having written a lot of latte papers. >> Yes. >> Yeah. [laughter] Yeah. So, so >> me too. The number of hours as a grad student I spent like trying to get some diagram to line up. Exactly. And Oh,</p>\n<p><strong>[03:07]</strong></p>\n<p>man. >> Yeah. >> Uh and uh Victor, you this is your sort of baby. >> Yeah, I guess uh it started off as um just a a project. I I left Meta about three years ago. Um trying to look for various different projects to start. Uh and uh this was this was one that like when I sort of presented it to people, they're like, \"Oh, I get it. That's I I see what you're doing.\" And so I've just been focused on that, building it for about a about a year and a half and um you [clears throat] know, it it it has now has become part of OpenAI and that's</p>\n<p>been very exciting. >> Congrats. Thank you. >> Yeah. So it's kind of a kind of a fun story, right? I mean we as we were thinking we had this thesis around it's it's not just models it's also building models into the workflow and and accelerating scientists in that way and this is there are obviously a lot of different ways that you can do that but the the scientific collaboration and publishing uh thing is definitely one of them and I was looking around like what is there in this space and there hadn't been a lot of innovation for a long time uh like it wasn't that different from</p>\n<p>when I was like writing up you you know, my assignments and papers in tech and grad school. And uh and then I found on this uh Reddit forum, maybe it was Rlettech, I don't remember, but somewhere on this Reddit forum, I found uh this thing about a company uh called Cricket. And uh I was like looking around. I couldn't find who the founder was. It took me a little while. And then I think I found you on Twitter and DM'd you out of the blue and just said, \"Hey, I don't know if you want to talk about</p>\n<p>this, but I would love to talk about this if you're open to it.\" And gave you my number. And uh we talked on the phone and then like um jumped on a Zoom and eventually met in San Francisco and uh made it happen. That's right. And it's uh it's awesome to have you guys here, but it's just um yeah, I have a ton of respect for what you what you started to build. >> I actually never heard that full story from you until now. >> [laughter] >> You got to find that Reddit user and thank them because you know >> it might have been me. >> I thought you were totally in stealth because uh it was it was the hardest</p>\n<p>thing to actually figure out who the founder of this thing was >> and then I was like, \"Oh, for sure he's not going to respond to my random DM.\" >> I mean, I guess that's a part of part of our focus has always just been entirely on product and to the point where it's almost embarrassing how little we focus on anything else. >> Worked out for you. >> Yeah. So also full circle from moment for you using Twitter to do your business development. >> Yeah, that's right. [laughter] >> So that's kind of interesting. >> Your DMs forever, >> right? Like I actually Yeah, like probably one of the most important</p>\n<p>social network uh innovations I guess is is those that stuff and I'm sure you know a lot about that. Um shall we go right into a demo or talk about it? >> It's always fun to show it. Okay. >> I I'm a fan of like show don't tell, push people to the video. >> Yeah. All right. I'll try and arrange this so you guys can see a little bit. >> Yes. >> Um, all right. So, what you have here, so this is this is Prism. >> Um, and what you can see is on the left</p>\n<p><strong>[06:10]</strong></p>\n<p>here, this is actual latte. You can see why you might want AI to help you write it because it's, you know, >> a language, >> a little bit, it's a language. It's a little bit messy. And then on the right, this is my colleague's uh paper, Alex Lupas. He's a physicist. Um, this is a paper that he wrote on black holes. And so you see it over here all the all the l you know you can imagine trying to write this in like Google Docs or something it'd be impossible. This is why latte is uh super powerful. Um and then and you've got kind of your your files here that make up the project tech file which is the actual main source</p>\n<p>file bibliography files etc. And um you know you can go through and you can change it and then you compile that into into the PDF itself. But here I can say um this is where at the bottom you can use the the AI you using GPT 5.2 and I could say you know this introduction maybe I want a little help writing the introduction. So uh help me proofread the introduction section paragraph by paragraph.</p>\n<p>Uh suggest places where where I can simplify. This is a live demo and we were we're working on it pretty heavily. So just uh [laughter] you nervous yet? You can't be nervous. You're good. >> Spoken like a true founder. [laughter] >> Um and so one of the nice things is you could do this in chat GPT, but you'd have to go upload your files into a chat, right? You're going back and forth here because the AI is built into the product. It has all of the files that</p>\n<p>are part of your project. It automatically puts them in context. it works the way you you think it would work. So, here it's looking at the files. All right. Um, and it's given us kind of a diff here. So, it's suggesting changes. You've got the the part in red, which is the part that it's changing. The part in green what it wants to change it to. And you can see the different places where it uh is suggesting that we change things. So, okay, we can we'll just keep all of them, right? YOLO. Um, >> hope</p>\n<p>is all true. Yeah, we're changing Alex's paper. What's the big deal? [laughter] Um, so here's another thing. We were talking about diagrams in Latte. Uh, so I've got a say I wanted to input a commutive diagram, right? It's really easy to draw a commutive diagram like this. >> It is an absolute nightmare to put these things [laughter] into tech. >> So I will upload this photo and I'll say here, whoops. >> Is there a tech bench for this kind of stuff?</p>\n<p>uh like a set of evals. We totally need one. I think there's an opportunity to do that for sure. So, here's uh a communive diagram that I drew on the whiteboard. Can you make it into a tix diagram and put it right after</p>\n<p><strong>[09:13]</strong></p>\n<p>the I don't know, right after right before right at the top of the introduction section. Make sure you get the details right. [snorts] >> So, so I didn't want to interrupt you while you were typing, but why don't you use voice? >> Oh, actually, I should and I totally could. Yeah. >> No, but isn't it interesting that we all have these voice buttons and we don't use it? >> Yeah. >> It's not second nature yet. >> Yeah. >> Like it's interesting. >> Um, and that one I I totally should have I was gonna also show something. So it</p>\n<p>you have the you have the the you know here I am in the tech and it's working. You also can create new parallel chats. So you can have whole sessions with chat GBT that you can be you that can be going in parallel. >> So here I'll ask it um there's all these equations. We're talking about symmetries of this uh of this black hole uh wave equation >> and in particular there's this complex symmetry here. >> Um >> I like how it Yeah. And notice how it syncs when I highlight it. But I'll say</p>\n<p>like why don't you I'll go to my chat so I can start doing this in parallel. I'll say um please make sure or please uh verify that the H+ operator in the new symmetries section is indeed a symmetry of the stationary axis symmetric. Do >> you understand those questions? Are there whole I have but after that Brandon is actually</p>\n<p>[laughter] >> I'll say don't do it in the paper you know show it show it here >> I don't want it to actually like edit the paper I just wanted to prove it here right okay so I'll get that going >> now while we're waiting for the diagram to finish we can also get another thing going in parallel so I'll say um I need to write up a set of uh lecture notes on general relativity. You know, say I'm a professor, right? I've got I'm teaching a class or something. Um, put together a</p>\n<p>uh 30 minute set of lecture notes on uh Romanian curvature. >> Wow, that's a very different task. >> Put it into the file. I made this grle lecture.te. Okay. And so I've got this going. All right. Well, it came back on my earlier one. H+ symmetry. Is it really? Here you got chatbt doing a whole bunch of uh uh of work to verify that this is indeed a</p>\n<p>symmetry of the equation. Okay, it does. It confirms it. Right. So you've got the full power of a reasoning model that can think deeply about frontier science. Uh and now we can go back while it works on the other thing. Okay. So it it this was where I was making the diagram, right? Uh it put it right below the</p>\n<p><strong>[12:15]</strong></p>\n<p>introduction. I'll compile it again. >> So it is an autoco compile. >> Uh >> actually you can turn that on. Okay. >> And look. Wow. It it nailed it. >> Um so it looks like it got it pretty much exactly. >> Just a small check the details. >> Oh yeah, check the details. >> Uhoh. [laughter] Good enough for me. >> Yeah, it's pretty good. But all right, we can we can see if it'll get it right. Let's say um uh the Cvertex should be directly >> to your point about voice though I do think uh maybe over time the code kind of might recede into the background more</p>\n<p>as you're just really interact you're interacting with the paper you're having conversation [clears throat] with it. >> Yeah. >> When you when you started this product was this how you envisioning it would be used or were there other design choices that you were considering and you didn't take that path? Um, >> by the way, before you answer, we have our we have our uh general relativity lecture notes here. >> Well, that was quick. >> So, >> 30 minutes. >> This is a six pages. >> Yeah. So, 30 page 30 minute section. Okay. So, we got curvature, coariant, derivatives. Yeah, this looks like a</p>\n<p>reasonable set of uh of notes if you were going to go teach a class, right? It just did it for you. >> Or you can even think like, you know, generate the problem set for for this week. >> Yeah. Right. You've got work. So, it's got some examples here. we could tell it to like work out solutions to the examples. Um, >> that's sort of a hidden feature of Latte, too, that it it actually makes it pretty easy to generate problem sets with like answer sheets and things like this. >> There's so many there's so many cool features of Latte that I think uh are underutilized. >> Yeah. So, anyways, you could see we we went we we uh had it proofread the</p>\n<p>paper. We had it check some of the answers uh to verify that our calculations were correct. We generated a set of lecture notes. We added a diagram that we didn't have to actually type up ourselves, which I promise you is horrendous. And that's just, you know, we did that all all basically in parallel. And you know, you can imagine lots of other things. You can you if you have a proof that you you know, you maybe have like the the sort of the bullet points on a proof, you can just say, \"Here are the bullet points. Now, flesh it out for me.\" You can imagine having it check all of your references</p>\n<p>before you publish. Make sure all of them are real, up to-date. You can imagine having it generate your references based on the topic of, you know, so there's so many areas where AI can help. [laughter] >> That's a big problem when you're trying to put together a paper is get all the references right. >> Yeah. Well, okay. So, >> and all of this is time that used to go to, you know, typing up a paper >> not science >> and not science and now it could go back to science and that's just one of the ways that we look at accelerating scientists all over the world. Yeah, I I would say uh definitely, you know, be</p>\n<p>careful about including references you haven't read, [laughter] right? Like that's the whole point. Like you can include 100 references, but if you didn't read them, then you might as well not have them. >> Uh but yeah, I think that web connection is is very important. And like is this stock GPT5 or GPU? >> GPT 5.2. Yeah. >> Um but and by the way, you when you're</p>\n<p><strong>[15:16]</strong></p>\n<p>looking at references, you can also ask chat GPT to help you understand the reference. you know, read this paper, tell me the relevance. So, all of the things that you might want to do to accelerate your work, you can just do from within this interface. >> You still have to do your work, but it should [laughter] make it it should make it faster, especially like even linking to the references. So, you can go and verify like, okay, this is this one. >> So, this might also make it easier to write the paper as you do the work, right? Rather than [clears throat] rather than, oh, okay, now I got to spend two days in Latic land trying to get my paper, right? like a tool for</p>\n<p>thought rather than just a publishing tool. >> Yeah. >> Yeah. Yeah. >> What about collaboration? >> It's a great Yeah. So, it's built for I mean, you can speak to this well. It's built for collaboration. So, you can bring on as many uh >> uh collaborators as you want. Okay. >> Which is nice. I think most other tools in the space have hard limits and charge you money and other things. >> In Prism, it's as many collaborators as you want for free. >> Um Yeah. So, you've got commenting, you've got all the kind of collaboration tools that you would want. Um, good. >> And then any other like engineering</p>\n<p>choices like um, you know, what might engineers not appreciate when just looking at a tool like this? Uh, you know, often it would be like multi-line uh, diff generation that you need to do because you're editing a pretty complex document. >> It does get pretty complicated. I mean, we're using um, let me know if I'm getting too technical into the weeds, but uh, you know, we're relying heavily on the Monaco uh, uh, JavaScript framework. So >> I'm very familiar with the lack of documentation of Mono. [laughter] >> That's actually it's interesting you say that because it's it's very true there.</p>\n<p>It's extremely powerful library that is almost entirely undocumented. So >> you can use codecs now to generate the documentation [laughter] for you. >> Yeah, you you think Microsoft should get on that. Uh but yeah, you know, like just stuff like that. Like I I like to hear about like the behind the scenes of like building something like this. What what do you what do you struggle with? What's the model really like surprisingly good at? and what's the model it should be good at but it's not. >> What were some of the hardest problems as you were building this in the first place? What are some of the hardest things to get right? >> I think um initially maybe one</p>\n<p>interesting challenge was that we really pushed on it being um web assembly and fully just running in the browser at first the whole entire latte compilation and that did help us in the sense that we were able to like flesh out the design and the AI capabilities early on without having to invest heavily in like the backend infrastructure. Uh but eventually we did hit a wall with that approach and once we switched it to backend PDF rendering like that's when we really started to hit an inflection point with like usage. >> Yeah. Fast. >> Yeah.</p>\n<p>>> Yeah. >> Yeah. I think we also the AI in here benefits a lot from everything that we've learned building codecs. >> Um and as we go forward I think we'll likely just integrate the the full codeex harness into the application here. So you get all the benefits of the tools and the skills and all the things that Codex can do today. >> Uh and you just sort of automatically can bring that into your environment here. >> Yeah. Is there a future they're just the same app? Uh maybe [clears throat]</p>\n<p><strong>[18:18]</strong></p>\n<p>I think potentially it depends on I mean here's the reason I'm hesitating is I think the the interesting thing with um with this and with codeex is we're still mostly in a world today where people are you have you know your your main screen is your is your document and then you have your AI on the side but the more that AI that improves people trust it and they're just yoloing it right? You're like you're generating code and you're you're like looking at the code is sort of secondary to instructing the AI and and</p>\n<p>driving from that. The UI probably changes for all of these things, right? You don't you don't need your your document front and center because you're actually not looking at your document as much. >> You're that's sort of your backup and your interaction with your AI is primary. >> And as that happens, I think you might these these UIs can kind of converge over time. So, we'll see. Uh, but I definitely would love to see a world where people needed to spend less time thinking about the actual syntax and much more about what they're trying to</p>\n<p>create. >> Yeah. I mean, I I I feel like this plus a notebook would be amazing. Yeah. >> Because because you and something that uh the AI can run equal, generate plots. Oh, stick that in the paper here. like oh read you know like this paper like this part of the paper like take that equation and like you know do something with it that would be a really amazing uh integration. >> Yeah like think through the different corlaries [clears throat] of this thing from this paper and produce some</p>\n<p>alternatives and then like yeah I I completely agree. >> Yeah. >> Yeah. I do think that's sort of the progression where it's like doing doing maybe work for a few seconds versus maybe we're already at a point where it's doing work for a few minutes eventually doing work for hours, days, coming back with very complicated analysis. >> Mhm. Yeah. I mean that that's actually maybe a good segue into some of the other questions that I had about your um your initiative. I mean uh so stepping back to AI for science in general um can you talk a little bit I I have a million</p>\n<p>questions but uh maybe start with what I okay I feel that validation of AI for science so uh is critical to its success right you have to have some sort of um real world validation of of the results that you produce with your AI right so what are the I I know that there's been some publicity in the in the past. What are the like the latest and greatest hits of the things that big labs or any</p>\n<p>lab is doing with uh with open AIS AIS? >> Uh I mean when you step back and look at the trend I think that's the biggest thing because we can we can debate exactly like you've probably seen in in the last few weeks even there have been a bunch of different examples of like GPT 5.2 to contributing to open airish problems and things like that. And then</p>\n<p><strong>[21:19]</strong></p>\n<p>you get into this debate of well was it uh was it really just really good at literature search and it found an example over here an example over here when you combine the two you know that it was sort of a trivial step from there to the solution and >> was that novel or did it really do something new and >> you know that's a that it's a legitimate discussion but when you step back >> two years ago we were like you know this thing can pass the SAT that's amazing and uh [laughter] and you progress to like it can do a little bit of contest</p>\n<p>math and it can start to solve harder problems. Wow. And then you keep going and it's starting to solve graduate level problems and then you have a model that gets a gold medal at the IMO and now we're sitting here talking about you know it solving open problems at the frontier of math and physics and biology and other fields. So it it's just I mean the progression is incredible. And if you think about where we are today, then you fast forward 6 months, 12 months, like I I I'm very optimistic about what</p>\n<p>the models are going to be do able to do to accelerate science. It's like it's already happening. And if there's one thing that I've learned from uh my like two-ish years at OpenAI, >> it's you go very quickly from this is this thing is just impossible for AI to do. like [snorts] it's too hard, AI can't do it to like AI can just barely do it and it like kind of doesn't work and you know only early adopters are doing it because it's not particularly reliable yet but it like</p>\n<p>sort of works to oh my god AI like does this thing really well and I could never imagine not using AI for this in the future. It's like once you start to get to, you know, 5 10% on some particular eval, you very quickly go to like 60 70 80 >> and we're just at the phase where AI can help in some, not all, but in some elements of frontier science, math, you know, biology, chemistry, etc. And it it just means we're like right at the at</p>\n<p>the cusp and it's super exciting. So I mean so it it fast forward a year or you know the end of the year uh and we have AIs that can do you a lot of this um discovery process then the bottleneck becomes the wet lab or the the lab right so what what what is what are you seeing um in that domain? Yeah, I I by the way I totally we were talking a little bit about software engineering before and the analogies. I think 2026 for AI and science is going to look a lot like what</p>\n<p>2025 looked like for soft AI and software engineering. >> Yeah. >> Where if you go back to the beginning of 2025 if you were using AI heavily to write your code, >> you were sort of an early adopter and it like kind of worked and but it wasn't like certainly not everybody was doing it. And then you fast forward 12 months and at the end of 2025, if you are not using AI to write a lot of your code, you're probably falling behind. I think</p>\n<p><strong>[24:20]</strong></p>\n<p>we're going to see that same kind of uh of progression in AI and science. You know, today it's a early adopters, but you're really starting to see some proof points and solving open problems and, you know, developing new kinds of proteins and things like that. Um, but you're right, as it as it really starts to work, and I think this is the year that it's really going to start to work, uh, it it shifts the bottleneck, and I think we're going to be starting to talk a lot more about robotic labs and other things,</p>\n<p>>> you know, [clears throat] like do you need to have a grad student like pipetting things? >> No. >> Probably not, right? right now you do, but why why shouldn't we have why shouldn't we have uh robotic labs that where you have AI models doing what they do best reasoning over a huge amount of of different information um you know they have read substantially every paper in every field and can bring a lot of information to bear to help prune the search tree on you know a new material for example that you're trying to create</p>\n<p>and then you have a robotic lab that can uh roll out a bunch of experiments in parallel do them while we sleep. Um, and then feed the results back into the AI, let it learn from them, design the next set of experiments and go. >> I mean, it's hard to imagine that's like >> it doesn't even have to be YOLO science, right? To your point, it's you're verifying it as you go cuz you have an actual lab building it in real life. >> Um, but you can just do so much more in parallel. You can think harder up front with AI to design the experiments. uh and and again like prune the search tree</p>\n<p>so you're you're searching over a smaller number of higher value targets and then you automate the experimentation uh and and turn it around faster. And again like this is acceleration like the whole if we're successful then it's you end up doing you know maybe the next 25 years of science in 5 years instead. So in 2030 we could be doing 2050 level science and that would be an awesome outcome. like the world is a better place if that happens. >> Absolutely. I I guess uh so we spoke</p>\n<p>recently with Heather Kulik at MIT and one of the things she pointed out was that there's a element of serendipity to working in a lab that you lose and so she was of the opinion that there's a class of problems especially when you have like a large search space or something like that where robotics is going to really accelerate science and there's another class of problems where even experimental science will not move forward very fast because of robotics. And so then again, you're at a bottleneck. But I guess humans need something to do. So</p>\n<p>>> well, that [laughter] what she said sounds totally reasonable to me, right? There are probably places where the humans are adding no value because they're literally just trying to pipet a certain amount of a thing into another thing or, you know, do some uh the same motion repeatedly in a bunch of different ways. And then there are places where it it's less well understood. You want the full flexibility that you have of a really smart human thinking about the work that they're doing. Um, by the way, the same</p>\n<p><strong>[27:21]</strong></p>\n<p>is true in in uh the more theoretical fields as well. It's not this isn't about let's automate all the humans out of their jobs. This is about accelerating scientists. It's scientist plus AI together being better than scientist alone or AI alone. >> Um, and I think the same is true whether you're talking something that's happening in silic proving a theoretical problem or happening in the real world with a lab. like find the parts that you don't need a human to do and try and automate them as much as you possibly can so that the humans can spend their time on the most valuable things.</p>\n<p>>> Yeah, I'm very pro like the incilical uh acceleration because obviously you have more control over that and you can parallelize and repeat and >> yeah do all those all those things. Yeah, I think there will be a huge amount of value in you know a lot of fields are are heavily simulatable and they you know and so you know nuclear fusion for example they're running a lot of simulations before they do any particular experiment because the experiments are very timeconuming and expensive. >> Yeah. Um, but I'm excited to see what you can do when you have a a loop between, you know, a a very intelligent</p>\n<p>reasoning model that understands fusion and a simulation and you get the model thinking about what parameters to set for the simulation and then running, you know, a bunch of simulations in parallel, feeding that back and you have that same sort of lab loop except it's all in silicon and in an exper in um and running on a giant GPU cluster. >> Yeah. And then when you really have like gotten to the end of that calculation, then you go run it in >> IRL. This is bringing it back to Prism. This is sort of a a nice aspect that</p>\n<p>you're you're getting a more sophisticated view of your result, right? instead of just um you know like a chat output and it I would I would hope as it develops it's a way for a scientist to be able to interact with the information before you kick off your nuclear fusion experiment for you know $10 million or whatever. >> Mhm. And the human can learn from more things right you just you get more data that you can that you can look at and evaluate. Oh yeah, >> this by the way this fusion discussion</p>\n<p>makes me think like you know if one day open for science you know it gets serious enough and starts to self accelerate you should solve cold fusion and you know be your own power source. [laughter] >> Well I mean this is this is why we're so excited about this, right? I mean imagine our our our mission is is to you know to to bring AGI to the world in a way that's beneficial to all humanity. >> It's right there at the lobby. >> Yeah. You see it every day you walk in, you see it. >> Yeah, absolutely. And and imagine I mean if we had GPT9 inside of</p>\n<p>chat GPT today, it would be awesome. You could do lots of things, but if you had GPT9 and it could um which I'm using as a standin for AGI, right? And and it could >> create new materials and we were the devices we were using were all incredible and you know had 30-day battery lives and things like that. and we had personalized medicine and we all</p>\n<p><strong>[30:21]</strong></p>\n<p>knew someone whose life was saved because we were developing personalized, you know, >> uh, cancer treatments and things so much faster. Like >> that's the real benefit of AGI. That's I think maybe the most tangible way that we're all going to feel AGI as it starts to be real. Yeah. >> And that's why this work is so mission driven for us. >> So, so that does it brings up like kind of two questions in my mind. One is the first one is so then who uh who owns the invention and [clears throat] then the other half of that is okay so then does does open AI become a drug company and a</p>\n<p>fusion company and and right cuz this is how I mean you laugh but it's a little bit serious that all the AI for drug discovery companies ended up being drug companies because they couldn't sell the so far with some exceptions now with no edetic for example but they end up being drug companies because they can't sell the the drug. But in any event that there's like a lot of precedence for using basically building your own portfolio using uh AI. So like are you thinking</p>\n<p>about that that angle or this is right now you're just let's get what's enabled scientists for outside of open AI? Yeah. I mean, my my personal belief about as we drive towards AGI is not that we're going to we're going to create AGI and then we're all going to like sit back and enjoy our universal basic income and like write poetry. I we're people the future will involve [snorts] I mean especially advanced science is going to involve experts helping to drive these</p>\n<p>models and I don't believe that any one company is just going to do everything right. It's why we're focusing on first and foremost on accelerating scientists outside of these walls, right? Our goal is not to win a Nobel Prize ourselves. It is for a 100 scientists to win Nobel prizes using our technology. >> Yeah. And at the same time, I think there are there are like places where sometimes you actually when you're trying to build for other people, you learn best if you actually try and go end to end on something >> because then you're your own customer</p>\n<p>and you get you understand it in a tighter loop than you would if you were purely building for people outside the walls. >> So I think it makes sense for us to take a handful of bets like that. But >> by and large, we're going to partner because the the surface area of science is massive. Yeah. >> And we want to accelerate all of science. >> Yeah. >> Yeah. We're covering all sorts of disciplines from like chemistry to we are >> structural biology [laughter] >> and we're we're releasing the first first episode this week. So >> material science it's all over the place. Uh it's there's a lot to do. uh one thing I did wanted to bring across</p>\n<p>also was so afraid sits within the broader sort of research uh org at open AAI and you know one of the more more interesting things is like self acceleration let's call it you know >> [clears throat] >> um where yakub has very publicly declared that we'll have a automated researcher by September 2026 >> yeah the beginnings of what I think you said right and it's like the intern</p>\n<p><strong>[33:22]</strong></p>\n<p>version this year >> first product uh and I'm sure you have more cooking internally but like why so soon like that's 8 months away and uh what's the what's the goal there? What you know just anything above that that you can share? >> Yeah, I mean 8 months that feels like forever in this industry [laughter] >> basically infinite time. Um I mean no it's exactly what you said right? It's if uh if we can if we can create a a a model an AI researcher that is um that can actually do novel AI research then</p>\n<p>we can move way faster right we will we will self- accelerate uh we can discover more things quickly we can apply GPUs and compute to to moving our own research faster and that just means that we can improve our models at a faster rate and every bit that we improve our models means that we We're a step closer to bringing AGI and all the things that we were talking about with personalized medicine and new materials and like we can bring these amazing things into the world faster. >> So it is about self acceleration. >> Yeah. I think one one thing I'm also</p>\n<p>trying to figure out is how closely is machine learning research which is a science. >> Yeah. uh or high performance compute which is also something that you guys are doing a lot of uh close to the traditional hard sciences let's call it like physics and chemistry >> I think in a lot of ways it's it's sort of a parallel effort to this like it is the work that we're trying to do with AI open AI for science and accelerating other scientists the parallel internally is they're trying to uh build products and models for AI researchers to</p>\n<p>accelerate them so it's there there's a lot of sort of uh parallelism to these two work streams. They're they're similar in in uh in in goal just for a different set of users. >> Yeah. Okay. Um any parting thoughts, questions, anything we should have asked? >> Uh well, I hope everybody tries Prism. It's it's available today at prism.openai.com. It's totally free. You log in with your chat GPT account and you can go build anything you would like. We're really</p>\n<p>excited to see what people use it for and um if if you run into issues or have any feedback, let us know. >> I have a paper I'm going to write [laughter] really really soon on that. >> Amazing. Show notes in this thing. I don't know. Let's let's see what it does in Latte. >> Yeah, [laughter] totally. >> Yeah. Congrats on your first Open AI launch. >> There you go. >> Congratulations. >> Congrats. Thanks for having us. >> Yeah. Thank you.</p>"}