{"video_id": "qvrdCpLPbuQ", "title": "Reiner Pope of MatX on accelerating AI with transformer-optimized chips", "link": "https://www.youtube.com/watch?v=qvrdCpLPbuQ", "published": "2026-02-26T13:08:59+00:00", "summary": "Reiner Pope is the co-founder and CEO of MatX, designing specialized chips for Large Language Models. A former Google TPU architect, he joins John to discuss why the current generation of AI hardware is hitting a wall. They cover the \"uncomfortable trade-off\" between latency and throughput for current chips, why MatX is betting on combining HBM and SRAM to solve it, and the massive logistical challenge of manufacturing chips at scale with TSMC. Reiner also shares his predictions for AI in 2027, why he prefers Rust for hardware design, and why the best iteration loops happen in your head before writing a line of code.\n\nSubscribe to Cheeky Pint\nSpotify: https://open.spotify.com/show/2IHbGJJMpiFoz5YrvRfTFw?si=a2e54003fd084884\nApple Podcasts: https://podcasts.apple.com/gb/podcast/cheeky-pint/id1821055332\nSubstack: https://cheekypint.substack.com/\n\nKey moments\n00:00:15 Google\u2019s AI revival\n00:07:54 MatX\n00:17:11 AI supply chain\n00:21:48 Designing chips\n00:37:11 TSMC\n00:44:17 Token pricing\n00:44:55 RL-ing chip design\n00:49:26 Design to production\n00:56:05 MatX culture\n01:02:57 Rust\n01:05:21 Cuckoo hashing\n01:09:35 Unexplored model architectures", "transcript_html": "<p><em>No transcript available for this video.</em></p>", "cleanup_applied": false, "cleanup_reason": "no_transcript"}