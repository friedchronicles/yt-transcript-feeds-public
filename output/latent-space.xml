<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Transcripts: Latent Space</title>
    <link>https://friedchronicles.github.io/yt-transcript-feeds-public/latent-space.xml</link>
    <description>YouTube video transcripts from Latent Space</description>
    <atom:link href="https://friedchronicles.github.io/yt-transcript-feeds-public/latent-space.xml" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <language>en</language>
    <lastBuildDate>Sun, 01 Mar 2026 19:23:02 +0000</lastBuildDate>
    <item>
      <title>Goodfire AI’s Bet: Interpretability as the Next Frontier of Model Design — Myra Deng &amp; Mark Bissell</title>
      <link>https://www.youtube.com/watch?v=ck63uv6APBA</link>
      <description>From Palantir and Two Sigma to building Goodfire into the poster-child for actionable mechanistic interpretability, Mark Bissell (Member of Technical Staff) and Myra Deng (Head of Product) are trying to turn “peeking inside the model” into a repeatable production workflow by shipping APIs, landing real enterprise deployments, and now scaling the bet with a recent $150M Series B funding round at a $1.25B valuation. (https://www.goodfire.ai/blog/our-series-b)

In this episode, we go far beyond the usual “SAEs are cool” take. We talk about Goodfire’s core bet: that the AI lifecycle is still fundamentally broken because the only reliable control we have is data and we post-train, RLHF, and fine-tune by “slurping supervision through a straw,” hoping the model picks up the right behaviors while quietly absorbing the wrong ones. Goodfire’s answer is to build a bi-directional interface between humans and models: read what’s happening inside, edit it surgically, and eventually use interpretability during training so customization isn’t just brute-force guesswork. (https://www.goodfire.ai/blog/on-optimism-for-interpretability)

We discuss:
• Myra + Mark’s path: Palantir (health systems, forward-deployed engineering) → Goodfire early team; Two Sigma → Head of Product, translating frontier interpretability research into a platform and real-world deployments
• What “interpretability” actually means in practice: not just post-hoc poking, but a broader “science of deep learning” approach across the full AI lifecycle (data curation → post-training → internal representations → model design)
• Why post-training is the first big wedge: “surgical edits” for unintended behaviors likereward hacking, sycophancy, noise learned during customization plus the dream of targeted unlearning and bias removal without wrecking capabilities
• SAEs vs probes in the real world: why SAE feature spaces sometimes underperform classifiers trained on raw activations for downstream detection tasks (hallucination, harmful intent, PII), and what that implies about “clean concept spaces”
• Rakuten in production (https://www.goodfire.ai/research/rakuten-sae-probes-for-pii-detection): deploying interpretability-based token-level PII detection at inference time to prevent routing private data to downstream providers plus the gnarly constraints: no training on real customer PII, synthetic→real transfer, English + Japanese, and tokenization quirks
• Real-time steering at frontier scale: a demo of steering Kimi K2 (~1T params) live and finding features via SAE pipelines, auto-labeling via LLMs, and toggling a “Gen-Z slang” feature across multiple layers without breaking tool use
• Hallucinations as an internal signal: the case that models have latent uncertainty / “user-pleasing” circuitry you can detect and potentially mitigate more directly than black-box methods
• Steering vs prompting (https://www.goodfire.ai/blog/feature-steering-for-reliable-and-expressive-ai-engineering): the emerging view that activation steering and in-context learning are more closely connected than people think, including work mapping between the two (even for jailbreak-style behaviors)
• Interpretability for science: using the same tooling across domains (genomics, medical imaging, materials) to debug spurious correlations and extract new knowledge up to and including early biomarker discovery work with major partners

—

Goodfire AI
• Website: https://goodfire.ai
• LinkedIn: https://www.linkedin.com/company/goodfire-ai/
• X: https://x.com/GoodfireAI

Myra Deng
• Website: https://myradeng.com/
• LinkedIn: https://www.linkedin.com/in/myra-deng/
• X: https://x.com/myra_deng

Mark Bissell
• LinkedIn: https://www.linkedin.com/in/mark-bissell/
• X: https://x.com/MarkMBissell

 Introduction
 Welcome + episode setup + intro to Goodfire
 Fundraise news + what’s changed recently
 Guest backgrounds + what they do day-to-day
 “What is interpretability?” (SAEs, probing, steering and quick map of the space)
 Post-training failures (sycophancy/reward hacking) + using interp to guide learning
 Surgical edits: bias vectors + grokking/double descent + subliminal learning
 How Goodfire decides what to work on (customers → research agenda)
 SAEs vs probes: what works better for real-world detection tasks
 Rakuten case study: production PII monitoring + multilingual + token-level scrubbing
 Live steering demo on a 1T-parameter model (and scaling challenges)
 Feature labeling + auto-interpretation + can we “turn down” hallucinations?
 Steering vs prompting equivalence + jailbreak math + customization implications
 Open problems + how to get started in mech interp
 Applications: healthcare + scientific discovery (biomarkers, Mayo Clinic, etc.)
 Induction + sci-fi intuition (Ted Chiang)</description>
      <content:encoded><![CDATA[<p><strong>YouTube:</strong> <a href="https://www.youtube.com/watch?v=ck63uv6APBA">https://www.youtube.com/watch?v=ck63uv6APBA</a></p>
<h2>Introduction</h2>
<p>If you ask 50 people who quote unquote work in interp like what is interpretability, you&#x27;ll probably get [music] 50 different answers to some extent. Also, like we&#x27;re where Goodfire sits in the space. We&#x27;re an AI research company above all else and interpretability is a is a set of methods that we think are really useful and worth [music] kind of specializing in in order to accomplish the goals we want to accomplish. But I think we also sort of see some of the goals as even more broader as as almost like the science of deep learning and just taking a not blackbox [music] approach to sort of internal representations and then</p>
<p>bringing interpretability to training which I don&#x27;t think has been done all that much before.</p>
<h2>Welcome + episode setup + intro to Goodfire</h2>
<p>So welcome to the lane space. We&#x27;re back in the studio with our special mech co-host Vivu. Welcome &gt;&gt; Mochi. Moi special co-host &gt;&gt; and Mochi the mechanistic interpretability doggo. Uh we have with us Mark and Myra from Goodfire. Welcome. &gt;&gt; Thanks for having us on. &gt;&gt; Maybe we can sort of introduce Goodfire and then and then introduce you guys. How do you introduce Goodfire today? &gt;&gt; Yeah. Uh it&#x27;s a great question. So GoodFire we like to say is an AI research lab that focuses on using interpretability to understand, learn</p>
<p>from, and design AI models. And we really believe that interpretability will unlock the new generation, next frontier of safe and powerful AI models. Um, that&#x27;s our description right now. And I&#x27;m excited to dive more into the work we&#x27;re doing to make that happen. &gt;&gt; Yeah. And there&#x27;s there&#x27;s always like the official description. Is there like an unofficial one that sort of resonates more with a different audience? Well, being an AI research lab that&#x27;s focused on interpretability, there&#x27;s obviously a lot of people have a lot that they think about when they think of</p>
<p>interpretability. And I think we have a pretty broad definition of what that means and the types of places that can be applied and in particular applying it in production scenarios in highstakes industries and really taking it sort of from the research world into the real world which you know it&#x27;s a it&#x27;s a new field so that hasn&#x27;t been done all that much and we&#x27;re excited about actually seeing that sort of put into put into practice. Yeah, I would say it&#x27;s it</p>
<h2>Fundraise news + what’s changed recently</h2>
<p>wasn&#x27;t too long ago that topic was like still putting out like toy models or supervisition and that kind of stuff. And I wouldn&#x27;t have pegged it to be this far along. Uh when you and I talked at New Reps, you were talking a little bit about your production use cases and your customers. And then not to bury the lead, today we&#x27;re also announcing the fund raise uh your series B $150 million at a 1.25b valuation. Congrats. You&#x27;re a unicorn. &gt;&gt; Thank you. Yeah. No, things move fast. We were talking to you in December and</p>
<h2>Guest backgrounds + what they do day-to-day</h2>
<p>already some big updates since then. &gt;&gt; Let&#x27;s dive I guess into a bit of your backgrounds as well. Mark, you you were at Palanteer uh working on health stuff which is uh really interesting because uh GoodFire has some interesting like health use cases. I don&#x27;t know how related they are in practice. &gt;&gt; Yeah. Not not super related but um I don&#x27;t know it was helpful context to know what it&#x27;s like just to work with uh health systems and generally in that domain. &gt;&gt; Yeah. And Mara, you were at Two Sigma, which actually I was also at, uh, Two Sigma. Really back in the day. &gt;&gt; Wow, nice. Did we overlap at all?</p>
<p>&gt;&gt; No. Uh, this is this is when I was the briefly a software engineer before I became a sort of developer relations person and now you head of product. &gt;&gt; What are your sort of respective roles just to introduce people to like what all gets done in Goodfire? &gt;&gt; Yeah, prior to Goodfire, I was at Palunteer for about 3 years uh as a as a forward deployed engineer, now a now a hot term. uh wasn&#x27;t always that way and as a technical lead on the healthcare team and at Goodfire I&#x27;m a member of the technical staff um and honestly that I think is about as specific as [laughter] like as as I could describe myself cuz I&#x27;ve worked on a range of things and you</p>
<p>know it&#x27;s it&#x27;s a fun time to be at a team that&#x27;s still reasonably small. I think when I joined one of the first like 10 employees now we&#x27;re above 40 but still it looks like there&#x27;s always a mix of research and engineering and product and all of the above that needs to get done and I think everyone across the team is is you know pretty pretty switch hitter in the roles they do. So I think you&#x27;ve seen some of the stuff that that I worked on related to image models which was sort of like a research demo. More recently, I&#x27;ve been working on our scientific discovery team with some of our life sciences partners, but then</p>
<p>also building out our our core platform from more of like a flexing some of the kind of MLE and and developer skills as well. &gt;&gt; Very generalist. Um, and you you also had like a very like a founding engineer type role. &gt;&gt; Yeah. Yeah. So, I I also started as I still am member of technical staff. Did a wide range of things from the very beginning including like finding our office space and all of these like nittygritty. people visited when you had that open house thing. It was really nice. &gt;&gt; Thank you. Thank you. Yeah. Plug to come visit our office. Um &gt;&gt; like it was it was like 200 people like</p>
<p>it has room for 200 people but there you guys were like 10. [laughter and clears throat] &gt;&gt; Yeah. &gt;&gt; For a while it was very empty. &gt;&gt; But yeah like like Mark I I spend a lot of my time as as head of product. I think product is a bit of a weird role these days, but a lot of it is thinking about um how do we take our frontier research and really apply it to the most important real world problems and how does that then translate into a platform that&#x27;s repeatable or a product and working across you know the engineering and research teams to make that happen.</p>
<p>And also communicating to the world like what is interpretability, what is it used for, what is it good for, um why is it so important? All of these things are part of my day-to-day as well. &gt;&gt; I love like what is things because that&#x27;s a very crisp like starting point for people like coming to a field. Leo I&#x27;ll do a fun thing VU why you want to try tackling what is interpretability and then they can correct us.</p>
<h2>“What is interpretability?” (SAEs, probing, steering and quick map of the space)</h2>
<p>&gt;&gt; Okay great. Um so I think like one just to kick off it&#x27;s a very interesting role to be hit a product right because you guys at least as a lab you&#x27;re more of an applied interp lab right which is pretty different than just normal interp like a lot of background research but you guys actually ship an API to try these things you have ember you have products around it which not many do okay what is interp so basically you&#x27;re trying to have an understanding of what&#x27;s going on in model like in the model in the internals so different approaches to do that you can do probing saes transcoders, all this stuff. But basically, you have an</p>
<p>you have a hypothesis. You have something that you want to learn about what&#x27;s happening in a model internals and then you&#x27;re trying to solve that. From there, you can do stuff like you can, you know, you can do activation mapping. You can try to do steering. There&#x27;s a lot of stuff that you can do. But the key question is, you know, from input to output, we want to have a better understanding of what&#x27;s happening and, you know, how can we how can we adjust what&#x27;s happening on the model internals? How&#x27;d I do? &gt;&gt; That was really good. I think that was great. I I think it&#x27;s also a it&#x27;s kind of a minefield of a if you ask 50 people</p>
<p>who quote unquote work in interp like what is interpretability, you&#x27;ll probably get 50 different answers. And to some extent also like where where GoodFire sits in the space. I think that we&#x27;re an AI research company above all else and interpretability is a is a set of methods that we think are really useful and worth kind of specializing in in order to accomplish the goals we want to accomplish. But I think we also sort of see some of the goals as even more broader as as almost like the science of deep learning and just taking a not blackbox approach to kind of any part of the like AI development life cycle</p>
<p>whether that means using inter for like data curation while you&#x27;re training your model or for understanding what happened during post- training or for the you know understanding activations and sort of internal representations what is in there semantically and then a lot of sort of exciting updates that were, you know, are sort of also part of the the fund raise around bringing interpretability to training, which I don&#x27;t think has been done all that much before. A lot of the stuff is sort of post talk poking at models as opposed to actually using this to intentionally</p>
<p>design them. Is this post- training or pre-training or is is that not &gt;&gt; focused on post- training? But there&#x27;s no reason the techniques wouldn&#x27;t also work in pre-training. It seems like it would be more act applicable post training because basically I I&#x27;m thinking like rollouts or like um you know having different variations of a model that you can tweak with your &gt;&gt; steering. Yeah. And I think in a lot of</p>
<h2>Post-training failures (sycophancy/reward hacking) + using interp to guide learning</h2>
<p>the news that you&#x27;ve seen in in on like Twitter or whatever, you&#x27;ve seen a lot of unintended side effects come out of post-training processes. You know, overly sycopantic models or models that exhibit oh god strange reward hacking behavior. I think these are like extreme examples. There&#x27;s also, you know, very uh mundane more mundane like enterprise use cases where, you know, they try to customize or post-train a model to do something and it learns some noise or it doesn&#x27;t appropriately learn the target task. And a big question that we&#x27;ve always had is like how do you use your understanding of what the model knows</p>
<p>and what it&#x27;s doing to actually guide the learning process more effectively? &gt;&gt; Yeah. I mean, you know, just to anchor this for people, uh, la one of the biggest controversies of last year was 40 glazegate. [laughter] I&#x27;ve never heard I didn&#x27;t know that was what it was called. &gt;&gt; No, the other one they called it that on the blog post and I was like [laughter] why the opening I call it like officially used that term and I&#x27;m like that&#x27;s funny but like yeah I I guess is is the pitch that if they had worked to a good fire they wouldn&#x27;t have avoided it like you know [laughter] &gt;&gt; I think so. &gt;&gt; Yeah. &gt;&gt; I I think that&#x27;s certainly one of the use cases I think and another reason why</p>
<p>post training is a place where this makes a lot of sense is a lot of what we&#x27;re talking about is surgical edits. you know, you want to be able to have expert feedback very surgically change how your model is doing. Whether that is, you know, removing a certain behavior that it has. So, you know, one of the things that we&#x27;ve been looking at or is is another like common area where you would want to make a somewhat surgical edit is some of the models that have say political bias. Like you look at Quen or um R1 and they have sort of like this CCP bias in them. And you know,</p>
<p>&gt;&gt; is there a CCP vector? Well, there&#x27;s there are certainly internal Yeah. parts of the representation space where you can sort of see where that lives. Yeah. [laughter] Um and you want to kind of, you know, extract that piece out. &gt;&gt; Well, I always say, you know, whenever you find a vector, a fun exercise is just like make it very negative to see what what the opposite of CCP is.</p>
<h2>Surgical edits: bias vectors + grokking/double descent + subliminal learning</h2>
<p>[laughter] &gt;&gt; The Super America bald eagles flying everywhere. But yeah, so in general like lots of post- training tasks where you&#x27;d want to be able to to do that whether it&#x27;s unlearning a certain behavior or you know some of the other kind of cases where this comes up is are you familiar with like the the groing behavior? &gt;&gt; I mean I know the machine learning term of groing. &gt;&gt; Yeah. sort of this like double descent idea of of having a model that is able to learn a generalizing a generalizing solution as opposed to even if</p>
<p>memorization of some task would suffice, you want it to learn the more general way of doing a thing. And so, you know, another way that you can think about having surgical access to a model&#x27;s internals would be learn from this data but learn in the right way. um if there are many possible you know ways to to do that &gt;&gt; can meant trips solve the double descent problem &gt;&gt; depends I guess on how you &gt;&gt; okay so I I I view that double ascent as a problem because then you&#x27;re like well if the loss curves level out then you&#x27;re done but maybe you&#x27;re not done</p>
<p>&gt;&gt; right [clears throat] right &gt;&gt; but like if you actually can interpret what is uh generalizing or what is what is still changing even though the loss is not changing then maybe you you can actually not view it as a double the problem and actually you&#x27;re just sort of uh translating the space in which you view loss and you like then you have a smooth curve. &gt;&gt; Yeah, [laughter] I I think that&#x27;s certainly like the domain of of problems that we&#x27;re that we&#x27;re looking to get at. Yeah. to me like double descent is like the biggest thing to like ML research where like if you believe in scaling then you don&#x27;t you need to know where to</p>
<p>scale and but if you believe in double descent then you don&#x27;t you don&#x27;t believe in anything where like anything levels off like [laughter] &gt;&gt; yeah I mean also tangentially there&#x27;s like okay when you talk about the China vector right there&#x27;s the subliminal learning work it was from the anthropic fellows program where basically you can have hidden biases in a model and as you distill down or you know as you train on distilled data, those biases always show up even if like you explicitly try to not train on them. So, you know, it&#x27;s just like another use case of okay, if we can interpret what&#x27;s happening in</p>
<p>post- training, you know, can we clear some of this? Can we even determine what&#x27;s there? Because, yeah, it&#x27;s just like some worrying research that&#x27;s out there that shows, you know, we really don&#x27;t know what&#x27;s going on. &gt;&gt; That is, yeah, I think that&#x27;s the biggest sentiment that we&#x27;re sort of hoping to tackle. Nobody knows what&#x27;s going on, right? Like subliminal learning is just an insane concept when you think about it, right? Train a model on not even the lojits literal literally the output text of a bunch of random numbers and now your model loves owls. And you see behaviors like that that are just they defy they defy intuition and</p>
<p>and there are mathematical explanations that you can get into, but &gt;&gt; I mean early days &gt;&gt; objectively there are a sequence of numbers that are more allike than others. There there should be &gt;&gt; according [laughter] to according to certain models, right? It&#x27;s interesting. I think it only applies to models that were initialized from the same starting &gt;&gt; usually. Yes. But I mean I think that&#x27;s a that&#x27;s a cheat code because there&#x27;s not enough compute. But like it if you believe in like platonic representation like probably will transfer across different models. &gt;&gt; Oh, you think so? I think of it more as</p>
<p>a statistical artifact of models initialized from the same seed sort of um there&#x27;s something that is like path dependent from that seed that might cause certain overlaps in the latent space and then sort of doing this distillation. Yeah. Like pushes it towards having certain other tendencies. &gt;&gt; Got it.</p>
<h2>How Goodfire decides what to work on (customers → research agenda)</h2>
<p>&gt;&gt; I think research &gt;&gt; a bunch of these open-ended questions, right? like you can&#x27;t train in new stuff during the RL phase, right? RL only reorganizes weights and you can only do stuff that&#x27;s somewhat there in your base model. You&#x27;re not learning new stuff. You&#x27;re just reordering chains and stuff. But okay, my broader question is when you guys work at an interp lab, how do you decide what to work on and what&#x27;s kind of the thought process? Right? Cuz we can ramble for hours. Okay, I want to know this, I want to know that, but like how do you concretely like you know what&#x27;s the workflow? Okay, there&#x27;s like approaches towards solving a problem,</p>
<p>right? I can try prompting. I can look at chain of thought. I can train probes, SAEs. But how do you determine, you know, like okay, is this going anywhere? Like do we have set stuff? Just, you know, if you can talk about that. &gt;&gt; It&#x27;s a really good question. I feel like we&#x27;ve always um at the very beginning of the company thought about like let&#x27;s go and try to learn what isn&#x27;t working in machine learning today. whether that&#x27;s talking to customers or talking to researchers at other labs trying to understand um both where the frontier is going and where things are are really not falling apart today and then</p>
<p>developing a perspective on how we can push the frontier using interpretability methods. Um and so you know even our chief scientist Tom spends a lot of time talking to customers and trying to understand what real world problems are and then taking that back and trying to apply the current state-of-the-art in inter to those problems and then seeing where they fall down basically and then uh using that those failures or those shortcomings to understand what hills to climb when it comes to interpretability uh research. So like on the fundamental</p>
<p>side for instance when we have done some work applying SAE and and probes we&#x27;ve encountered you know some shortcomings in in Saes that we found a little bit surprising and so have gone back to the drawing board and and done work on um better foundational interpreter models and a lot of our team&#x27;s research is focused on what is the next evolution beyond SAES for instance and then when it comes to like control and design of models you know we tried steering with our first API and realized that it still fell short of blackbox techniques like prompting or fine-tuning and so went</p>
<p>back to the drawing board and were like how do we make that not the case and how do we improve it beyond that and one of our researchers ECDE who just joined is actually ECDE and Attakus are like steering experts and and have spent a lot of time trying to figure out like what is the research that enables us to actually do this in a much more powerful robust way. So yeah, the answer is like look at real world problems, try to translate that into a research agenda and then like hill climb on on both of those at the same time. &gt;&gt; Yeah, Mark has the steering CLI demo queued up which we&#x27;re going to go into a sec, but I always want to double click</p>
<p>on when you drop hints like we found some problems with SAEs. Okay, what are they? You know, and uh let&#x27;s let&#x27;s then we then we can go into the demo.</p>
<h2>SAEs vs probes: what works better for real-world detection tasks</h2>
<p>&gt;&gt; Yeah, I mean I I&#x27;m curious if you have more thoughts here as well because you&#x27;ve done it in in the healthcare domain. Um, but I think like for instance when we do things like trying to detect behaviors within models that are harmful or like behaviors that a user might not want to have in their model. So hallucinations for instance, harmful intent, PII, all of these things. We first tried using SAPE probes for a lot of these tasks. So taking the feature activation space from SAEs and then training classifiers on top of that and then seeing how well we can detect</p>
<p>the properties that we might want to detect in model behavior. And we&#x27;ve seen in many cases that probes just trained on raw activations seem to perform better than SAPE probes, which is a bit surprising if you think that SAEs are actually also capturing the concepts that you would want to capture cleanly and more surgically. And so that is an interesting observation. I don&#x27;t think that is like I&#x27;m not down on SAEs at all. I think there are many many things they&#x27;re useful for. But we have definitely run into cases where I think</p>
<p>the concept space described by SAEs is not as clean and uh accurate as as we would expect it to be for actual like real world downstream performance um metrics. &gt;&gt; Fair enough. &gt;&gt; Yeah. &gt;&gt; Yeah. It&#x27;s the blessing and the curse of unsupervised methods where you got to peek into the AI&#x27;s mind, but sometimes you wish that you saw other things when you when you looked [laughter] inside there. &gt;&gt; Although in the in the PII instance, I think weren&#x27;t SA an SAPE based approach actually did prove to be the most generalizable. &gt;&gt; Well, in in the case that we published with Rocketin and I think a lot of the</p>
<p>reasons it worked well was because we had a noisier data set. And so actually the blessing of unsupervised learning is that we actually got uh to get more meaningful generalizable signal from SAEs when the data was noisy. But in other cases where we&#x27;ve had like good data sets, it hasn&#x27;t been the case. &gt;&gt; And just because you named Rakutin and I don&#x27;t know if we&#x27;ll get it another chance like uh what what is the overall like what is Rakutin&#x27;s uh usage uh or production usage? Yeah. So they are</p>
<h2>Rakuten case study: production PII monitoring + multilingual + token-level scrubbing</h2>
<p>using us to essentially guard rail and inference time monitor their language model usage and their agent usage to detect things like PII so that they don&#x27;t route um private user information to um downstream model providers. And so that&#x27;s you know going through all of their user queries uh every day. And that&#x27;s something that we deployed with them a few months ago. And now we are actually exploring um very early partnerships not just with Rocketin but with other people around how we can help</p>
<p>with potentially training and customization use cases as well. &gt;&gt; Yeah. And for those who don&#x27;t know like it&#x27;s Racketin is like I think number one or number two e-commerce &gt;&gt; store in Japan. &gt;&gt; Yes. &gt;&gt; Yeah. Yeah. And I think that use case actually highlights a lot of like what it looks like to deploy things in practice that you don&#x27;t always think about when you&#x27;re doing sort of research tasks. So when you think about some of the stuff that came up there that&#x27;s more complex than your idealized version of a problem, they were encountering things like synthetic toreal transfer of methods. So they couldn&#x27;t train probes,</p>
<p>classifiers, things like that on actual customer data of PII. So what they had to do is use synthetic data sets and then hope that that transfers out of domain to real data sets and so we could evaluate performance on the real data sets but not not train on customer PII. So that right off the bat is like a big challenge. You have multi-ingual requirements. So this needed to work for both English and Japanese text. Japanese text has all sorts of quirks including tokenization behaviors that caused lots of bugs that caused us to be pulling our hair out. And then also a lot of tasks</p>
<p>you&#x27;ll see you might make simplifying assumptions if you&#x27;re sort of treating it as like the easiest version of the problem to just sort of get like general results where maybe you say you&#x27;re classifying a sentence to say does this contain PII but the need that racketin had was token level classification so that you could precisely scrub out the PII. So as we learned more about the problem and you&#x27;re sort of speaking about what that looks like in practice. Yeah. a lot of assumptions end up breaking and that was just one instance where you a problem that seems simple right off the bat ends up being more</p>
<p>complex as you keep diving into it. &gt;&gt; Excellent. One of the things that&#x27;s also interesting with interp is a lot of these methods are very efficient right so where you&#x27;re just looking at a model&#x27;s internals itself compared to a separate like guardrail LM as a judge a separate model one you have to host it two there&#x27;s like a whole latency so if you use like a big model you have a second call some of the work around like self detection of hallucination it&#x27;s also deployed for efficiency right so thinking of someone like rakuten doing it in production live you know that&#x27;s just another thing people should</p>
<p>consider Yeah. And something like a probe is super lightweight. Adds no extra latency really. &gt;&gt; Excellent. Uh you have the steering demos uh lined up. So we were just kind of see what you got. I I don&#x27;t I don&#x27;t actually know if this is like the latest latest or like alpha thing.</p>
<h2>Live steering demo on a 1T-parameter model (and scaling challenges)</h2>
<p>&gt;&gt; No, this is a pretty hacky demo from uh from a presentation that someone else on the team recently gave. So this will give a sense for for steering in action. Honestly, I think the biggest thing that this highlights is that as we&#x27;ve been growing as a company and taking on kind of more and more ambitious versions of interpretability related problems, a lot of that comes to scaling up in various different forms. And so here you&#x27;re going to see steering on a one trillion parameter model. This is Kimmy K2. Uh, and so it&#x27;s sort of fun that in addition</p>
<p>to the research challenges, there are engineering challenges that we&#x27;re now tackling because for any of this to be sort of useful in production, you need to be thinking about what it looks like when you&#x27;re using these methods on frontier models um as opposed to sort of like toy kind of model organisms. So yeah, this was thrown together hastily, pretty fragile behind the scenes, but uh I think it&#x27;s quite a fun demo. So screen sharing is is on. So, I&#x27;ve got two terminal sessions pulled up here. On the left is a forked version that we have of the Kimmy uh CLI that we&#x27;ve got running to point at our custom hosted Kimmy</p>
<p>model. And then on the right is a uh setup that will allow us to steer on certain concepts. So, I should be able to chat with Kimmy over here. Tell it hello. &gt;&gt; Is this running locally? So the CLI is running locally, but the Kimmy server is running back to the office. Well, hopefully should be. [laughter] Um, &gt;&gt; that&#x27;s too much to run on that Mac. &gt;&gt; Yeah, I think it&#x27;s uh it takes a full like H100 node. I think it&#x27;s like you can run it on 8GPUs. H100. So So yeah, Kimmyy&#x27;s running. We can ask it to</p>
<p>prompt. It&#x27;s got a forked version of our uh of the SGline codebase that we&#x27;ve been working on. So I&#x27;m going to tell it, hey, this SGLine codebase is slow. I think there&#x27;s a bug. Can you try to figure it out? It&#x27;s a big code base, so it&#x27;ll it&#x27;ll spend some time doing this. And then on the right here, I&#x27;m going to initialize in real time some steering. Let&#x27;s see here. Continue searching for any bugs. &gt;&gt; Feature ID 43205 layers 20 30 40. &gt;&gt; So, let me uh this is basically a feature that we found that inside Kimmy</p>
<p>seems to cause it to speak in Gen Z slang. &gt;&gt; [laughter] &gt;&gt; And so on the left, it&#x27;s still sort of thinking normally. It might take, I don&#x27;t know, 15 seconds for this to kick in, but then [clears throat] we&#x27;re going to start hopefully [laughter] seeing it. Dude, this code base is massive for real. [laughter] So, we&#x27;re going to start seeing Kimmy transition as the steering kicks in from normal Kimmy to Gen Z Kimmy [laughter] and both in its chain of thought and its actual outputs.</p>
<p>And interestingly, you can see, you know, it&#x27;s still able to call tools uh and stuff. It&#x27;s um it&#x27;s purely sort of its its demeanor. And there are other features that we found for interesting things like concision. So, that&#x27;s more of a practical one. You can make it more concise. Um the types of programs uh programming languages it uses. But yeah, as we&#x27;re seeing it come in, pretty good output. &gt;&gt; Scheduler code is actually wildl</p>
<h2>Feature labeling + auto-interpretation + can we “turn down” hallucinations?</h2>
<p>[laughter] um something about how agents for interp is different than like coding agents. I don&#x27;t know. While this is spewing up, how how do we find feature 43205? &gt;&gt; Yeah. So, in this case, um we our platform that we&#x27;ve been building out for a long time now supports all the</p>
<p>sort of classic out of the box interp techniques that you might want to have like SAPE training, probing, things of that kind. I&#x27;d say the techniques for like vanilla ses are pretty wellestablished now where you take your model that you&#x27;re interpreting run a whole bunch of data through it gather activations and then yeah pretty straightforward pipeline to train an SAPE there are a lot of different varieties there&#x27;s top kes batch top kes um normal relu seaes and then once you have your sparse features to your point</p>
<p>assigning labels to them to actually understand that this is the Gen Z feature. That&#x27;s actually where a lot of the kind of magic happens. And the most basic standard technique is look at all of your input data set examples that cause this feature to fire most highly and then you can usually pick out a pattern. So for this feature, if I&#x27;ve run a diverse enough data set through my model, feature 43.205 probably tends to fire on all the uh tokens that sound like Gen Z slang. And um so you know you could have a human go</p>
<p>through all 43,000 concepts and look at the pattern but to automate that you just kind of hand those examples off to a frontier LLM and ask it to identify that pattern. &gt;&gt; And I&#x27;ve got to ask the basic question you know can we get examples where it hallucinates pass it through see what feature activates for hallucinations? Can I just you know turn hallucination down? &gt;&gt; Oh wow. you you really uh solved it. &gt;&gt; You really predicted [laughter] some a project we&#x27;re already working on right now, which is um detecting hallucinations using interpretability techniques. And this is interesting because hallucinations is something</p>
<p>that&#x27;s very hard to detect and it&#x27;s like a kind of a hairy problem and something that blackbox methods really struggle with. Um whereas like Gen Z, you could always train a classifi a simple classifier to to detect that um hallucinations is harder. But we&#x27;ve seen that models internally have some awareness of of like uncertainty or some sort of like user pleasing behavior that leads to hallucinatory behavior. Um, and so yeah, we have a project that&#x27;s trying to detect that accurately and then also working on mitigating the hallucinatory</p>
<p>behavior in the model itself as well. &gt;&gt; Yeah. And I would say most people are still at the level of like, oh, I&#x27;ll just turn temperature to zero and that turns off hallucination. And I&#x27;m like, well, that&#x27;s a fundamental misunderstanding of how this works. &gt;&gt; Yeah. Although, so part of what I like about that question is you there are SAPE based approaches that might like help you get at that. But often times the beauty of SAEs and like we said the curse is that they&#x27;re unsupervised. So when you have a behavior that you deliberately would like to remove and that&#x27;s more of like a supervised task, often it is better to use something like probes and and specifically target the</p>
<p>thing that you&#x27;re interested in reducing as opposed to sort of like hoping that when you fragment the latent space, one of the vectors that pops out will be the thing you&#x27;re interested in. And as much as we&#x27;re training an autoenccoder to be sparse, we&#x27;re not like for sure certain that, you know, we will get something that just correlates to hallucination, right? you&#x27;ll you&#x27;ll probably split that up into 20 other things and who knows what they&#x27;ll be &gt;&gt; of course right yeah so there&#x27;s known sort of problems with like feature splitting um and feature absorption and then there&#x27;s the offt target effects right ideally you would want to be very</p>
<p>precise where if you reduce the hallucination feature suddenly maybe your model can&#x27;t write creatively anymore and maybe you don&#x27;t like that but you want to still stop it from hallucinating facts and figures &gt;&gt; good uh so people has a paper to recommend there that we&#x27;ll put in the show notes but yeah I mean I guess just because your demo is done. Uh any any other things that you want to highlight or any other interesting features you want to show? &gt;&gt; I don&#x27;t think so. Yeah, like I said, this is a pretty small snippet. I think the main sort of point here that I think is exciting is that there&#x27;s not a whole lot of inter being applied to models</p>
<p>quite at at this scale. You know, Anthropic certainly has some some research and yeah, other other teams as well. But it&#x27;s it&#x27;s nice to see these techniques, you know, being put into practice. I think not that long ago the idea of real time steering of a trillion parameter model would have sounded &gt;&gt; yeah the fact that it&#x27;s real time like you you started the thing and then you edited uh the steering vector I think it&#x27;s it&#x27;s an interesting one uh TBD what the actual like production use case would be on that like the real-time editing um &gt;&gt; it&#x27;s like that&#x27;s the fun part of the demo right you can kind of see how this could be served behind an API right like</p>
<p>you&#x27;re you only have so many knobs and you can just tweak it a bit more and I don&#x27;t know how it plays in people haven&#x27;t done that much with like how does this work with or without prompting right how does this work with fine-tuning like there&#x27;s the whole hype of continual learning right so there&#x27;s just so much to see like is this another parameter like is it like parameter we just kind of leave it as a default we don&#x27;t use it so I don&#x27;t know maybe someone here wants to put out a guide on like how to use this with prompting when to do what &gt;&gt; oh well I have a paper recommendation that I think you would love from uh ectep on our team who um is an amazing</p>
<h2>Steering vs prompting equivalence + jailbreak math + customization implications</h2>
<p>research just can&#x27;t say enough amazing things about act. He actually has a paper that as well as some you know others from from the team and elsewhere that go into the essentially equivalents of activation steering and in context learning and how those are from a he he thinks of everything in a cognitive neuroscience basian framework. But basically how you can precisely show how prompting in context learning and steering exhibit similar behaviors and even like get quantitative about the</p>
<p>like magnitude of steering you would need to do to induce a certain amount of behavior similar to certain prompting uh even for things like jailbreaks and stuff. It&#x27;s a really cool paper. &gt;&gt; Are you saying steering is less powerful than prompting? more like you can almost write a formula that tells you how to convert between the two of them and so &gt;&gt; be formally equivalent actually in the in the limit &gt;&gt; right so like one case study of this is for jailbreaks there I don&#x27;t know have you seen the stuff where you can do like</p>
<p>manyot jailbreaking you like flood the context with examples of the behavior &gt;&gt; when put out that paper a lot of people were like yeah we&#x27;ve been doing this guys like what [laughter] happens Yeah. Um, what&#x27;s in this in context learning and activation steering equivalence paper is you can like predict the number of examples that you will need to to put in there in order to jailbreak the model. That&#x27;s cool. &gt;&gt; By doing steering experiments and using this sort of like um equivalence mapping. &gt;&gt; That&#x27;s cool. That&#x27;s really cool. &gt;&gt; That&#x27;s very neat. &gt;&gt; Yeah. I was going to say like uh you</p>
<p>know I can like back rationalize that this makes sense because you know what context is is basically just you know it updates the KV cache kind of and like and and and then every next token inference is still like you know that the the sheer sum of everything all the weights plus all the context up to date and you could I guess theoretically steer that with uh you probably replace that with your um steering. The only problem is steering typically is on one layer, maybe three layers like like you did. So it&#x27;s like not exactly equivalent.</p>
<p>&gt;&gt; Right. Right. There&#x27;s sort of you need to uh get precise about Yeah. like how you sort of define steering and like what how how you&#x27;re modeling the setup. But yeah, I&#x27;ve got the paper pulled up here. Belief dynamics reveal the dual nature. &gt;&gt; Yeah. The title is belief dynamics reveal the dual nature of in context learning and activation steering. So Eric Bigalow um Dana Warcraft on the um who are uh doing fellowships at Goodfire ECE&#x27;s the the final author there. I think actually to your your question of like what is the production use case of steering I think maybe if you just think like one level beyond steering as as it</p>
<p>is today like imagine if you could adapt your model to be I don&#x27;t know an expert legal reasoner like in almost real time like very efficiently using human feedback or using like your semantic understanding of what the model knows and where it knows that uh behavior. I think that while it&#x27;s not clear what the product is at the end of the day, it&#x27;s clearly very valuable. Thinking about like what&#x27;s the next interface for for model customization and adaptation is a</p>
<p>really interesting um problem for us. Like we have heard a lot of people actually interested in fine-tuning and RL for openweight models in in production. And so people are using things like um Tinker or kind of like uh open source libraries to do that. But it&#x27;s still very difficult to get models fine-tuned and RL for exactly what you want them to do unless you&#x27;re an expert at at model training. And so that&#x27;s like something we&#x27;re looking into. &gt;&gt; Yeah. Um I never thought so Tinker from thinking machines famously uses uh rank</p>
<p>one Laura. Is that basically the same as steering? Like you know what&#x27;s the comparison there? &gt;&gt; Well, so in that case you are still applying updates to the parameters, right? You&#x27;re not you&#x27;re not touching a base model. You&#x27;re you&#x27;re touching an adapter. It&#x27;s kind of &gt;&gt; Yeah. &gt;&gt; Right. But I I guess it still is like more in parameter space than I guess it&#x27;s maybe like are you modifying the pipes or are you modifying the water flowing through the pipes? &gt;&gt; Okay. &gt;&gt; To get what you&#x27;re after. &gt;&gt; Yeah. &gt;&gt; Is maybe one way. [laughter] &gt;&gt; I like that analogy. &gt;&gt; That that&#x27;s my mental map of it at</p>
<p>least. But it gets at this idea of model design and intentional design which is something that we&#x27;re that we&#x27;re very focused on. And just the fact that like I hope that we look back at how we&#x27;re currently training models and post-training models and just think what a primitive way of doing that right now. Like there&#x27;s no intentionality really in &gt;&gt; it&#x27;s just data right the only thing can control what data we feed in. So, so Dan from Goodfire likes to use this analogy of um, you know, he has a couple of young kids and he talks about like, &quot;What if I could only teach my kids how</p>
<p>to be good people by giving them cookies or like, you know, giving them a slap on the wrist if they do something wrong?&quot; Like not telling them why it was wrong or like what they should have done differently or something like that. Just figure out action. Right. Exactly. &gt;&gt; So that&#x27;s RL. &gt;&gt; Yeah. Right. And then, you know, it&#x27;s sample inefficient. There&#x27;s, you know, what do they say? It&#x27;s like slurping uh feedback. It&#x27;s like slurping supervision throughout. And so you&#x27;d like to get to the point where you can have experts giving feedback to their models that are uh internalized</p>
<p>&gt;&gt; and and you know steering is &gt;&gt; an inference time way of sort of getting that idea but ideally you&#x27;re moving to a a world where it is much more intentional design in perpetuity for these models. Okay, this is one of the questions we asked Emanuel from Anthropic on the podcast a few months ago. Basically, the question was, you&#x27;re at a research lab that does model training, foundation models, and you&#x27;re on an interp team. How does it tie back, right? Like, does this do ideas come from the pre-training team? Do they go back? Um, you know, so for those interested, you can you can watch that.</p>
<p>There wasn&#x27;t too much of a connect there, but it&#x27;s still something, you know, it&#x27;s something they want to push for down the line. &gt;&gt; It can be useful for all of the above. like there are certainly post hawk use cases where it doesn&#x27;t need to touch that. I think the other thing a lot of people forget is this stuff isn&#x27;t too computationally expensive right like I would say if you&#x27;re interested in getting into research mechan is one of the most approachable fields right a lot of this train a probe this stuff like the budget for this one there&#x27;s already a lot done there&#x27;s a lot of open source</p>
<p>work you guys have done some too um you know you can &gt;&gt; there&#x27;s like there&#x27;s like notebooks from the Gemini team from Neil Nanda who are like this is how you do it just step through the notebook &gt;&gt; even if you&#x27;re like not even technical with any of this you can still make like progress there. You can look at different activations, but uh if you do want to get into training, you know, training this stuff, correct me if I&#x27;m wrong, is like in the thousands of dollars, not even like it&#x27;s not that high scale. And then same with like, you know, applying it, doing it for post- training, RL, all this stuff is fairly cheap in scale of okay, I want to get into like model training. I don&#x27;t have</p>
<p>compute for like, you know, pre-training stuff. So, it&#x27;s it&#x27;s a very nice field to get into. And also, there&#x27;s a lot of like open questions, right? There&#x27;s so many questions we have. Some of them have to go with, okay, I want a product. I want to solve this. Like, there&#x27;s also just a lot of open-ended stuff that people could work on that&#x27;s interesting, right? I don&#x27;t know if you guys have any calls for like what&#x27;s open questions, what&#x27;s open work that you either open</p>
<h2>Open problems + how to get started in mech interp</h2>
<p>collaboration with or like you&#x27;d just like to see solved or just, you know, for people listening that want to get into mechan because people always talk about it. What are what are things they should check out? Start of course, you know, join you guys as Well, I&#x27;m sure you&#x27;re &gt;&gt; there&#x27;s a paper I think from was it Lee uh Shy? It&#x27;s open problems in interpretability which I recommend everyone who&#x27;s interested in the field read. Um just like a really comprehensive overview of what are the things that experts in the field think are the most important problems to be solved. I also think to your point it&#x27;s been really really inspiring to see I think a lot of young people getting</p>
<p>interested in interpretability. actually not just young people also like scientists who have been you know experts in physics for many years and in biology or things like this um transitioning into interp because the barrier to entry is is you know in in some ways low and and there&#x27;s a lot of information out there um and ways to get started. There&#x27;s this anecdote of like professors at university saying that all of a sudden every incoming PhD student wants to study interpretability um which was not the case a few years ago. So it just goes to to show how I guess like</p>
<p>exciting the field is, how fast it&#x27;s moving, how quick it is to get started and things like that. And also just a very welcoming community. You know, there&#x27;s an open-source mechan slack channel where people are always posting questions and just folks in the space are always responsive if you ask things on various forums and stuff. Um, but yeah, the open paper uh open problems uh paper is is a really good one &gt;&gt; for other people who want to get started. I think you know Matts is a great program. What&#x27;s the acronym for? Machine learning and alignment theory scholars I think. [laughter]</p>
<p>&gt;&gt; It&#x27;s like the normally summer internship style. &gt;&gt; Yeah. But they&#x27;ve been doing it year round now and um actually a lot of our full-time staff have come through that program or or gone through that program and um it&#x27;s great for anyone who is transitioning into interpretability. Um there&#x27;s a couple other fellows programs. we do one as well as anthropic and so those are great places to get started if anyone is is interested &gt;&gt; also I think been seen as a research field for a very long time but I think engineers are sorely wanted for for</p>
<p>interpretability as well um especially at good fire but but elsewhere uh as as it does scale up &gt;&gt; I should mention that Lee actually works with you guys right and in the London office and um I&#x27;m adding our first ever meant track and edi Europe because I I see this industry applications now emerging and I&#x27;m pretty excited to, you know, help get push that along. &gt;&gt; Yeah, I &gt;&gt; it&#x27;ll effectively be the first industry mechan conference. &gt;&gt; Yeah, I&#x27;m uh I&#x27;m so glad you added that. &gt;&gt; You know, it&#x27;s it&#x27;s a still a little bit</p>
<p>of a bet like this there it&#x27;s not like that widespread, but like I I can definitely see like this is the time to like really get into it like you want to be early on things &gt;&gt; for sure. And I think the field is understands this, right? So like at ICML the I think like title of the mech interp workshop this year was actionable interpretability and there was a lot of discussion around bringing it to to various domains. Um, &gt;&gt; everyone&#x27;s everyone&#x27;s adding like pragmatic pragmatic &gt;&gt; actionable like whatever like okay well we weren&#x27;t actionable before I guess I don&#x27;t know &gt;&gt; and I mean like just you know being at Europe you see the interp room uh one</p>
<p>like old school conferences like I think they had a very tiny room till they got lucky and they got it doubled but there&#x27;s definitely a lot of interest a lot of nich niche research so you see a lot of research coming out of university students we covered the paper uh last week it&#x27;s two unknown authors, not many citations, but you know, you can make a lot of meaningful work there. &gt;&gt; One thing I I did want to call out because I think people haven&#x27;t really uh mentioned this yet is uh just interfer uh I think is is like an abnormally important field. We haven&#x27;t mentioned this yet. The conspiracy theory last two years ago was when the first SA word</p>
<p>came out of anthropic was they they were like, &quot;Oh, we just used uh SAEs to turn the bad code vector down [laughter] uh and then turn up and then code &gt;&gt; turn up the good code.&quot; Uh and uh I think like isn&#x27;t that the the dream like you know like but basically I guess maybe why is it funny like it&#x27;s it&#x27;s if it was realistic it would not be funny it would be like no actually we should do this but it&#x27;s funny because we know there&#x27;s like we feel there&#x27;s some limitations to what steering can do and I think a lot of the public image of uh steering is like the Gen Z stuff like</p>
<p>like oh you can make it really love the Golden Gate Bridge or you can make it speak like Gen Z to like be a legal no reason or seems like a huge stretch. &gt;&gt; Yeah. &gt;&gt; And I don&#x27;t know if that we&#x27;ll get there this way. &gt;&gt; Yeah. I think um I will say we are announcing something very soon that I will not speak too [laughter] much about. Um but I think yeah, this is like what we&#x27;ve run into again and again is like we we don&#x27;t want to be in the world where steering is only useful for like stylistic things. That&#x27;s definitely not not what we&#x27;re um aiming for. But I think the types of interventions that</p>
<p>you need to do to get to things like legal reasoning um are much more sophisticated and require breakthroughs than in learning algorithms. And that&#x27;s um &gt;&gt; and is this an emerging property of scale as well? &gt;&gt; I think so. Yeah. I mean I think scale definitely helps. I think scale allows you to learn a lot of information and and reduce noise across you know large amounts of data. But I also think we think that there&#x27;s ways to do things much more effectively. um even even at scale. So like actually learning exactly what you want from the data and not</p>
<p>learning things that you do that you don&#x27;t want exhibited in the data. So we&#x27;re not like anti-scale but we are also realizing that scale is not going to get us to the type of AI development that we want to be at in in the future as these models get more powerful and get deployed in all these sorts of like mission critical contexts. current life cycle of training and deploying and evaluations is is to us like deeply broken and and has opportunities to to improve. So uh more to come on that very very soon</p>
<p>&gt;&gt; and I think that the basically maybe are just like a proof point that these concepts do exist like if you can manipulate them in the precise best way you can get the ideal combination of them that you desire and steering is maybe the most coar grained sort of peak at what that looks like but I think it&#x27;s evocative of what you could do if you had total surgical control over &gt;&gt; every &gt;&gt; concept every parameter. Yeah, exactly. &gt;&gt; There were like bad code features. &gt;&gt; I&#x27;ve got it pulled up &gt;&gt; just coincidentally as you guys were</p>
<p>talking. So, &gt;&gt; this was like this is exactly what people thought it &gt;&gt; there&#x27;s like specifically a code error feature that activates and they show it off. It&#x27;s not it&#x27;s not typo detection. It&#x27;s like it&#x27;s it&#x27;s typos in code. It&#x27;s not typical typos. And you know, you can you can see it clearly activates where there&#x27;s something wrong in code. And they have like malicious code, code error. They have a whole bunch of sub, you know, subbroken down little grain features. &gt;&gt; Yeah. &gt;&gt; Yeah. So, so the the rough intuition for me, the why I talked about post training was that well, you just, you know, have a few different rollouts with all these</p>
<p>things uh turned off and on and whatever and then, you know, you can that&#x27;s that&#x27;s synthetic data you can kind of post train on. &gt;&gt; Yeah. &gt;&gt; And I think we make it sound easier than it is just saying, you know, do they they do the real hard work. &gt;&gt; I mean, you guys you guys have the right idea. Exactly. Yeah. We replicated a lot of these features in in our llama models as well. I remember there was like &gt;&gt; and I think a lot of this stuff is open right like yeah you guys opened yours um deep mind has opened a lot of essays on um Gemma even anthropic has opened a lot of this there&#x27;s there&#x27;s a lot of resources that you know we can probably share of people that want to get</p>
<p>involved &gt;&gt; and special shout out to like Neuronedia as well like uh yeah amazing piece of work to visualize those things &gt;&gt; yeah exactly</p>
<h2>Applications: healthcare + scientific discovery (biomarkers, Mayo Clinic, etc.)</h2>
<p>&gt;&gt; I guess I wanted to pivot a little bit on onto the healthcare side uh because I I think that&#x27;s a big use case for you guys. Uh we haven&#x27;t really talked about it yet. This is a bit of a crossover for me because we are se we are we do have a separate science pod that we&#x27;re starting up for [laughter] science. &gt;&gt; Wow. Okay. &gt;&gt; Uh just because like it&#x27;s such a huge investment category and also I&#x27;m like less qualified to do it. We actually have bio PhDs to cover that which is great but I just kind of recap your work maybe on the EVO 2 stuff but then and then building forward. &gt;&gt; Yeah, for sure. And maybe to frame up the conversation, I think another kind of interesting just lens on</p>
<p>interpretability in general is a lot of the techniques that we&#x27;re describing are ways to solve the AI human interface problem and it&#x27;s sort of like birectional communication is the goal there. So what we&#x27;ve been talking about with intentional design of models and you know steering but also more advanced techniques is having humans impart our desires and control into models and over models and the reverse is also very interesting especially as you get to superhuman models whether</p>
<p>that&#x27;s narrow super intelligence like these scientific models that work on genomics data medical imaging things like that but down the line you know super intelligence of other forms as well. what knowledge can the AIS teach us as sort of that that the other direction in that and so some of our life science work to date has been getting at exactly that question which is well some of it does look like debugging these various life sciences models understanding if they&#x27;re actually performing well on tasks or if they&#x27;re picking up on spurious correlations for</p>
<p>instance genomics models you would like to know whether they are sort of focusing on the biologically relevant things that you care about or if it&#x27;s using some simpler coralate like the ancestry of the person that it&#x27;s looking at. But then also in the instances where they are superhuman and maybe they are understanding elements of the human genome that we don&#x27;t have names for or um specific you know yeah discoveries that they&#x27;ve made that that we don&#x27;t know about. That&#x27;s that&#x27;s a big goal. And so we&#x27;re already seeing that right</p>
<p>we are partnered with organizations like Mayo Clinic leading research health system in in the United States Arc Institute as well as uh a startup called Prima which focuses on neurodeenerative disease and in our partnership with them we&#x27;ve used foundation models they&#x27;ve been training and applied our interpretability techniques to find novel biomarkers for um Alzheimer&#x27;s disease. So, I think this is just the tip of the iceberg, but it&#x27;s uh that&#x27;s like a flavor of some of the things that we&#x27;re working on.</p>
<p>&gt;&gt; Yeah, I think that&#x27;s really fantastic. We obviously we did the Chan Zuckerberg uh pod last year as well, and like there&#x27;s a plethora of these models coming out because there&#x27;s so much um potential and research. Um and it&#x27;s like very interesting how it&#x27;s basically the same as language models, but just with a different underlying data set, but like it&#x27;s the same exact techniques. like there&#x27;s no change basically. &gt;&gt; Yeah. [laughter] Well, and even in like other domains, right? Like I you know, robotics I know like a lot of the companies just use Gemma as like the the like backbone and then they like make it</p>
<p>into a VLA that like takes these actions. It&#x27;s it&#x27;s it&#x27;s transformers all the way down. So like we we have Medma now, right? Like this week even there was Medma 1.5. Uh and they&#x27;re they&#x27;re training it on this stuff like 3D scans, medical domain knowledge and all that stuff too. So there&#x27;s a push from both sides but I think the thing that you know one of the things about mechan is like you&#x27;re a little bit more cautious in some domains right so healthcare mainly being one like guard rails understanding you know we&#x27;re we&#x27;re more riskadverse to something going wrong</p>
<p>there so even just from a basic understanding like if we&#x27;re trusting these systems to make claims we want to know why and what&#x27;s going on. Yeah, I think there&#x27;s totally a kind of like deployment bottleneck to actually using foundation models for real patient usage or things like that. Like say you&#x27;re using a model for rare disease prediction, you probably want some explanation as to why your model predicted a certain outcome and an interpretable explanation at that. So that&#x27;s definitely a use case. But I also think like being able to extract</p>
<p>scientific information that no human knows to accelerate drug discovery and disease treatment and things like that actually is a really really big unlock for sc like scientific discovery and you&#x27;ve seen a lot of startups like say that they&#x27;re going to accelerate scientific discovery and I feel like we actually are doing that through our interp techniques and kind of like almost by accident like I think We got reached out to very very early on from these healthcare institutions and none of us had healthare.</p>
<p>&gt;&gt; How did they even hear of you? Like &gt;&gt; a podcast. &gt;&gt; Okay. Yeah, podcast. Okay. Well, now is that time, you know, like [laughter] everyone everyone can call us up. &gt;&gt; Podcast are the most important thing. Everyone should listen to podcast and everyone should come to &gt;&gt; podcast. They were like, you know, we have these really smart models that we&#x27;ve trained and we want to know what they&#x27;re doing. Um, and we were like really early that time, like 3 months old, and it was a few of us, and we were like, &quot;Oh my god, let&#x27;s [laughter] we&#x27;ve never used these models. Let&#x27;s figure it out.&quot; Um, but it&#x27;s also like great proof that interpret techniques scale pretty well across across domains. We didn&#x27;t really have to learn too much about</p>
<p>&gt;&gt; interp is a a machine learning technique, machine learning skills everywhere, right? Like, and then there&#x27;s obviously it&#x27;s just like a general insight. Um, probably to finance too, I think, which would be fun for our history. Um I don&#x27;t know if you have anything to say there. &gt;&gt; Well, just across the science like we&#x27;ve also done work on material science. Yeah, it it really runs the gambit. &gt;&gt; Yeah. Awesome. &gt;&gt; And you know, for those that should reach out like you&#x27;re obviously experts in this, but like is there a call out for people that you&#x27;re looking to partner with, design partners, people to use your stuff outside of just, you</p>
<p>know, the general developer that wants to plugandplay steering stuff? like on the research side more so like are there ideal design partners, customers, stuff like that that &gt;&gt; yeah I can talk about maybe non life sciences and then I&#x27;m curious to hear from you on the life sciences side but um we&#x27;re looking for design partners across many domains language anyone who&#x27;s customizing language models or trying to push the frontier of code or reasoning models is really interesting to us and then also interested in the frontier of models that work in like</p>
<p>pixel space as we call it. So if you&#x27;re doing world models, video models, um even robotics um where there&#x27;s not a very clean natural language interface to interact with um I think we think that interp can really help and are looking for a few partners in in that space. &gt;&gt; Just cuz you you mentioned the keyword world models um is that a big part of your thinking? Do you have a definition that I can use because everyone&#x27;s asking me about it [laughter] &gt;&gt; uh about world models? There&#x27;s quite a few definitions. Let&#x27;s say &gt;&gt; I don&#x27;t feel equipped to be [laughter]</p>
<p>an expert on world model definitions, but the reason we&#x27;re interested in them is because they give you like, you know, with language models when you get uh features, you still have to do auto interpret and things like that to actually get an understanding of of what this concept is. But in image and video and world, it&#x27;s like extremely easy to to gro what the concept is because you can see it and you can visualize it. And um this makes the feedback cycle extremely fast um for us also for things like I don&#x27;t know if you take think about probes in language model context</p>
<p>and then take it to world models like what if you wanted to detect harmful actors in world model scenes like you can&#x27;t actually like go and label all of that data feasibly but you maybe you could um synthetically generate you know I don&#x27;t know world like harmful actor uh data using SAPE feature activations or whatever. and then actually train a probe that was able to detect that much more scalably. So, [snorts] I just think like video and image and world has always been something we&#x27;ve explored and are continuing to explore. Um, Mark&#x27;s</p>
<p>demo was probably the first moment we really like were like, &quot;Oh, wow.&quot; Like, this is really going to this could really like change the world of &gt;&gt; the steering demo. &gt;&gt; Yeah. No, the image demo. &gt;&gt; The the diffusion one. Exactly. &gt;&gt; Yeah. Yeah. We should probably show that and and you demoed it at Worlds Fair. So we can choose to link that. &gt;&gt; Nice. Yeah, &gt;&gt; people can play with it, right? &gt;&gt; Yes. &gt;&gt; Yeah. I think for for me one way in which I I think about world models is just like this like having this consistent model of the world where everything that you generate operates</p>
<p>within the rules of that world. And imagine it would be a bigger deal for science uh or like math or anything that where like you have verifiable rules whereas I guess in natural language maybe there&#x27;s less rules. And so it&#x27;s not not that important. &gt;&gt; Yeah. And and which makes the debugging of the model&#x27;s internal representations or it&#x27;s internal world model to the extent you can make that legible and explicit and have control over that. I think it makes it all the more important because in language it&#x27;s sort of a fuzzy enough domain that if its world model</p>
<p>isn&#x27;t fully like ours, it can still sort of like pass the Turing test so to speak. But I know there have been papers that have looked at like even if you train certain astrophysics models, it does not learn F= MA. Like the same way that you can, you know, have a model do well for modular arithmetic, but it doesn&#x27;t really like learn what how we think of modular arithmetic. It learns some crazy heristic that is like essentially functionally equivalent, but it&#x27;s probably not the sort of groed solution that you would hope for. &gt;&gt; It&#x27;s how an alien would do it,</p>
<p>&gt;&gt; right? Exactly. Uh but but no no I that&#x27;s probably I think a function of our learning being bad rather than the well that approach probably not being real because it&#x27;s it&#x27;s how we humans learn &gt;&gt; right &gt;&gt; yeah right well it&#x27;s just it&#x27;s the problem of induction right all of ML is based on induction and and it&#x27;s impossible to say I have a physics model you might have a physics model that works all the time except when there is a character wearing a blue shirt and green shoes and like you you can&#x27;t disprove that that&#x27;s the case unless you test every particular situation your</p>
<p>model might be in. Um, so we know that the laws of physics apply no matter where you are, what scenario it is, but from a model&#x27;s perspective, maybe something that&#x27;s out of distribution, it just never needed to learn that the same laws of physics apply there. &gt;&gt; Yeah. You were very excited because I I</p>
<h2>Induction + sci-fi intuition (Ted Chiang)</h2>
<p>read Ted Chang over the holidays. Um, and I was very inspired by this uh short story called Understand. Uh, which apparently it&#x27;s like pretty old. You you must be familiar with it. To me, it was like it&#x27;s this fictional story. It&#x27;s like the inverse of flowers for Alenon where uh you had someone like uh get really smart but then also try to outsmart the tester &gt;&gt; and the story just read like the chain of thought of an of a super intelligence right where they&#x27;re like oh I realize I&#x27;m being tested therefore and okay what&#x27;s the consequence of being tested oh they&#x27;re testing me and if I score</p>
<p>well they will use me for things that I don&#x27;t want to do therefore I will score badly and like but not too badly that they&#x27;ll raise alarms. So [laughter] it&#x27;s just like uh so model sandbagging is a thing that people have have explored but I just think like uh Ted Chang&#x27;s work just in general seems to be something that inspires you. I just wanted to prompt you to talk about it. &gt;&gt; I think so Ted Chang has two is a is a sci-fi author who writes amazing short stories and &gt;&gt; his other claim to fame is uh stories of our lives which became uh the movie Arrival. &gt;&gt; Exactly. Yeah. So so two books of short stories that I&#x27;m aware of. He also actually also has a great um just online</p>
<p>blog post. I think he&#x27;s the one who coined the term of LLMs as like a blurry JPEG of the internet. I should fact check that, but he it&#x27;s a good it&#x27;s a good post. But I think almost every one of his short stories has some lesson to bear on thinking about AI and thinking about AI research. So, you know, you you&#x27;ve been talking about alien intelligence, right, in this AI human communication translation problem. That&#x27;s, you know, exactly sort of what&#x27;s going on in arrival in story of um story of your life. And just the fact that other beings will think and operate and</p>
<p>communicate in ways that are not just challenging for us to understand, but just fundamentally different in ways that we might not even be able to expect. And then the one that&#x27;s just super relevant for interpretability is the other short book of short stories he has is called Exhalation. And that is literally about a robot doing interpretability on its own mind. &gt;&gt; Oh, okay. &gt;&gt; Uh so I just think that that you know you don&#x27;t you don&#x27;t even have to squint to make the analogies there. &gt;&gt; Well, I I actually take uh Exhalation as a discussion about entropy and order. Uh</p>
<p>but yes, there&#x27;s this there&#x27;s a scene in Exhalation where basically the the uh so everyone is a robot. Uh so the the guy realizes he can set up a mirror to work on the back of his own head and then starts doing operations like that and by looking at the mirror and doing this. [laughter] &gt;&gt; Yeah. And I think Ted Chang has written about like the inspiration for that story. It was like half inspired by some of the thing he had been doing on Entropy. There&#x27;s apparently some other short story that is similar where a character goes to the doctor and opens up his chest and there&#x27;s like a like a ticker tape going along. It&#x27;s like he basically realizes he&#x27;s like a touring</p>
<p>machine. Um and I don&#x27;t know I I think especially as it comes to using agents for interp that story always sticks in my mind. &gt;&gt; I find the uh brain surgery or like surgery analogies a little bit a little bit morbid but it is very apt. Um and when we talked to a lot of computational neuroscientists they moved to interp because they were like look we have unfettered access to this artificial intelligent mind. It&#x27;s so much. You have access to everything. You can run as many ablations, the experiments as you</p>
<p>want. It&#x27;s an amazing bed for science. And um you know, human brains obviously we can&#x27;t just go and do whatever we want to them. Um and and I think uh it is really just like a moment in time where we have intelligent systems that can really like do things better than humans in many ways. And um it&#x27;s time I think for us to to do the science on it. I&#x27;ll ask a a brief like safety question. You know, uh me and Turk was kind of born out of the alignment and safety conversation. I safety is on your website. It&#x27;s not like something that you you like depprioritize, but like</p>
<p>there&#x27;s like a sort of very militant safety arm that like wants to blow up data centers and like stop AI and and then there&#x27;s this like sort of middle ground and like is is this like a conversation in your part of the world? Do you go up to Berkeley and Light Haven and like talk to those guys or are they like, you know, there&#x27;s like a brief like civil war going on? I don&#x27;t know. &gt;&gt; I think I think a good amount of us have spent some time in Berkeley. Um, and then there are researchers there that we really admire and respect. Um, I think for us it&#x27;s like we have a very grounded view of alignment and and safety in that</p>
<p>we want to make sure that we can build models that do what we want them to do and that we have scalable oversight into what these models are doing and and we think that that is the key to a lot of these like technical alignment challenges and I think that is our opinion that&#x27;s our research direction. Um, we of course are going to do safety related research to make sure that our techniques also work on, you know, things like reward hacking and and other like more concrete safety issues that we&#x27;ve seen in the wild. But we want to</p>
<p>be kind of like grounded in solving the technical challenges we see to having humans be humans play a big role in in the deployment of of these super intelligent agents of the future. Yeah, I found the community to actually be remarkably cohesive. Whether it&#x27;s talking about academia or the interpretability work being done at the frontier labs or some of the independent programs like maths and stuff. I think we&#x27;re all shooting for the same goal. I don&#x27;t know that there&#x27;s anyone who doesn&#x27;t want our understanding of models</p>
<p>to increase. I I think everyone regardless of where they&#x27;re coming from or the use cases that they&#x27;re thinking, whether it&#x27;s alignment as the premier thing they&#x27;re focused on or someone who&#x27;s coming in purely from the angle of scientific discovery, I think we would all hope that models can be more reliably and robustly controlled and understood. It seems like a pretty unambiguous goal. I&#x27;ll maybe phrase it in terms of like there&#x27;s maybe like a U curve of uh of this where like if you&#x27;re extremely doomer you don&#x27;t want any research whatsoever. If you&#x27;re like mildly doomer</p>
<p>you&#x27;re like okay there&#x27;s this like high agency doomer is like well the default path is where we&#x27;re all dead but like we can do something about it. Whereas there&#x27;s there&#x27;s other people who are like no just like don&#x27;t ever do anything. Um you know &gt;&gt; Yeah. Yeah. There&#x27;s also the other side like there is the super alignment like people that are like okay weak to strong generalization we&#x27;re going to get there we&#x27;re going to have models smarter than us and use those to train even smarter models how do we do that safely that&#x27;s you know there&#x27;s the camp there too that&#x27;s trying to solve it but yeah there&#x27;s there&#x27;s a lot of doomers too</p>
<p>[laughter] &gt;&gt; well and I and I think there&#x27;s a lot to be learned from taking a very um like even regardless of the problems s that you&#x27;re applying this to. Also just like the notion of like scalable oversight as a method of saying let&#x27;s take super intelligent or or current frontier models and help use them to understand other models is another case where I think it&#x27;s just like a good lesson that everyone is aligned on of ideally you are setting up your research so that as super</p>
<p>intelligence arrives that is a tailwind that&#x27;s also bolstering our ability to like understand the models cuz otherwise you&#x27;re fighting a losing battle if it&#x27;s like the systems are getting more and more capable and our methods are sort of linearly growing at like human pace. &gt;&gt; Yeah. Yeah. Uh Viva did call out something like you know I I I do think a consistent part of the mechan field is consistently strong to weak meaning that we we train weaker models to understand stronger models something like that. Um or maybe I got it the other way around. &gt;&gt; The other way weak. Yeah. Yeah. The question that Ilia and Yan Leica posed</p>
<p>was well is that going to scale because eventually these are going to be stronger than us right so I I don&#x27;t know if you have a perspective on that because I that is something I still haven&#x27;t got over even after seeing that &gt;&gt; there&#x27;s a good paper from open AI but it&#x27;s somewhat old I think it&#x27;s like 23 24 it&#x27;s literally weak to strong generalization but the thing is that most of OpenAI super alignment team has &gt;&gt; they&#x27;re gone &gt;&gt; but like I think the idea the idea is &gt;&gt; so now it&#x27;s it&#x27;s back there&#x27;s no more &gt;&gt; they&#x27;re so Yeah. Yeah. I [laughter] think I think there&#x27;s some new blog posts coming out. &gt;&gt; I know. And just, you know, check the</p>
<p>Thinking Machine&#x27;s uh website to see who&#x27;s back. &gt;&gt; Go [snorts] back. Um [laughter] there&#x27;s more coming. &gt;&gt; You know, you know what I mean? Like we too strong seemed like a very different direction. And when when it first came out, I was like, &quot;Oh my god, this is like this is what we have to do.&quot; &gt;&gt; Uh and like it may be completely different than everything all all the techniques we have today. &gt;&gt; Yeah. My understanding of that is it&#x27;s that&#x27;s more like weak to strong when when you trust the weak model and you&#x27;re uncertain whether you can trust the strong model that&#x27;s that&#x27;s being developed. I&#x27;m sort of speaking out of my depth on some of these topics, but I think right now we&#x27;re in a regime where</p>
<p>even the strong models we uh trust as reasonably aligned and so they can be good co-scientists on a lot of the problems that we&#x27;ve been we&#x27;ve been tackling which is a nice a nice state to be in. &gt;&gt; Yeah. Any last thoughts, calls action? &gt;&gt; I don&#x27;t think so. As we mentioned, actively hiring MLES, research scientists. Um, you can check out the careers page at Goodfire. Um, &gt;&gt; where are you guys based? &gt;&gt; San Francisco. We&#x27;re in um Levis&#x27;s Plaza, like by Court Tower. It&#x27;s where our office is. So, come hang out. Um we&#x27;re also looking for design partners</p>
<p>across um people working in in reasoning models um world models, robotics and then also of course people who are working on building super intelligent science models or looking at drug discovery or disease treatment. We would love to partner as well. Yeah, maybe the way I&#x27;ll phrase it is like, you know, maybe you have a use case where LLMs are almost good enough, but you need one magical knob to tune so that it is good enough. You guys make the knob. &gt;&gt; Yeah. Yeah. Or foundation models uh in in other domains as well. The some of</p>
<p>those are the um especially opaque ones because you can&#x27;t you can&#x27;t chat with them. &gt;&gt; What what do you do if you can&#x27;t chat with them? &gt;&gt; Oh, well like thinking about like a genomics model or material science model. So like a Yeah. narrow foundation. Yeah. They predict. Yeah. Got it. Got it. &gt;&gt; I was going to say I thought the diffusion work you guys did early was pretty, you know, pretty fun. Like you could see it directly applied to images, but we don&#x27;t see as much interp in diffusion or images, right? Like I see genomics, &gt;&gt; it&#x27;s going to be huge. Like look at this video models. They&#x27;re so expensive to produce. And like I mean basically a midjourney sref is kind of a feature,</p>
<p>&gt;&gt; right? &gt;&gt; The what? mid journey sref like the the string of numbers that you &gt;&gt; right right the style reference I guess. &gt;&gt; Yeah. No, I I mean I think we&#x27;re starting to see more of it and I&#x27;ll say like the the research preview of our diffusion model kind of like a creative use case and the steering demo you saw. I I think of those much more as as as demos than um a lot of the sort of core platform features that that we&#x27;re working with partners are unfortunately sort of under NDA and less demoable. But I will, you know, hope that you&#x27;re going to see inter pervading a lot of what gets done even if it is behind the</p>
<p>scenes like that. So some of the Yeah, some of the public facing demos might not always be representative of like the it&#x27;s just the tip of the iceberg, I guess, is one way to put it. &gt;&gt; Okay, excellent. Thanks for coming on. &gt;&gt; Thanks for having us. This is a great time.</p>]]></content:encoded>
      <guid isPermaLink="false">https://www.youtube.com/watch?v=ck63uv6APBA</guid>
      <pubDate>Thu, 05 Feb 2026 20:45:28 +0000</pubDate>
    </item>
    <item>
      <title>⚡️ Reverse Engineering OpenAI's Training Data — Pratyush Maini, Datology</title>
      <link>https://www.youtube.com/watch?v=CSgjaC6y6Mk</link>
      <description>Should you add reasoning traces to your pretraining data? There’s been a surge of academic work speculating its advantages. But do frontier labs actually do this? Turns out, we can answer confidently, by forensically analyzing how models respond to a single question about an emoji.

This is exactly what today's guest, Pratyush, did: https://x.com/pratyushmaini/status/2001824826353418433

And we convened a quick ⚡️ pod to talk about it!

https://pratyushmaini.substack.com/p/reverse-engineering-a-phase-change-a96</description>
      <content:encoded><![CDATA[<p><strong>YouTube:</strong> <a href="https://www.youtube.com/watch?v=CSgjaC6y6Mk">https://www.youtube.com/watch?v=CSgjaC6y6Mk</a></p>
<h2>Transcript</h2>
<p>[music] Hi, welcome uh to the lane space lightning pod. Uh we have Pratush here from Dtology, one of the founding team members. Listeners to the pod will remember our episode with Ariotos. I think it was one of the top episodes of 2025. Uh so I want to double down on uh the interesting work coming on Dlogy. I think not enough people are looking at the data and we want to encourage engineers and researchers to think more deeply about data and I think data is one of the best teams that is like basically all data nerds. Uh Patric uh you your bio has like 70%</p>
<p>California 20% Pittsburgh 10% Delhi you&#x27;re in South Bay right now right with the at the office. &gt;&gt; That&#x27;s correct. I&#x27;m at the office. &gt;&gt; Yeah. Yeah. Cool. Cool. How else do you introduce yourself? any any other things that people should know about you before we get started? &gt;&gt; No, that was pretty good. Thank you so much for having me. Um I am um I&#x27;m basically finishing up my PhD at CMU and have been a part of the founding team at Dtology for more than 2 years now. It&#x27;s been a while that we&#x27;ve been building this company. I am very excited about datacentric aspects to AI and more of how we can build responsible and very</p>
<p>high performance systems by focusing on the data layer. Somehow data is still one of the more undervalued research topics and um I&#x27;ve been that&#x27;s been the focus of my PhD and now also a lot of the time at Dtology. I think you&#x27;re very well pointed that we&#x27;re all data nerds. We love looking at data in general. I think one of the coolest parts about looking at data is like we can share like strange artifacts about it. In fact, we even made a channel called data is weird on our Slack channel where we keep posting screenshots and snippets of like all of these random artifacts that</p>
<p>you see within data sets and they&#x27;ll keep surprising you. The internet is so weird in so many ways that you would never expect that oh the depths of the internet has this and we&#x27;re actually feeding these kinds of data points to our model. So I think there&#x27;s like a shared passion about really looking into data and like an investigative approach around the team in general. &gt;&gt; Yeah. Okay. Two follow-up questions and then we can go into the paper. Uh one, what what&#x27;s the what&#x27;s your thesis going to be about? What&#x27;s the overall theme of your works? &gt;&gt; This is uh called responsible and efficient use of webcale data for</p>
<p>pre-training which is basically when you&#x27;re training on this messy web data and you shove all of that into the model. How can we train efficiently which is like only use things that are useful but then also the responsible angle to it which is like how can we make sure we are attributing data to like giving the right credit to like artists who put data online or how can we make sure the data is safe for models model behaviors. So I do a lot of work on the evaluation aspects of this as well uh but then also on the efficiency and performance aspects. &gt;&gt; Okay. And then uh just in your data is</p>
<p>weird channel any uh fun anecdotes over the last recent anecdotes just just pull something out. No, we&#x27;re going to go into like the GPT training data stuff, but I&#x27;m just kind of curious what what what gets posted there. So some of the cool things is all from like researcher curiosity. I think one of the recent things that we were exploring was that how uh do various models like for instance you take the coen model and then ask it to do completions on certain questions. So we would just take like we took some example questions from J which is like an important olympiad like an</p>
<p>exam in India and we would like even ask see the models with the first two words of a question like the light the light bulb and it would like literally complete the actual questions and so then we started comparing this across like family of models and we consistently saw how many of these like models today are being like massively like kind of fine-tuned on problems from overfit &gt;&gt; massively overfit like even like imagine if I ask you the light bulb what comes next in your mind it won&#x27;t be a question from an Olympiad or a practice exam right and these give the right question</p>
<p>they also give the options after that and so I think that is one of the fascinating findings from uh data is weird from the last month &gt;&gt; but no nobody is benchmarking on J that&#x27;s not a that&#x27;s not a &gt;&gt; J bench now and I think it&#x27;s also been reported by various uh frontier model labs but like J is like one example I&#x27;m sure this happens like across um different exams but it&#x27;s very clear how the last stage of training for many of these models does have a massive amount of um example or exam benchmark because the model will not like behaviorally</p>
<p>complete exam questions with options if they have not really seen it at the end of training for multiple epochs &gt;&gt; and you&#x27;re saying there&#x27;s per there&#x27;s basically perfect memorization and I&#x27;m wondering if you have ablated this across different model sizes like does B do the same as 30D probably not right and I was curious about the memorization power &gt;&gt; that&#x27;s a great question I think it&#x27;s a mix of two things one is the recency of seeing that data and the second is also the size of this model I don&#x27;t we don&#x27;t see this phenomena in like the earlier versions of like quen 1.5 or even coen 2</p>
<p>but start seeing it in quen 3 so there&#x27;s something about a more like a significantly higher weight on benchmark or like uh J or like any types of evaluation questions during the final stages of training in these decent models and then definitely see we see the effect of like bigger models having memorization to a significantly higher level though I would say that with the coming of the models we&#x27;re starting to see this uh phenomena even like models which have a less number of active parameters so a phenomena that we would observe at a 72b model in the past is</p>
<p>probably now visible at a 20b active 120b also [snorts] so in some way the active parameters might be lesser in thee um life cycle but still be able to like regurgitate exact memorization. &gt;&gt; Yeah, it&#x27;s interesting when memorization is done in the like the router at thee actually ends up becoming like an index where you look up like oh here&#x27;s the index of the thing that you need and then it&#x27;s routed to that expert that is going to have memorized the answer. &gt;&gt; Exactly. &gt;&gt; That&#x27;s that&#x27;s a way to cheat. &gt;&gt; Okay. So let&#x27;s uh tell us about the seahorse emoji and GPT. So around</p>
<p>October last year, I saw on Twitter a few people had posted this very fascinating result where they would ask a frontier model such as GPT like uh is there a seahorse emoji and like that&#x27;s the only question they would ask and what you would see is that the model keeps going on and on and this was a phenomena that really fascinated me like imagine asking GPD a question and this uh answer does not stop. Which was really surprising to me because all of these models like are like these are</p>
<p>like frontier models. They would not really have this problem of like continually like going back and forth on a certain answer. If you see over here, it says yes in the beginning, then it starts to think more about it and then it says no and then goes yes and no and yes and no. So there&#x27;s like a huge amount of internal turmoil in the model and a phenomena where it just keeps saying this and does not really stop. And so then I tried this across models and I saw consistently across Grock and GPT and Gemini that you were seeing this phenomena where models will like</p>
<p>self-correct themselves quite a bit and these were like non-thinking models like the standard the auto or the smallest fast model and they would still do this and I was like quite perplexed that how is it possible that these models which are like so strong they&#x27;re able to solve these IMO problems and they&#x27;re like kind of just getting into this selfnarrative existential dilemma or something when you ask them about like is there a seahorse emoji and this was also a time when I was thinking a lot about reasoning data and like should like models uh learn more selfcorrection behavior during pre-training or not and</p>
<p>my initial thought was that this behavior that we are seeing of models saying yes or no is very reminiscent of all of these back correction and self-reflection behavior which is becoming very predominant um right in modern AI models uh and there are a lot of papers on like if you the models learn how to correct their wrong traces or like uh in their um data or in their post training data then the mod has become much stronger at at reasoning and so I was thinking this is very reminiscent of that and somehow feels like there is like an emergence of that behavior even when I did not ask for reasoning so uh I thought like it will</p>
<p>be very interesting to see like what really causes this behavior because we don&#x27;t really understand that and maybe there has some tie-in with the prevalence of reasoning data or self-correcting monologues within the mid-raining or pre-training phase of non thinking models and so my first thought was is this something that happened always what or is it just like a GPT5 phenomena and because people have been noting this in October and potentially people asked this in GP in in like a year ago also like would the models create this kind of a self-correcting monologue and the interesting thing was and I&#x27;ve like put the number of output</p>
<p>tokens on the y-axis on this graph and the release date of the model on the x-axis and so I like ran the uh openi API across like models released from 2023 to 2025 and you would see like all the models until 2024 December had very tur and short responses to the question is there a seahorse emoji they would either say that they exist sometimes they would say they do not exist but they would never go into this selfcorrection loop where they like say one answer in the beginning and then a different answer at the end and so something very interesting was happening</p>
<p>because we know that in December 2024 Four is when the 01 model came which is the first time where a model that could think and selfcorrect itself was available to the public and then 4 months after that we noticed that the GPT 4.1 series is the first model where suddenly this the response length of all the models had started to increase and then the chat GPT4 model uh update that was in the month of May again had like this recursive behavior and this became significantly more prevalent by the time GPT5 And so</p>
<p>&gt;&gt; and and just to insert your question here, this is specifically like the cutoff date that they have declared themselves, right? Like I don&#x27;t know if this is uh is this is what are you ordering by cut off date or the release date? &gt;&gt; Uh this is ordered by the release date and so &gt;&gt; it&#x27;s unclear what the cutoff date would be but very likely that it has seen likeam samples very close to that date. &gt;&gt; So for instance, Chad GPT 40 is an interesting case. its original release was somewhere in December uh like 2024 but then they had an update in May and only the May update shows this behavior</p>
<p>but the previous update does not show it and so they kind of potentially post trained the model on these kinds of reasoning traces and it certainly started showing the self-reflective behavior. I think should be important to point out that this seahorse emoji is an interesting question and like why it really brings out this behavior is because the existence of the seahorse emoji is kind of called like a mandela effect where a lot of people on Reddit are saying that hey I have seen the seahorse emoji it looked blue in color and had a horse pointing to the left or something like that and so there is like enough doubt or like enough</p>
<p>conversations on the internet that some people say yes and some people do say no and so it&#x27;s kind of acting like a trigger to elicit that thinking response which is great for us because we do want these edge cases that can help us do this discovery or this investigative analysis. So by now what we have figured out is that around the GPT 4.1 and then GPT 5 series there is something happening which leads the models to have a lot of self-reflection and now the question is like what happened over here uh like which led to models starting to do this and for me this was interesting</p>
<p>because I wanted to know if the frontier model labs also care about putting reasoning data in pre-training or in mid-training phases like you might have seen a lot of papers coming out these days which say that you should do reasoning pre-training and like RL pre-training and all of those papers which are saying that put the thinking tokens in the beginning and as academic researchers or like people who are not training frontier models it&#x27;s always a curiosity question are these things really valuable at the frontier level or are these questions only interesting at the 1B scale when you can move your data</p>
<p>distribution and so [snorts] that&#x27;s why I was excited about understanding like if there is relevant data in the mid-training phase for non-thinking models and something interesting uh that I was able to validate this was with the Almo series. So the Almo models are great uh for doing investigative science because they release everything they release the data the models um and they also have a very fantastic Almo trace. Now with Almo trace you can trace like what data in the pre-training of Almo was closest to its response right now.</p>
<p>Yeah, this is I was thinking of this when you&#x27;re talking about your PhD thesis was like directly the tool to use. &gt;&gt; Exactly. Exactly. &gt;&gt; Do do you use their approach? &gt;&gt; Yeah. I think like I honestly al trace or the original paper which produced the infinagram like I think it came out last year at Colum 24. Uh that was one of my favorite papers that year. I think they did a fantastic job in like being able to like actually trace data back. It&#x27;s like a big engineering problem to be able to like look up so fast and they did like a fantastic job. and I&#x27;ve used it a lot for multiple projects in my PhD. So coming back to this phenomena uh</p>
<p>and I was like curious like okay now we know that this suddenly happens or like this infection point happens in GPD 4.1 series can we trace it back to an open series of models and see if this is like um the same phenomena happens there and so you will see for the mode 2 model which was released a year ago like says there exist an emoji it&#x27;s the wrong answer but does not really try to selfcorrect itself right on the other hand in the 3.1 32b series it has the same selfcorrection behavior like it&#x27;s a long response I only have the last part of it but it first says yes then says</p>
<p>but wait there is no one and then so we see the same monologue within the Almo 3.1 model and if you look at the Almo trace there is no particular example that it is really referencing to over here that leads to this phenomena so it&#x27;s more like a capability rather than a regurgitation of the text so that&#x27;s great to know it&#x27;s not like someone has poisoned the data that was another thought in my mind has ply poisoned the data on the internet and and the models are like regurgitating something from there but that&#x27;s not happening. So that&#x27;s good that&#x27;s a good sanity check that what we&#x27;re seeing is a capability and not like a regurgitation from some</p>
<p>website or like Reddit post which might have said that yes and no. And then the more interesting thing is now we can actually trace the exact difference in the data sets for all mode 2 and mode 3 and the main difference for the instruct model over here. So Almo 3 has multiple variants some are the thinking variants some are the instruct variants. So with the instruct variant they do not have any thinking data in the post- training uh phase but they do mention that we are going to put like there&#x27;s a line that they write there&#x27;s some intentional addition of thinking traces in the mid-raining phase of Almo data and so</p>
<p>that&#x27;s the information available from their report and we can also see the actual data sets they use. This observation really well corroborates with the whole finding about the open AAI models where they potentially also did the same thing where even if in the non-thinking models the instruct models where you do not put thinking traces in the post-training phase you do put thinking traces in the mid-training phase and that leads to models becoming better and so this was like quite interesting for me uh because what they suggests about the GPT training data is that the self-reflection data has now actually become pretty much core to the</p>
<p>training of all frontier models because we&#x27;re seeing that happen in non-instruct models across the board. Which is very interesting to me because for the longest time people would always believe that the idea of foundation models is that you have trained this foundation and now you just post train it which meant that there&#x27;s a general purpose model you don&#x27;t need to really put everything that you care about in the general purpose model and then you can post train it to get the capability that you want. But this really shows us that even this foundation mod foundation needs to have the ingredients that of the capability that you desire at the</p>
<p>end. And so putting thinking traces in the foundation is actually useful for the post- training or fine-tuning of uh the thinking models. And so that&#x27;s why they can only have one single backbone and you would actually prefer to have the foundation also represent the capabilities that you desire. And so self-reflection is a capability that we desire and it&#x27;s become core to the foundation and not left as a cosmetic after afterthought of just post training. I think also was interesting to me that the GPD 4.1 series came about 4 months after the O1 data was available. So it&#x27;s kind of interesting</p>
<p>like how fast do Frontier Labs move. O1 reasoning traces would have been available to the pre-training team in December or the mid-training team I should say in December and then from December until u what&#x27;s like 4 months from there end of April the mid-training team would have potentially used the traces which they obviously were dis developing and there was a lot of talk about the Omni models &gt;&gt; but not directly right like it&#x27;s just went into the the the web and the the pre-changing back &gt;&gt; no I would be very surprised if it went into the web I I think this was very intentional because that&#x27;s exactly how the Almost series happened where they</p>
<p>have an intentional addition of the thinking uh data. So they have added a data set which has this self-reflection behavior where you will self-correct yourself by first gening a wrong sequence and then the right one. &gt;&gt; Yeah. I mean this is why I wanted to feature this piece because I think like the the you know like how people are training reasoning into their models and when they&#x27;re choosing to include it and all this uh it&#x27;s very actually very important and not well known. And so this is one of the first like actual like somewhat investigative piece uh I&#x27;ve seen about it. So</p>
<p>&gt;&gt; yeah and you you might have seen all these papers which show that RL is only like kind of enhancing or amplifying a capability that the model already has and you actually need the core to have that capability. So I think this reinforces all of those things that the core actually contain the capability and then you can actually do better RL, you can do better post training all of that. And so I think in general it was very nice to like be able to like see that these are not just things that are relevant to a 3B or a 7B model but also relevant at the real frontier uh where people are training like the best models. &gt;&gt; Any reactions, criticisms or follow-up</p>
<p>work &gt;&gt; for now like um in general I think the community was pretty excited about this like a lot of people uh felt that this was either reinforcing their beliefs or very interesting investigative work. I think that&#x27;s something people always appreciate when you just like put your detective hat on and try to like dig into um whatever is happening. Something that we are actually following this up um with uh and also in general we have been working on that for a few months is a work uh which should be out like in a few weeks called the finetuners fallacy which is basically kind of arguing</p>
<p>pretty much the same thing which is that if there is a core capability that you actually care about that capability should be part of the foundation and not a fine-tuned artifact. So we kind of show this for various types of domains and we&#x27;re actually in general seeing adoption of like AI in a lot of like domain specific use cases. So the old idea of you have a foundation model and you can just fine-tune it and get the desired capability is kind of like uh we are past that stage now and this really means there&#x27;s going to be a lot of</p>
<p>specialized pre-training going forward. So I think like 2026 and 227 are going to be the years where different enterprises start doing specialized pre-training because the cost of pre-training really amortizes itself very fast when you think of the fact that by doing specialized pre-training you can train a smaller model which is as capable as a much larger model when fine-tuned. And so that&#x27;s the core thesis that we&#x27;ve been working towards in the past few months and also very relevant to datology in general. &gt;&gt; Okay, got it. Um I may need to uh go some because I&#x27;m being sort of chased</p>
<p>down this thing. But no uh this is uh secretly a daty pitch I&#x27;m realizing you know because everything you&#x27;re saying is like exactly the the pieces of data which is uh very fascinating. You know you&#x27;ve also done other work uh you are you&#x27;re one of the authors on beyond web u I don&#x27;t know any anything else you want to sort of plug or or feature um you know in terms of this the stuff that&#x27;s going on. Yeah. Uh uh I can quickly share something about beyond web and how it&#x27;s been like making waves and I also want to talk about the same idea of having the core capability that you care about at pre-training in something</p>
<p>called safety pre-training and maybe like a few minutes over there. So let&#x27;s go to beyond web first. So this was like one of our big releases last year where we were trying to showcase how to scale synthetic data to trillion scale like works which are like doing like 100 billion token training with synthetic data and 200 billion training token with synthe data but the actual dynamics of how you work well with synthety. [snorts] And so this work was majorly about like</p>
<p>understanding and like giving the lessons back to the community of like how can you do good hybrid model training where there&#x27;s like a part of data that&#x27;s synthetic. So like uh just like as a high level like flagship numbers this model that we released this results were very strong. So the neurotron data set is like one of the top data sets today which is like based with a lot of synthetic data. uh so the and the datology uh data that we a model that we released called beyond web uh is the blue line over here as you can see that we achieve the same performance as the Nvidia model in almost like 2.7x</p>
<p>like lesser time and then much faster than anything that hugging face or at pajama does very interestingly our 3B model is pretty much the same performance as the 8B model of Nvidia and this is quite like strong given that Nvidia&#x27;s Neotron data is like literally the most downloaded uh open-source data set. It&#x27;s like being downloaded like I think a million times every month I was seeing uh recently and so that&#x27;s huge. So internally we&#x27;ve been doing a lot to improve um synth data. So just a little bit of backstory to explain the types of</p>
<p>synth data approaches that exist today. So for the longest for the beginning of how synth data came into picture was through the tiny stories and the fee model family and so &gt;&gt; really &gt;&gt; yeah so so that was like uh I think the big push &gt;&gt; yeah textbooks are all you need. Yeah, &gt;&gt; the textbooks are all you need. And even before that, there was this paper called tiny stories which was by a couple of researchers at Microsoft on telling like how can you train small models with entirely synthetic data. And so I would bucket these approaches into something</p>
<p>that I call the generatordriven paradigm which means you have a big model for instance it could be the GPT4 model and you&#x27;re trying to query that model to generate a textbook or an essay or a paragraph but all the information in your data set is coming from the generator or from the model. And so you really need that the generator is huge and massive and contains information about everything on the world so that you can train models in the generator-driven paradigm. And so a couple of years ago when I was actually an intern at Apple, we released this paper called rephrasing the web. And we</p>
<p>modeled this alternate paradigm which is called the source rephrasing paradigm. And so we said the generative driven paradigm is exciting and doing well but it just does not scale. You need the model to be massive and generating data will be very expensive. Plus it really depends on you prompting in the right way because if I ask you to generate a paragraph about the laws of motion then my data will have it otherwise it will not. So it really puts the burden on the researchers to make sure that the data is diverse. But on the other hand uh we have the entire corpus of the internet which has so much knowledge available. The only issue is</p>
<p>that the data might not be high quality and so we can basically rephrase all of this data into higher quality data. So for instance, the internet becomes the source of knowledge and the synth data generation model is only modifying that knowledge into styles that you care about. So for instance, if question answering is something that you care about, then you repurpose the knowledge of the internet into smaller styles into into the question answering styles. So this really trans changes the whole philosophy of generating data by making</p>
<p>the cost of synth data generation extremely small because now you can use like a very small off-the-shelf model you can put the actual information inside it uh and you can ask it to rephrase it into question answering and so the capability to transform data is actually very cheap even a 1B model or a 3B model can do this very well you do not need all the knowledge of the internet to be within this And so the source rephrasing paradigm has actually become the dominant paradigm in 2026. Like even the Kim K2 model has like a long section of like how they do rephrasing of internet</p>
<p>content. Then the even Gro 4 has been using the same source rephrasing paradigm. Nvidia&#x27;s Neotron data that we are benchmarking against is also using this idea of source rephrasing. And so philosophically in the pre-training phase uh we have kind of almost finalized how we do synth data which is like we transform existing knowledge into patterns that are useful for us and in beyond web we really go beyond what we had released at Apple when I was interning over there which was called rephrasing the web and now we have beyond web which really like multiplies</p>
<p>the advantages of um what we were doing in synthetic and uh it&#x27;s really good to sort of uh get a sense And I think like I want to also just like use lit space to [music] feature this kind of work. People are going to read the paper on their own. We&#x27;re not going to cover the whole thing, right? So, but if they can reach out to you, I&#x27;ll leave all the socials and all there. Um, yeah, and uh probably join you as well. &gt;&gt; Awesome. Yeah, thank you so much for having me and uh yeah, uh very excited to see the response. &gt;&gt; Thanks for all the great work. Yeah, I I would say like yeah, I I is to me it&#x27;s amazing because like when Red Pajama</p>
<p>came out like I I realized like that was like the start of something. It&#x27;s interesting to me that every single generation is a different company, you know, like, oh, it was together AI and then it&#x27;s like Microsoft or whatever and it&#x27;s Apple, then it&#x27;s Hugging Face, then it&#x27;s Nvidia, now it&#x27;s you guys. And I&#x27;m like, you know, where where&#x27;s the the the persistence or like it&#x27;s just such a competitive field or you guys keep changing companies. So, it&#x27;s the same it&#x27;s the same people. &gt;&gt; Now, we have a hub for all data enthusiasts. I think it&#x27;s going to be</p>
<p>the same for a while. &gt;&gt; Yeah. Okay. Well, thank you so much. That was great. &gt;&gt; Thank you so much. Bye-bye. &gt;&gt; [music]</p>]]></content:encoded>
      <guid isPermaLink="false">https://www.youtube.com/watch?v=CSgjaC6y6Mk</guid>
      <pubDate>Tue, 10 Feb 2026 02:45:04 +0000</pubDate>
    </item>
    <item>
      <title>🔬Generating Molecules, Not Just Models</title>
      <link>https://www.youtube.com/watch?v=nP0N1kYLegc</link>
      <description>This episode traces the remarkable journey from AlphaFold2’s landmark achievement in protein structure prediction to the broader landscape of molecular interaction modeling and protein design. The problem AlphaFold2 addressed—predicting the structure of single-chain proteins—was long considered intractable due to its perceived NP-hard nature. The breakthrough came not only from advances in machine learning but also from leveraging evolutionary data to infer co-evolution of amino acids, providing powerful hints about spatial proximity in protein structures. Yet, as the guests explain, the field quickly moved beyond this milestone toward more complex questions, like how proteins interact, how they fold dynamically, and how to model these interactions with small molecules, RNA, and DNA.

AlphaFold3 marks a critical shift in this evolution, moving from static structure prediction to modeling heterogeneous molecular interactions. Rather than treating these interactions as isolated problems, AlphaFold3 unifies them within a single model trained across modalities. This progress also reflects a broader trend in machine learning: the shift from regression-style prediction to generative models capable of expressing uncertainty and capturing system dynamics. By sampling from a distribution of plausible structures and interactions, these models allow researchers to better understand the flexibility and variability of biological systems. However, such models also introduce new challenges, particularly around validation and ranking of generated outputs.

Enter Boltz and its suite of tools, which aim to democratize access to these cutting-edge capabilities. Boltz builds on open-source principles and a strong community foundation to deliver models that are both state-of-the-art and accessible, with a focus on usability, extensibility, and real-world validation. Boltz2 and BoltzGen combine structure prediction, affinity estimation, and generative design in one pipeline, enabling users to design new proteins and small molecules with high confidence. Notably, Boltz emphasizes the importance of experimental validation, collaborating with partners across academia and industry to test new designs in the lab. This feedback loop is essential to the iterative improvement of models and benchmarks.

BoltzLab, the newly launched platform, encapsulates this vision by providing a cloud-based interface for running large-scale protein and molecule design campaigns. With support for both computational and experimental scientists, BoltzLab offers APIs, collaboration tools, and automated agentic workflows to make advanced molecular modeling accessible to users with varying levels of computational expertise. It embodies the shift from abstract model development to practical deployment, where infrastructure, cost-efficient compute, and user-friendly interfaces make a meaningful difference. As the guests emphasize, the real progress lies in enabling scientists to use these tools creatively and collaboratively to accelerate discovery in biology and medicine.

Timestamps

 Introduction to Benchmarking and the “Solved” Protein Problem
 Evolutionary Hints and Co-evolution in Structure Prediction
 The Importance of Protein Function and Disease States
 Transitioning from AlphaFold 2 to AlphaFold 3 Capabilities
 Generative Modeling vs. Regression in Structural Biology
 The “Bitter Lesson” and Specialized AI Architectures
 Development Anecdotes: Training Boltz-1 on a Budget
 Validation Strategies and the Protein Data Bank (PDB)
 The Mission of Boltz: Democratizing Access and Open Source
 Building a Self-Sustaining Research Community
 Boltz-2 Advancements: Affinity Prediction and Design
 BoltzGen: Merging Structure and Sequence Prediction
 Large-Scale Wet Lab Validation Results
 Boltz Lab Product Launch: Agents and Infrastructure
 Future Directions: Developpability and the “Virtual Cell”
 Interacting with Skeptical Medicinal Chemists</description>
      <content:encoded><![CDATA[<p><strong>YouTube:</strong> <a href="https://www.youtube.com/watch?v=nP0N1kYLegc">https://www.youtube.com/watch?v=nP0N1kYLegc</a></p>
<h2>Introduction to Benchmarking and the “Solved” Protein Problem</h2>
<p>Actually, we only trained the big model once. Uh that&#x27;s how much compute we had. We could only train it once. And so, like while the model was training, we were like finding bugs left and right. Uh a lot of them that I wrote. &gt;&gt; And like I would I remember like us like sort of like you know doing like surgery in the middle like stopping the run, making the fix, like relaunching and um yeah, we never actually went back to the start. We just like kept training it with like the bug fixes along the way. Uh which was &gt;&gt; impossible to reproduce now. Yeah. Yeah. No, that model is like has gone through such a curriculum that you</p>
<p>know it&#x27;s learned some weird stuff. Uh but uh yeah, somehow a miracle it worked out. &gt;&gt; It&#x27;s a pleasure to have with us today Gabriella Corso and Jeremy Vulvin. They are they recently founded Boltz, a company trying to democratize and bring art, structure prediction and biology to you know the masses. uh they were both uh recent PhD grads from MIT and have been working on all sorts of foundational papers in like generative biology. Um anyway, uh pleasure to have you here. Thanks for coming. &gt;&gt; Thank you.</p>
<p>&gt;&gt; Uh I guess we&#x27;re maybe what 6 years post Alphold 2 right now, which was like kind of a big moment. &gt;&gt; Um is that right? Yeah. &gt;&gt; I think was it 2021? &gt;&gt; So yeah, on going on 5 years. &gt;&gt; 5 years. 5 years. Yeah. Um, yeah. So maybe for the audience like can can let&#x27;s go back to that moment in time and explain like what was this big moment and why was it interesting? Why was everyone so excited and I think you two were probably quite excited. So why were you personally excited? &gt;&gt; I would start on kind of why that was interesting kind of you know from a</p>
<p>scientific standpoint. So Alpha so maybe first as a kind of introduction for uh the ones in the audience and not structural biologists. So the idea of structural biology is that you know we want to try to understand how you know proteins and other molecules take shape inside our cells and you know how they interact and structural biology is sort of this beautiful discipline uh where we are somehow able to understand this minuscule structure at know kind of atomic details using uh these incredibly</p>
<p>um complex methods like you X-ray crystalallography and you know the the dream has always been of computational biology. Can we understand kind of the structures without having to you know resolve this crystal you know shoot X-rays and so on. And so Alphafold um was a real breakthrough in this problem of protein folding which is trying to understand the structure of a single uh protein. And to me it was exciting across kind of many dimensions. One I</p>
<p>was a computer scientist. I was working a lot on machine learning. And I saw kind of the impact that kind of the work similar somewhat similar to what I was doing could have on like a longstanding scientific problem. And on the second perspective from a more you know personal side, the seeing kind of the structures coming out of these models where you know you see kind of this beautiful you know um creation of life is something that was was very</p>
<p>inspiring to me and so that was kind of one of the things that led me to start uh working on uh structural biology and in particular with machine learning. &gt;&gt; Were you a structural biologist before Alpha Flood came out? I mean did you you did machine learning but it was not in structural biology so that actually shifted your career quite dramatically. &gt;&gt; Yeah very dramatically. I was I was working on some pretty kind of theoretical methodological things and I was starting to see kind of you know some of the challenges in you know kind of doing somewhat theoretical or methodological work and you know seeing</p>
<p>kind of the potential impact of you know doing excellent you know alpha fold was really a machine learning breakthrough but you know and applied machine learning and so that led me to uh want to start working in applied ML. our our group at the time was um working a lot on like small molecules already and um I think alpha is kind of what triggered I think this shift to like working on on biologics um and at the time I think it like opened as many questions you know as it answered in a sense like we um the immediate follow-ups were okay like can</p>
<p>we do this on other things than proteins can we do um you know interactions of small molecules with proteins nucleic acid with proteins Can we model more complex protein systems? And I think yeah very rapidly I think after alpha fold uh people realized I think that there was you know machine learning could have a could really yeah sort of target this problem very differently than you know than previous methodologies &gt;&gt; clarification. So what what does small molecule mean? What does protein mean? What is you know the terms that you just</p>
<p>mentioned? &gt;&gt; Yeah maybe we can start with protein. Um, so you know, protein is is maybe the most fundamental one. It&#x27;s what gets decoded out of our DNA. &gt;&gt; Um, it&#x27;s uh essentially a sequence of uh amino acids. Each amino acid you can kind of consider as a we call a small molecule. Um, and there&#x27;s 20 of them in the at least in the human body. Um, and you know any compositions of these 20 amino acids in a sequence um you know creates a different form of a protein. Um and so you know obviously they are a</p>
<p>very large number of those sequences that you can create. Um small molecules are sort of you know following the name um typically considered to be um you know a much smaller number of atoms. Um and the atoms that compose them I think are also generally a bit more diverse right amino acids have um you know this composition and it&#x27;s always the same. uh with small molecule you know there&#x27;s a larger set of possible atoms that also we have to consider that also make the problem uh pretty challenging and then we have nucleic acids so DNA and RNA uh</p>
<p>which are also very interesting to model the structure for and those a little bit more similar to proteins you know they&#x27;re sort of composed of four um nucleic acids and you form sequences from them and um any uh codon which is like three uh nucleic acid um translates into a specific amino acid. Um so yeah, different forms of molecules at the end of the day just a bunch of atoms uh you know that are bonded together uh that we try to understand the interaction of. &gt;&gt; Going back to the alpha fold 2 moment</p>
<p>like um I remember this very well. I was</p>
<h2>Evolutionary Hints and Co-evolution in Structure Prediction</h2>
<p>at uh Nurifs when I guess the results of this famous competition came out. So um you can you want to talk about CASP and like what it is and why it is it was so interesting and exciting. &gt;&gt; Yeah, I think every so um every couple years um and the goal has always been to you know find u protein structures that are a little bit different from what&#x27;s known. So CASSP over the years has like you know put in a lot of effort to like gather structures from you know academic</p>
<p>groups and uh even industry groups uh to try to create sort of a test set that would be um difficult um for uh different methods and CASP uh 14 was when uh Alpha 2 really you know blew everything out of the water. Um and the the improvement was so large over you know the previous previous method and also over the previous competitions. Um and now CASP continues you know we&#x27;ve had CAS 15 we have CAT 16 and you know</p>
<p>sort of what&#x27;s happened now is that it&#x27;s really expanding to also all these other modalities like I was mentioning like protein small molecule nucleic acid and u but the goal remains to like you know really challenge the models like how well do these models generalize and you know we&#x27;ve seen in some of the latest GAS competitions like while we&#x27;re become really really good at proteins basically monomeic proteins um you know Adamal is remain pretty difficult. So it&#x27;s really essential you know in the field that there are like these efforts to um you know to to to gather um you know benchmarks that that are challenging so</p>
<p>keeps us in line you know about what the models can do or not. &gt;&gt; Yeah. &gt;&gt; It&#x27;s interesting you say that like in some sense cast you know at cast 14 a problem was solved and like pretty comprehensively right but at the same time it was really only the beginning. So can you explain like what was the specific problem you would argue was solved and then like you know what is remaining which is probably quite open. &gt;&gt; I think I think we&#x27;ll we&#x27;ll steer away from the term solved because we have many friends in community who get pretty</p>
<p>upset at that word and I think you know fairly so. Um uh but the the problem that was um you know that a lot of progress was made on um was the ability to predict the structure of single chain proteins. So proteins can like be composed of many chains and single chain proteins are you know just a single sequence of amino acids and uh one of the reason that we&#x27;ve been able to make such progress is also because um we take a lot of uh hints from evolution. So the</p>
<p>way the models work is that you know they sort of decode a lot of hints um that that comes from evolutionary landscapes. So if you have like you know some protein in an animal and you go find the uh similar protein across like you know different organisms uh you might find different mutations um in them. And as it turns out if you uh take a lot of these sequences together and you analyze them you see that uh some</p>
<h2>The Importance of Protein Function and Disease States</h2>
<p>positions in the sequence tend to evolve um at the same time as other positions of the sequence. sort of this like uh correlation between different positions and um in it turns out that that is typically a hint that these two positions are close in three dimension. So part of the you know part of the breakthrough has been like our ability to also decode that very very effectively. uh but what it implies also is that you know in absence of that co-evolutionary landscape the models don&#x27;t quite perform as well and so you</p>
<p>know I think when that information is available maybe one could say you know the the problem is like somewhat solved from the perspective of structure prediction &gt;&gt; when it isn&#x27;t it&#x27;s it&#x27;s much more challenging and I think it&#x27;s also worth also differentiating the um sometime we confound a little bit structure prediction and folding folding is the more complex process of actually understanding like how it goes from like this disordered state into like a structured like state and that I don&#x27;t think we&#x27;ve made that much progress on but the idea of like yeah going straight to the answer uh we&#x27;ve become uh pretty good at. So there&#x27;s this protein that is</p>
<p>like just a long chain and it folds up. Yeah. And and so we&#x27;re good at getting from that long chain in whatever form it was originally to &gt;&gt; the thing, but we don&#x27;t know how it necessarily gets to that state and there might be intermediate states that it&#x27;s in sometimes that we&#x27;re not aware of. &gt;&gt; That&#x27;s right. And and that relates also to like you know our general ability to um model like the different you know proteins are not static. they move, they take different uh shapes based on their energy states. And I think we are also not that good at understanding the</p>
<p>different states that the protein can be in and at what frequency, what probability. &gt;&gt; Um so I think the two problems are quite related in some ways. Um so yeah, still still a lot to solve. Um but I think the it was yeah I think I think it was very surprising at the time you know that uh even with these evolutionary hints that we were able to you know to make such such dramatic progress. &gt;&gt; So I want to ask why does the you know sort of like intermediate states matter but first I kind of want</p>
<p>to understand why do we care what proteins are shaped like? Yeah, I mean the proteins are kind of the machines of uh our body. You know the way that all the processes that we have in our cells, you know, work is typically through proteins, sometimes other molecules sort of intermediate, you know, interactions and through that interactions, we have all sorts of cell functions. And so when we try to understand you know a lot of biolog how our body works how disease work we often try to boil it down to</p>
<p>okay what is going right in case of you know our fun normal biological function and what is going wrong uh in case of the disease state and we boil it down to kind of you know proteins and kind of other molecules and their interaction. And so when we uh we try predicting the structure of proteins, it&#x27;s critical to you know have an understanding of kind of those those interaction. It&#x27;s a bit like um seeing the difference between having kind of a list of parts that you</p>
<p>would put it uh in a car and seeing kind of the car uh in its final form. You know, seeing the car really helps you uh kind of understand what it does. Yeah. &gt;&gt; Uh on the other hand, kind of going to your question of you know why do we care about you know um how the protein folds or you know how the car is made uh to some extent is that you know sometimes when it something goes wrong you know there are you know cases of you know proteins misfolding in some diseases and so on. Um if we don&#x27;t understand uh this</p>
<p>folding process we don&#x27;t really know how to uh intervene. &gt;&gt; Okay. And so do proteins when they&#x27;re in the body, do they are they typically in that folded state or are they kind of just like you know doing whatever until they&#x27;re in a location where they need to interact with something? That&#x27;s a great question. Uh and it really depends on the protein. Uh it depends on basically the stability of the protein. There are some proteins that are very stable and so once they are produced you know from the ribosome they sort of fold in this</p>
<p>shape then more or less they keep that shape with a minor variations. &gt;&gt; The ribosome is the part of the cell that actually translates and and turns DNA to RNA to proteins. &gt;&gt; RNA to proteins that final part of RNA to proteins. &gt;&gt; And so once they come out they&#x27;re pretty stable. Uh but then on the other hand there are some that you know for example have multiple states that they switch to depending on their environment. You know uh the bi biologists really figure out some incredible machines. Uh there are</p>
<p>machines where you know proteins where you know depending on whether for example another molecule is present not they will take different shapes and that different shape will give it a different function. And so we have this you know so-called fault switching uh proteins that take multiple and we have some proteins that are completely disordered and these disorder proteins are actually</p>
<h2>Transitioning from AlphaFold 2 to AlphaFold 3 Capabilities</h2>
<p>pretty important in kind of many diseases and those are kind of ones of the ones that we have you know the least understanding of &gt;&gt; there&#x27;s this nice line in the um I think it&#x27;s in the full 2 manuscript where they sort of discuss also like why we even hopeful that we can target the in the first place. And then this this notion that like um well four proteins that fold um the folding process is almost instantaneous which is a strong like you know signal that like yeah like we we might be able to um you know predict that this very like constrained</p>
<p>uh thing that that the protein does so quickly. Um, and of course that&#x27;s not the case for, you know, for for all proteins and there&#x27;s a lot of like really interesting mechanisms in the cells, but um, yeah, I remember reading that I thought, yeah, that&#x27;s somewhat of an insightful insightful point. Um, yeah, &gt;&gt; I think one of the interesting things about the protein folding problem is that it used to be actually studied and part of the reason why people thought it was impossible, it used to be studied as kind of like a classical example of like an MP problem. uh like there are so many</p>
<p>different you know type of you know shapes that you know this amino acid could take and so uh this grows combinatorily with the size of the sequence and so there used to be kind of a lot of actually kind of more theoretical computer science thinking about and studying pro problem protein folding as an MP problem and so it was very surprising also from that perspective kind of seeing machine learning So clear there is some you know signal in those sequences uh through evolution but also through kind of other</p>
<p>things that you know us as humans we&#x27;re probably not really able to uh to understand but that this uh models have have learned. Yeah. So and Andrew White we were talking to him a few weeks ago and he said that he was following the development of this and that there were actually uh AS6 that were developed just to solve this problem. So um yeah that like and that there were many many many many millions of computational hours spent trying to solve this problem before alpha fold. And just to be clear um one thing that you mentioned was that</p>
<p>uh there&#x27;s this kind of co-evolution of um mutations and that you see this again and again in different species. So explain why does that give us a good hint that they&#x27;re close by to each other? &gt;&gt; Yeah. um like think of it this way that you know if I have you know some amino acid that mutates um it&#x27;s going to impact everything around it right in three dimensions and so it&#x27;s almost like the protein you know through several probably you know random mutations in evolution like um you know ends up sort</p>
<p>of figuring out that this other amino acid needs to change as well for the structure to be conserved. Uh so this whole principle is that the structure is probably largely conserved you know because there&#x27;s this function associated with it. Um and so it&#x27;s really sort of like different yeah different different positions compensating for for each other. &gt;&gt; I see. So the the those hints in aggregate kind of give us a lot of information about what is close to each other and then you can start to look at what kinds of folds are possible given the structure and then what where where what is the end state and therefore you</p>
<p>can make a lot of inferences about what the actual total shape is. &gt;&gt; Yeah, that&#x27;s right. It&#x27;s almost like, you know, you have this big like three-dimensional valley, you know, where you&#x27;re sort of trying to find like these like low energy states and um there&#x27;s so much to search through that&#x27;s almost overwhelming. Um but these hints, they sort of maybe put you in an area of the space that&#x27;s already like kind of close to the solution, maybe not quite there yet. And and there&#x27;s always this question of like how much physics are these models learning, you know, versus like just pure like statistics. And like I think one of the thing at least I</p>
<p>believe is that um once you&#x27;re in that sort of approximate you know area of the solution space then the models have like some understanding you know of how to get you to like you know the low energy uh low energy state and so maybe you</p>
<h2>Generative Modeling vs. Regression in Structural Biology</h2>
<p>have some some light understanding of of of physics but maybe not quite enough you know to to know how to like navigate the whole space well. So we need to give it these hints to like &gt;&gt; get it into the right valley and then it finds the the minimum or something. Yeah. &gt;&gt; One interesting uh explanation about how free works that I think it&#x27;s quite insightful of of course doesn&#x27;t cover kind of the entirety of of what does that is um that I&#x27;m going to borrow from uh Sergey Chico at MIT. And so he sees kind of alphaold and the interesting</p>
<p>thing about Alphaold is got this very peculiar architecture that we have since you know um used and this architecture operates on this you know pair-wise context between amino acids and so the idea is that probably the MSA gives you this first hint about what potential uh amino acids are close to each other. &gt;&gt; MSA is m &gt;&gt; multiple sequence alignment. Exactly. This evolutionary exactly this evolutionary information &gt;&gt; and you know from this evolutionary information about potential contacts then is almost as if the model is sort</p>
<p>of running some kind of you know da algorithm where it&#x27;s sort of decoding okay these have to be closed okay then if these are closed and this is connected to this then this has to be somewhat close and so you decode uh this that becomes basically a pair-wise kind of distance matrix and then from this rough pair-wise distance matrix. You decode kind of the actual potential structure. &gt;&gt; Interesting. So there&#x27;s kind of two different things going on in the the kind of coarse grain and then the fine grain optimizations. Interesting. Yeah. &gt;&gt; Very cool.</p>
<p>&gt;&gt; Yeah. You mentioned Alpha Fold 3. So maybe good time to move on to that. So the Alpha Flow 2 came out and it was like I think fairly groundbreaking for this field. Everyone got very excited. A few years later, Alpha Fold 3 came out and um maybe for some more history like what was the difference between Alpha what were the advancements in Alpha Fold 3 and then I think maybe we&#x27;ll after that we&#x27;ll talk a bit about the uh sort of how it connects to bolts but anyway yeah so after Alphaold 2 came out I mean um you know Jeremy and I got into the field and with many others you know the</p>
<p>clear problem that you know uh was you know obvious after that was okay now we can do individual chains can we do interactions, interaction different proteins, proteins with small molecules, proteins with other other molecules and so &gt;&gt; so quick why why are interactions important? &gt;&gt; Interactions are important because to some extent that&#x27;s kind of the way that you know these machines that you know these proteins have a function. You know the function comes by the way that uh they interact with other uh with other proteins and</p>
<p>other molecules. actually in the first place you know uh the machines the individual machines are often as Jeremy was mentioning not made of a single chain but they&#x27;re made of multiple chains and then these multiple chains interact uh with other molecules to give uh the function to uh those and on the other hand you know when we try to intervene of these interactions think about like a disease think about like a bio sensor or many other ways we are trying to design a molecules or proteins that interact in a particular way with</p>
<p>what we would call a target protein or target. Um and so you know this problem after 2, you know, became clear kind of the the big uh one of the biggest problems in the field to to solve. uh many groups including kind of ours and others you know started making some kind of contributions uh to this problem of trying to model these interactions and Alpha 3 was um you know put a was significant advancement on the problem of modeling interactions and one of the</p>
<p>interesting thing that uh they were able to do while you know some of the rest of the field that really tried to try to model different interactions separately ly you know how protein interacts with small molecules, how protein interacts other proteins, how RNA or DNA um have their structure. They put everything together and you know train a very large models with a lot of advances including kind of changing kind of some of the key uh architectural choices and managed to get a single model that was able to set a new state-of-the-art performance</p>
<p>across u all of these different kind of modalities whether that was protein small molecules is critical to developing kind of new drugs protein protein understanding you know interactions of you know proteins with RNA A and DNA and so on. &gt;&gt; So just uh to satisfy the AI engineers and in the audience, what were some of the key architectural and data changes that made that possible? &gt;&gt; Yeah. So one uh critical one that was not necessarily just unique to Alphaold 3, but there were actually um a few other teams including ours in the field</p>
<p>that proposed this was moving from you know modeling structure prediction as a regression problem. So where there is a single answer and you&#x27;re trying to shoot for that answer to a generative modeling</p>
<h2>The “Bitter Lesson” and Specialized AI Architectures</h2>
<p>problem where you have a posterior distribution of possible structures and you&#x27;re trying to sample uh this distribution and this achieves two things. one is starts to allow us to try to model um more dynamic systems as we said you know some of these structures can actually take multiple um multiple structures uh and so you know you can now you know model that you know through kind of modeling the entire distribution but on the second hand from more kind of core modeling questions when you move from a regression problem to a</p>
<p>generative modeling uh problem you are really tackling the way that you think about uncertainty in the model in a different way. So if you think about, you know, I&#x27;m undecided between different answers, what&#x27;s going to happen in a regression model is that, you know, I&#x27;m going to try to make an average of those different kind of answers that I had in mind. And uh when you have a generative model, what you&#x27;re going to do is you know sample all these different answers and then maybe use a separate models to analyze those</p>
<p>different answers and pick out um the best. So that was kind of one of the uh critical improvement. The other improvement is that they significantly simplified to some extent the architecture especially of the um final model that takes kind of those pair wise representations and turns them uh into an actual structure and that&#x27;s now looks a lot more like a more traditional transformer than you know like a very um specialized equivariant architecture that it was uh in Alpha 4. So this is a</p>
<p>bitter lesson a little bit. &gt;&gt; There is some aspect of a bitter lesson but the interesting thing is that it&#x27;s very far from you know being like a simple transformer. I think one of um this field is one of the uh I would argue very few fields in uh applied machine learning where we still have kind of architecture that are very specialized and you know there are many people that have tried to replace these architectures with you know simple transformers and you know there&#x27;s a lot of debate in the field but I think kind</p>
<p>of the uh most of the consensus is that you know the performance that we get from the specialized architecture is faster ly superior than what we get through a single transformer. &gt;&gt; Yeah. &gt;&gt; Can can you talk a bit about that like specialized architecture? Um I assume you&#x27;re referring to triangle layers probably as the core idea or &gt;&gt; there&#x27;s something uh maybe it&#x27;s probably quite fundamental about the fact that we sort of model this in like a you know second order. So like instead of just the sequence we model every single pair and then to update every pair then we</p>
<p>need to have these like sort of triangular type operations and um I think what&#x27;s interesting about it is is is is a couple of things like one I think it relates a little bit to what the input is you know we talked about these multiple sequence alignments before and kind of this notion that like um you know we need to look at pairs of residues to try to understand you know maybe this initial like distance matrix like Gabri was talking about um and that&#x27;s something that is very natural right to to model um in 2D um and and I think also there&#x27;s something about the</p>
<p>output as well I think where I think supervising you know over these pairs I think is also quite powerful you know it&#x27;s this idea of telling the model hey like these two things are close to one another these two things are not um And doing that I think in in 3D is is maybe a bit more challenging. Um you know when I say 3D sorry I mean like so it&#x27;s like 1D where we model the coordinates in three dimensions but doing that in like one dimension I think is probably more challenging for the model and and yeah I think to it&#x27;s it&#x27;s really survived the test of time. I mean you know this thing</p>
<p>came out in 2021 and it&#x27;s largely the same. I mean there&#x27;s been this change to the the structure module that&#x27;s been like largely simplified but where the a lot of the magic happens you know I think it&#x27;s still it&#x27;s still in the same place um with these like large like pair-wise interaction modeling</p>
<h2>Development Anecdotes: Training Boltz-1 on a Budget</h2>
<p>&gt;&gt; um that&#x27;s maybe like the most differentiated portion the other part I think that&#x27;s in off three uh is sort of this moving away from modeling just at the amino acid level to actually sort of having um the model sort of alternate between um you know sort of atomic resolution modeling and then more like it&#x27;s called token level which is like at the amino acid level that&#x27;s also something that was introduced um that I think you know was particularly helpful in like you know modeling these other modalities like small molecule etc and like this idea of like coarse grain like</p>
<p>um finer grain is I think that&#x27;s actually quite popular I think in other areas as well so that&#x27;s maybe like not too surprising but yeah I think this the fact that you for some reason you you know the models that have so much more inductive bias when you when you go you know into this 2D representation I think is is is very interesting. &gt;&gt; So you you mentioned coarse and fine grain and that brings to mind the sort of ribbony diagrams of proteins that I&#x27;ve that everyone has probably seen. Can you actually pull up a like a</p>
<p>molecule and kind of talk about what &gt;&gt; you know what the different components of that protein are we&#x27;re looking at like with the spiral and the arrows and all those what components and those like what what level of uh granularity are we looking at h like how do we think about that how does a model think about that &gt;&gt; yeah so um there&#x27;s actually a little image of our of our own bull platform. Um I have a protein here. Um and you actually like sort of see both uh the</p>
<p>coarse grain and the finer grain here. So we have the sort of ribbon like structure here that is um you know representing these these different amino acids in the protein. But then like when we zoom in over this like interaction with the small molecule um then you see like sort of this at the atomic level like how these things like you know interact with one another. There&#x27;s even like the actual like bond interactions uh here that are like shown. Um and yeah like you know we we go from like this very abstract representation of these things you know like the the sequence the graph of the molecule and and the</p>
<p>goal is like every single atom should have a coordinate and um and you know ends up looking like something like this. It&#x27;s actually pretty pretty elegant. I think this is like something that&#x27;s nice really nice that this field has done is like it&#x27;s made really beautiful visualizations of stuff which is like really nice to look at and yeah I mean this is this is this is one example &gt;&gt; and so the there&#x27;s like okay um the there&#x27;s like ribbons there there&#x27;s like the coily ribbons there&#x27;s arrows there&#x27;s like some sort of like not coily ribbons like what do those mean how does someone</p>
<h2>Validation Strategies and the Protein Data Bank (PDB)</h2>
<p>think about those &gt;&gt; yeah so um we can zoom into a few different areas of the protein this one&#x27;s actually a good example because there&#x27;s a few different secondary structures here. So, um here you have, you know, we call an alpha helix. Um there essentially like sort of three categories. There&#x27;s the alpha helyses. Um this is where it takes a little bit of like this like ribbon uh shape. Um there&#x27;s here what we call a better sheet. Um which actually, you know, as the name says, uh sort of like ribbon going like this forming forming a bit of a of a sheet. And then you have um these</p>
<p>more like loopy regions uh which look like more unstructured and those are you know the parts of the protein that are most flexible. they are super important. Uh you know maybe like one of the most like canonical you know drug modalities are antibodies and antibodies have like you know six of these loops that are like largely flexible but when they interact you know kind of come into this like fixed structure when interacting with the um you know with with its target. Um so harder to model and really critical to interactions. Um, and yeah,</p>
<p>those are largely the three sort of big families. &gt;&gt; Okay. And and as a, you know, as a structural biologist or just a biologist, when you look at that, so you you&#x27;re basically looking, okay, here&#x27;s the the sheet part. Here&#x27;s the and then you&#x27;re you&#x27;re kind of saying, okay, that so that&#x27;ll be bendy and then I have like these coils those like what what do those mean to you when you look at them? &gt;&gt; Yeah, I mean, you know, I I should say I am not a structural biologist by any any way, shape or form. Um but you know there&#x27;s certain types of interactions that are more canonically associated with these different types of</p>
<p>structures. Yeah. &gt;&gt; Um I think uh a more well-versed structural biologist you know could give you a more thorough answer than that. I don&#x27;t know if you know anything more than I do but yeah um yeah and and and you know like we&#x27;ve seen for example this this maybe related to that point like we&#x27;ve seen um you know some of the early successes of protein design um being able to design a binder you know to to any any target um a lot of the early success was like these like very you know alpha helix centric type peptides which I think are um almost like bricks you know um and the models</p>
<p>had like a pretty good understanding of those like kind of interactions and so like there was like good success with that and then took a little bit of time to like go from that to like you know more exotic uh binders and and things like that and so um yeah there&#x27;s certainly a lot of um yeah a lot of important um interaction behaviors associated with with these structures. Yeah, &gt;&gt; another interesting thing that I think on the staying on the modeling machine learning side which I think is somewhat counterintuitive seeing some of the other kind of uh fields and applications</p>
<p>is that scaling hasn&#x27;t really worked kind of the same uh in this field. Um now you know models like alpha 2 and alpha 3 uh are you know still very large models but at the same time they in terms of parameters they&#x27;re actually not very big. they are definitely below a billion parameters. You know, if you hear these days in LLM space, you know, a model with less than a billion parameters, you would think can do anything. But on the other hand, when you look at the computational cost of running these models, they are actually</p>
<p>a lot more expensive than uh it is to run a language models because as Jeremy was saying, we go from instead of having sort of like quadratic operations, we now a cubic operation and and so it&#x27;s interesting how right now in the field and and this is maybe related to you know having kind of less data or you know needing more inactive biases but we have um this ratio of you know amount of computation to parameters that is much much higher than in other in other places.</p>
<p>&gt;&gt; Yeah, if I recall Alpha 2 was like what 70 million parameters something like that. &gt;&gt; Um yeah it&#x27;s it&#x27;s something like that. It&#x27;s quite yeah it&#x27;s quite small around 100 or so. Yeah. &gt;&gt; So like these these decisions of triangle layers and like these for alpha 2 this like interesting equavarian architecture like really were priors that it baked in a lot of the physics of the system and also co-evolution data is I think people have argued that is kind of like almost like a database lookup of some sorts. It also sort of so that</p>
<p>provides in some sense more parameters as well. Yeah, I mean it&#x27;s uh it&#x27;s more definitely the amount of like you know pure like compute flops, right? Is is very high and it&#x27;s almost like more yeah more almost more like reasoning based maybe than like more just like information extraction. You know, I think one of the things that the part of the reason the LMS are so large isn&#x27;t just because of their reasoning capability, but also because of like like the sheer quantity of information that they store. And I think here there&#x27;s a little bit less of that, you know, and I think it&#x27;s more about like, you know, decoding this input rather than maybe like memorizing as much of</p>
<p>it. &gt;&gt; So is there like a loop in the architecture that allows it to compute more for per parameter? Like how does that work? Part of it is just you know exclusively this fact that instead of you know having operations that operate on the uh on the single chain they operate on the pair wise and so you instead of having like quadratic number of kind of interactions you have a cubic number of interactions and so that on</p>
<h2>The Mission of Boltz: Democratizing Access and Open Source</h2>
<p>its own you know leads you to have you know smaller kind of representation sizes but more representation that leads to more flops but fewer parameters. On the other hand, you know, there is actually also this idea of, you know, they somewhat similar to to reasoning where you recycle kind of this operation. from Alpha 4 2 but also kind of Alpha 4 3. They have this interesting framework where you know you start we as we were discussing kind of the input to the model is sort of like this initial</p>
<p>understanding of the interactions either from the evolution of the multiple sequence but also potentially from what we call templates that are basically database lookup of similar structures. And so how the model works is that you know it decodes these and tries to understand a good you know potential rough structure of the pair wise interaction and then what you can do is basically do this recycling where you feed this uh kind of understanding back to the input of the model and then try to decode it again and people do this you know three or four times and you know in some cases you know I&#x27;ve even</p>
<p>tried to do it uh tens of times and so you can see it as a very very early version of kind of reasoning uh or you know trying to uh to get. &gt;&gt; Yeah. So you you know uh Alpha 2 really cool, Alpha 3 really cool. Um but Alpha 3 came with a catch and I think this catch was important for the development of you know bolts and so on. So &gt;&gt; yeah the catch was that it was an amazing paper nature uh paper but unfortunately they uh decided not to</p>
<p>release the model. uh you know Alpha Fall 2 uh was open source and since then was was used I think the the reported numbers is you know more than a million scientists. Alpha for free for you know commercial reasons that you know um did mine has since spin-off as a morphic lab that is now trying to become sort of like a new pharmaceutical company uh and decided to keep this model internal and and only use internally and now uh both you know we were in the field and you know building on top of models like Alphafold and so now we no longer add</p>
<p>you know kind of the base starting point uh to build on top but even more importantly everyone in uh both kind of academic research and in industry no longer had access to these incredible models that you know was you know really useful to try to understand um kind of biologies but also try to develop new therapeutics. And so we um decided that you know to to take the the matter in our own hands and decided to kind of um try to obtain a model that was of</p>
<p>similar accuracy. And so largely also you know using a lot of you know the uh information that was in the alpha free manuscript we went ahead and built boltzswan which was um the first fully open source kind of model to approach the the level of accuracy of of our fault 3 and you know along the way and and you know uh we can talk about it more but you know we realized that you know it was probably too ambitions to have you know to see this as a an academic project and you know there are a lot of things that were kind of</p>
<p>missing and so um we decided to also start a public benefit company to push kind of this this mission of you know democratizing access to these models that we started with bolts one &gt;&gt; quick interjection I mean I remember this it was actually shocking how fast you got bolts one out like it was just like two or three months right &gt;&gt; I think we started in late May and it came in November if I remember correctly. So slightly longer but yeah. Yeah, it was relatively quick. I mean</p>
<p>for what it&#x27;s worth like &gt;&gt; you know we were working on some of the some similar ideas at the time. I think like we you know for example this idea of like having a diffusion model on top of um this like more this pair wise strong was something that we were we were exploring independently. Um now when the paper came out it was like really clear like especially for example on the data pipelines there was like so much that we were like not really doing</p>
<h2>Building a Self-Sustaining Research Community</h2>
<p>and so um there was a lot to like catch up on. Um but we were already in a place I think where we had you know some experience working in you know with with the data and working with these type of models and I think that put us already in like a good place to you know to to produce it quickly and you know and I would I would even say like I think we could have done it quicker. The problem was like for a while we didn&#x27;t really have the compute and so we couldn&#x27;t really train the model and actually we only trained the big model once. Uh that&#x27;s how much compute we had. We could only train it once and so like while the</p>
<p>model was training we were like finding bugs left and right. Uh a lot of them that I wrote and like I would I remember like us like sort of like you know doing like surgery in the middle like stopping the run, making the fix like relaunching and um yeah we never actually went back to the start. We just like kept training it with like the bug fixes along the way. Uh which was &gt;&gt; impossible to reproduce now. &gt;&gt; Yeah. Yeah. No, that model is like has gone through such a curriculum that you know it&#x27;s learned some weird stuff. Uh but uh yeah, somehow by miracle it worked out.</p>
<p>&gt;&gt; The other uh funny thing is that the way that we were training most of that model was through uh a cluster from the department of energy, but that&#x27;s sort of like a share cluster that many groups use. And so we were basically training the model for 2 days and then it would go back into the queue and stay a week in the queue. And so it was it was it was pretty painful. And so we actually kind of towards the end um I caught up with with Deon the CEO of of Genesis and and basically I was telling him a bit a bit about the project and you know kind</p>
<p>of telling him about this frustration with the computer. And so luckily, you know, uh he offered to kind of help and so we uh we got the help from Genesis to, you know, finish up the um the model otherwise it probably would have taken a couple of extra weeks of weeks. &gt;&gt; Yeah. &gt;&gt; Yeah. Bolt one. How did that compare to Alpha Fold 3? And then and then there&#x27;s some progression from there. &gt;&gt; Yeah. So I would say kind of the bolts one but also kind of these other kind of set of models that came um around the</p>
<p>same time were kind of approaching were a big leap from you know kind of the previous kind of open source models uh and you know kind of uh really kind of approaching the level of alpha 3. But I would say still say that you know even to this day there are you know some specific instances where uh alpha 3 uh works better. I think one one common examples is antibbody antigen uh prediction where you know alpha fold 3 still seems to have an edge uh in in</p>
<p>many situations. Obviously these are somewhat different models. They are you know you run them you obtain different results. So it&#x27;s it&#x27;s not always the case that one model is better than the other but kind of in aggregate we still</p>
<h2>Boltz-2 Advancements: Affinity Prediction and Design</h2>
<p>uh especially at the time so 3 is you know still having a bit of an edge we should talk about this more when we talk about volt but like how do you know one is one model is better than the other like so you I make a prediction you make a prediction like how do you know &gt;&gt; yeah so the easily you know the the great thing about kind of structure prediction and you know once we&#x27;re going to go into the design space of designing new small molecule new proteins this becomes It&#x27;s a lot more complex. But a great thing about structure prediction is that a bit uh like you know CASP was doing basically the way that you can evaluate</p>
<p>them is that you know you train uh the model on a structure that was you know released across the field up until a certain time. And you know one of the things that we didn&#x27;t talk about that was really critical in all this development is the uh PDB which is the protein data bank is this um common resources basically common database where every uh biologist and uh publishes their structures and so we can you know train on you know all the structures that were put in the PTB until a certain date and then we</p>
<p>basically look for recent structures. Okay, which structures look pretty different from anything that was published before? Because we really want to try to understand generalization and on this new structure we evaluate all these different models. &gt;&gt; So you just know when alpha 4 was three three was trained, you know when you&#x27;re you intentionally train to the same date or something like that. &gt;&gt; Exactly. &gt;&gt; Right. Yeah. &gt;&gt; And so this is kind of the way that you can somewhat easily kind of compare these models. Obviously that assumes that you know the the training set &gt;&gt; you&#x27;ve always been very passionate about</p>
<p>validation. I remember like diff doc and then there was like diff do l and dogen like you you really thought you&#x27;ve thought very carefully about this in the past like um yeah I mean actually I think dogen is like a really funny story that I think um I don&#x27;t know I don&#x27;t know if you want to talk about that it&#x27;s an interesting like uh &gt;&gt; yeah I think one of the amazing things about putting things open source is that you know it um we get a ton of feedback from from the field and you know sometimes we get kind of great feedback of people really</p>
<p>liking the model. But honestly, most of the times and you know to be honest that&#x27;s also maybe the most useful feedback is you know people sharing about where it doesn&#x27;t work. And so you know at the end of the day it&#x27;s critical and this is you know also something you know across other fields of of machine learning it&#x27;s always critical to set uh to do progress in machine learning set clear uh benchmarks and you know as you know you start you know doing progress of certain benchmarks then you know you need to improve the benchmarks and make</p>
<p>them harder and harder and this is kind of the progression of you know how the field operates and so you know the example of of uh doctrine was you know we um published this initial uh model called diff do um in my first year PhD which was sort of like you know one of the early um models to try to predict uh bio kind of interactions between proteins small molecules um that we about a year after alpha 2 was published and now on the one end you know on these</p>
<p>benchmarks that we were using at the I am uh diff was doing uh really well kind of you know uh outperforming kind of some of the traditional physics based methods but on the other hand you know when we started you know kind of giving these uh tools to kind of many biologists and uh one example was uh that we collaborated with was the group of Nick Pitzy at Harvard. uh we not started noticing that there was this clear pattern where for proteins that were very different from the ones that we&#x27;re trained on uh the models was was</p>
<p>struggling. And so you know that seemed clear that you know this is probably kind of where we should you know put our focus on. And so we first developed you know with uh Nick and his group a new benchmark and then you know went after and said okay what can we change and kind of about the current architecture to improve this uh pattern and generalization and this is the same that you know we uh we&#x27;re still doing today you know uh kind of where does the model not work you know and then you know once we have that benchmark you know let&#x27;s try to uh throw everything we uh any</p>
<p>ideas that we have at the pro &gt;&gt; and there&#x27;s a lot of like healthy skepticism in the field which I think you know is is is great and I think you know it&#x27;s very clear that there&#x27;s a ton of things the models don&#x27;t really work well on but I think one thing that&#x27;s probably you know undeniable is just like the pace of pace of progress you know and how how much better we&#x27;re getting you know every year and so I think if you you know if you assume you know any constant you know rate of progress moving forward I think you know um things are going to look pretty cool at some point in future was only 3 years ago</p>
<p>&gt;&gt; yeah I mean it&#x27;s wild like &gt;&gt; what? &gt;&gt; Yeah. Yeah. Yeah. It&#x27;s one of those things like even being in the field, you don&#x27;t see it coming, you know, and like I think Yeah. Um hopefully we&#x27;ll, you know, we&#x27;ll we&#x27;ll continue to have as much as we&#x27;ve had the past few years. &gt;&gt; So, this is maybe an an aside, but I I&#x27;m really curious. You get this great feedback from the from the community, right, by being open source. Um my question is partly like okay yeah if you open source then everyone can copy what you did but it&#x27;s also maybe balancing priorities right where you like all my</p>
<p>customers are saying I want this like there&#x27;s all these problems with the model yeah yeah yeah but that like my customers don&#x27;t care right so like how do you how do you think about that &gt;&gt; yeah so I would say a couple of things one is you know part of uh our goal with bolts and you know this is also kind of established as kind of the mission of the public benefit company that we started is to democratize the access to these tools. But one of the reason why we realized that Boltz needed to be a company it couldn&#x27;t just be an academic project is that putting a model on</p>
<p>GitHub is definitely not enough to get you know chemists and biologists you know across you know uh both academia, biotech and and pharma to use your model to uh in their therapeutic programs. And</p>
<h2>BoltzGen: Merging Structure and Sequence Prediction</h2>
<p>so a lot of what we think about you know at Bolts beyond kind of the just the models is thinking about all the layers that come on top of the models to get you know from you know those models to something that can really uh enable scientists uh in the industry. And so that goes you know into building kind of the right kind of uh workflows that take in kind of for example the data and try to answer kind of directly that those problems that you know the chemists and the biologists are asking and then also kind of building the infrastructure. And</p>
<p>so this to say that you know even with kind of you know models fully open you know we see kind of a ton of um potential for you know um you know products in the space and um the critical part about a product is that even you know for example with an open source model you know running the model is not free you know as we were saying these are pretty expensive model and especially and maybe we&#x27;ll get uh into this you know these is we&#x27;re seeing kind of pretty dramatic inference time</p>
<p>scaling uh of of these models where you know the more you run them the better the results are. Uh but there you know you start getting into a point that compute and compute cost becomes a critical factor and so putting a lot of work into building the right kind of infrastructure building the optimizations and so on really allows us to provide you know a much better service potentially to the open source models. But that to say you know even though you know with a product we can provide a much better service. I do still think and we will continue to put a lot of our models open source because</p>
<p>the um the critical kind of role I think of open source models is you know helping kind of the community progress on the research and you know from which we we all benefit and so you know we&#x27;ll continue to on the one end you know put some of our kind of base models open source so that the field can can build on top of it and you know as we discussed earlier we learn a ton from you know the way that the field uses and builds on top of our models but then you know try to build a product that gives the best experience possible to</p>
<p>scientists um so that you know like a chemist or a biologist doesn&#x27;t need to you know spin off a GPU and you know set up you know our open source model in a particular way but can just you know uh a bit like you know I even though I am a computer scientist machine learning scientist I don&#x27;t necessarily you know take a open-source LLM and try to kind of spin it off. But, you know, I just maybe open um the Chipy app or CL code and just use it as an amazing product. Uh we kind of want to give the same</p>
<p>experience to scientists around the world. &gt;&gt; I heard a good analogy yesterday that a surgeon doesn&#x27;t want the hospital to design a scalpel, &gt;&gt; right? So, just buy the scalpel. You wouldn&#x27;t believe like the number of people even like in my short time um you know between a full three coming out and and the end of the PhD like the um number of people that would like reach out just for like us to like run off a full three for them &gt;&gt; you know or things like that just because like um or bolts in our case &gt;&gt; you know just because it&#x27;s like not that</p>
<p>easy you know to do that you know if you&#x27;re not a computational person and I think like part of the goal here is also that you know We continue to obviously build an interface with competitional folks but that you know the models are also accessible to like a larger broader audience and and then that comes from like you know good interfaces and stuff like that. &gt;&gt; I think one like really interesting thing about Bolt is that with the release of it you didn&#x27;t just release a model but you created a community. &gt;&gt; Yeah. &gt;&gt; Did that community it grew very quickly. Did that surprise you and like what is then the evolution of that community and</p>
<p>how is that fed into Bolts? &gt;&gt; If you look at its growth, it&#x27;s it&#x27;s like very much like when we release a new model, it&#x27;s like there&#x27;s a big uh big jump. Um but yeah, it&#x27;s I mean it&#x27;s been great. You know, we have a Slack community that has like thousands of people on it. Um and it&#x27;s actually like self-sustaining now, which is like the really nice part because, you know, it&#x27;s it&#x27;s almost overwhelming, I think. you know, to be able to like answer</p>
<h2>Large-Scale Wet Lab Validation Results</h2>
<p>everyone&#x27;s questions and help. It&#x27;s really difficult, you know, with the the few people that we were, but it ended up that like, you know, people would answer each other&#x27;s questions and like sort of like, you know, help one another. And so, the the the Slack, you know, has been like kind of yeah, self self sustaining and that&#x27;s been that&#x27;s been really cool to see. Um, and um, you know, that&#x27;s that&#x27;s for like the Slack bar, but then also obviously on GitHub as well. We&#x27;ve had like a nice nice community. Um you know I think we also aspire to be even more active on it you know than we&#x27;ve been in the past 6 months which been like a bit challenging</p>
<p>you know for us but um yeah the the community has been has been really great and you know there&#x27;s a lot of papers also that have come out with like new evolutions on top of bolts and um it&#x27;s surprised us to some degree because like there&#x27;s a lot of models out there and I think like you know sort of people converging on that was was really cool and you know I think it speaks also I think to the importance of like you know when when you put code out like to try to put a lot of emphasis in like making it like as easy to use as possible and something we thought a lot about when we released the the codebase um you know it&#x27;s far from perfect but you know</p>
<p>&gt;&gt; do you think that that was one of the factors that caused your community to grow is just the focus on easy to use make it accessible &gt;&gt; I think so yeah and we we&#x27;ve we&#x27;ve heard it from a few people over over the over the years now and um you know and some people still think it should be a lot nicer and and they&#x27;re right &gt;&gt; uh and they&#x27;re right but um Yeah, I think it was, you know, at the time maybe a little bit easier than than other things. The other I think part that I think led to to the community and to some extent I think you know like the somewhat the trust in the community and kind of what we what we put out is the fact that you know it&#x27;s not really been</p>
<p>kind of you know one model but and maybe we&#x27;ll talk about it you know after bolts one you know there were maybe another couple of models kind of released you know uh or open source kind of soon after we kind of continued kind of that open source journey release bolts too where we are not only improving kind the structure prediction but also starting to do affinity prediction. So understanding kind of the strength of the interactions between these different models which is this critical component critical property that you often want to optimize uh in discovery programs and then you know more recently also kind of</p>
<p>protein design model. And so we&#x27;ve sort of been building this suite of of models that come together interact with one another where you know kind of there is almost an expectation that you know we we take very at heart of you know always having kind of you know across kind of the entire suite of different task the best or across the best model uh out there. So that it&#x27;s sort of like uh our open source tool can be kind of the go-to uh model for everybody in the in the industry.</p>
<p>&gt;&gt; I really want to talk about bold gen. But before that one last question in this direction. Was there anything about the community which surprised you? Were there any like someone was doing something and you&#x27;re like why would you do that? That&#x27;s crazy. Or that&#x27;s actually genius and I never would have thought about that. &gt;&gt; I mean we&#x27;ve had you know many contributions. I think like some of the interesting ones like I mean we had you know this one individual who like wrote like a complex GPU kernel you know for part of the architecture</p>
<p>um on on a piece of the funny thing is like that piece of the architecture had been there since Alpha 2 and I don&#x27;t know why it took bolts for this you know office person to you to decide to do it but that was like a really great contribution we&#x27;ve had a bunch of others There&#x27;s like you know people figuring out like ways to you know hack the model to do cyclic peptides like you know there&#x27;s I don&#x27;t know if there&#x27;s any other interesting one cool one and and this was you know something that initially was uh proposed as you know as a message in the slack channel by by Tim O&#x27;Donnell was basically he was you know</p>
<p>there are some cases especially for example we discussed you know antibody antigen interactions where the models don&#x27;t necessarily kind of uh get the right answer what he noticed is that you the models were somewhat stuck into predicting kind of the the antibbody to interact with a part of the antigen that was incorrect. And so he basically um run the experiments. In this model, you can condition uh basically you can give hints. And so he basically gave uh you know random hints uh to the model basically. Okay, you should bind to this residue uh you should bind to the first</p>
<p>residue or you should bind to the 11th residue or you should bind to the 21st residue. you know basically every 10 residue scanning the entire antigen and &gt;&gt; residues are the the &gt;&gt; the amino acids amino acid so the first amino acids the 11 amino acids and so on. So it&#x27;s sort of like doing a scan and then you know conditioning the model to predict all of them and then looking at the confidence of the model in each of those cases and taking the top and so it&#x27;s sort of like a very somewhat crude way of doing kind of inference time search but surprisingly you know for for antibbody antigen prediction actually</p>
<p>kind of helped quite a bit and so there&#x27;s some you know interesting ideas that you know as a um obviously as kind of developing the model you say kind of you know wow this is why would the model you know, be so dumb. But, you know, it&#x27;s it&#x27;s very interesting and and that, you know, leads you to also kind of, you know, start thinking about, okay, how do I can I do this, you know, not, you know, with this brute force, but, you know, in a in a smarter way. And so, we&#x27;ve also done a lot of work on that direction. &gt;&gt; And that speaks to like the, you know, the power of scoring. Uh we&#x27;re seeing that a lot. I&#x27;m sure we&#x27;ll talk about it</p>
<p>more when we talk about bulls gen. But um you know, our ability to like take a structure and determine that that structure is like good, &gt;&gt; you know, like somewhat accurate. uh whether that&#x27;s a single chain or like an interaction is a really powerful you know way of improving you know the the models like sort of like you know if you can sample a ton and you assume that like you know if you sample enough you&#x27;re likely to have like you know the good structure then it really just becomes a ranking problem. Um, and you know, now we&#x27;re, you know, part of the</p>
<p>inference time scaling that Gabri was talking about is is very much that it&#x27;s like, you know, the more we sample, the more we like, you know, the ranking model ends up finding something it really likes. Um, and so I think our ability to get better at ranking, I think is also what&#x27;s going to enable sort of the next, you know, next big big breakthroughs. &gt;&gt; Interesting. But I guess there&#x27;s a my understanding there&#x27;s a diffusion model and you generate some stuff and then you I guess it&#x27;s just what you said, right? Then you rank it using a score and then you finally um and so like can you talk about those different parts?</p>
<p>&gt;&gt; Yeah. So first of all like the one of the critical kind of you know beliefs that we had you know also when we started working on pulse one was sort of like the structure prediction models are somewhat you know our field version of some foundation models you know learning about kind of how proteins and other molecules interact and and then we can leverage that learning to do also to other things and so with Bolu we leverage that learning to do things uh affinity prediction So understanding kind of you know if I give you this</p>
<p>protein these small molecules how tightly is the interaction uh for bolshen what we did was taking kind of that kind of foundation models and then fine-tune it to predict kind of entire new proteins and so the way basically</p>
<h2>Boltz Lab Product Launch: Agents and Infrastructure</h2>
<p>that that works is sort of like instead of uh for the protein that you&#x27;re designing instead of feeding in an actual sequence you feed in a set of blank tokens and you train the models to you know predict both the structure of kind of that protein and with the structure also what the different amino acids uh of um that proteins are. And so basically the way that uh bolt chain operates is that you feed a this a target a protein that you may want to kind of bind to or you know another DNA</p>
<p>RNA and then you feed um the highle kind of design specification of you know what you want your new protein uh to be for example it could be like an antibbody with a particular framework could be a peptide could be many other things &gt;&gt; and that&#x27;s with natural lang language or &gt;&gt; and that&#x27;s you know basically you know prompting and we have kind of this sort of like spec that you you specify &gt;&gt; and you know you feed kind of this this spec to the model and then the model translate this into you know a set of</p>
<p>you know uh tokens a set of conditioning to the model a set of you know blank tokens and and then you know basically decodes as part of the um diffusion models decodes a new structure and a new sequence for your your protein and you know basically and then we take that and as Jeremy was saying you know trying to score it and you know how good of you know a binder it is to that original target that you you&#x27;re using both basically bolts to to predict the folding and the</p>
<p>affinity to that molecule. So and then that is your that kind of gives you a score. Is that &gt;&gt; exactly? So you you use this model to predict the structure and then you do two things. One is that you predict the structure &gt;&gt; and with something like bolts do and then you basically compare that structure with what the model uh predicted what bolshion predicted um and this is sort of like in the field calls consistency. It&#x27;s basically you want to make sure that you know the structure that you&#x27;re predicting is actually what you&#x27;re trying to design and that gives</p>
<p>you a much better confidence that you know that&#x27;s a good design. And so that&#x27;s the the first filtering and the second filtering that we did as part of kind of the the Bolshion pipeline um that was released is uh that we look at the confidence that the model has in the structure. Now unfortunately kind of going to your your question of you know predicting affinity unfortunately confidence is not a very good predictor of affinity um and so one of the things that we&#x27;ve actually done a ton of</p>
<p>progress you know since uh we released Bolchen and kind of we have some uh new results that we are going to kind of announce soon is kind of you know the ability to get much better rates when instead of you know trying to rely on confidence of the model we are actually directly trying to predict the affinity uh of that interaction. &gt;&gt; Okay, just backing up a minute. So your diffusion model actually predicts not only the protein sequence but also the folding of it. &gt;&gt; Exactly. And actually kind of the way</p>
<p>one of the big um kind of different things that we did compared to uh other models in the space and you know there were some uh papers had already kind of done this before but we uh really scaled it up was you know basically somewhat merging kind of the structure prediction and the sequence prediction into almost the same task. And so the way that Bolsten works uh is that you are basically the only thing that you&#x27;re doing is predicting the structure. So the only sort of like supervision is we</p>
<p>give you a supervision on the structure but because the structure is atomic and you know the different amino acids have a different atomic composition basically from the way that you place the atoms. We also understand not only kind of the structure that you wanted but also the identity of the amino acid that you know the models believed was there. And so we&#x27;ve basically instead of you know having these two supervision signals you know one discrete one continuous that somewhat you know don&#x27;t interact well together we sort of like build kind of</p>
<p>like an encoding of you know sequences in structures that allows us to basically use exactly the same supervision signal that we using to bolts 2 that you know uh you know largely similar to what Alpha 3 uh proposed which is very scalable and we we can use that to design new proteins. &gt;&gt; Oh, interesting. &gt;&gt; Maybe a quick shout out to Hannes uh Stark on our team who like did all this work. Um yeah. &gt;&gt; Yeah, it was a really cool idea. I mean like looking at the paper and there&#x27;s just this like encoding where you just add a bunch of I guess kind of atoms</p>
<p>which can be anything and then they get sort of rearranged and then basically plopped on top of each other so that and then that encodes what the amino acid is and there&#x27;s sort of like a unique way of doing this. It was that was like such a really such a cool fun idea. Yeah, &gt;&gt; I think that idea was had existed before. Yeah, there were a couple of papers that had proposed this and and analysts really took it to um to the large scale. &gt;&gt; In the paper, a lot of the paper for both gen is dedicated to actually the validation of the model. In my opinion,</p>
<p>we talk a all the people we basically talk about feel that this sort of like in the wet lab or whatever the appropriate you know sort of val like in real world validation is the whole problem or not the whole problem a big giant part of the problem. So can you talk a little bit about the highlights from there that really because to me uh the results are uh impressive both from a the perspective of the you know the model and also just the the effort that went into the validation by a large</p>
<p>team. First of all, I think I should tr start saying is that both when we were at MIT and Thomas Yakolas and Regina Barcel&#x27;s lab as well as at Bolts, you know, we are not a we&#x27;re not a biolab and you know, we are not a therapeutic company. And so to some extent, you know, we were first forced to, you know, look outside of, you know, our group, our um team to do the experimental validation. And so one of the things that um really honest uh in the team pioneer was the idea okay can we go not</p>
<p>only to you know maybe a specific group and you know trying to find a specific system and you know maybe overfitit a bit to that system and and trying to validate but how can we test these models across a very wide variety of different settings so that you know anyone in uh in the field and you know printing design is you know such a kind of wide um task with all sorts of different applications from therapeutic to you know bio sensors and uh many others that you know so can we get a validation that</p>
<p>is kind of goes across uh many different tasks and so he basically put together you know I think it was something like you know 25 different you know academic and industry labs that you know sort of like committed to you know testing uh some of designs from the model and some of this testing is is still ongoing. uh and you know giving uh results kind of uh back to us in exchange for you know hopefully getting some you know new se new great sequences for uh their task and and he was able to you know</p>
<p>coordinate this you know very wide uh set of you know uh scientists and uh already in the paper I think we uh shared uh results from I think uh 8 to 10 different uh labs uh kind of showing results from you know designing peptides uh designing uh to target you know ordered proteins, peptides targeting disordered proteins. We show results you know of uh designing proteins that bind to small molecules. Uh we showed results of you know designing nanobodies and</p>
<p>across a wide variety of different targets. And so that sort of like gave to the to the paper a lot of you know validation and to the model a lot of validation that was kind of uh wide uh &gt;&gt; just uh again um for our nonbiologist uh audience peptides nanoparticles what are these things that are being designed why like what is interesting about these particular things why are is there focus in them &gt;&gt; yeah so largely you know they&#x27;re all proteins it&#x27;s just different shape the proteins they peptides</p>
<p>uh is is a small protein uh and is you know a relatively common type of of therapeutic the very common examples these days are the you know GLP1 ompic right &gt;&gt; ompic and so on they&#x27;re all peptides formed by both canonical and non-cononical amino acids um the when we think about kind of larger proteins there also can take different shapes There is you know maybe one of we have this term called mini proteins which is</p>
<p>like a very vague term to say kind of any sort of shape. Uh but then there are some specific shapes that you know proteins can take and um so one very common one is antibodies and antibodies are uh particular type of protein in our body that is involved uh in our immune system and it&#x27;s formed by um basically a set of you know four different um protein chains you know two uh two heavy call heavy which are longer and to light that come together and form</p>
<p>kind of this interesting structure and those are you know very common type also</p>
<h2>Future Directions: Developpability and the “Virtual Cell”</h2>
<p>of therapeutic because of you know the function that they have in our immune system and finally there are kind of what are called nanobodies that I mentioned that are sort of like the equivalent of antibodies but on specific in specific animals so there are some animals and I think some examples are &gt;&gt; llamas camels and sharks that instead of having kind of this more complex set of you know four proteins coming together, it&#x27;s a single protein and and so recent in recent years has</p>
<p>been also a relatively common type of therapeutic uh that people are trying to design. And so these are sort of like have a similar function to antibodies but are simpler in terms of uh structure. &gt;&gt; And so those would be therapeutics for those animals or they relevant to humans as well? they&#x27;re relevant to humans as well. Obviously, you need to do some work into uh quote unquote humanizing them, making sure that you know they have the right characteristic to so they&#x27;re not uh toxic to humans and so on. Uh but there are um some approved</p>
<p>medicine in the uh in the market there are no &gt;&gt; there&#x27;s a general pattern I think in like in trying to design things that are smaller, you know, like it&#x27;s easier to manufacture. Um at the same time like that comes with like potentially other challenges like maybe a little bit less selectivity than like if you have something that has like more hands you know um but the yeah there&#x27;s this big desire to you know try to yeah design many proteins nanobodies small peptides you know that just are just great drug modalities &gt;&gt; and that that&#x27;s because they&#x27;re more</p>
<p>selective. &gt;&gt; No generally I think it&#x27;s largely a manufacturing thing. &gt;&gt; Oh okay I see. So it&#x27;s you know the bigger the bigger the protein the more complex essentially. Yeah, &gt;&gt; I put a pin in. I want to understand like how do you actually build a protein? Like I know you guys are not wet lab technicians, but &gt;&gt; I want to like hear more about the validations that you&#x27;ve done. &gt;&gt; Um I can try &gt;&gt; essentially like so we work with uh organizations to do the the lab evaluation. um we we don&#x27;t do any of it ourselves and typically what we send those people is we send them you know</p>
<p>the sequence of the target and the sequence of the binder in this case for example an antibbody it would be like a single single chain uh we have to order the DNA that&#x27;s yet another company that produces that DNA sends it over and then you have to like express the proteins so you have to like express the target you have to express the binders and by expressing what I mean is like you put you know the the DNA uh typically in like you know either uh some capsid or you put it in like a and then you express it in like a yeast for example or you can like do it in like sulfury</p>
<p>systems now but um essentially you know you you use like typical biological mechanism um to &gt;&gt; you&#x27;re kind of like hijacking the yeast to create &gt;&gt; yeah you give it the extra DNA and you&#x27;re like okay like create this thing &gt;&gt; so so you want to this is like um you&#x27;re amplifying the DNA in some way is that basically &gt;&gt; yeah yeah so there yeah so they&#x27;re jumping some steps there&#x27;s like a yeah amplifying the DNA there&#x27;s all this stuff and then um but at the end of the day the you starts to produce a lot of this protein then you need to purify it because there&#x27;s a lot of other stuff in</p>
<p>there so typically you have like a tag on the protein and then like based on that tag you can sort of purify um once you have like your pure target your pure binder you can then like run your binding assay and then that&#x27;s where my knowledge stops but there&#x27;s various methods to do that uh you know you put things in a well and then you can measure um the you know the the binding strength um and then we get the results back um and we also get to know like you know whether it was a binder but also like how strong of a binder it was um and that&#x27;s generally the the process</p>
<p>&gt;&gt; right so so that you kind of you specify the molecule they create some DNA that can create the RNA they create some RNA from that that creates the &gt;&gt; uh the protein You take the protein and you use lab voodoo to measure the the binding strength of that or the two proteins or two molecules. &gt;&gt; Yeah. Okay. That&#x27;s right. &gt;&gt; Okay. So, we were I think we were left off we were talking about &gt;&gt; validation in the lab and I was very excited about</p>
<h2>Interacting with Skeptical Medicinal Chemists</h2>
<p>seeing like all the diverse validations that you&#x27;ve done. Can you &gt;&gt; Yeah. &gt;&gt; go into some more detail about them &gt;&gt; specific ones? Yeah, the nanobbody one I think we did what was it 15 targets is that correct 14 &gt;&gt; 14 targets um testing um so we typically the way this works is like we uh make a lot of designs all right on the order of like tens of thousands and then we like rank them and we pick like the top n uh in this case n was 15 right um for each target and then we like measure sort of</p>
<p>like the success rates both on like how many targets we were ble to um to get a binder for and then also like more generally like out of all of the you know binders that we designed how many actually proved to be uh good binders. Some of the other ones I think involved like yeah like we had a a cool one where there was a small molecule or design a protein that uh you know binds to it. Um that has a lot of like interesting applications you know for example like Gabby mentioned like biosensing and things like that uh which is pretty cool. Um we had we had a disordered protein I think you mentioned also. Um</p>
<p>and yeah I think some of maybe some those were some of the the highlights. &gt;&gt; Yeah. So I would say that the way that we structure kind of some of those validations was on the one end we have validations across a whole set of different problems uh that you know the biologists that we&#x27;re working uh with came to us with. So we are trying to uh for example in some of the experiments design peptides that would uh target rack C which is uh a target that is involved in metabolism. Um we had you</p>
<p>know number of other uh applications where we were trying to design you know peptides or other modalities against some other therapeutic relevant targets. Um we designed some um proteins to bind small molecules and then some of the other uh testing that we did was really trying to get like a more broader sense of how does the model work especially when tested you know on somewhat generalization. So one of the things that you know we we found uh with the field was that a lot of the validation</p>
<p>especially outside of the validation that was done on specific problems was done on targets that have a lot of you know known interactions in in the training data. And so it&#x27;s a bit always a bit hard to understand, you know, how much are these models really just regurgitating kind of what they&#x27;ve seen or trying to imitate what they&#x27;ve seen in training data versus, you know, really be able to design uh new proteins. And so one of the experiments that we did was to uh take nine targets from</p>
<p>um the PDB filter into things where there is no known interaction. uh in in the PDB. So basically the model has never seen kind of this particular protein bound or a similar protein bound to another protein. So there is no way that the model uh you know from its training set can sort of like say okay I&#x27;m just going to uh kind of &gt;&gt; tweak something &gt;&gt; tweak something and and just imitate this particular kind of interaction and and so we we took those nine proteins we worked with adaptive CRO and basically</p>
<p>tested you know 15 mini proteins and 15 nanobodies against each one of them and the very cool thing that we saw was that on twothirds of those targets we were able to from these 15 designs uh get uh nanomolar uh binders. Nanomolar roughly speaking is just a measure of you know how strongly kind of the interaction is and roughly speaking kind of like a nanomolar binder is approximately the kind of binding strength of binding that you need for a therapeutic.</p>
<p>&gt;&gt; Okay. &gt;&gt; Yeah. So maybe switching uh directions a bit. Um so I I Boltz Lab was just announced um this week or was it last week? Yeah. &gt;&gt; Um uh this is like your first I guess product if if that&#x27;s the if you want to call it that. Um can you talk about what Bolts Lab is and um yeah you know what you hope that people take away from this. Yeah, you know, as we mentioned like I think at the very beginning is the goal with the product has been to,</p>
<p>you know, address what the models don&#x27;t on their own. Um, and there&#x27;s largely sort of two categories there. Um, you know, or let&#x27;s say let&#x27;s say I&#x27;ll split it in three. Um, the first one is that you know it&#x27;s one thing to predict you know a single interaction for example like a single structure. Um it&#x27;s another to like you know very effectively uh search a space a design space you know to to produce something of value and you know what we&#x27;ve what we found like sort</p>
<p>of building up this product is that there&#x27;s a lot of steps involved you know in that that we sort of need to like you know accompany the user through. Um you know one of those steps for example is like you know the the creation of the target itself. you know, how do we make sure the model has like a good enough understanding of the target so we can like design something and there&#x27;s all sorts of tricks, you know, that you can do uh to improve like a particular, you know, structure prediction. And so that&#x27;s sort of like you know the first stage and then there&#x27;s like this stage of like you know designing and searching the space efficiently you know for something like BSG for example like you</p>
<p>you know you design many things and then you rank them for example for small molecule the process is a little bit more complicated. we actually need to also make sure that uh the molecules are synthesizable. And so the way we do that is that you know we have a generative model that um learns to use like appropriate building blocks such that you know it can design within a space that we know is like synthesizable. And so there&#x27;s like you know this whole pipeline really of different models involved you know in being able to um to design a molecule. And so that&#x27;s been sort of like the first thing we call</p>
<p>them agents. We have a protein agent and we have a small molecule design agents. And that&#x27;s really like at the core of like what powers, you know, the post platform. &gt;&gt; So these agents are are they like a language model wrapper or they&#x27;re just like your models and you&#x27;re just calling them agents because they they they sort of perform a function on behalf of &gt;&gt; they&#x27;re more of like a you know a recipe if you wish and I think uh we use that term sort of because of you know sort of the complex pipelining and automation you know that goes into like all this plumbing. Um so so that&#x27;s the first part of the product. Um the second part is</p>
<p>the infrastructure. You know we need to be able to do this at very large scale for any one you know group that&#x27;s doing a design campaign. Um you know let&#x27;s say you&#x27;re designing you know let&#x27;s say a 100,000 possible candidates right to find the good one. Um that is you know a very large amount of compute. Uh you know for small molecules it&#x27;s on the order of like a few seconds per uh per design. for proteins can be a bit longer and so you know ideally you want to do that in parallel otherwise it&#x27;s going to take you weeks um and so you know we&#x27;ve put a lot of effort into like you know</p>
<p>our ability to have a GPU fleet that allows any one user you know to be able to do this kind of like large parallel search &gt;&gt; so you&#x27;re amvertising the cost over your your users basically &gt;&gt; exactly and you know to some degree like it&#x27;s whether you do uh you use 10,000 GPUs for like you know uh a minute is the same cost as using you know uh one GPUs for god knows how long, right? So, you might as well try to paralyze if you can. So, you know, a lot of work has gone has gone into that making it very robust, you know, so that we can have like a lot of people on the platform doing that at the same time. Um, and and</p>
<p>the third one is is the interface and the interface comes in in two shapes. one is um in form of an API and that&#x27;s you know um really suited for companies that want to integrate you know these pipelines these agents directly in existing you know workflows that they have or like existing user interfaces that they have and we&#x27;re already like partnering with you know a few distributors you know that are going to integrate our API and then the second part is the the act the user interface and you know we we&#x27;ve put a lot of thoughts also into that and this is when I I mentioned earlier you know this idea</p>
<p>of like broadening the audience that&#x27;s kind of what the the user interface is about and we&#x27;ve built a lot of interesting features in it. You know, for example, for collaboration, um you know, when you have like potentially multiple medicine chemists are going through the results and trying to pick out, okay, like what are the molecules that we&#x27;re going to go and test in the lab, it&#x27;s powerful for them to be able to, you know, for example, each provide their own ranking and then do consensus building and um so there&#x27;s a lot of features around, you know, launching these large job, but also around like collaborating on analyzing the results um that we try to solve, you know, with with that part of the platform. So,</p>
<p>Boltz Lab is sort of combination of these three objectives into like one, you know, sort of cohesive platform. &gt;&gt; Who is this accessible to? &gt;&gt; Everyone. Uh, you do need to request access today. We&#x27;re still like, you know, sort of ramping up the usage. Um, but anyone can request access. Um, if you are an academic in particular, uh, we uh, you know, we provide um, you know, a fair amount of free credit. So, you can like play with the platform. If you are a startup uh or a biotech, you may also, you know, reach out and we&#x27;ll typically like actually hop on a call just to like understand what you&#x27;re</p>
<p>trying to do and um also provide a lot of free credit to to get started. Um and uh of course also with larger companies uh you know we uh we can deploy this this platform in a more like secure environment and so that&#x27;s like more like custom you know uh deals that we make you know with with the partners. Um, so you know that and that&#x27;s sort of that the ethos of Bolt. I think this idea of like uh servicing everyone and not necessarily like going after just you know the um the really large enterprises. Um and that starts from the open source but it&#x27;s also you know main</p>
<p>a key key design principle of of the product itself. &gt;&gt; Yeah. &gt;&gt; One thing I was thinking about with regards to infrastructure like in the LLM space you know the cost of a token has gone down by I think a factor of a thousand or so over the last three years right. Yeah. &gt;&gt; And is it possible that like essentially you can exploit economies of scale and infrastructure that you can make it cheaper to run these things yourself than for any person to roll their own &gt;&gt; 100%. Yeah. I mean we&#x27;re already there you know like running bolts on our platform especially on in a large screen is like considerably cheaper um than it would probably take anyone to put the</p>
<p>open source model out there and run it. And you know on top of the infrastructure like one of the thing that we&#x27;ve been working on is is accelerating the models. So you know our our small molecule screening pipeline is 10x faster on bolts lab than it is in the open source. Um you know and that&#x27;s that&#x27;s also part of like you know building building a a product you know of something that that scales really well. Um and yeah uh we really wanted to get to a point where like you know we could keep prices uh very low um you know in in a way that it would be a no</p>
<p>no-brainer you know to to use bolts through through our platform. How do you think about validation of your like agentic systems? Because you know as you saying earlier like we&#x27;re alphafold style models are really good at let&#x27;s say monomeic you know proteins where you have you know co-evolution data but now suddenly the whole point of this is to design something which doesn&#x27;t have &gt;&gt; you know co-evolution data something which is really novel. So now you&#x27;re basically leaving the the domain that you thought was you know that you you know you were good at. So like how do</p>
<p>you validate that? &gt;&gt; Yeah. Um I mean I I like Gabri complete but there&#x27;s um there&#x27;s obviously you know a ton of computational metrics that we rely on but those are only take you so far. Um you really got to go to the lab you know and and test you know okay with this method A and this method B uh how much better are we you know how much better is my uh my hit rate? How stronger are my binders? Also it&#x27;s not just about hit rate it&#x27;s also about how how good the binders are. And there&#x27;s really like no way no way around that. And I think, you know, we&#x27;ve really ramped up the amount of experimental</p>
<p>validation um that we do so that we like really track progress, you know, as scientifically sound, you know, as as possible. um out of this I think. &gt;&gt; Yeah. Know I think you know one thing that is unique about us and maybe companies like us is that because we&#x27;re not working on like maybe a couple of therapeutic uh pipelines where you know our validation would be focused on those. We when we do an experimental validation, we try to test it across tens of targets. And so that on the one end we can get a much more statistically</p>
<p>significant um results and and really allows us to make progress from the methodological side without being you know steered by you know overfitting on any one particular system. And of course we choose you know we always try to choose uh targets and problems are sort of like at the frontier of what&#x27;s possible today. So you know you don&#x27;t want something too easy you don&#x27;t want something too hard otherwise you&#x27;re not going to see progress. And so you know this is a somewhat evolving set of targets. We talked earlier about the</p>
<p>targets that we looked at with with bolt and now we are even trying kind of you know even harder targets both for molecule and proteins. And so we try to keep oursel on the on the boundary uh of what&#x27;s possible. &gt;&gt; So do you have like infrastructure or this is like you just have a lot of different partnerships with academic labs and you&#x27;re just going to keep pushing on these and driving these? We do partially this through academic labs but more and more we do this through uh CRO just because of you know to some extent is also we need kind of replicability often kind of you know going after the same targets you know</p>
<p>multiple times and you know to see the the progress from you know one month to the next &gt;&gt; and speed of execution. Yeah. &gt;&gt; And so what happens if you start getting a bunch of like really strong biters against therapeutic targets? What do you do? &gt;&gt; Um I miss them. Yeah. &gt;&gt; In open sort like &gt;&gt; Yeah. I mean, you know, I mean, when we say we have no interest in making dress, we&#x27;re serious like you know, uh I mean when it when it was with the academic labs basically, you know, it was they keep it, they do whatever they want with it. And with the with the CRO so far,</p>
<p>yeah, we&#x27;ve been we&#x27;ve been very Yeah. releasing releasing them. You know, I I will also say and and I think this is a bit been a bit of the issue that I I have with with some of kind of the things I&#x27;ve been said in the field is like when we say that we design new proteins or we say that we design new molecules, you know, uh that you know go and bind these particular targets, &gt;&gt; we should be very clear, you know, these are not drugs, you know, these are not things are ready to be put into into a human And there is still a lot of</p>
<p>development that that goes with it. And so this is this is kind of to to us you know we see oursel as you know building tools for scientists. You know at the end of the day you know it really relies on the scientist having a great therapeutic appease and then pushing through kind of all the stages of development and you know we try to build tools that can accompany them uh in that journey. We It&#x27;s not like a a magic box where, you know, uh you can just turn it and get &gt;&gt; get FDA approved drugs, &gt;&gt; FDA approved drugs, FDA approved drugs.</p>
<p>Um, yeah. But but actually that brings up an interesting question that I have I&#x27;ve been wondering about is do you guys see yourself like staying in this like this for lack of a better way of saying it layer or do you think that you&#x27;ll start to like either on the physical sense looking at different layers of the virtual cell so to speak or um also you know so there&#x27;s the like the development process that goes you know sort of like design preclinical clinical approval and thinking about</p>
<p>like improving the performance throughout that process based on the designs. Is that a direction that you guys are pushing? &gt;&gt; Yeah. So one of the things as Jeremy said you know we are not a therapeutic company and we want to kind of stay not to be a therapeutic company always be at the service of you know all the different you know companies including therapeutic companies that we serve and you know that to some extent does mean you know that we need to try to you know go deeper and deeper in getting these models better and better. One of the</p>
<p>things that we are doing across you know uh many other uh in the field is you know now that we already they&#x27;re start to be good both for small molecule and for proteins to design kind of binders designed relatively tight binders is starting to look at all these other properties you know called developabilities or atme that you know we care about when developing a drug and trying can we uh design them from uh from get and the thing about those properties in some of them, you know, um you need to, you know, start having an</p>
<p>understanding of of the cell and and so that&#x27;s on the one hand kind of why we need that understanding, but also, you know, the way that we also think about kind of, you know, um all different and complex diseases is that these models and these tools that we&#x27;re building have a good understanding of kind of, you know, biomolelecular interactions and kind of their interactions. Now at the same time every disease is often kind of unique and every therapeutic hypothesis is unique and so you maybe want to have something that um needs to uh hit the particular you know um let&#x27;s say target</p>
<p>uh in in a virus in a particular way but you don&#x27;t maybe know exactly what uh way you want to do. And so maybe in the first set of designs, you&#x27;re going to try to target different epitopes in different ways and then you&#x27;re going to test them in the lab, maybe directly in vivo, and you&#x27;re going to see which ones work and which one don&#x27;t. And so then you need to bring those results back into the models. And then the models can start to have a more uh wider understanding you know not just of the biohysical of the uh antibodies interacting with that target but also</p>
<p>how that is shaped within the entire uh the entire cell. And so first of all you know that means on the one end that we need you know kind of these loops and this is also partially how we we design the platform to be but that also means that we also need to start understanding more and more kind of higher level things and you know I wouldn&#x27;t say that we&#x27;re working in any way on like a virtual cell like others are but we&#x27;re definitely thinking kind of very deeply about kind of you know how does you know kind of the way that we target um certain proteins interfere here interact</p>
<p>with you know maybe pathways that are existing in the cell. &gt;&gt; One question that has come up is you talk a lot about user interface and so on and I think this is really important but like my experience with dealing with medicinal chemists when you give them machine learning models is they are the most superstitious skeptical like pseudo religious people I&#x27;ve ever talked to when it comes to doing science. So sorry for the medicinal chemist. Yeah, they&#x27;re they&#x27;re amazing. Like they&#x27;re absolutely I&#x27;ve worked with some spectacular medicinal chemists who just pull magic</p>
<p>out of their hat again and again and I have no idea how they do it. But when you bring them a machine learning model, it is sometimes quite tricky to get them to deal with it. How how has your interaction been with this and how have you thought about like building Boltz Lab to work with the skeptics? One of the great value unlocks for us and for our product has been when we brought to the team um m chemist his name is Jeffrey. So I think kind of like on the one end you know day one you know he obviously had a lot of opinions on kind of a lot of the ways that we should uh</p>
<p>change you know both kind of the way that the agents worked the way that the platform worked. Uh but it&#x27;s been really amazing kind of you know once also we started kind of shaping kind of the platform uh in a better way with with this feedback how we went from you know some extent you know fair skepticism to him you know actually using a lot more compute than any of our computational uh folks in the team you know um at times that you know he&#x27;s you know running you know he has all these sort of tur uh hyp</p>
<p>hypothesis. Okay, maybe I can hit this protein this particular way. I can hit in that way. Actually, let me look at for this particular molecular space. Let me try to optimize for this particular interactions. So, he ends up, you know, running several screens in parallel, you know, using hundreds of GPUs, you know, on his own. And you know, so this has been, you know, pretty incredible to see kind of how, you know, maybe the way that I was more thinking about a problem, which is okay, you just trying to design a binder, a small molecule to a particular protein. The way that he thinks about it is, you know, much more</p>
<p>deeply and, you know, trying all these different things, these different hypothesis. And then you know once he gets the results from the um from the model he doesn&#x27;t just you know take the top 15 uh but he it really kind of looks over and you know kind of tries to understand you know the different things and then when we uh select you know maybe some designs to uh to bring forth you know he has you know something where you know both the models understand that something is good but all himself as well and that&#x27;s why we also built kind of the platform to be uh an interface for you know this kind uh this kind of</p>
<p>chemist and you know also like collaborative experience. I &gt;&gt; I think at the end of the day like you know for people to be convinced you have to show them something that they didn&#x27;t think was possible and until you have that aha moment you know I think the skepticism will remain but then when you know every once in a while I think there&#x27;s like a result that like really surprises people and then it&#x27;s like oh wow okay this actually I can do something with this. &gt;&gt; So you just get in their hands have them try it out and they&#x27;ll be convinced. &gt;&gt; Yeah. or like at maybe once the lab results come back</p>
<p>&gt;&gt; or their their friend Yeah. or maybe one of their colleagues is convinced and &gt;&gt; I think it it it takes going to the lab I think at some point there&#x27;s no avoiding that you know as beautiful as the platform can be as nice as the molecules might look you know that the model predicted I think what really convinces people is like you know hits &gt;&gt; you see the results &gt;&gt; exactly yeah &gt;&gt; cool thank you for you know taking the time to chat with us &gt;&gt; yeah you know is there anything that you would like your audience to know &gt;&gt; I mean first of all you know uh we&#x27;re just getting started, you know, uh</p>
<p>continuing to to build a team. And so, uh definitely always looking for, uh great folks both on, you know, kind of, you know, software side, you know, machine learning side, but also scientists, uh to join the team and help us, you know, uh shape &gt;&gt; on the infrastructure side too. &gt;&gt; Indeed. &gt;&gt; If you if you think that if you want a new challenge because this is not just next token prediction, this is really a new engineering challenge. &gt;&gt; Exactly. If you if no matter you know how much experience you have with you know biologist and chemistry if you want</p>
<p>to come you know help us you know shape what you know biology and chemistry hopefully will look like in 5 10 years um we&#x27;d love to hear from you and so um go to bold bio and you know come join the team. &gt;&gt; Cool. Thank you. &gt;&gt; Awesome. Thank you so much. Thank you.</p>]]></content:encoded>
      <guid isPermaLink="false">https://www.youtube.com/watch?v=nP0N1kYLegc</guid>
      <pubDate>Thu, 12 Feb 2026 02:05:23 +0000</pubDate>
    </item>
    <item>
      <title>The AI Frontier: from Gemini 3 Deep Think distilling to Flash — Jeff Dean</title>
      <link>https://www.youtube.com/watch?v=F_1oDPWxpFQ</link>
      <description>From rewriting Google’s search stack in the early 2000s to reviving sparse trillion-parameter models and co-designing TPUs with frontier ML research, Jeff Dean has quietly shaped nearly every layer of the modern AI stack. As Chief AI Scientist at Google and a driving force behind Gemini, Jeff has lived through multiple scaling revolutions from CPUs and sharded indices to multimodal models that reason across text, video, and code.

Jeff joins us to unpack what it really means to “own the Pareto frontier,” why distillation is the engine behind every Flash model breakthrough, how energy (in picojoules) not FLOPs is becoming the true bottleneck, what it was like leading the charge to unify all of Google’s AI teams, and why the next leap won’t come from bigger context windows alone, but from systems that give the illusion of attending to trillions of tokens.

We discuss:
• Jeff’s early neural net thesis in 1990: parallel training before it was cool, why he believed scaling would win decades early, and the “bigger model, more data, better results” mantra that held for 15 years
• The evolution of Google Search: sharding, moving the entire index into memory in 2001, softening query semantics pre-LLMs, and why retrieval pipelines already resemble modern LLM systems
• Pareto frontier strategy: why you need both frontier “Pro” models and low-latency “Flash” models, and how distillation lets smaller models surpass prior generations
• Distillation deep dive: ensembles → compression → logits as soft supervision, and why you need the biggest model to make the smallest one good
• Latency as a first-class objective: why 10–50x lower latency changes UX entirely, and how future reasoning workloads will demand 10,000 tokens/sec
• Energy-based thinking: picojoules per bit, why moving data costs 1000x more than a multiply, batching through the lens of energy, and speculative decoding as amortization
• TPU co-design: predicting ML workloads 2–6 years out, speculative hardware features, precision reduction, sparsity, and the constant feedback loop between model architecture and silicon
• Sparse models and “outrageously large” networks: trillions of parameters with 1–5% activation, and why sparsity was always the right abstraction
• Unified vs. specialized models: abandoning symbolic systems, why general multimodal models tend to dominate vertical silos, and when vertical fine-tuning still makes sense
• Long context and the illusion of scale: beyond needle-in-a-haystack benchmarks toward systems that narrow trillions of tokens to 117 relevant documents
• Personalized AI: attending to your emails, photos, and documents (with permission), and why retrieval + reasoning will unlock deeply personal assistants
• Coding agents: 50 AI interns, crisp specifications as a new core skill, and how ultra-low latency will reshape human–agent collaboration
• Why ideas still matter: transformers, sparsity, RL, hardware, systems — scaling wasn’t blind; the pieces had to multiply together

Substack Article w/Show Notes: https://www.latent.space/p/jeffdean

—

Jeff Dean
• LinkedIn: https://www.linkedin.com/in/jeff-dean-8b212555
• X: https://x.com/jeffdean

Google
• https://google.com
• https://deepmind.google

 Intro
 Frontier vs Flash &amp; Distillation Strategy 
 Distillation, RL &amp; Flash Economic Advantage 
 Flash in Products + Importance of Latency 
 Benchmarks, Long Context &amp; Real Use Cases 
 Attending to Trillions of Tokens &amp; Multimodality 
 LLM Search &amp; Google Search Evolution 
 Systems Design Principles + Latency Numbers 
 Energy, Batching &amp; TPU Co-Design 
 Research Frontiers: Reliability &amp; RL Challenges 
 Unified Models vs Symbolic Systems (IMO) 
 Knowledge vs Reasoning + Vertical/Modular Models 
 Multilingual + Low-Resource Language Insights 
 Vision-Language Representations Example 
 Gemini Origin Story + Organizational Memo 
 Coding with AI &amp; Agent Interaction Style 
 Prompting Skills &amp; Spec Design 
 Latency Predictions &amp; Tokens/sec Vision 
 Future Predictions: Personal Models &amp; Hardware 
 Closing</description>
      <content:encoded><![CDATA[<p><strong>YouTube:</strong> <a href="https://www.youtube.com/watch?v=F_1oDPWxpFQ">https://www.youtube.com/watch?v=F_1oDPWxpFQ</a></p>
<h2>Intro</h2>
<p>[music] Hey everyone, welcome to the L in space podcast. This is Allesio, founder of Colonel Labs, and I&#x27;m joined by Swix, editor of L in Space. &gt;&gt; Hello. Hello. We&#x27;re here in the studio with Jeff Dean, chief AI scientist at Google. Welcome. &gt;&gt; Thanks for having me. [laughter] &gt;&gt; It&#x27;s a bit surreal to have you in the studio. I&#x27;ve I&#x27;ve watched so many of your talks uh and obviously uh you your career has been super legendary. So, uh I mean, congrats. I I think the the first thing must be said congrats on owning the Purto Frontier. [laughter] &gt;&gt; Thank you. Thank you. Parto Frontiers are good and it&#x27;s good to be out there.</p>
<p>&gt;&gt; Yeah. I mean I I think it&#x27;s a combination of both uh your you have to own the Parto Frontier you have to have like frontier capability but also efficiency and then offer that range of models [snorts] that people like to use. uh and you know some part of this was started because of your hardware work some part of that is your model work and uh you know I&#x27;m sure there&#x27;s lots of secret sauce that you guys uh have worked on uh accumulatively but like it&#x27;s it&#x27;s really impressive to see it all come together in like this steadily advancing frontier. &gt;&gt; Yeah. Yeah. I mean I think as you say</p>
<p>it&#x27;s not just one thing it&#x27;s like a whole bunch of things up and down the stack &gt;&gt; and uh you know all of those really combined to help make you an OS able to make highly capable large models as well as you know software techniques to get those large model capabilities into much smaller lighter weight models that are you know much more cost-effective and lower latency but still you know quite capable for their size. So</p>
<h2>Frontier vs Flash &amp; Distillation Strategy</h2>
<p>&gt;&gt; yeah, &gt;&gt; how how much pressure do you have on like having the lower bound of the prior frontier too? I think like the new labs are always trying to push the top performance frontier because they need to raise more money and all of that. And you guys have billions of users and I think initially when you work on the CPU you were thinking about you know if everybody that used Google we used the voice model for like 3 minutes a day they were like you need to double your CPU number like what&#x27;s that discussion today at Google like how do you prioritize frontier versus like we actually need to deploy it if we build</p>
<p>it. Yeah, I mean I think we always want to have models that are at the frontier or pushing the frontier because I think that&#x27;s where you see what capabilities now exist that didn&#x27;t exist at the sort of slightly less capable last year&#x27;s version or last [clears throat] six months ago version. &gt;&gt; Um at the same time, you know, we know there those are going to be really useful for a bunch of use cases, but they&#x27;re going to be uh a bit slower and a bit more expensive than people might like for a bunch of other broader use cases. So I think what we want to do is always have um kind of a highly capable</p>
<p>uh sort of uh affordable model that enables a whole bunch of you know lower latency use cases. People can use them for agentic coding much more readily. Um and then have the the high-end you know frontier model that is really useful for um you know deep reasoning you know solving really complicated math problems those kinds of things. And and it&#x27;s not that one or the other is useful. They&#x27;re both useful. So I think we like to do both. And also, you know, through distillation, which is a key technique for making the smaller models more</p>
<p>capable, you know, you have to have the frontier model in order to then distill it into your your smaller model. So it&#x27;s not like an either or choice. You sort of need that in order to actually get a highly capable more modest size model. &gt;&gt; Yeah. And I mean you and Jeffrey In came out with this solution in 2014. &gt;&gt; Don&#x27;t forget L&#x27;Oreal Vine as well. a long time ago. Like &gt;&gt; I&#x27;m curious how you [snorts] think about the cycle of these ideas even like you know sparse models and uh you know how do you re-evaluate them? How do you think about in the next generational model what is worth revisiting like a yeah they&#x27;re just kind of like a you</p>
<p>know you worked on so many ideas that end up being influential but like in the moment they might not feel that way necessarily. Yeah, I mean I I think distillation was originally motivated because we were seeing that we had a very large image data set at the time, you know, 300 million images that we could train on with, you know, I forget like 20,000 categories or something, so much bigger than ImageNet. And we were seeing that if you create specialists for different subsets of those image categories, you know, this one&#x27;s going to be really good at sort of mammals and this one&#x27;s going to be really good at sort of indoor room scenes or whatever.</p>
<p>and you can cluster those categories and train on an enriched stream of data after you do pre-training on on a much broader set of images. You get much better performance if you then treat that whole set of maybe 50 models you&#x27;ve trained as a large ensemble. Um but that&#x27;s not a very practical thing to serve, &gt;&gt; right? So distillation really came about from the idea of okay what if we want to actually serve that and train all these independent sort of expert models um and then squish it into something that</p>
<p>actually fits in a form factor that you can actually serve. And that&#x27;s you know not that different from what we&#x27;re doing today. You know often today we&#x27;re instead of having an ensemble of 50 models we&#x27;re having a much larger scale model that we then distill into a much smaller scale model.</p>
<h2>Distillation, RL &amp; Flash Economic Advantage</h2>
<p>Yeah, a part of me also wonders if distillation also has a story with the RL um revolution. So what let me let me maybe try to articulate what I mean by that. uh which is you can uh RL basically spikes models in a certain uh part of the distribution and then you have to sort of well you can spike models but usually sometimes it might be lossy in other areas and it&#x27;s kind of like an uneven technique but you can probably distill it back uh and you can uh I think that the sort of general um</p>
<p>dream is to be able to advance capabilities without regressing on anything else &gt;&gt; and I think like that that whole capability merging without loss. Uh uh I feel like it&#x27;s like you know some part of that should be a distillation process but I can&#x27;t quite articulate it. I haven&#x27;t seen much papers about it. &gt;&gt; Yeah. I mean I I tend to think of one of the key advantages of distillation is that you can have a much smaller model and you can have a very large uh you know training data set and you can get utility out of making many passes over that data set because you&#x27;re now getting</p>
<p>the logits from the much larger model in order to sort of &gt;&gt; sort of coax the right behavior out of the smaller model uh that you don&#x27;t wouldn&#x27;t otherwise get with just the hard labels and and so um you know I think that&#x27;s what we&#x27;ve observed is you can get, you know, clo very close to your largest model performance with distillation approaches. And that that seems to be, you know, a nice sweet spot for a lot of people because it enables us to kind of for multiple Gemini generations now, we&#x27;ve been able to make &gt;&gt; the sort of flash version of the next</p>
<p>generation &gt;&gt; as good or even substantially better than the previous generations pro. And I think we&#x27;re going to keep trying to do that because that seems like a good uh trend to follow. &gt;&gt; Um dare I ask uh so it was it was the original map was Flash Pro and Ultra. &gt;&gt; Uh is ultra are you just sitting on ultra and distilling from that? Is that like the mother load? [laughter] &gt;&gt; Uh I mean we have a lot of different kinds of models. Some are internal ones that are not necessarily meant to be released or served. Some are you know our pros scale model and we can distill from that as well into our flash scale</p>
<p>model. So I think you know uh it&#x27;s u it&#x27;s an important set of capabilities to have and also inference time scaling can also be a useful thing to improve the capabilities of a model and</p>
<h2>Flash in Products + Importance of Latency</h2>
<p>&gt;&gt; yeah cool yeah and obviously I think the economy of flash is what led to the total dominance I think the the latest number is like 50 trillion uh tokens I I don&#x27;t know I mean obviously it&#x27;s changing every day &gt;&gt; but uh you know by market share &gt;&gt; hopefully hopefully up [laughter] &gt;&gt; no I mean there&#x27;s no I mean Just the economics wise like uh because flash is so economical like you can use it for everything like it&#x27;s in Gmail now it&#x27;s in YouTube like it&#x27;s it&#x27;s in everything &gt;&gt; we&#x27;re using it more in our search products of various AI mode overviews. &gt;&gt; Oh my god flash parts AI mode. Oh my god. Yeah that&#x27;s yeah I didn&#x27;t even</p>
<p>think about that. &gt;&gt; Um [laughter] I mean I think one of the things that is uh quite nice about the flash model is not only is it more affordable it&#x27;s also a lower latency. And I think latency is actually a pretty important characteristic for these models because we&#x27;re going to want models to do much more complicated things that are going to involve, you know, generating many more tokens from when you ask the model to do something until it actually finishes what you ask it to do because you&#x27;re going to ask now not just write me a for loop, but like write me a a whole software package to do X or Y or Z. And so having low</p>
<p>latency systems that can do that uh seems really important. and flash is one direction, one one way of doing that. &gt;&gt; Yeah. &gt;&gt; You know, obviously our hardware platforms enable a bunch of interesting aspects of our, you know, serving stack as well like TPUs. Uh the interconnect between chips on the TPUs, uh is actually quite quite high performance and quite amendable to for example long context kind of attention operations. You know, having sparse models with lots of experts. These kinds of things really really matter a lot in terms of how do</p>
<p>you make them servable at scale. &gt;&gt; Yeah. Does it feel like there&#x27;s some breaking point for like the protoflash distillation kind of like one generation delayed? I I almost think about almost like the capability asmtote in certain tasks like the pro model today is as saturated some sort of task. Mhm. &gt;&gt; So next generation that same task will be saturated at the flash price point and I think for most of the things that people use models for at some point the flash model in two generation will be</p>
<p>able to do basically everything and how do you make it economical to like keep pushing the pro frontier when a lot of the population will be okay with the flash model? I&#x27;m curious how you think about that. &gt;&gt; I mean I think that&#x27;s true if your distribution of what people are asking people the models to do is stationary, right? But I think what often happens is as the models become more capable, people ask them to do more, right? So I mean I think this happens in my own usage like I used to try our models a year ago for some sort of coding task and it was okay at some simpler things</p>
<p>but wouldn&#x27;t do work very well for more complicated things. And since then we&#x27;ve improved dramatically on the more on the more complicated coding tasks and now I&#x27;ll ask it to do much more complicated things. And I think that&#x27;s true not just of coding but of you know now you know can you analyze all the you know renewable energy uh deployments in the world and give me a report on solar panel deployment or whatever. That&#x27;s a very complicated you know more complicated task than people would have asked a year ago. &gt;&gt; And so you are going to want more capable models to push the frontier in</p>
<p>some sense of what people ask the models to do. And that also then gives us insight into okay where does the where do things break down? How can we improve the model in these these particular areas uh in order to sort of um make the next generation even better?</p>
<h2>Benchmarks, Long Context &amp; Real Use Cases</h2>
<p>&gt;&gt; Yeah. Are there any benchmarks or like test sets that you use internally? Because it&#x27;s almost like the same benchmarks get reported every time and it&#x27;s like all right it&#x27;s like 99 instead of 97. Like how do you have to keep pushing the team internally too to like this is what we&#x27;re building towards? &gt;&gt; Yeah. I mean, I think benchmarks, particularly external ones that are publicly available, have their utility, but they often kind of have a lifespan of utility where they&#x27;re introduced and maybe they&#x27;re quite hard for current models. You know, I I like to think of the best kinds of benchmarks are ones</p>
<p>where the initial scores are like 10 to 20 or 30% maybe, but not higher. And then you can sort of work on improving that capability for uh whatever it is the benchmark is trying to assess and get it up to like 80 90% whatever. I I think once it hits kind of 95% or something you get very diminishing returns from really focusing on that benchmark because it&#x27;s sort of it&#x27;s either the case that you&#x27;ve now achieved that capability [snorts] or there&#x27;s also the issue of leakage in public data or very related kind of data being being in</p>
<p>your training data. Um, so we have a bunch of held out internal benchmarks that we really look at where we know that wasn&#x27;t represented in the training data at all. There are capabilities that we want the model to have um that it doesn&#x27;t have now and then we can work on, you know, assessing, you know, how do we make the model better at these kinds of things? Is it we need different kind of data to train on that&#x27;s more specialized for this particular kind of task? Do we need um you know a bunch of uh you know architectural improvements or some sort of uh model capability improvements? You know what would help</p>
<p>make that better? &gt;&gt; Is there is there such an example that you uh a benchmark inspired an architectural improvement? like uh I&#x27;m just kind of jumping on that because you just &gt;&gt; uh I mean I think some of the long context capabilities of the of the Gemini models that came I guess first in 1.5 &gt;&gt; really were about looking at okay we want to have um &gt;&gt; you know [clears throat] &gt;&gt; immediately everyone jumped to like completely green charts of like everyone had I was like how did everyone crack this at the same time like [laughter] &gt;&gt; right yeah I mean I think um and once</p>
<p>you&#x27;re set I mean as you say that needle single needle in a haststack benchmark is really saturated for at least context lengths up to 128k or something. I think most people &gt;&gt; don&#x27;t actually have you know much larger than 128k these days or 256 or something. Um you know we&#x27;re trying to push the frontier of 1 million or 2 million context language. &gt;&gt; I think Google&#x27;s still the leader 2 million. &gt;&gt; Yep. which is good because I think there are a lot of use cases where you know putting a thousand pages of text or putting you know multiple you know hourlong videos in the context and then actually being able to make use of that</p>
<p>is useful but the the single needle in a haststack benchmark is sort of saturated. Um so you really want more complicated uh sort of multi- needle or you know more realistic take all this content and produce this kind of answer from uh uh a long context that sort of better assesses what it is people really want to do with long context which is not just you know can you tell me the product number for this particular thing.</p>
<p>&gt;&gt; Yeah it&#x27;s retrieval it&#x27;s it&#x27;s retrieval within machine learning. Uh yeah, it&#x27;s it&#x27;s interesting because like I think that the more meta lesson level I&#x27;m trying to operate at here is uh you have a benchmark you&#x27;re like okay I see the architectural thing I need to do in order to go fix that but like should you do it because sometimes you know that&#x27;s an inductive bias basically that you&#x27;re Jason we used to work at Google would say like exactly the kind of thing like yeah you&#x27;re going to win short term longer term I don&#x27;t know if that&#x27;s going to scale you might have to undo that</p>
<h2>Attending to Trillions of Tokens &amp; Multimodality</h2>
<p>[laughter] &gt;&gt; I mean I I I like to sort of not focus on exactly what solution one should drive but what capability would you want and I think we&#x27;re very convinced that you know long context is useful but it&#x27;s way too short today &gt;&gt; right like I think what you would really want is can I attend to the internet while I answer my question right [laughter] &gt;&gt; but that&#x27;s not going to be solved by purely scaling the existing solutions which are quadratic so a million tokens kind of pushes &gt;&gt; uh what you can do you&#x27;re not going to</p>
<p>do that to a trillion tokens, let alone, you know, a billion tokens, let alone a trillion. Um, but I think if you could give the illusion that you can attend to trillions of tokens, that would be amazing. You&#x27;d be find all kinds of uses for that. You would have um attend to the internet. you could attend to the pixels of YouTube and the sort of deeper representations that we can form for a single video, but across many videos, you know, uh on a personal Gemini level, you could attend to all of your personal state with your permission. So like your</p>
<p>emails, your photos, your &gt;&gt; yeah, &gt;&gt; your docs, your plane tickets you have. Um I I think that would be really really useful. And the question is, how do you get algorithmic improvements and system level improvements that get you to something where you actually can attend to trillions of tokens in some meaningful way? &gt;&gt; Yeah. But by the way, I think I I did some math and if like if you spoke all day every day for eight hours a day, um you only generate a maximum of like 100k tokens, which like very comfortably fits, [laughter]</p>
<p>&gt;&gt; right? But if you then say okay I want to be able to um understand everything people are putting on video. &gt;&gt; Exactly. Exactly. Well also I think that the classic example is um you start going beyond language into like proteins and whatever else is extremely information dense. &gt;&gt; Yeah. &gt;&gt; Yeah. I mean, I think one of the things about Gemini&#x27;s multimodal aspects is we&#x27;ve always wanted it to be multimodal from the start. And so, you know, that sometimes to people means text and images and video sort of</p>
<p>humanlike and audio audio humanike modalities. But I think it&#x27;s also really useful to have Gemini know about nonhuman modalities. like LAR sensor data from say Whimo vehicles or like robots or you know various kinds of health modalities, X-rays and MRIs and imaging and genomics information. Um and I think there&#x27;s probably hundreds of modalities of data where you&#x27;d like the model to be able to at least be exposed to the fact that this is an interesting modality and has certain meaning in the</p>
<p>world. uh where even if you haven&#x27;t trained on all the LAR data or MRI data you could have because maybe that&#x27;s not you know doesn&#x27;t make sense in terms of trade-offs of you know what you include in your main pre-training data mix at least including a little bit of it is actually quite useful because it sort of &gt;&gt; uh tempts the model that this is a thing. &gt;&gt; Yeah. Yeah. Do do you believe I mean since we&#x27;re on this topic and something I just get to ask you all the questions I always wanted to ask which is fantastic. uh like there are there some king modalities like modalities that supersede all the other modalities. So</p>
<p>the a simple example was vision um can on a pixel level encode text and deepc had this deepr paper that did that. Uh vision has also been shown to maybe incorporate audio because you can do audio spectrograms and that&#x27;s that&#x27;s also like a vision uh capable thing like so so maybe vision is just the king modality and like &gt;&gt; yeah I mean [laughter] vision and motion are quite important things right &gt;&gt; motion uh &gt;&gt; video as opposed to static images &gt;&gt; because I mean there&#x27;s a reason evolution has evolved eyes like 23 independent ways because it&#x27;s such a</p>
<p>useful capability for sensing the world around you which is really what we want these models to be able to do is interpret the things we&#x27;re seeing or the things we&#x27;re we&#x27;re paying attention to and then help us in uh using that information to to do things. &gt;&gt; Yeah, I I think motion uh you know I still want to shout out I think Gemini uh still the only native video understanding model that is out there. Uh so I use it for YouTube all the time. &gt;&gt; Yeah. Yeah. I mean, it&#x27;s actually I think people kind of are not necessarily aware of what the Gemini models can</p>
<p>actually do with video. Like, uh, I have an example I&#x27;ve used in one of my talks. &gt;&gt; It had like, uh, it was like a YouTube highlight video of 18 memorable sports moments across the last 20 years or something. So, it has like Michael Jordan hitting some jump shot at the end of the finals and, you know, some soccer uh, goals and things like that. And you can literally just give it the video and say, &quot;Can you please make me a table of what all these different events are, what when the date is, when they happened, and a short description of the event.&quot; And so you get like now an 18</p>
<p>row table of that information extracted from the video, which is, you know, not something most people think of as like a turn video into SQL like table. &gt;&gt; Yeah. Has there been any discussion</p>
<h2>LLM Search &amp; Google Search Evolution</h2>
<p>inside of Google of like you mentioned tending to the whole internet? Right. Google it&#x27;s almost built because the a human cannot tend to the whole internet and you need some sort of ranking to find what you need. &gt;&gt; Yep. &gt;&gt; That ranking is like much different for an LLM because you you can expect a person to look at maybe the first five six links in a Google search &gt;&gt; versus for an LLM should you expect to have 20 links that are highly relevant? like how do you internally figure out you know how do we build the AI mode that is like maybe like much broader &gt;&gt; search [clears throat] and span versus</p>
<p>like the more human one. &gt;&gt; Yeah. I mean I think even pre- language model based work you know our ranking systems would be built to start with a giant number of web pages in our index. Many of them are not relevant. So you identify a subset of them that are relevant with very lightweight kinds of methods. Now you&#x27;re down to like 30,000 documents or something. And then you have gradually refine that to apply more and more sophisticated algorithms and more and more sophisticated sort of signals of various kinds in order to get</p>
<p>down to ultimately what you show which is you know the final 10 results or you know 10 results plus other kinds of information. And I think an LLM based system is not going to be that dissimilar, right? you&#x27;re going to tend to trillions of tokens, but you&#x27;re going to want to identify, you know, what are the 30,000ish documents that with the, you know, uh, maybe 30 million interesting tokens and then how do you go from that into what are the 117 documents I really should be paying attention to in order to carry</p>
<p>out the task that the user has asked me to do. Um and I think you know you can imag you can imagine systems where you have you know a lot of uh highly parallel processing to identify those initial 30,000 candidates maybe with very lightweight kinds of models. Um then you have some system that sort of helps you narrow down from 30,000 to the 117 uh with maybe a little bit more sophisticated um model uh or set of models. And then maybe the final model is the thing that looks at 117 things.</p>
<p>That might be your most capable model. So I think it has to it&#x27;s going to be some system like that that is really enables you to give the illusion of attending to trillions of tokens. Um sort of the way Google search gives you you know not the illusion but you are searching the internet. Yeah. &gt;&gt; But you&#x27;re finding you know a very small subset of things that are that are relevant. &gt;&gt; Yeah. I I often tell a lot of people uh that are not steeped in like Google search history that uh well you know like BERT was like used like basically immediately inside of Google search uh</p>
<p>and that improves results a lot right like I I don&#x27;t I don&#x27;t have any numbers off the top of my head but like I&#x27;m sure you that&#x27;s obviously the most important numbers to to Google. Yeah, I mean I I think going to an LLMbased representation of text and words and so on enables you to get out of the explicit hard notion of of particular words having to be on the page, but really getting at the notion of this topic of this page or this paragraph is highly relevant to this query. &gt;&gt; Yeah. Yeah. I I don&#x27;t think people understand how much LMS have taken over</p>
<p>all these very high traffic system. very high traffic. Yeah, like [laughter] &gt;&gt; it&#x27;s Google. Uh it&#x27;s YouTube. Uh YouTube has this like semantics uh ID thing where there&#x27;s like every token or every uh item in the vocab is a YouTube video or something that predicts the video using a code book which is absurd to me for YouTube size. And then most recently Grock also for for XAI which is like &gt;&gt; I mean I&#x27;ll call out even before LLMs were used extensively in search we put a lot of emphasis on softening the notion of what the user actually entered into</p>
<p>the query so that &gt;&gt; do you have like a history of like what&#x27;s the</p>
<h2>Systems Design Principles + Latency Numbers</h2>
<p>&gt;&gt; yeah I mean I actually gave a talk in uh I guess uh web search and data mining conference in 2009. &gt;&gt; Okay. uh where we never actually published any papers about the origins of Google search uh sort of but we went through sort of four or five or six generations four or five or six generations of uh redesigning of the search and retrieval system uh from about 1999 through 2004 or five and that talk is really about that evolution and one of the things that really happened in 2001 was we were</p>
<p>sort of working to scale the system in multiple dimensions. So one is we wanted to make our index bigger so we could retrieve from a larger index which always helps your quality in general uh because if you don&#x27;t have the page in your index you&#x27;re going to not do well. Um and then we also needed to scale our capacity because we were our traffic was growing quite extensively. Um and so we had you know a sharded system where you have more and more shards as the index grows. you have like 30 shards and then if you want to double the index size you make 60 shards so that you can bound the</p>
<p>latency by which you respond for any particular user query. Um and then as traffic grows you add more and more replicas of each of those. And so we eventually did the math that realized that in a data center where we had say 60 shards and um you know 20 copies of each shard we now had 1,200 machines uh with discs. and we did the math and we&#x27;re like, hey, one copy of that index would actually fit in memory across,200 machines. &gt;&gt; Mhm. &gt;&gt; So in 2001 we introduced uh we put our entire index in memory.</p>
<p>&gt;&gt; And what that enabled from a quality perspective was amazing because before you had to be really careful about, you know, how many different terms you looked at for a query because every one of them would involve a disk seek on every one of the 60 shards. And so you as you make your index bigger, that becomes even more inefficient. But once you have the whole index in memory, it&#x27;s totally fine to have 50 terms you throw into the query from the user&#x27;s original three or four word query because now you can add synonyms like restaurant and restaurants and cafe and</p>
<p>uh beastro and all these things. And you can suddenly start uh sort of really uh getting at the meaning of the word as opposed to the exact semantic form. the user typed in. And that was, you know, 2001, very much preLLM, but really it was about softening the the strict definition of what the user typed in order to get at the meaning. &gt;&gt; What are like principles that you use to like design the systems, especially when you have I mean in 2001 the internet is like doubling tripling every year in size. It&#x27;s not like a you know, and I</p>
<p>think today you kind of see that with LLMs too where like every year the jumps in size and like capabilities are just so big. Are there just any you know principles that you use to like think about this? &gt;&gt; Yeah, I mean I think uh you know first whenever you&#x27;re designing a system you want to understand what are the sort of design parameters that are going to be most important in deciding that you know so you know how many queries per second do you need to handle? How big is the index you need to handle? How much data do you need to keep for every document in the index? How are you going to look at it when you</p>
<p>retrieve things? um what happens if traffic were to double or triple you know will that system work well and I think a good design principle is you&#x27;re want to design a system so that the most important characteristics could scale by like factors of five or 10 but probably not beyond that because &gt;&gt; often what happens is if you design a system for X and something suddenly becomes 100X that would enable a very different point in the design space that would not make sense at X but all of a sudden 100x makes total sense. So like</p>
<p>going from a disk spaced index to a in-memory index makes a lot of sense once you have enough traffic because now you have enough replicas of the sort of state on disk that those machines now actually can hold uh you know a full copy of the me uh index in memory. &gt;&gt; Yeah. &gt;&gt; And that all of a sudden enables a completely different design that wouldn&#x27;t have been practical before. &gt;&gt; Yeah. Um, so I&#x27;m I&#x27;m a big fan of thinking through designs in your head, just kind of playing with the design space a little before you actually do a</p>
<p>lot of writing of code. But you know, as you said, in the early days of Google, we were you growing the index uh quite extensively. We were growing the update rate of the index. So the update rate actually is the parameter that changed the most surprisingly. So it used to be once a month. &gt;&gt; Yeah. And then we went to a system that could update any particular page in like sub one minute. &gt;&gt; Okay. Yeah. Because this is a competitive advantage, right? &gt;&gt; Because all of a sudden news related queries, you know, if you&#x27;re if you&#x27;ve got last month&#x27;s news index, it&#x27;s not</p>
<p>actually that useful for &gt;&gt; a special beast. Was there any like you could have split it onto a separate system? &gt;&gt; Well, we did we launched a Google News product, but you also want news related queries that people type into the main index to also be &gt;&gt; sort of updated. So, &gt;&gt; yeah. Yeah. It&#x27;s interesting. And then you have to like classify whether the page is you have to decide which pages should be updated at what frequency. &gt;&gt; Oh yeah, there&#x27;s a whole like uh system behind the scenes that&#x27;s trying to decide update rates and importance of the pages. So even if the update rate seems low, you might still want to rec crawl important pages quite often</p>
<p>because &gt;&gt; uh the likelihood they change might be low but the value of having them updated is high. &gt;&gt; Yeah. Yeah. Yeah. Yeah. uh what you know this uh you know mention of latency and and saving things to this reminds me of one of your classics which I have to bring up which is latency numbers every programmer should know. &gt;&gt; Uh &gt;&gt; was there was there just a just general story behind that did you just write it down? &gt;&gt; I mean this has like sort of eight or 10 different kinds of metrics that are like how long does a cache miss take, how long does branch miss predict take, how long does a reference domain memory</p>
<p>take, how long does a distance take these &gt;&gt; how long does it take to send you know a packet from the US to the Netherlands or something. Um, &gt;&gt; why Netherlands by the way or is it is that because of Chrome? &gt;&gt; Uh, we had a data center in [laughter] &gt;&gt; um so I mean I think this gets to the point of being able to do these back at the envelope calculations. So these are sort of the raw ingredients of those and you can use them to say okay well if I need to design a system to do image search and thumbnailing or something of the result page you know how might I do</p>
<p>that? I could premp compute the image thumbnails. I could like try to thumbnail them on the fly from the larger images. What would that do? How much dis bandwidth I need? How many disc seeks would I do? Um and you can sort of actually do thought experiments in you know 30 seconds or a minute with the sort of uh basic uh basic numbers at your fingertips. Uh and then as you sort of build software using higher level libraries, you kind of want to develop the same intuitions for how long does it take to you know look up something in this particular kind of hash table I use</p>
<p>or you know how long will it take me to sort a million numbers or something. &gt;&gt; Yeah. The the reason I bring it up actually is actually for I think like two years now I&#x27;ve been trying to make numbers every AI programmer should know. &gt;&gt; Okay. Yeah. &gt;&gt; Uh I don&#x27;t have a great one. uh because it&#x27;s not as it&#x27;s not physical constants like you have physical constants in here you know it&#x27;s and &gt;&gt; uh but I do think like uh so a simple one would be number of parameters to um uh disk size if you if you need to convert that uh which is a simple bite conversion that&#x27;s not that&#x27;s nothing</p>
<p>interesting I wonder if you have any if you want if you if you were to update your &gt;&gt; I mean I think uh it&#x27;s really good to think about uh calculations you&#x27;re doing in a model either for training or inference. Um,</p>
<h2>Energy, Batching &amp; TPU Co-Design</h2>
<p>often a good way to view that is how much uh state will you need to bring in from memory either like onchip SRAMM or HPM from the accelerator attached uh memory or DRAM or over the network. Um and then how expensive is that data motion relative to uh the cost of say an actual multiply in the matrix multiply unit &gt;&gt; and that cost is actually really really low right because it&#x27;s you know order you know uh depending on your precision</p>
<p>I think it&#x27;s like sub pico one picole &gt;&gt; oh okay you measure it by energy &gt;&gt; yeah yeah I mean it&#x27;s all going to be about energy and how do you make the most energy efficient Um, and then moving data from the SRAMM on the other side of the chip, not not even off the off chip, but on the other side of the same chip can be, you know, a thousand pajles. &gt;&gt; Oh. &gt;&gt; Or Yeah. And so all of a sudden this is why your accelerators uh require batching because if you move like say</p>
<p>the parameter of a model from SRAMM on the on the chip into the multiplier unit that&#x27;s going to cost you a thousand pico tools. So you better make use of that that thing that you moved many many times with. So that&#x27;s where the batch dimension comes in because all of a sudden, you know, if you have a batch of 256 or something, that&#x27;s not so bad. But if you have a batch of one, that&#x27;s really not good. &gt;&gt; Yeah. Yeah. &gt;&gt; Right. Because then you paid a thousand podles in order to do your one pico multiply. &gt;&gt; I have never heard a energy based analysis of batching. [laughter] &gt;&gt; Yeah. I mean, that&#x27;s why people batch,</p>
<p>right? Yeah, ideally you&#x27;d like to use batch size one because the latency would be great &gt;&gt; but the energy cost and the the compute cost inefficiency that you get um is is quite large. So &gt;&gt; yeah is there a similar trick like uh like like you did with uh you know putting everything in memory like you know I think uh obviously Nvidia has caused a lot of waves with uh betting very hard on on SRAMM with grock. Uh I I I wonder if like that&#x27;s something that you already saw with with the TPUs, right? Like that that you had to uh to serve at your scale. Uh you probably</p>
<p>sort of saw that coming like what what what hardware uh innovations or insights were formed because of what you&#x27;re seeing there. &gt;&gt; Yeah. I mean, I think you know, TPUs have this nice uh sort of regular structure of 2D or 3D meshes with a bunch of chips connected and each one of those has HPM attached. Um I think for serving some kinds of models, &gt;&gt; uh you know, you you pay a lot higher cost and time latency um bringing things in from HBM than you do bringing them in from uh SRAMM on the</p>
<p>chip. So if you have a small enough model, you can actually do model parallelism, spread it out over lots of chips, and you actually get quite good throughput improvements and latency improvements from doing that. And so you&#x27;re now sort of striping your smalish scale model over say 16 or 64 chips. Uh but if if you do that and it all fits in SRAMM, uh that can be a big win. So yeah, that&#x27;s not a surprise, but it is a good technique. &gt;&gt; Yeah. What about the TPU? design like how much do you decide where the</p>
<p>improvements have to go? So like this is like a good example of like is there a way to bring the thousand pig jewel down jewels [clears throat] down to 50 and like is it worth designing a new chip to do that? The extreme is like when people say oh you should burn the model on the ASIC and that&#x27;s kind of like the most extreme thing. &gt;&gt; How much of it is it worth doing in hardware when things change so quickly? Like what what&#x27;s the internal discussion? Yeah, I mean we we have a lot of interaction between say the TPU chip design architecture team and the sort of higher level modeling uh experts</p>
<p>because we really want to take advantage of being able to co-design what should future TPUs look like based on where we think the sort of ML research puck is going uh in some sense because uh you know as a hardware designer for ML in particular you&#x27;re trying to design a chip starting today and that design might take two years before it even lands in a data center and then it has to sort of be a reasonable lifetime of the chip to take you three, four or five years. So you&#x27;re trying to predict two</p>
<p>to six years out where what ML computations will people want to run two to six years out in a very fast changing field. And so having people with interesting ML research ideas of things we think will start to work in that time frame or will be more important in that time frame. Uh really enables us to then get you know interesting hardware features put into you know TPU N plus2 where TPUn is what we have today. &gt;&gt; Oh the cycle time is plus two</p>
<p>&gt;&gt; roughly. I mean &gt;&gt; because uh &gt;&gt; I mean sometimes you can squeeze some changes into N plus1 but you know bigger changes are going to require the chip design be earlier in its lifetime design process. Um, so whenever we can do that, it&#x27;s generally good. And sometimes you can put in speculative features that maybe won&#x27;t cost you much chip area, but if it works out, it would make something, you know, 10 times as fast. And if it doesn&#x27;t work out, well, you burned a little bit of tiny amount of your chip area on that thing, but it&#x27;s not that big a deal. Uh, sometimes it&#x27;s</p>
<p>a very big change and we want to be pretty sure this is going to work out. So we&#x27;ll do like lots of careful ML experimentation to show us uh this is actually the the way we want to go. &gt;&gt; Yeah. &gt;&gt; Is there a reverse of like we already committed to this chip design so we cannot take the model architecture that way because it doesn&#x27;t quite fit? &gt;&gt; Yeah. Yeah, I mean you you definitely have things where you&#x27;re going to adapt what the model architecture looks like so that they&#x27;re efficient on the chips that you&#x27;re going to have for both</p>
<p>training and inference of that of that uh generation of model. So I think it kind of goes both ways. Um you know sometimes you can take advantage of you know lower precision things that are coming in a future generation. So you might train it at that lower precision even if the current generation doesn&#x27;t quite uh do that. &gt;&gt; Mhm. Yeah. How low can we go in precision? &gt;&gt; People are saying like turner is like [laughter] &gt;&gt; Yeah. I mean I&#x27;m a big fan of very low precision because I think that gets that</p>
<p>saves you a tremendous amount of energy, right? Because it&#x27;s poujles per bit that you&#x27;re transferring and reducing the number of bits is a really good way to &gt;&gt; to reduce that. Um, you know, I think people have gotten a lot of luck, uh, mileage out of having very low bit precision things, but then having scaling vectors that apply to a whole bunch of, uh, those those weights &gt;&gt; scaling. Okay. Interesting. You so low precision but scaled up weights. &gt;&gt; Yeah. &gt;&gt; Huh. Yeah. Never considered that. Interesting. Uh while we&#x27;re on this</p>
<p>topic, you know, I think there&#x27;s a lot of um uh just the concept of precision at all is weird when we&#x27;re sampling, you know, uh we just at the end of this we&#x27;re going to have all these like chips that all do like very good math and then we&#x27;re just going to throw a random number generator at the start and [laughter] &gt;&gt; so I mean I there&#x27;s a movement towards energy based uh models and pro processors. I&#x27;m just curious if you&#x27;ve obviously you&#x27;ve thought about it but like what&#x27;s your commentary? Yeah, I mean I think there&#x27;s a bunch of interesting trends. So energy based models is one. You know, diffusion based</p>
<p>models which don&#x27;t sort of sequentially decode tokens is another. &gt;&gt; Yes. Um, you know, speculative decoding is a way that you can get sort of an equivalent very small &gt;&gt; draft &gt;&gt; batch factor uh for like you predict eight tokens out and that enables you to sort of increase the effective batch size of what you&#x27;re doing by a factor of eight even and then you maybe accept five or six of those tokens. So you get five a 5x improvement in the amortization of moving weights uh into the multipliers to do the prediction for</p>
<p>the the tokens. So these are all really good techniques and I think it&#x27;s really good to look at them from the lens of uh energy real energy not energy based models um and and also latency and throughput right if you look at things from that lens that sort of guides you to solutions that are going to be uh you know better from uh you know being able to serve larger models or you know equivalent size models more cheaply and</p>
<p>with lower latency. &gt;&gt; Yeah. Well, I think I think I um it&#x27;s appealing intellectually. Uh haven&#x27;t seen it like really hit the mainstream, but um I do think that uh there&#x27;s some poetry in the sense that uh you know, we don&#x27;t have to do uh a lot of shenanigans if like we fundamentally design it into the hardware. &gt;&gt; Yeah. Yeah. I mean, I think there&#x27;s still a there&#x27;s also sort of the more exotic things like analog based uh uh computing substrates as opposed to digital ones. Uh I&#x27;m, you know, I think</p>
<p>those are super interesting because they can be potentially low power. &gt;&gt; Uh but I think you often end up wanting to interface that with digital systems and you end up losing a lot of the power advantages in the digital to analog and analog to digital conversions you end up doing &gt;&gt; uh at the sort of boundaries and periphery of that system. M &gt;&gt; um I still think there&#x27;s a tremendous distance we can go from where we are today in terms of energy efficiency with sort of uh much better and specialized hardware for the models we care about. &gt;&gt; Yeah.</p>
<p>&gt;&gt; Um any other interesting research ideas that you&#x27;ve seen or like maybe things that you cannot pursue at Google that you would be interested in seeing researchers take a stab at? I guess you have a lot of researchers. Yeah, we have a lot of our our research portfolio is</p>
<h2>Research Frontiers: Reliability &amp; RL Challenges</h2>
<p>[laughter] pretty broad. I would say um I mean I think [snorts] uh in terms of research directions, there&#x27;s a whole bunch of uh you know open problems and how do you make these models reliable and able to do much longer kind of uh more complex tasks that have lots of subtasks? How do you orchestrate you know maybe one model that&#x27;s using other models as tools in order to sort of build uh things that can accomplish uh you know much more significant pieces of work uh collectively than you would ask a single model to do. Um so that&#x27;s super</p>
<p>interesting. How do you get more verifiable uh you know how do you get RL to work for non-verifiable domains? I think it&#x27;s a pretty interesting open problem because I think that would broaden out the capabilities of the models, the improvements that you&#x27;re seeing in both math and coding. Uh if we could apply those to other less verifiable domains because we&#x27;ve come up with RL techniques that actually enable us to do that uh effectively that would that would really make the models improve quite a lot. I think &gt;&gt; I&#x27;m curious like when we had no brown on the podcast, he said um they already</p>
<p>proved you can do it with deep research. Mhm. &gt;&gt; Um, you kind of have it with AI mode in a way. It&#x27;s not verifiable. &gt;&gt; I&#x27;m curious if there&#x27;s any thread that you think is interesting there. Like what is it? Both are like information retrieval of JSON. So I wonder if it&#x27;s like the retrieval is like the verifiable part that you can score or what are like yeah how how would you model that that problem? Yeah, I mean I think there are ways of having other models that can evaluate the results of what a first model did. Maybe in retrieving, can you have</p>
<p>another model that says, is this things are these things you retrieved relevant or can you rate these 2,00 things you retrieved to assess which ones are the 50 most relevant or something. Um, I think those kinds of techniques are actually quite effective. Sometimes that can even be the same model just prompted differently to be a you know critic as opposed to a uh actual retrieval system. &gt;&gt; Yeah. Um, I do think like there there is that that weird cliff where like it feels like we&#x27;ve done the easy stuff and then now it&#x27;s but it always feels like</p>
<p>that like every year [clears throat] it&#x27;s like oh like we know you know and the next part is super hard and nobody&#x27;s figured it out and &gt;&gt; uh like exactly with this RLVR thing where like everyone&#x27;s talking about well okay how do we do the next stage of the non-verifiable stuff and everyone&#x27;s like I don&#x27;t know you know judge [laughter] &gt;&gt; I mean I feel like The nice thing about this field is there&#x27;s lots and lots of smart people thinking about creative solutions to some of the, you know, problems that we all see. Uh because I think everyone sort of sees that the models, you know, are great at some</p>
<p>things and they fall down around the edges of those things and and are not as capable as we&#x27;d like in those areas. And then coming up with good techniques and trying those and seeing which ones actually make a difference is sort of what the whole research aspect of this field is is pushing forward. And I think that&#x27;s why it&#x27;s super interesting. You know, if you think back two years ago, we were struggling with GSM8K problems, right? Like, you know, Fred has two rabbits, he gets three more rabbits. How many rabbits does he have? &gt;&gt; That&#x27;s a pretty far cry from the kinds of mathematics that the models can.</p>
<p>&gt;&gt; And now you&#x27;re doing Yeah. And erosure language. Yeah. &gt;&gt; Yeah. Pure language. So that is a really really amazing jump in capabilities in you know a year and a half or something. And I think um for other areas it&#x27;d be great if we could make that kind of leap. Uh and you know we don&#x27;t exactly see how to do it for some some areas but we do see it for some other areas and we&#x27;re going to work hard on making that better. &gt;&gt; Yeah. &gt;&gt; Yeah. Like YouTube thumbnail generation that would be very helpful.</p>
<p>&gt;&gt; We need that. That would be AGI. we need for as far as content creators go. &gt;&gt; I guess I&#x27;m not a YouTube creator, so I don&#x27;t care that much about that problem, but I guess uh many people do.</p>
<h2>Unified Models vs Symbolic Systems (IMO)</h2>
<p>&gt;&gt; It Yeah, it doesn&#x27;t it doesn&#x27;t matter. People do judge books by their covers as it turns out. &gt;&gt; Um just to draw a bit on the IMO gold. Um I&#x27;m still not over the fact that a year ago we had Alpha Proof and Alpha Geometry and all those things and then this year we were like screw that, we&#x27;ll just chuck it into Gemini. What&#x27;s your reflection? Like I think this this question about like the merger of like symbolic systems and like and and LLMs uh was a very much core belief and then somewhere along the line people just said nope we&#x27;ll just all do it in LLM.</p>
<p>&gt;&gt; Yeah. I mean, I think it makes a lot of sense to me because, you know, humans manipulate symbols, but we probably don&#x27;t have like a symbolic representation in our heads, &gt;&gt; right? We have some distributed representation that is neural netlike in some way of lots of different neurons and activation patterns firing when we see certain things and that enables us to reason and plan and, you know, do chains of thought and, you know, roll them back. you know that that approach for solving the problem doesn&#x27;t seem</p>
<p>like it&#x27;s going to work. I&#x27;m going to try this one. And you know, in a lot of ways, we&#x27;re emulating what we intuitively think uh is happening inside real brains in neural netbased models. So it never made sense to me to have like completely separate discrete uh symbolic things and then a completely different way of of uh you know thinking about those things. &gt;&gt; Interesting. Yeah. Uh I mean it&#x27;s maybe seems obvious to you but it wasn&#x27;t obvious to me a year ago. [laughter]</p>
<p>&gt;&gt; Yeah. I mean I do think like that &gt;&gt; IMO with you know translating to lean and using lean and then the next year and and also a specialized geometry model and then this year switching to a single unified model that is roughly the production model with a little bit more inference budget uh is actually you know quite good because it shows you that the capabilities of that general model yeah have improved dramatically and and now you don&#x27;t need these specialized models. This is actually sort of very similar to the 2013 to6 era of machine learning,</p>
<p>right? Like it used to be people would train separate models for lots of different each different problem, right? I have I want to recognize street signs in something. So I train a street sign recogn recognition model or I want to you know decode speech recognition. I have a speech model. Right? I think now the era of unified models that do everything is really upon us and the question is how well do those models generalize to new things they&#x27;ve never been asked to do and they&#x27;re getting better and better &gt;&gt; and you don&#x27;t need domain experts like one of my uh so I interviewed Eay who</p>
<p>was on who&#x27;s on that team &gt;&gt; uh and he was like yeah I I don&#x27;t know how they work I don&#x27;t know where the IMO competition was held I don&#x27;t know the rules of it I just train the models I&#x27;m good at training [laughter] models &gt;&gt; and it&#x27;s kind of interesting thing that like people with these this like universal skill set of just like machine learning you just give them data and give them enough compute and they can kind of tackle any task which is &gt;&gt; yeah right [laughter] and &gt;&gt; a bitter lesson I guess I don&#x27;t know &gt;&gt; yeah yeah I mean I think uh general models uh will win out over specialized ones in most cases</p>
<p>&gt;&gt; so I want to push there a bit I think there&#x27;s one hole here which is like uh there&#x27;s this concept of like uh maybe capacity of a model like abstractly a model can only contain [clears throat] the number of bits that it has and uh and so you know god knows like Gemini Pro is like one to 10 trillion parameters we don&#x27;t know but uh the Gemma models for example right like a lot of people want like the open source local models that are like that that that and and uh they have some knowledge which is not necessary right like they can&#x27;t know</p>
<p>everything like like you have the luxury of you have the big model and big model should be able to capable of everything but like when when you&#x27;re distilling and you&#x27;re going down to the small models, you know, you&#x27;re actually memorizing things that are not useful &gt;&gt; and so like how do we I guess do we want to extract that? Can we can we divorce knowledge from reasoning, you know?</p>
<h2>Knowledge vs Reasoning + Vertical/Modular Models</h2>
<p>&gt;&gt; Yeah. I mean, I think you do want the model to be most effective at reasoning if it can retrieve things, right? having the model devote precious parameter space to remember obscure facts that could be looked up &gt;&gt; is actually not the best use of that parameter space right like you might prefer something that is more generally useful in more settings than this obscure fact that it has um so I think that&#x27;s always a tension at the same time you also don&#x27;t want your model to be kind of completely detached from you</p>
<p>know knowing stuff about the world right like it&#x27;s probably useful to know how long the Golden Gate Bridge is just as a general sense of like how long are bridges, right? And uh it should have that kind of knowledge. It maybe doesn&#x27;t need to know how long some teeny little bridge in some other more obscure part of the world is, but uh it does help it to have a fair bit of world knowledge. And the bigger your model is, the more you can have. Uh but I do think combining retrieval with sort of reasoning and making the model really</p>
<p>good at doing multiple stages of retrieval and reasoning through the intermediate retrieval results is going to be a a pretty effective way of making the models seem much more capable because if you think about say a personal Gemini &gt;&gt; Yeah. Right? Like we&#x27;re not going to train Gemini on my email. Probably we&#x27;d rather have a single model that uh we can then use and use being able to retrieve from my email as a tool and have the model reason about it and retrieve from my photos or whatever. Uh and then make use of that and have</p>
<p>multiple u you know stages of interaction. &gt;&gt; That makes sense. Do you think the vertical models are like [clears throat] an interesting pursuit? Like when people are like, &quot;Oh, we&#x27;re building the best healthcare LLM. We&#x27;re building the best law LLM.&quot; Are those kind of like short-term stop caps or &gt;&gt; No, I mean I think I think vertical models are interesting like you want them to start from a pretty good base model, but then you can sort of I sort of viewing them view them as enriching the data distribution for that particular vertical domain for</p>
<p>healthcare. say um we&#x27;re probably not going to train or for say robotics, we&#x27;re probably not going to train Gemini on all possible robotics data. We you could train it on because we wanted to have a balanced set of capabilities. Um, so we&#x27;ll expose it to some robotics data, but if you&#x27;re trying to build a really, really good robotics model, you&#x27;re going to want to start with that and then train it on more robotics data and then maybe that would hurt its multilingual translation capability but improve its robotics capabilities. And we&#x27;re always making these kind of uh,</p>
<p>you know, tradeoffs in the data mix that we train the base Gemini models on. You know, we&#x27;d love to include data from 200 more languages and as much data as we have for those languages. &gt;&gt; Yeah. &gt;&gt; But that&#x27;s going to displace some other capabilities of the model. &gt;&gt; It won&#x27;t be as good at um you know, Pearl programming. you know, it&#x27;ll still be good at Python programming because we&#x27;ll include enough of that, but there&#x27;s other longtail computer languages or coding capabilities that it may suffer on or multi- uh multimodal reasoning capabilities may suffer</p>
<p>because we didn&#x27;t get to expose it to as much data there, but it&#x27;s really good at multilingual things. So, I I think some combination of specialized models, maybe more modular models. So it&#x27;d be nice to have the capability to have those 200 languages plus this awesome robotics model plus this awesome healthcare uh module that all can be knitted together to work in concert and called upon in different circumstances, right? Like if I have a health related thing, then it should enable using this health module in conjunction with the main base model</p>
<p>to be even better at those kinds of things. &gt;&gt; Yeah. Installable knowledge. Yeah. Right. just [clears throat] download as a as a &gt;&gt; and some of that installable stuff can come from retrieval, &gt;&gt; but some of it probably should come from training on you know uh 100 billion tokens or a trillion tokens of health data. &gt;&gt; Yeah. And for listeners I think uh I will highlight the GEMA 3 end paper where they there was a little bit of that I think. &gt;&gt; Yeah. &gt;&gt; Yeah. I guess the question is like how many billions of tokens do you need to outpace the frontier model &gt;&gt; improvements? You know, it&#x27;s like if I</p>
<p>have to make this model better at healthcare and the main Gemini model is still improving, &gt;&gt; do I need 50 billion tokens? Can I do it with 100? If I need a trillion healthcare tokens, it&#x27;s like they&#x27;re probably not out there that you don&#x27;t have, you know, I think that&#x27;s really like the challenge. &gt;&gt; Oh, I mean, I think healthcare is a particularly challenging domain. So there&#x27;s a lot of healthcare data that you know we don&#x27;t have access to appropriately but there&#x27;s a lot of you know uh healthcare organizations that want to train models on their own data that is not public healthcare data uh not public health but public healthare</p>
<p>data. Um, so I think there are opportunities there to say partner with a large healthcare organization and train models for their use that are going to be, you know, more bespoke but probably uh might be better than a general model trained on say public</p>
<h2>Multilingual + Low-Resource Language Insights</h2>
<p>data. &gt;&gt; Yeah. &gt;&gt; Yeah. I I believe uh by the way al this is like somewhat related to the language conversation. Uh I think one of your your favorite examples was you can put a low resource language in the context and it just learns [laughter] in context. &gt;&gt; Oh yeah. I think the example we used was Calamong which is truly low resource because it&#x27;s only spoken by I think 120 people in the world and there&#x27;s no written text. &gt;&gt; So &gt;&gt; so you can just do it that way just to get in the context. &gt;&gt; Yeah. [laughter] &gt;&gt; Yeah. But I put your whole data set in context, right? &gt;&gt; If you if you take a language like uh you know Somali or something there is a</p>
<p>fair bit of Somali text in the world that uh or Ethiopian Amharic or something um you know we probably are not putting all the data from those languages into the Gemini based training. We put some of it but if you put more of it you&#x27;ll improve the capabilities of those models. &gt;&gt; Yeah. &gt;&gt; So or of those languages. &gt;&gt; Uh yeah cool. Uh it&#x27;s uh the I I have a side interest in linguistics. I I I I did a few classes in back in college and like uh part of me like if I was a</p>
<p>linguist and I could have access to all these models I would just be asking really fundamental questions about language itself like uh one is there&#x27;s one very obvious one which is superior warf like how much does like the language that you speak affect your thinking but then also there are some languages where there&#x27;s just concepts that are not represented in other languages but some others many others that are just duplicates right where uh there&#x27;s also another paper that people love called the platonic representation where you know like the the an image of a cup is uh if you say learn a model on that and you you you have a lot of text with the word cup it eventually maps to</p>
<p>like roughly the same place in laten space and so like that should apply to languages except where it doesn&#x27;t and that&#x27;s actually like very interesting differences in what humanity has discovered as concepts that maybe English doesn&#x27;t have. [laughter] &gt;&gt; I I don&#x27;t know. That&#x27;s just like my my rant on languages.</p>
<h2>Vision-Language Representations Example</h2>
<p>&gt;&gt; Yeah, I I did some work on a early model that fused together a languagebased model with you have, you know, nice word-based representations and then an image model where you have trained it on imageet like things. Yes. &gt;&gt; And then you fuse together the top layers of &gt;&gt; uh no this is device &gt;&gt; device. &gt;&gt; Uh the you do a little bit more training to fuse together those representations. And what you found was that if you give a novel image that is not in any of the categories in the image model it was</p>
<p>trained on the model can often assign kind of the right c the right label to that image. Um so for example um I think uh telescope and uh binoculars were both in the training uh categories for the image model but um microscope was not. M. &gt;&gt; And so if you give it an image of a microscope, it actually can come up with something that&#x27;s got the word microscope as the label that are designed even though it&#x27;s never actually seen an image labeled that.</p>
<p>&gt;&gt; Oh, that&#x27;s nice. &gt;&gt; Yeah. &gt;&gt; Um, so yeah, &gt;&gt; useful. Uh, cool. I think there there&#x27;s more general like broad questions, but like I guess what what do you uh wish you were asked more in in in general? Like you know you have such a broad scope. We&#x27;ve covered the hardware. covered the the models research. &gt;&gt; Yeah, I mean I think uh one thing that&#x27;s kind of interesting is you know I I did a undergrad thesis on neural network uh training uh parallel neural network training uh back in 1990</p>
<p>when I got exposed to to neural nets and I always felt kind of they were the right abstraction but we just needed way more compute than we had then. So like the 32 processors in the department parallel computer you know could get you a a little bit more interesting uh model but not not enough to solve real problems. And so starting in 2008 or nine, you know, the world started to have enough computing power through Moors law and, you know, larger interesting data sets to train on to actually, you know, start training neural nets that could tackle real problems that people cared about, speech</p>
<p>recognition, vision, and eventually language. Um and so um when I started working on neural nets at Google in in late 2011 um you know I really just felt like we should scale up the size of neural networks we can train using you know large amounts of parallel computation and so I actually revived some ideas for my undergrad thesis where I&#x27;d done both model parallel and data parallel uh training and I compared them. &gt;&gt; I called them something different. It was like pattern partitioned and you</p>
<p>know model partitioned or something. &gt;&gt; We&#x27;ll have to Is it is it public? Can we go dig? &gt;&gt; Yeah, it&#x27;s on it&#x27;s on the web. &gt;&gt; Okay. &gt;&gt; Um but uh you know I think combining a lot of those techniques and really just trying to push on scaling things up over the last you know 15 years has been you know really important and that means you know improvements in the hardware. So you know pushing on building specialized hardware like TPUs. Uh it also means you know pushing on software abstraction layers to let people express ML ideas uh effectively. Um and then also working on things like uh say sparse models. I&#x27;ve</p>
<p>felt for a long time that sort of sparsely activated models are a really important thing because you want the models to have a lot of capacity to our earlier discussion about remembering a lot of stuff. &gt;&gt; Yeah. &gt;&gt; But you also want to be super efficient in how you activate your models. So you&#x27;d like you know trillions of parameters but activate only you know one 1% or 5% or 10% of that and um that you know we did a early u paper on this where we really scaled up uh you know outrageously large neural networks that</p>
<p>the title I think that&#x27;s Nome&#x27;s uh Gnome&#x27;s wording in the title which is a good catchy title. &gt;&gt; I mean in 2017 he was out there talking about one trillion parameter models. &gt;&gt; Yeah. So I mean that that that is really good because that gave you like a 10x improvement in you know time to quality or compute cost to qual a given quality level relative to non-sparse models. Um transformers similarly gave you a 10x to 100x improvement in you know uh compute cost to a given quality level uh versus say LSTMs at the time and all of those</p>
<p>things multiply together. Um so I think all those things really are important to work on you know the hardware the systems infrastructure the you know algorithmic aspects of model architecture improving the data you know improving the RL recipes all these things uh are what are stacking together and multiplying together &gt;&gt; to give us models of 2026 are much more better than models of 25 and are awesomely better than 24 and 23 and</p>
<p>and and a huge uh honestly like organizational challenge like there&#x27;s like a thousand people or maybe more like I know I know when the first Gemini paper came out it was like a thousand of co-authors. &gt;&gt; Yeah. Yeah. We have uh 10 pages of co-authors in the in the tech [laughter] report &gt;&gt; but it was nice. I mean you know people want to be acknowledged on probably a historical paper. &gt;&gt; Yeah. I mean, I think it&#x27;s perfectly good to have actually a lot of co-authors and I do think &gt;&gt; organizing that number of people so that they&#x27;re effectively pushing in common directions that all all their work actually sort of multiplies together in</p>
<p>the ultimate output which is you know the next generation of model is actually pretty tricky and we have awesome people uh throughout the Gemini team to help orchestrate this. So you know myself, Noom and Oral are sort of helping steer this and then we have people thinking about you know what is the pre-training uh setup look like what does the infrastructure look like what does the post-raining recipe look like and what does the data preparation and eval multimodal capabilities and IN capabilities &gt;&gt; um you know there&#x27;s a lot of different</p>
<p>kinds of areas coding capabilities all these areas are are super important and it&#x27;s really good to have people uh paying close attention to those things and then also paying close attention to all the other things. &gt;&gt; Yeah. I&#x27;m told Sergey is like very actively back and like very much involved in coding stuff. &gt;&gt; Yep. Yeah. Yeah. Yeah. We all use the same micro kitchen. &gt;&gt; Yeah. Uh oh. Okay. Like there&#x27;s so many jumping off point. Uh so by the way I found out from the recent uh I mean you&#x27;ve probably told this story a few times but apparently Google brain was also started in a micro kitchen.</p>
<p>&gt;&gt; Yeah. Yeah. [laughter] &gt;&gt; Just like your micro kitchens are very important. &gt;&gt; Yeah. I don&#x27;t know if people like understand. &gt;&gt; Yeah. Uh yeah, I actually bumped into Andrew Ing who&#x27;s a Stanford faculty member and uh I knew him from I&#x27;d given talks at Stanford a couple years before so I sort of knew him and I&#x27;m like, &quot;Oh, what are you doing here?&quot; He&#x27;s like, &quot;Oh, I&#x27;m not sure yet. I just started, you know, a couple weeks ago. I&#x27;m going to spend one day a week here consulting. Um I&#x27;m not sure what I&#x27;m working on, but my students at Stanford are starting to get good results um on using u neural nets for speech uh recognition. I&#x27;m</p>
<p>like, &quot;Oh, neural nets. I like neural nets.&quot; Like I remembered back to my 1990 thesis. I&#x27;m like, &quot;Oh, that sounds interesting. We should train really really big neural nets.&quot; &gt;&gt; So [snorts] that was the &gt;&gt; which you say that and that&#x27;s a very interesting first instinct, which is that we should scale this up a lot. &gt;&gt; Yeah. Well, I mean, I felt like Google is is has lots of computational uh capability and so if they were seeing good results on, you know, what were effectively single GPU or uh models, &gt;&gt; you know, if we were uh we actually</p>
<p>didn&#x27;t have GPUs in our data centers then we didn&#x27;t have any accelerators. We had lots of CPUs, but you know, we could build a software system that would enable you to distribute with both model parallelism and data parallelism across lots of computers. And we ended up training a pretty big model was 50x bigger than any previous neural net as far as we could tell. Um, so it&#x27;s two billion parameters uh vision model uh trained on 16,000 CPU cores for like multiple weeks. Uh and that&#x27;s what gave us really good it would gave us a 70% relative error improvement in imageet</p>
<p>22k which is the 22,000 category thing and that&#x27;s how we really saw okay scaling this up actually matters. We didn&#x27;t write a, you know, a sophisticated scaling analysis, but we had a a saying, bigger model, more data, better results. &gt;&gt; And that was our our mantra for like six or seven years of scaling. And we every time we did that, we saw better results in speech, in language, in in vision. &gt;&gt; Uh, speaking of um bets, and this might and this, you know, I&#x27;ll preface with</p>
<p>like this might be a little bit more sensitive topic, but you have obviously a lot of opinions about this. We had a previous guest, David Juan, who used to work for you, and uh he he kind of like blames almost the brain marketplace as like the reason that Google didn&#x27;t invest enough in language models. And I wonder if that&#x27;s uh something you would you would agree with at the time or uh is there like a different sort of</p>
<h2>Gemini Origin Story + Organizational Memo</h2>
<p>postmortm &gt;&gt; the brain marketplace for computers &gt;&gt; compute quotas where basically he was like okay the like &gt;&gt; David worked at OpenAI as VP engine then he worked at Google he was like fundamentally open was willing to go all in like bet the farm on one thing whereas Google was more democratic like everyone had a &gt;&gt; had a quota and I was like okay like like if if you believe in scaling as an important thing that&#x27;s a that&#x27;s an important organizationalwide decision to do. &gt;&gt; Yeah. Uh yeah, I mean I think uh I would somewhat agree with that. I mean I think</p>
<p>I actually wrote a one-page memo saying we were being stupid by uh fragmenting our resources. &gt;&gt; Um so in particular at the time we had uh you know uh efforts within Google research on uh and and in the brain team in particular on large language models. We also had efforts on multimodal models um in uh other parts of brain and and Google research and then legacy deep mind had uh efforts like um chinchilla models and uh flamingo models. Uh and so</p>
<p>really we were fragmenting not only our compute uh across those separate efforts but also our best people and our best ideas, right? And so I said this is just stupid. Why don&#x27;t we combine things and have one effort to uh train &gt;&gt; and this is the merge. Yeah. &gt;&gt; To train an awesome single unified model that is multimodal from the start that&#x27;s good at everything and that was the origin of the Gemini effort and my one page memo worked which is good. &gt;&gt; Did you have the name because also for</p>
<p>those who don&#x27;t know you named Gemini. &gt;&gt; I did. Yeah. [laughter] Yeah. There was there was another name proposed and I I said, you know, it&#x27;s sort of like these two organizations really are like uh twins &gt;&gt; in some sense coming together. Um so I kind of like that. And then there&#x27;s also the NASA interpretation of you know the early Gemini project &gt;&gt; uh being an important thing on your way to um you know the Apollo project. So it seemed like a good name. Twins coming together,</p>
<h2>Coding with AI &amp; Agent Interaction Style</h2>
<p>&gt;&gt; right? Yeah. Nice. Um, I know we&#x27;re already running out of time, but I&#x27;m curious how you use AI today to code. So, I mean, you&#x27;re probably one of the most prolific engineers in the history of computer science. Um, I was reading on through the article about you and Sanji&#x27;s friendship and how you work together [clears throat] and &gt;&gt; you have one quote about you need to find someone that you&#x27;re going to pair program with who&#x27;s compatible with your way of thinking so that the two of you together are a complimentary force. Mhm. &gt;&gt; And I was thinking about how you think about coding agents in this like how do you shape</p>
<p>&gt;&gt; a coding agents to be compatible with your way of thinking like h how would you rate the tools today? Like where should things go? &gt;&gt; Yeah. I mean first I think the coding tools are you know getting vastly better compared to where they were a year or two two years ago. So now you can actually rely on them to do more complex things that you as a as a software engineer want to accomplish and you can sort of delegate you know pretty complex things to these tools. And I think one really nice aspect about the uh interaction between a a human uh</p>
<p>software engineer and a a coding model that they&#x27;re working with is your way of talking to that uh coding model actually sort of uh dictates how it interacts with you, right? Like you could ask it please write a bunch of good tests for this. You could ask it, please help me brainstorm performance ideas. And your way of doing that is going to shape how the model responds, what kinds of problems it tackles. You know, how much do you want the model to go off and do</p>
<p>things that are larger and more independent versus interact with it more to make sure that you&#x27;re shaping the right kinds of of things? And I think it&#x27;s not the case that any one style is the right thing for everything, right? like some kinds of problems you actually want uh maybe a more frequent interaction style with the model and other ones you&#x27;re just like, &quot;Yeah, please just go write this cuz I I know I need this thing. I can specify it well enough.&quot; Um and go off and do it and come back when you&#x27;re done. And so I do think there&#x27;s going to be more of a style of having lots of independent uh</p>
<p>software agents off doing things on your behalf and figuring out the right sort of human computer interaction model and UI and so on for when should it interrupt you and say hey I need a little more guidance here or I&#x27;ve done this thing now what now what should I do? Um I think we we&#x27;re not at the end all answer to that question and as the models get better that uh set of decisions you put into how the interaction should happen may may change right like if you if you have a team of 50 interns how would you manage that if</p>
<p>they were people and I think it&#x27;s not &gt;&gt; do you want 50 interns [laughter] &gt;&gt; you might if they&#x27;re really good right &gt;&gt; it&#x27;s a lot of management &gt;&gt; but but it&#x27;s a lot of Uh yeah, I mean I think that is probably within the realm of possibilities that lots of people could have 50 interns &gt;&gt; and so how would you actually deal with that as a person, right? Like you would probably want them to form small sub teams so you don&#x27;t have to interact with 50 of them. You could interact with five of five of those teams and they&#x27;re off doing things on your behalf.</p>
<p>But I don&#x27;t know exactly what the how this is going to unfold. &gt;&gt; Yeah. How do you think about bringing people like the pair programming is always helpful to like get net new ideas in the distribution so to speak? It feels as we have more of these coding agents write the code. It&#x27;s hard to bring other people into the problem. Say you go to like you know you have 50 interns [clears throat] right and then you want to go to nom shazir be like hey nom I want to like pair on this thing &gt;&gt; but now there&#x27;s like this huge amount of work that has been done in parallel that you need to catch him up on &gt;&gt; right</p>
<p>&gt;&gt; and I&#x27;m curious like if people are going to be in a way more isolated in their teams where it&#x27;s like okay there&#x27;s so much context in these 50 interns that it&#x27;s just hard for me to like relay everything back to you &gt;&gt; maybe I mean on the other hand like imagine a classical software or organization without any AI assisted tools, right? You would have, you know, 50 people doing stuff and their interaction style is going to be naturally very hierarchical because, you know, these 50 people are going to</p>
<p>be working on this part of the system and not interact that much with these other people over here. But if you have, you know, five people each managing 50 virtual agents, you know, they might be able to actually have much higher bandwidth communication among the five people uh than you would have among five people who are also trying to coordinate, you know, a 50 person software team each. Yeah. So, &gt;&gt; how do you I&#x27;m curious how you change your just working rhythm, you know, like do you spend more time ahead with people going through specs and design goals</p>
<p>like</p>
<h2>Prompting Skills &amp; Spec Design</h2>
<p>&gt;&gt; um I mean I do think it&#x27;s interesting that you know whenever people were taught how to write software they were taught that it&#x27;s really important to write specifications super clearly. But no one really believed that. Like it was like yeah whatever I don&#x27;t need to do that I&#x27;m going to [laughter] &gt;&gt; really &gt;&gt; I don&#x27;t know. I mean, writing the English the English language specification was never kind of an artifact that was really paid a lot of attention to. I mean, it was important, but it wasn&#x27;t sort of the thing that drove the actual creative process quite as much as if you</p>
<p>specify what software you want the agent to write for you, you&#x27;d better be pretty darn careful in how you specify that because that&#x27;s going to dictate the quality of the output, right? like if you if you don&#x27;t cover that it needs to handle this kind of thing or that this is a super important corner case or that you know you really care about the performance of this part of it you know it may uh not do what you want and the better you get at interacting with these models and and I think one of the ways people will get better is they will get really good at crisply specifying things</p>
<p>rather than leaving things to ambiguity &gt;&gt; and that is actually probably not a bad It&#x27;s not a bad skill to have regardless of whether you&#x27;re a software engineer or a you know trying to do some other kind of uh task. You know, being able to crisply specify what it is you want. It&#x27;s going to be really important. &gt;&gt; Yeah. My joke is um you know, good prompting [clears throat] is in uh indistinguishable from sufficially advanced executive communication. Like it&#x27;s like writing an internal memo. Like &gt;&gt; Yeah. Yeah. &gt;&gt; Weigh your words very carefully. And also I think very important to be multimodal, right? I think one thing</p>
<p>that anti-gravity from from Google also did was like just come out the gate very very strong multimodal including videos and that&#x27;s the highest bandwidth communication prompt that you can give the &gt;&gt; the model which is fantastic. &gt;&gt; Yeah. &gt;&gt; How do you collect things that you often you would have in your mind. So you have this amazing like performance hints thing that you wrote about how to look for performance improvements and is there a lot more value in like people writing these like generic things down so that they can then put them back as like potential retrieval artifacts for the model like or do I have like the</p>
<p>edge cases is like a good example right it&#x27;s like [snorts] if you&#x27;re building systems you already have in your mind specific edge cases depending on it but now you have to like every time repeat it &gt;&gt; like are you having people spend a lot more I&#x27;m writing out more generic things to bring back or &gt;&gt; um I mean [snorts] I do think [clears throat] well-written guides of of how to do good software engineering are going to be useful because they can be used as input to models or you know read by other developers so that their prompts are you know more clear about what the the underlying software system</p>
<p>should should be doing. Um, you know, I think it may not be that you need to create a custom one for every situation. If you have general guides and put those into, you know, the context of a coding agent that that can be helpful like in you can imagine one for distributed systems. You could say, okay, think about failures of these kinds of things and these are some techniques you can deal with failures. you know, you can have uh, you know, Paxos like replication or, you know, you can, uh, send the request to two places and</p>
<p>tolerate failure because you only need one of them to come back. You know, a little description of 20 techniques like that in building distributed systems probably would go a long way to having a coding agent be able to sort of cobble up more reliable and robust distributed systems. &gt;&gt; Yeah. Yeah. [clears throat] Wonder when Gemini will be able to build spanner, &gt;&gt; right? Probably already has the code inside, you know. [laughter] &gt;&gt; Yeah, that I mean that&#x27;s a good example, right? When you have like you know the cap theorem and it&#x27;s like well this is like truth and you cannot break that and</p>
<p>then you build something that broke it. Like I&#x27;m curious like models in a way are like [clears throat] what did he say he broke it? Would you say you broke cat theorem? &gt;&gt; Really? Yeah. Okay. All right. &gt;&gt; I mean [laughter] &gt;&gt; under local assumptions. Yeah. And some and they&#x27;re like, you know, good clocks. &gt;&gt; Yeah. [laughter] It&#x27;s like some sometimes you don&#x27;t have to like always follow what is known to be true. And I I think models in a way like if you tell them something, they like really buy into that, you know. Um &gt;&gt; so yeah, just more thinking than any answer on how to fix that. Yeah, my my</p>
<p>uh you know just on this like like big prompting and and uh iteration you know I think that coming back to your latency point um I always I always trying to one one AB test or experiment or benchmark or research I would like is what is the uh performance difference between let&#x27;s say three dumb fast model calls with human alignment because the human will correct &gt;&gt; human alignment means the human looks at the first one and produces a new prompt for the second one as opposed to like you [clears throat] spec it out, you know, you spend a long time writing a pro a big big fat prompt and then you</p>
<p>have a very smart model do it, right? You know, because uh really is is our lacks in performance uh an issue of like, well, you just haven&#x27;t specified well enough. There&#x27;s no universe in which I can produce what you want because you just haven&#x27;t told me, &gt;&gt; right? It&#x27;s underspecified. So, I could produce 10 different things and only one of them is the thing you wanted. &gt;&gt; Yeah. And the multi-turn taking with a flash model is enough. &gt;&gt; Yeah. [laughter]</p>
<h2>Latency Predictions &amp; Tokens/sec Vision</h2>
<p>&gt;&gt; Yeah. I&#x27;m I&#x27;m a big believer in pushing on latency because I think being able to have really low latency interactions with a system you&#x27;re using is just much more delightful than something that is, you know, 10 times as slow or 20 times as slow. And I think, you know, in the future, we&#x27;ll see models that are and and underlying software and hardware systems that are 20x lower latency than what we have today, 50x lower latency. And that&#x27;s going to be really really important for systems that need to do a lot of stuff uh between your interactions.</p>
<p>&gt;&gt; Yeah. Yeah. There&#x27;s two extremes, right? And then meanwhile [clears throat] you also have deep think which is all the way on the other side, &gt;&gt; right? [laughter] But you would use deep think all the time if it weren&#x27;t for cost and latency, right? If if you could have that capability in a model because the latency improvement was 20x uh in the underlying hardware and system and costs, you know, there&#x27;s no reason you wouldn&#x27;t want that. &gt;&gt; Yeah. But at the same time, then you&#x27;d probably have a model that is even better that would take you 20 times longer even on that new hardware.</p>
<p>&gt;&gt; Yeah. Uh you know that there&#x27;s the Fredo curve keeps climbing. Um &gt;&gt; yeah, &gt;&gt; onward and outward. on way. [laughter] &gt;&gt; Yeah. Should we ask him for predictions to to go? I don&#x27;t know if you have any &gt;&gt; predictions that you that you like to keep, you know, like uh one one way to do this is you have your tests whenever a a new model comes out that you run. Uh what&#x27;s something that you&#x27;re not quite happy with yet that you think will get done soon? &gt;&gt; Um</p>
<h2>Future Predictions: Personal Models &amp; Hardware</h2>
<p>let me make two predictions that are not quite in that vein. &gt;&gt; Yeah. So I think a personalized model that knows you and knows all your state and is able to retrieve over all state you have access to that you opt into is going to be incredibly useful compared to a more generic model that doesn&#x27;t have access to that. So like can something attend to everything I&#x27;ve ever seen, every email, every photo, every video I&#x27;ve watched. That&#x27;s going to be really useful. uh I think uh more and more specialized hardware is going to</p>
<p>enable much lower latency models and much more capable models for affordable prices uh than say the current current status quo. Uh that&#x27;s going to be also quite important. &gt;&gt; Yeah. When you say much lower latency, uh people usually talk in tokens per second. Is that a term that is okay? Okay. Uh you know [clears throat] we&#x27;re at let&#x27;s say 100 now. Yeah, we can go to the thousands. Is it meaningful to go 10 thousands? &gt;&gt; Yes. &gt;&gt; Really? Okay. &gt;&gt; Absolutely. Right. &gt;&gt; Yeah. Because of chain of thought and all</p>
<p>&gt;&gt; chain of thought reasoning. I mean you could think you know uh many more tokens. You could do many more parallel rollouts. You could generate way more code uh and check that the code is correct with uh chain of thought reasoning. So I think you know being able to do that at 10,000 tokens per second would be awesome. &gt;&gt; Yeah. At 10,000 tokens per second you are no longer reading code. Yeah. like you&#x27;ll just generate it. You&#x27;ll not remember it may not it may not &gt;&gt; end up with 10,000 tokens of code a thousand tokens of code that with 9,000 tokens of reasoning behind it. &gt;&gt; Yeah. Yeah.</p>
<p>&gt;&gt; Which would actually be probably much better code to read.</p>
<h2>Closing</h2>
<p>&gt;&gt; Yeah. Yeah. &gt;&gt; Yeah. If I had more time, I would have written a shorter letter. &gt;&gt; Yeah. Yeah. &gt;&gt; Um awesome, Jeff. This was amazing. Thanks for making the time. &gt;&gt; Thank you. It&#x27;s been it&#x27;s been fun. Thanks for having me. &gt;&gt; [music]</p>]]></content:encoded>
      <guid isPermaLink="false">https://www.youtube.com/watch?v=F_1oDPWxpFQ</guid>
      <pubDate>Thu, 12 Feb 2026 22:03:01 +0000</pubDate>
    </item>
    <item>
      <title>Inside AI’s $10B+ Capital Flywheel — Martin Casado &amp; Sarah Wang of a16z</title>
      <link>https://www.youtube.com/watch?v=p1k7TiAFqdE</link>
      <description>From pioneering software-defined networking to backing many of the most aggressive AI model companies of this cycle, Martin Casado and Sarah Wang sit at the center of the capital, compute, and talent arms race reshaping the tech industry. As partners at a16z investing across infrastructure and growth, they’ve watched venture and growth blur, model labs turn dollars into capability at unprecedented speed, and startups raise nine-figure rounds before monetization.

Martin and Sarah join us to unpack the new financing playbook for AI: why today’s rounds are really compute contracts in disguise, how the “raise → train → ship → raise bigger” flywheel works, and whether foundation model companies can outspend the entire app ecosystem built on top of them. They also share what’s underhyped (boring enterprise software), what’s overheated (talent wars and compensation spirals), and the two radically different futures they see for AI’s market structure.

We discuss:
• Martin’s “two futures” fork: infinite fragmentation and new software categories vs. a small oligopoly of general models that consume everything above them
• The capital flywheel: how model labs translate funding directly into capability gains, then into revenue growth measured in weeks, not years
• Why venture and growth have merged: $100M-$1B hybrid rounds, strategic investors, compute negotiations, and complex deal structures
• The AGI vs. product tension: allocating scarce GPUs between long-term research and near-term revenue flywheels
• Whether frontier labs can out-raise and outspend the entire app ecosystem built on top of their APIs
• Why today’s talent wars ($10M+ comp packages, $B acqui-hires) are breaking early-stage founder math
• Cursor as a case study: building up from the app layer while training down into your own models
• Why “boring” enterprise software may be the most underinvested opportunity in the AI mania
• Hardware and robotics: why the ChatGPT moment hasn’t yet arrived for robots and what would need to change
• World Labs and generative 3D: bringing the marginal cost of 3D scene creation down by orders of magnitude
• Why public AI discourse is often wildly disconnected from boardroom reality and how founders should navigate the noise

Substack Article w/Show Notes: https://www.latent.space/p/a16z

—

Martin Casado
• LinkedIn: https://www.linkedin.com/in/martincasado/
• X: https://x.com/martin_casado

Sarah Wang
• LinkedIn: https://www.linkedin.com/in/sarah-wang-59b96a7
• X: https://x.com/sarahdingwang

a16z
• https://a16z.com/

Timestamps
Intro: Live from a16z
The New AI Funding Model: Venture + Growth Collide
Circular Funding, Demand &amp; “No Dark GPUs”
Infrastructure vs Apps: The Lines Blur
The Capital Flywheel: Raise → Train → Ship → Raise Bigger
Can Frontier Labs Outspend the Entire App Ecosystem?
Character AI &amp; The AGI vs Product Dilemma
Talent Wars, $10M Engineers &amp; Founder Anxiety
What’s Underinvested? The Case for “Boring” Software
Robotics, Hardware &amp; Why It’s Hard to Win
Custom ASICs &amp; The $1B Training Run Economics
American Dynamism, Geography &amp; AI Power Centers
How AI Is Changing the Investor Workflow (Claude Cowork)
Two Futures of AI: Infinite Expansion or Oligopoly?
If You Can Raise More Than Your Ecosystem, You Win
Are All Tasks AGI-Complete? Coding as the Test Case
Cursor &amp; The Power of the App Layer
World Labs, Spatial Intelligence &amp; 3D Foundation Models
Thinking Machines, Founder Drama &amp; Media Narratives
Where Long-Term Power Accrues in the AI Stack</description>
      <content:encoded><![CDATA[<p><em>No transcript available for this video.</em></p>]]></content:encoded>
      <guid isPermaLink="false">https://www.youtube.com/watch?v=p1k7TiAFqdE</guid>
      <pubDate>Thu, 19 Feb 2026 16:47:08 +0000</pubDate>
    </item>
    <item>
      <title>SWE-Bench Verified is Contaminated: What Comes Next — with OpenAI Frontier Evals team</title>
      <link>https://www.youtube.com/watch?v=0HaUD_olwQU</link>
      <description>Olivia Watkins (Frontier Evals team) and Mia Glaese (VP of Research at OpenAI, leading the Codex, human data, and alignment teams) discuss a new blog post (https://openai.com/index/why-we-no-longer-evaluate-swe-bench-verified/) arguing that SWE-Bench Verified—long treated as a key “North Star” coding benchmark—has become saturated and highly contaminated, making it less useful for measuring real coding progress. 

SWE-Bench Verified originated as a major OpenAI-led cleanup of the original Princeton SWE-Bench benchmark, including a large human review effort with nearly 100 software engineers and multiple independent reviews to curate ~500 higher-quality tasks. But recent findings show that many remaining failures can reflect unfair or overly narrow tests (e.g., requiring specific naming or unspecified implementation details) rather than true model inability, and cite examples suggesting contamination such as models recalling repository-specific implementation details or task identifiers. 

From now on, OpenAI plans to stop reporting SWE-Bench Verified and instead focus on SWE-Bench Pro (from Scale), which is harder, more diverse (more repos and languages), includes longer tasks (1–4 hours and 4+ hours), and shows substantially less evidence of contamination under their “contamination auditor agent” analysis. 

We also discuss what future coding/agent benchmarks should measure beyond pass/fail tests—longer-horizon tasks, open-ended design decisions, code quality/maintainability, and real-world product-building—along with the tradeoffs between fast automated grading and human-intensive evaluation. 

 Meet the Frontier Evals Team
 Why SWE Bench Stalled
 How Verified Was Built
 Contamination In The Wild
 Unfair Tests And Narrow Specs
 When Benchmarks Saturate
 Switching To SWE Bench Pro
 What Great Coding Evals Measure
 Beyond Tests Dollars And Autonomy
 Preparedness And Future Directions</description>
      <content:encoded><![CDATA[<p><em>No transcript available for this video.</em></p>]]></content:encoded>
      <guid isPermaLink="false">https://www.youtube.com/watch?v=0HaUD_olwQU</guid>
      <pubDate>Mon, 23 Feb 2026 18:33:04 +0000</pubDate>
    </item>
    <item>
      <title>Claude Code, the Finance Junior Analyst + The Global Memory Shortage: Doug O'Laughlin, SemiAnalysis</title>
      <link>https://www.youtube.com/watch?v=x9rWFiIubmc</link>
      <description>A special double pod on the 1 year anniversary of Claude Code: we chat with one of its most vocal fans, who thinks it will write 25-50% of all code on GitHub, plus get a breakdown on the memory crunch

 AI Slop vs Expertise
 Reconnecting and Origin Stories
 Falling for Semiconductors
 Moores Law Thesis and Nvidia
 Claude Code Awakening
 Agent Swarms Reality Check
 Claude Bot Security Limits
 Claude Code Workflow Setup
 Hygiene and Junior Analysts
 GDPval and Economic Impact
 Railroad CapEx Parallel
 Funding Bubbles and Demand
 AI as Junior Analysts
 Death of the IDE
 Microsoft and Oracle Stakes
 TPU Window Opens
 Supply Chain Reality Check
 HBM Memory Squeeze
 Context Rationing Era
 Writing And Trail Lessons</description>
      <content:encoded><![CDATA[<p><em>No transcript available for this video.</em></p>]]></content:encoded>
      <guid isPermaLink="false">https://www.youtube.com/watch?v=x9rWFiIubmc</guid>
      <pubDate>Tue, 24 Feb 2026 20:30:38 +0000</pubDate>
    </item>
    <item>
      <title>🔬Max Welling: Materials Underlie Everything</title>
      <link>https://www.youtube.com/watch?v=V7_Ec2WFAWs</link>
      <description>In this episode recorded at NeurIPS 2025, Max Welling traces the intellectual thread connecting quantum gravity, equivariant neural networks, diffusion models, and climate-focused materials discovery.

We begin with a provocative framing: experiments as computation. Welling describes the idea of a “physics processing unit”—a world in which digital models and physical experiments work together, with nature itself acting as a kind of processor. It’s a grounded but ambitious vision of AI for science: not replacing chemists, but accelerating them.

Along the way, we discuss:
- Why symmetry and equivariance matter in deep learning
- The tradeoff between scale and inductive bias
- The deep mathematical links between diffusion models and stochastic thermodynamics
- Why materials—not software—may be the real bottleneck for AI and the energy transition
- What it actually takes to build an AI-driven materials platform

Welling reflects on moving from curiosity-driven theoretical physics (including work with Gerard 't Hooft) toward impact-driven research in climate and energy. The result is a conversation about convergence: physics and machine learning, digital models and laboratory experiments, long-term ambition and incremental progress.

Timestamps
 Introduction to Max Welling and the concept of Physics Processing Units (PPUs)
 Max’s career evolution: From quantum gravity to climate-focused AI
 Physics as the "thread": Symmetries, gauge theory, and stochastic thermodynamics
 The explosion of "AI for Science" and the emerging investment bubble
 Successes in protein folding and machine learning inter-atomic potentials
 Why materials matter: The physical foundation of the AI software layer
 Transforming material discovery into a search engine problem
 The origin and mission of CuspAI: Solving carbon capture
 CuspAI’s platform architecture: Generative models, digital twins, and agents
 The role of humans in the loop: Moving from manual workflows to automation
 Strategy for breakthroughs: Lighthouse moonshots vs. incremental partnerships
 Technical Deep Dive: Explaining Equivariance and symmetry in neural networks
 The "Bitter Lesson" in the context of scientific inductive biases
 Preview of "Generative AI and Stochastic Thermodynamics" (Upcoming Book)</description>
      <content:encoded><![CDATA[<p><em>No transcript available for this video.</em></p>]]></content:encoded>
      <guid isPermaLink="false">https://www.youtube.com/watch?v=V7_Ec2WFAWs</guid>
      <pubDate>Wed, 25 Feb 2026 17:19:37 +0000</pubDate>
    </item>
    <item>
      <title>How models memorize from one pass #substack #shorts</title>
      <link>https://www.youtube.com/shorts/aS-kuCwRBt4</link>
      <description>This is a clip from https://www.latent.space/p/paid-anthropic-distillation-and-how?utm_source=youtube_shorts

See the full video: https://www.youtube.com/watch?v=7EBQ04OL-is

#shorts #substack</description>
      <content:encoded><![CDATA[<p><em>No transcript available for this video.</em></p>]]></content:encoded>
      <guid isPermaLink="false">https://www.youtube.com/shorts/aS-kuCwRBt4</guid>
      <pubDate>Thu, 26 Feb 2026 21:07:43 +0000</pubDate>
    </item>
    <item>
      <title>Why SweetBench slipped through #substack #shorts</title>
      <link>https://www.youtube.com/shorts/cxHHpCpaWTY</link>
      <description>This is a clip from https://www.latent.space/p/paid-anthropic-distillation-and-how?utm_source=youtube_shorts

See the full video: https://www.youtube.com/watch?v=7EBQ04OL-is

#shorts #substack</description>
      <content:encoded><![CDATA[<p><em>No transcript available for this video.</em></p>]]></content:encoded>
      <guid isPermaLink="false">https://www.youtube.com/shorts/cxHHpCpaWTY</guid>
      <pubDate>Thu, 26 Feb 2026 21:07:50 +0000</pubDate>
    </item>
    <item>
      <title>Privacy or policing? #substack #shorts</title>
      <link>https://www.youtube.com/shorts/aa9CthKlPH4</link>
      <description>This is a clip from https://www.latent.space/p/paid-anthropic-distillation-and-how?utm_source=youtube_shorts

See the full video: https://www.youtube.com/watch?v=7EBQ04OL-is

#shorts #substack</description>
      <content:encoded><![CDATA[<p><em>No transcript available for this video.</em></p>]]></content:encoded>
      <guid isPermaLink="false">https://www.youtube.com/shorts/aa9CthKlPH4</guid>
      <pubDate>Thu, 26 Feb 2026 21:07:54 +0000</pubDate>
    </item>
    <item>
      <title>‘You guys are so inefficient’ #substack #shorts</title>
      <link>https://www.youtube.com/shorts/T3dVFTCXzKE</link>
      <description>This is a clip from https://www.latent.space/p/paid-anthropic-distillation-and-how?utm_source=youtube_shorts

See the full video: https://www.youtube.com/watch?v=7EBQ04OL-is

#shorts #substack</description>
      <content:encoded><![CDATA[<p><em>No transcript available for this video.</em></p>]]></content:encoded>
      <guid isPermaLink="false">https://www.youtube.com/shorts/T3dVFTCXzKE</guid>
      <pubDate>Thu, 26 Feb 2026 21:07:54 +0000</pubDate>
    </item>
    <item>
      <title>Dylan Patel Explains the AI War While Cooking | In-Context Cooking</title>
      <link>https://www.youtube.com/watch?v=UwnqWAYOjPU</link>
      <description>In this episode, we have Dylan Patel founder and CEO of SemiAnalysis joining us to recreate restaurant-style chicken fried rice. From semiconductor bottlenecks and Nvidia’s paranoia, to $200B hyperscaler capex and why Big Tech may sacrifice profits for AI dominance, we cover all the hot topics of the AI arms race.

We talk about:
• Why the AI infrastructure race is accelerating
• The real semiconductor bottleneck
• Taiwan endgame scenarios
• AI backlash and political risk
• Nvidia vs. vertical integration
• What happens when hyperscalers stop optimizing for profit
Intro
Guest Introduction
Guessing the Dish
From Beekeeper to Semiconductor Powerhouse
Starting the SemiAnalysis Blog
Part 1: Cooking
Velveting Chicken &amp; Talking Taiwan/TSMC Endgames
China, Taiwan &amp; Semiconductor Geopolitics
AI Talent, Export Controls &amp; U.S. China Tensions
Is AI a Bubble? Hyperscaler CapEx Explosion
Claude Code, GitHub Commits, &amp; AI Adoption Acceleration
Why Markets Hate $200B AI Spending
The Hyperscaler Innovator’s Dilemma
Who Wins the Chip War? Nvidia vs Vertical Integration
Jensen Huang &amp; The Paranoid Founder Advantage
What’s the Real Bottleneck in AI Progress?
The Semiconductor Fab Constraint
Part 2: Tasting
Slop vs Technique: Flavor Philosophy Debate
Hiring at SemiAnalysis &amp; AI Infrastructure Alpha
Final Verdict: Whose Fried Rice Wins?</description>
      <content:encoded><![CDATA[<p><em>No transcript available for this video.</em></p>]]></content:encoded>
      <guid isPermaLink="false">https://www.youtube.com/watch?v=UwnqWAYOjPU</guid>
      <pubDate>Thu, 26 Feb 2026 21:15:18 +0000</pubDate>
    </item>
    <item>
      <title>Measuring Exponential Trends Rising (in AI) — Joel Becker, METR</title>
      <link>https://www.youtube.com/watch?v=9QSm_mRGpN8</link>
      <description>Joel Becker explains METR’s focus on Model Evaluation and Threat Research to assess whether AI could pose enormous or catastrophic risks. Becker discusses METR’s publicized work such as the time horizon chart (task difficulty measured in human-time at 50% reliability), how tasks are selected and constrained (economic relevance, auto-grading, non-messy scope), and why time horizon is often misinterpreted as how long agents run. They cover Opus 4.5’s perceived jump, challenges redoing developer productivity RCTs as workflows and adoption change, and why current models aren’t yet catastrophically dangerous while discontinuous capability gains remain possible if R&amp;amp;D loops fully automate. Becker also summarizes research linking compute growth slowdowns to slower capability progress, describes his Manifold trading story driven by a charity market he could influence, notes mixed social value of prediction markets, and previews METR’s 2026 plans, safeguards work, and hiring.

 What METR Does
 Podcast Intro
 Threat Models Shift
 Time Horizon Origin
 Choosing Eval Tasks
 Messy Real Work
 HCAST And RE Bench
 Human Time Misread
 Opus 4.5 Surprise
 Redoing Uplift RCTs
 Measuring Productivity
 Why Not Dangerous Yet
 Capability Explosion
 Benchmarks Miss Tail
 Beyond One Number
 Compute Slows Progress
 Algorithms Need Compute
 Lab Spend and Visibility
 Cluster Timelines and Shipping
 Prediction Markets and Models
 Manifold Trading Story
 Ethics and Insider Info
 Beyond Benchmarks Evals
 Harnesses and Scaffolding
 METER Roadmap and Hiring
 Karaoke and Human Voice
 Closing Thoughts</description>
      <content:encoded><![CDATA[<p><em>No transcript available for this video.</em></p>]]></content:encoded>
      <guid isPermaLink="false">https://www.youtube.com/watch?v=9QSm_mRGpN8</guid>
      <pubDate>Fri, 27 Feb 2026 18:46:42 +0000</pubDate>
    </item>
    <item>
      <title>⚡️ Polsia: Solo Founder Tiny Team from 0 to 1m ARR in 1 month &amp; the future of Self-Running Companies</title>
      <link>https://www.youtube.com/watch?v=Yw-m0PI2Atk</link>
      <description>https://x.com/bencera_/status/2027825976261111966?s=20</description>
      <content:encoded><![CDATA[<p><em>No transcript available for this video.</em></p>]]></content:encoded>
      <guid isPermaLink="false">https://www.youtube.com/watch?v=Yw-m0PI2Atk</guid>
      <pubDate>Sun, 01 Mar 2026 02:30:04 +0000</pubDate>
    </item>
  </channel>
</rss>
