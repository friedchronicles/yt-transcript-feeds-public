<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Transcripts: Oxide Computer Company</title>
    <link>https://friedchronicles.github.io/yt-transcript-feeds-public/oxide-and-friends.xml</link>
    <description>YouTube video transcripts from Oxide Computer Company</description>
    <atom:link href="https://friedchronicles.github.io/yt-transcript-feeds-public/oxide-and-friends.xml" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <language>en</language>
    <lastBuildDate>Wed, 18 Feb 2026 13:01:16 +0000</lastBuildDate>
    <item>
      <title>Oxide and Friends 12/1/2025 -- Death by Uptime</title>
      <link>https://www.youtube.com/watch?v=JFtCJVxuug8</link>
      <description>We hit a new (and disturbing!) failure mode recently when a production rack that had been up for several months saw every (!) compute sled's service processor become simultaneously unresponsive. Bryan and Adam were joined by the members of the Oxide team who debugged the vexing issue -- and reached its surprising root cause.

Context: https://github.com/oxidecomputer/hubris/issues/2304
Notes: https://github.com/oxidecomputer/oxide-and-friends/blob/master/2025_12_01.md</description>
      <content:encoded><![CDATA[<p><strong>[00:00]</strong></p>
<p>Full enough house. >> Full enough house. Uh yeah, that this was a this was a wild one. This was a really wild one. So, I'm going to give you my uh if you don't mind, I I'm going to give you kind of my introduction to this problem, Adam, and then will maybe we can back up and get your introduction to this problem and kind of go forward from there. Um because my intro to the problem was I come into the office and I think on a meeting and Robert came up to me Robert of holistic engineer fame. So</p>
<p>we can we can ring the chime even though people on YouTube >> the much the much loved chime >> the much loved chime. We we will be we we we've heard your comment on YouTube and we'll be ringing the chime a lot. We will be making as many possible references to previous episodes. But um Robert of host engineer fame uh came up to me with a wild look in his eyes and I mean Adam you have known Robert for a very long time. >> Yeah. W a wild look in the eyes is not</p>
<p>common from Robert. I mean that like that alone is enough to I mean recall just to just to get that chime really working um during when we had the data center reboot when we rebooted the data center. Robert was the one who was actually like healing the water. Cool. I was one that I thought I thought I was going to pass out and or vomit on my keyboard. I bet. But Robert was actually like the cool head in the room. >> No, if Robert's panicking, it's because the fire station itself has burned down. >> That's right. That's right. So, Robert comes up to me with a wild look in his</p>
<p>eyes and like I'm like I was clearly on a call, but it was like so okay. I mean, obviously, yes, Robert, what is it? And Robert says, "If I attempt to write to a device address via MDU minus KW, do you think it'll let me?" [snorts] And I'm like, "Oh, where where are we right now?" It is. Do you ever watch Quantum Leap? That show? >> Yes. I couldn't quote, you know, chapter and verse from it, but yeah. >> I mean, I can Matt, have you ever Matt, I'm sorry to to As a as a token</p>
<p>millennial, can you just does quantum leap ring any bells? Um, as we've learned in previous episodes, uh, if it wasn't featured on Spongebob, uh, it might not have left the generational chasm. I I can't imagine that it would. >> We had >> Yeah. >> Okay. So, good cliff. You You've seen you've heard of Quantum Leap. >> I'm familiar with it. Yeah, we had reruns on satellite. >> Yeah. There you go. Okay. So the quantum leap was a pretty like interesting show because the guy would travel into someone else's body and part of the like in the beginning of the show he's trying</p>
<p>to figure out like where am I? Like I've arrived in a new body and I've got no idea like I clearly this body knows something that's going. I felt like that I had that feeling of like okay I've obvious I've been transported into the middle of this problem where where we are asking if if writing to device memory is going v. So what Robert is asking is that I do a a a write via the</p>
<p><strong>[03:00]</strong></p>
<p>kernel debugger. MB minus KW and MDB is is our debugger. MD minus K is running it such as it's debugging the kernel. The W flag denotes I want to actually write to memory which is obviously like wait a minute is that like is this a debugger or is this a destroyer? It's like well line gets blurry. >> That's right. But but any any idea that is like MDB minus KW it's like all it raises raises certain goosebumps right like that >> what's the craziest thing you've done MD minus KW Adam</p>
<p>>> uh I have um changed locking primitives so that uh everyone gets a lock that's [laughter] the I've just changed it so that like it doesn't just like whoever wants for a lock wants a lock gets a lock. Uh, no. This was not on a production system. One assumes. [laughter] >> No, no, no. What is the craziest thing you've done on a production system? >> Uh, probably changed an instruction to like um, you know, uh, to like bounce over a like, you know, a condition</p>
<p>basically. Uh but that felt very it feels very sticky because you're like if I have computed this instruction incorrectly, we are going to we're going to bounce into outer space. >> That's right. Um I for me it was I changed the branch displacement to uh to I changed a particular um or I call displacement actually. Um I change to change a CV broadcast into a CV signal. >> That's exciting. Oh, it was super</p>
<p>exciting and this was on a definitely a hot customer system where the customer was upset. This is back in Sundays and you remember you remember Jesse, our our our dear friend that we'd worked with and uh this was a customer that he'd been working with >> and Jesse got very nervous when I started asking him permission for what I was about to do. He's like, "Wait, why are you asking like what why are you asking why are you so uncertain about what you're about to do? Like here's the the surgeon is not supposed to be asking me these kinds of questions. Why is the surgeon asking me permission in this</p>
<p>regard? Like is >> just to roll it back. You're like I'm seeing this thundering herd. >> So what if instead of waking up everybody we just wake up somebody >> and Yeah. Yeah. >> And like that'll probably that could be fine. >> Assuming I did all all this correctly. assuming [laughter] I I turned this CV broadcast into a call the CV signal and not a call into the middle of of an illegal instruction and or anything else that I could turn >> and you're probably like well if it does wedge up the system I could probably turn it back and maybe the system will</p>
<p>unwedge too. >> Um [laughter] I I did not really have no know I I kind of knew that there was no insurance policy this was going to be kind of a one-way trip. Uh, and I did start asking Jesse, "What are the consequences of this? If this system were to reboot right now, what would be the consequences?" And Jesse's like, "Not good." Like, "Why are you ask why are you asking me that?" That's a weird question to ask me. It's like, you know, it's like your surgeon asking you just like, "Oh, you know, are your your</p>
<p><strong>[06:01]</strong></p>
<p>affairs are in order?" So, like you do have a will, right? I mean, obviously, I mean, obviously you got a will. Me, my god, you you clearly done the most basic adult things. You're like, um, >> feel like it's more like your dentist asking that, but yeah, >> it's like your dentist asking [laughter] why. Uh, this is a super. Do you ask this for No, no. Just like this is a pretty I don't know. This is a little adventurous this one. This root canal is a little more adventurous than the ones I've done. And I just want to make sure just asking you your fair share or you've got like you know you don't want you don't want your you want your kids to be able to you know they're already</p>
<p>going to be devastated enough having lost a parent. You don't want them to be financially ruined. Um you're like what? Um no. So I it worked. I'd like to say it all worked and uh I was relieved and then maybe too relieved. Jesse thought I was a little too relieved and realized that like I should not have allowed you to do that. Okay, so Robert is asking me if he can write to device memory via MV minus KW. And I'm like if it did allow you to do that that would be that itself would be a bug. Like we don't that is like what do you want to do? And what Robert quickly explained and will this</p>
<p>is where we're going to jump to you to get more context is like he said so this is a customer system. We have lost contact with all service processors. And I'm like, what do you mean all? It's like every compute sled, we cannot talk to the service processor on any compute sled. Hosts are up, but all service processors are at this point like I can say, yeah, wildlook is definitely merited. And so what Robert like what Robert wanted to do, so what the first</p>
<p>thing what we needed to figure out and again we'll go to you to get more context on all this. Um, and I know Matt you jumped in here early too. We want to determine, you know, how dead is the service processor actually and how can we get what we can tell because the service processor is connected to the network and what we know is we can't reach it over to the network. Um but we or seemingly um we also know the service processor is in charge of certain basic maintenance of the system. Uh the</p>
<p>service processor among other things uh has the thermal loop which Matt wrote. Um, and we know if the service processor goes out to lunch completely, uh, the fans will all crank up. Um, so >> just for a little context, the service processor may be obvious here, but it's the computer within the computer. It's the computer that is is driving the basic kind of autonomic functions of of the of the server uh, as and including things like being able to reboot it or the or the fans as you're saying. >> Yeah, that's right. And I mean, this is</p>
<p>the this is our answer to the baseboard management controller. So we we we do not have a traditional baseboard management controller for a bunch of good reasons. Um and what we have instead is a service processor. So the u but that the SP is definitely important. So and the SP and we'll go into this in detail has been designed with an operating system that Cliff led the charge on Hubris that is designed to be very robust and it is really not</p>
<p><strong>[09:04]</strong></p>
<p>designed to disappear. It was very unusual that it would disappear. And so, uh, the the the reason for the wild look is that what Robert Robert's kind of bonkers idea was so requires a little bit of backstory, but the, um, so, uh, we, um, when we boot the, the service processor talks to the DIMs on the on the box. So there's there is an I squared C bus that the DIMs the the</p>
<p>memory is connected to and there are there's there's some identifying information in those DIMs and it's the service processor that is connected to that bus and gets that information. But the host CPU ultimately needs to get that information in order to train memory. It's got its own I squared C initiator and it when it thinks it's talking to the DIMs, it's actually talking to the service processor. Okay. >> So Okay. So this but this only happens when you boot the host CPU. Once it's</p>
<p>booted, the I squed C controller is like not really used. And one of the things that Robert has discovered over the last I'm not sure when he made this discovery but one of the things he's gotten working over the last couple of months is like so this I square C initiator is hidden from you know we we we talked about uh and um the the kind of the various other uh chips the hidden cores on the die um and we uh and all the</p>
<p>those kind of like the hidden things that we don't see that I C controller is controlled by one of those hidden cores. And what Robert realized is like actually the I squed C controller for that thing is actually mapped into our address space and we the host operating system can actually manipulate that I squed C controller. So we can initiate I squed C. And I'm not even sure like this kind of defies metaphor. I don't even know like we're kind of like borrowing its underwear. I don't know. I mean, I'm not even sure what the So, what Robert wanted to do was uh Robert's like,</p>
<p>actually, what I think we can go do is I can hit this memory mapped region for the I squ C controller and I can force this thing because the host CPU is up. I can force this thing to initiate I squed C transactions and see if the SP can respond to these I squared C transactions um to identify like memory which >> the I was like wow that okay we are really desperate um and uh we and even Robert is like yeah this this feels a</p>
<p>little too adventurous I'm like that definitely like my my CD broadcast a CB signal can just sit If you're going to do this, [laughter] this is definitely next level. Uh so um the but that was coming into this while it was already kind of evolved. So Will, I think you were among the first on scene on this to discover that the service processors were were were down.</p>
<p><strong>[12:05]</strong></p>
<p>What was kind of the the and you were attempting to do uh were kind of supporting another issue and you all noticed that like oh my god these things are all down. Uh how did the kind of things proceed from there? Um, do you want me to give us some context on like what the customer is seeing first? >> Yeah, sure. That'd be great. Yeah, that'd be great. >> Yeah. So, the customer reached out to us because they were they were trying to stop an instance via the CLI and the request was timing out. Um, which typically means that one of the the sleds is down and like isn't able to respond and so the the the request within the rack times out and so the the client times out. Um, so we ask for permission to to connect to the the rack</p>
<p>and they let us let us in. Um, and then we know we list all the hosts and we can see that sled 23 is down. Um, and then at that point we list all the SPs just kind like a matter of course just to like validate that the SP for that sled is there. And then as you said all of the the sleds are gone. We still have the SPS for the two PowerShell controllers um and the two switches but the other um 16 SPS are just completely missing. Uh >> so so like the list like you're able to</p>
<p>list them and it's like yeah I have these two or three that's what you're looking for right >> yeah there's four right [laughter] >> yeah so um so the tool we use to list SPS is called pilot and that has like a streaming feature where you can just like show me all the discoveries you have and so we use that next and we can see it's it's only discovering the the four that we see in the list which makes sense um so we look at the MGS or management gateway service logs next and we can see that you know the we're reaching out So all these SPs and it's timing after 20 seconds and five</p>
<p>attempts. Um so at that point, you know, we we reach out in the the channel and say we don't see any SPS on this this rack. And um you know, Matt and a number of other people hop in from that point to to start to troubleshoot more. And Matt, I'm sure you were like, you can't see you've lost all of them. I the I mean it definitely reminds me of that Far Side cartoon where it's like we paid you to look after the children and you cooked and ate them both when they are coming home to a wicked witch. I mean it feels like you've we've lost all of the SPs that must have been this is not a</p>
<p>failure mode that we've really uh this really shouldn't be possible. >> Yeah. I mean to lose one SP could be seen as careless. To lose 27 of them that's really [laughter] really impressive. Yeah. So, at this point, I get pinged and I'm like, "Oh, it's another quote unquote management network bug." Uh, which is never the management network's fault, but you know, I got to go in and prove that to my satisfaction. Uh, and so I, you know, pop into the system and we have pretty good counters and visibility to like what's going on in the management network where I guess the the context here is the management</p>
<p>network is the separate switch which has all of the SP traffic and then it has a bridge up to the main network. Uh, so we can use this. This is running before the main switch is running. it runs when the system is mostly powered off. And so we start looking at the counters and sure enough we see that we have packet counters for all of the SPS and the packet counters are going up for the</p>
<p><strong>[15:06]</strong></p>
<p>two side cars and the PSC and they are not going up for any of the SPs. So we're like oh well that's a bad sign. Uh that means that no packets are leaving the SP. this like this all checks out, right? Because the the whole point of the broad the way the discovery works is that the SPs are periodically broadcasting a message saying, "Hello, I'm an SP." And if we don't see that message, then it doesn't get through. So, the fact that the packet counters aren't going up, is like, okay, that's understandable, but not great. So, I actually, let me just see. I pulled out, unfortunately, this is in a</p>
<p>customer support ticket, so it's a private repo, but I pulled out my long list of things that we did. >> Oh, yeah. I love that that you were saying that I actually was coming into this several hours of bad ideas in. So I I cannot wait to hear some of the other ideas. >> Yeah, Robert's like, "Let's cut off our own hands was like that was the best idea." [laughter] >> That was exactly that was after several other ideas. >> So one other thing we try is running there's a command called IPCC which talks to the SP over the serial port in the system. Uh so that is like not using the network stack at all obviously and</p>
<p>so we tried using that to talk to the SPs on these stucks sleds and sure enough they didn't talk over IPCC the serial line either. So at this point we're like I'm like okay something has gone wrong and like the kernel has hung in all of these SPS and maybe it's like a timer that has gone wrong or something like that. And I think Robert is like well can we just try to ping the SPS just to see if that works? Uh, and I'm like, "Sure, sure, but that's not going to work." Like the whole system is hung. Uh, and so we, you know, figure out the IP address and we try to ping one of the</p>
<p>SPs and the SP answers on ping. And we see the packet counters go up for like the the two packets that it takes to do uh, ICMP discovery and echo and we're like, "Oh, the SP is still running. This is weirder than we thought." >> Yeah. Totally weird, right? Because we I mean >> Yeah. >> Yeah. Go ahead. No, no, I was going to say that I mean I I think because the expectation there is like when we are dead that the whole that we are the SP is actually dead. The colonel is panicked or something as as so the fact that this or that the networking task is</p>
<p>like totally dead. So the fact that this thing can actually respond to ICMP echoes is kind of wild. Something very weird is going on. The SPs are alive enough to answer pings but dead enough that they can't seem to do anything else. And one thing we know about pings is that pings are actually handled within the net task itself. So it doesn't do dispatch to a different task. And what it seems like now is that like every task below priority five, which is the priority of the net task, is not</p>
<p>running for some reason. And we're not sure why this is happening. I point out that if the net task was always runnable for mysterious reasons, then it would always be selected and that would cause the behavior we saw. But this is still in the like mysterious reasons category. Uh we then I think will do you want to talk a little bit about the like thermal current debugging that we tried to do as well?</p>
<p><strong>[18:06]</strong></p>
<p>>> Sure. Uh yeah so the the SPS will um collect um metrics on on current for the the sleds and then we also have and also from the power shelf controller. So we uh we did this two different ways. Um and we can we can query the metrics um with within the you know kind of like the management system of the rack using uh OMDb which is kind of internal tool. So it's really easy to to run metrics queries. Um so the first thing we did is we just queried for um hardware current um from one of the the deadl SPS just to see uh</p>
<p>like when when did this stop and we could see that it stopped you know roughly 25 days previously. Um and then we just repeated that for all the other sleds. Um just and we can see they'd all failed within the space of I think roughly a day. Um, and then we also like and I guess uh I and we also checked uh for the the PSC um or uh hardware metrics or uh current metrics just to see like when the SPS died, did we see</p>
<p>an increase in current indicating that the fans were kicking off and it looks like we did see an increase in draw which was suggestive of that. I don't know if we ever conclusively determined that though. Yeah, we so we ended up seeing like a moderate increase in current. So not enough that the fans were like at 100%. So it was like mixed results. Like we saw something change in current, but it was not strong evidence for exactly what was going on. At one point we're also considering asking the customer to go down to the actual data center and like car talk style like describe the noise</p>
<p>the server is making. Is it more of a woo or is it more of a woo? [laughter] Uh we didn't actually end up asking the customer to do that though. [laughter] Um, but maybe we should, you know, even in hindsight, we've got this thing completely debugged, why not actually just like, you know, I think Matt, as long as you ask them in exactly that way. I feel we should uh I like the various kinds of apes that we're trying to determine which one we're seeing. >> The other uh the other thing we did at this point was take the number like 188.5, which was the rough up time, and</p>
<p>like look at it in milliseconds, and try to turn it into an even power of two, cuz we're like, "Oh, maybe something is rolling over at this point." And it turns out you cannot turn 188.5 days into like anything that looks like power of two unfortunately. >> Yeah. So we've got uh and then we and but the host is up right. So we also don't want to like well yeah I mean we don't actually we don't have the ability to extract any more state other than we know we and we don't need to do um or</p>
<p>were there other bad ideas that um before Robert wanted to write to device memory to use the what were some of the other things? >> We kind of backed off the the device memory once we saw the ping working because we're like okay like the the SP is actually alive which was what we were trying to prove by showing that it responded over SPD. >> Um I think the other thing that we</p>
<p><strong>[21:08]</strong></p>
<p>hadn't done at this point is like we had not proven that the SPS would come back >> which was concerning. Uh yeah, the uh in terms of like we don't know if the SPS are actually dead dead. >> Yes. Although by by the time we saw them responding ping, we were maybe feeling a little bit better on that front, but we were still like if we power cycle one of these sleds like and the SP doesn't come back, then someone is flying off to a certain location with a debugger and not going to have a good week.</p>
<p>>> Yeah, that's a very dark thought. I I I guess I came into this after that I did that dark thought had not occurred to me that we had managed to actually like electrically destroy every one of the SPs. That would be uh that's dark. Yeah, that that that's definely dark. Fortunately, so um we and I think we did end up resetting Will, you ended up resetting the sled that was the cause of the investigation to begin with and that thing did come back up. Is that correct? >> Yeah, that's right. The next day um we</p>
<p>got had access to the rack again and um power cycled and it came the host and the people both came right right up. So that was a relief. That's a relief. Okay. So now we have got really just the symptoms of this problem. Um it's obviously a very bad problem. We really rely on that SP being up. Um, and but so we we're kind of we we're kind of reduced to we I think Matt we've kind of</p>
<p>exhausted the information we can get out of the running system. Um or maybe there were some other ideas on other information we could get out but um we're kind of reduced to like all right we're going to need to kind of go from first principles and try to reproduce elements of this problem. Um you had the thought that I think a lot of folks had is like could this be time related? um definitely reminds Adam of the Elbolt problem, the the famous Unix Elbolt problem where after with Elbolt is a 32-bit value. Um it and at its defbolt</p>
<p>is the lightning bolt variable that dates back to like sixth edition. Um yeah, they they took very like odd poetic license or poetic license at very odd times like >> drop the E off of Cat and uh and Elbolt as lightning bolt. But so this thing fires 100 times a second. This is the system clock at 100 hertz. Um you will that that value will become signed uh after 248 days. Um and kind of famously Unix systems of a certain vintage could</p>
<p>not stay up for longer than 248 days. And I mean they would be up after 248 days. It's just that it would be absolute madness of people thinking that that their timeouts that were in the future were in fact in the past and and a bunch of stuff would break. That was all this is all like in the 90s and actually one of the first things I don't I the first thing I actually did at Sun was actually fixed that. Um yeah that it</p>
<p><strong>[24:09]</strong></p>
<p>was kind of the I I someone else had kind of already started that work and was kind of handed to me. >> It's like a classic job to like send to the new guy too cuz you're like how hard like this doesn't seem that hard and I'm sure then like your phone was ringing for years or whatever uh on this critical code path. Uh, you know, it was funny actually on that in particular like the the that work had already been uh had already been broadly done >> and they also wanted to allow the hertz value to be to be tuned uh to be</p>
<p>configured and they had decided that they senior engineers had decided that the values that were acceptable were 100 and a thousand. So 100 Hz and a th000 Hz. I'm like, why not like why not just allow it to be configured to any value? Like, well, that'll be kind of unsupportable. Like, that feels like that should be supportable. So, I just like crank the values higher. So, what I would do is like I'm just going to crank the value until the machine no longer boots because it's just running the clock interrupt all the time, which was super satisfying strangely to do that. It was like I don't know. I think that</p>
<p>there's something there there's something sadistic in software engineers where we kind of enjoy computers that are in pain at some level. So, um, and I in particular remember that on Sun4C, this is Campus, this is a an old old machine at this point. Um, I don't know what the clock rate was on that thing. Um, I could get it to 26,000 and it hung at 2,600 hertz. Um, and I came back the next morning and I was very satisfied that it hung and I hit the the the carriage return and verified that it had</p>
<p>hung. Um, I guess I did that the night before because I came in back the next morning and it was actually making progress. It was executing like some very small number of instructions at a time. Um, and then the machine immediately panicked. Uh, and it panicked on what ultimately was a chip bug that we found. >> Wow. >> Yeah. It was just crazy. Um and the uh as it turns out uh there when you set the processor interrupt level um there was a two instruction window immediately after that where you could take in the interrupt at a level lower than you just</p>
<p>set the interrupt level to. Um and that was a chip bug as it turns out was a chip bug in every Spark microp processor they had made up before Ultra Spark. So um yeah it was and it was it was actually it was it was kind of an interesting lesson in a whole bunch of ways. one that like the the consequences of just time in general, the these problems that you have that you only see with uptime, right, that are really hard to test for. Um because how do you like you have to just like wait um and obviously there are ways to do this and</p>
<p>there are ways to kind of jump start time. I mean, Matt, that was one idea you had was around time. And did you end up doing the experiment of trying to accelerate time um closer to this value that of course is not even power of two to see if anything breaks? >> No, we had talked about just like booting the system with the clock set to 188 days, but didn't actually get around to that. >> Get around. Yeah. So, we're this kind of a you know, this is a high priority</p>
<p><strong>[27:10]</strong></p>
<p>issue, but we're kind of noodling around on how to like I got what to do. Um, and then Cliff, you uh you picked this up. It's like, well, this seems like a high priority issue obviously. Uh, what was your approach in terms of like because this is this is a tough one to kind of go from first principles on? >> Yeah. Um, so I had been out for a chunk of this dealing with family stuff. And so I get in and I have text messages waiting from a bunch of these folks being like, "Hey, so there's a weird thing. Hey, there's a weird thing. we'd</p>
<p>really like you to look at the weird thing. Oh my god, could you please look at the So anyway, uh but fortunately by the time I got in, a lot of this prep work had already been done and the the stuff that Matt and folks investigated really narrowed down the potential failure space. So by the time I showed up, what we knew was essentially machine goes unresponsive to everything except ICMP ping, which as Matt mentioned is handled on a fast path inside the network stack. So that can keep working sort of like a brain stem</p>
<p>reflex like a chicken with its head cut off long after the rest of the computer is doing something else. And Matt also mentioned earlier the the possibility of the net task like being really busy or doing something in a loop. And so that was sort of the leading hypothesis, but we didn't know what would cause that or why it would be doing a lot of work in a loop. So, Cubris has some interesting properties and tools here that actually came in really handy. And this sort of we need to model the operation of the system in</p>
<p>our heads because we can't get information in or out of the computer because it's that borked is the sort of situation that guided the design of a lot of the system and tooling. So what we had was uh from the build system we could get a graph showing the priority relationships of all of the IPCs between all of the tasks. Uh and from that we could clearly see that like the IPCC handling the serial port to the host was a lower priority than the network stack as are all of the</p>
<p>clients of the network stack by design. Uh the hubris network stack is a little weird, but it's a separate task rather than being in the kernel. And tasks that want to offer a network service are lower priority than the network stack, which means whenever the network stack has an opportunity to run, it wins. It will take the CPU away from any of its clients as a fairness thing mostly. But in this case, uh the IPCC was also lower than the network stack. So if the network stack were running with wild</p>
<p>abandon, it could explain why all of these interfaces are down except for ping. Uh the other thing that seemed plausible at the time though was one of the ways a task in hubris can burn lots of CPU is to crash a lot because our default response, >> yeah, >> generally it's an system is to restart the task. Now, Matt recently actually added a um</p>
<p><strong>[30:13]</strong></p>
<p>sort of smart timeout to give a waiting a cool down period whenever a task crashes before it gets restarted. But I believe that uh this customer was on an older release and I wasn't confident that that code was there. So, so that wasn't a possibility was that it was just falling over a lot. So, we had to sort of rewind. And the good news is is like thinking about this after the fact, there's a bunch of problems we didn't have to chase that would have been wild goose chases that we might have had to do on earlier systems I've supported. Like this was probably not a wild pointer</p>
<p>misuse in a different task because we're pretty confident the memory isolation between the tasks works at this point. Um it's probably not a scheduler bug because theuler is super super simple. So >> I had to Yeah. And just on that, a good especially on the wild pointer cliff because I think this is so important because when you have the possibility of kind of arbitrary corruption from arbitrary things, >> right? >> You've got this kind of like well magic</p>
<p>happens and sometimes there's bad magic in this system and we don't understand why and therefore like certain things are unknowable. Um, and >> yeah, supporting complex C firmware for a long time is the reason why I know what it looks like in a hack dump. If a pointer has been replaced by an IE E floating point number, [laughter] that's the sort of thing that happens, >> right? Oh, so having this that is a I mean not only do we have the solace that that</p>
<p>doesn't happen, but that also gives us a kind of resolve that like this is like there's something else going on like we we we can't just chalk it up to bad magic due to due to something having a straight pointer. >> Well, as you say, data corruption is almost is not is almost undebugable. That is to say, you're separated at such a distance. We talked about this last week and the ramifications are almost arbitrary. So it does give you some license to feel like giving up is an option. >> Totally.</p>
<p>>> Yeah. And and data corruption is sort of like the well I guess it was ghosts of software engineering. >> Exactly. Exactly. [laughter] >> Very un for better or worse don't really get to reach for that one. Um, so we instead stepped through everything sort of rigorously and I started with the kernel looking for potential bugs, but theuler is really simple and we didn't find anything there. So I started looking for things that might cause the network stack to crash because if it's crashing, it must be crashing for a reason. It's probably a panic cuz it's</p>
<p>Rust. Like that's basically how we crash. And the number of actual panics in the network stack code is pretty low. Although I did run off on a couple of tangents chasing ghosts that wound up not bearing any fruit, but we pretty quickly narrowed it down to the idea that um the network task was probably failing to correctly acknowledge an</p>
<p><strong>[33:13]</strong></p>
<p>interrupt. So hardware peripherals on on machines like this on these microcontrollers indicate some condition to software by signaling an interrupt which causes an interrupt handler. It basically interrupts the flow of instructions through the computer and in our case uh a small routine runs in the kernel to handle the interrupt and pass it off to a task outside of the kernel for further processing in this case the network stack. So if the stack were getting an interrupt from the network controller and was failing to like clear the</p>
<p>condition, then as soon as it tried to go back to sleep, the kernel would receive another interrupt and would flap the network stack again. And you'd wind up in this cycle where the network stack basically receives all userland cycles instead of the computer ever idling. But it wasn't clear what could be causing that because we've had this Ethernet driver for years and it's generally been pretty reliable and it's there weren't any obvious interrupt sources we wouldn't be clearing. So I had to go read the manual again and buried in the manual in an unexpected</p>
<p>location of the um let me just double check the page here. >> And can I just ask you something about your methodology here when you say I'm going to go read the manual again. So, >> the manual for the microcontroller >> is thousands of pages long. >> I just looked it up. It's 3,294 pages, >> which is a good thing to be clear. We've and I I believe >> I believe in our episode on transparency and hardware software interfaces, I've called out ST as a model in this regard.</p>
<p>So, love having this much documentation, but when you say I'm going to go back and read the manual, are you Um, and and clearly the documentation on Ethernet controller is is slimmer, but it's like I mean it's probably hundreds of pages, is it not? I mean, it's got to be >> Yeah, the Ethernet chapter is is only 300 pages long. And >> oh my god, I think the other problem with the Ethernet chapter is that >> there are several interrupts which are listed as enabled when the chip is</p>
<p>reset. And that is just straight up a lie. Like we were going through this and we found, oh, it says these interrupts are enabled. These interrupts are enabled and they're not enabled when the chip is reset. >> Yeah, the chapter is effectively crying wolf. There are three or four different interrupts where it asserts in plain English this is enabled by default. But it's not. But it turns out turns out one of those four actually is enabled by default. But the only way to confirm this is with this diagram that's hidden on page I don't know 2000 in</p>
<p>mumble that um I posted on the GitHub issue that uh shows that this one interrupt source for every other interrupt has this and gate that like masks it if an interrupt enable isn't on. This one interrupt source instead has an orgate that doesn't allow you to mask it ever.</p>
<p><strong>[36:14]</strong></p>
<p>So uh >> uh what is I mean do I may I are we taking questions at this time? [laughter] Why? >> Why? >> Yeah. So that I mean that that was just confusing to you that this would be we'd have this this particular interable. >> That's pretty bonkers. I mean so normally the sort of convention on an armed microcontroller like this is that the center central standard interrupt controller has enabled bits for every</p>
<p>interrupt source and sometimes something like an Ethernet controller will combine a bunch of sources internally into a a single bit that goes to the central interrupt controller. So in our case from the CPU's perspective Ethernet produces one interrupt but it's a combination of like two dozen possible event sources. So, the nice thing to do is to have bits in the peripheral that let you turn those individual interrupt sources on and off. The next nicer thing to do if you have some of them that can't be turned off is to have them</p>
<p>connected to some somehow optional and maybe a function that has to be turned on. So, there were actually two stanzas in the interrupt handler and the Ethernet uh driver in Hubris that said, you know, basically had a todo, we don't enable this interrupt, we don't need to handle this, which >> which is which is half true. It's >> true. So, well, actually, so it turns out to be all the way true. Folk folks had flagged that as a as an OSHA thing</p>
<p>we need to look into, which is valid, but it turns out those interrupt sources actually aren't enabled by default despite what the book says. So, those two are fine. There was a third that we didn't know about that was not listed in the Ethernet interrupt section of the manual that turns out to be the thing that's actually on by default. And it's the uh if I can jump to the spoiler, it's the management counters interface on the network interface controller. So,</p>
<p>it's this block of things which we skipped over because we're like, "Oh, management counters that'd be cool someday." Like, but it's probably fine, right? Counters, that doesn't sound dangerous. What would go wrong with a counter if we don't do anything? [laughter] Yeah. So, the answer is is there's a one of the counters is responsible for counting packets in and out. And by default, when that counter reaches its halfway value, it lets you know it's going to overflow by causing an interrupt. There's there's no way to turn this off. Actually, there it did turn out there's</p>
<p>a way to turn it off, but it's really hidden in a different register. Yeah. And I mean I I guess like thanks for letting me know that I thanks for thanks for killing me by letting me know that this is like a fire breathing canary. I'm trying to figure out like again what the metaphor is for this. But the uh and so it fires the interrupt when it you're when the the counter is</p>
<p><strong>[39:15]</strong></p>
<p>halfway at at its halfway mark which also feels like pretty aggressive. >> Anakin, come on man. Like you're halfway there. You're halfway there. >> I mean, the glass is like, isn't isn't the counter literally half empty? Like, why are you you're you're complaining that it's half full. >> So, Cliff, can you walk me through the So, then you get the interrupt >> and then what happens? >> So, in this case, because there was no software to handle the interrupt, what happens is the kernel interrupt handler runs as usual. The kernel notices that it's from the Ethernet controller, sends</p>
<p>a notification to the Ethernet handling task, the net stack. The net stack wakes from sleep uh looks at its notifications and says, "Oh, I've got an interrupt. Great. Let me go run my interrupt processing code." Doop doop doop. So, it goes through a whole series of reading device registers and looking at bits in them and trying to figure out what actual hardware event caused this interrupt. And it runs off the end of the code because it didn't think to check the one register for this thing we hadn't turned on. [clears throat]</p>
<p>>> Uh so then it says, "Great, I've handled the interrupt. This must have been spurious cuz that does happen. Uh, I'll just reenable the interrupt, which it does. Go back to sleep. And as soon as it goes back to sleep, the colonel says, "Hey, you got an interrupt." And then the whole thing is right over. So the the failure was interesting because what we basically had was a network activated time bomb in every service processor and actually in</p>
<p>in the other in the switch in the sidecar switch and the the power shelf. All of them had this time bomb lurking, but we never seen it kind of because we usually the machines before they hit this counter, but we in hindsight, we had had a couple of infrequently used dog food systems that would mysteriously fall off the network and we never really knew why, but I think now we know why. Um, >> yeah,</p>
<p>>> it's also fair. Is it fair to say that this this feels like it could be lurking in every consumer of this, right? Like the this counter is so buried, the documentation does not make it clear. In some cases, it's wrong. >> The pathology waits for a gajillion packets or whatever or half a gajillion, excuse me. [laughter] Right? Like could this be lurking in like everybody who thought they've properly implemented something on top of this? >> Right? I'm not accusing this construct</p>
<p>of being enemy action, but if it were enemy action, what would it look like? [laughter] >> Yeah. So, I actually was wondering that, too. So, I went and checked every open source driver I could find for the Ethernet block on this microcontroller. And it's not a super popular microcontroller, but it's kind of popular. So, there were several code bases I could check. And in general, every codebase I found tended to have a commit</p>
<p><strong>[42:16]</strong></p>
<p>usually months after the original version of the code >> that sheishly went in and turned these bits off. >> So people are hitting this in practice, but they're hitting it faster than us, which then sent me down a whole like why why are we so late to the party here? Like why are we getting bit with this at a customer site when other people like the the rust embedded how driver for this Ethernet controller actually fixed this in 2022 I think so >> oh interesting >> yeah and I think I think the reasons are kind of a side effect of the system</p>
<p>robustness if we get a failure like this the only symptom is that like oh wow it dropped off the network uh in a normal system having an interrupt storm like this means the entire computer locks up all interface has stopped working, you have a brick. And it's a lot more obvious when you're having this class of system failure. And with our systems, it's just like, huh, well, I don't know, maybe the cable to this one PSC is flaky. We should probably receat the cable uh and move on. And</p>
<p>>> yeah, and then you reboot it and receat the cable and the problem's gone. >> Yep. for you. >> I also could I also do wonder if the other folks using this mic controller because if you're you I mean we don't see this is not like a network device you you know what I mean like yes we we obviously the network's important here but we are not like pounding the network all the time like if we were making if we were using this microcontroller >> for you can imagine use cases that would hit this much faster than than we hit it. The management network on the rack is completely separate from the customer</p>
<p>data network and the amount of traffic flowing over it is relatively low and it's very controlled. It's all just our things talking to our things. It's also small packets. It's all UDP. It's very lightweight. So our packet frequency on that network is lower than probably your home Wi-Fi network. So we can we'll get to [clears throat] 202 to the 31st power packets sent a lot later than most people. >> Uh yeah 166 days later apparently I from our 186 days. Sorry Matt the number was</p>
<p>>> Yeah. >> Um so okay so but we've got this uh really interesting thing in the data sheet that you've discovered. Um, what's next in terms of like how can we go explore this hypothesis? >> Oh, yeah. So, I think I posted in chat saying I may have found a thing that that we're not handling, but I need to look into this more um because I don't know, I tend to be habitually uncertain about things. But uh</p>
<p>I went digging in the data sheet and I found a test register in the Ethernet block which lets you force the hardware to set the counters just below overflow. So there's actually >> in the controller for testing the overflow behavior without waiting for two to the 31st packets. So once I saw</p>
<p><strong>[45:20]</strong></p>
<p>that, it was like I was worried I was going to have to run the thing overnight spamming it with packets, but no, I I just went in with a debugger. And I mean, I know it sounds like and the colonel debugger, you would consider this a bug, but I I used the debugger to write a device register to uh force this bid on uh and the and then pinged it 16 times and the thing hung up with exactly the behavior we would expect in production or we were seeing in production. So that was a strong indicator. And then if you do humility tasks at that point, you can see the all the running tasks and net is always</p>
<p>marked as running. Idle never runs. So it's it's not yielding the CPU. >> Yeah. And I mean the great thing is that you've now you've reproduced this cuz when we are in a comput sled certainly in a customer site but even a comput sled that's just in a rack we don't have a debugger plugged into that thing like they we the header's populated but we don't actually there's not a a so when the network is actually our only way to understand what's going on inside that uh that service processor. You have now reproduced this on the bench where we you actually have a debugger attached to</p>
<p>it. So we can use the serial wire debug interface in and we can actually understand heaven and earth about what this thing is actually doing. >> We can ask it arbitrary questions even though it's network interfaces down because the nice thing about these embedded debugging interfaces like JTAG and serial wire debug is that they're not cooperative. They will work even if the computer doesn't want them to. It's >> also why we don't have them plugged in at a customer site because that would be rude and give us lots of weird powers over their computer. uh on the benches</p>
<p>>> as it has died. I and I can't remember if we've mentioned it here before or not, but I do feel like one of the one of the things I I love that we have done is that we have use the serial wire debug and in this incredible robustness of it. It really is a very robust mechanism and as you say it's like it's not an opt-in mechanism. Um this is how the root of trust can control the service processor on our machine. The root of trust actually has that squid line and it can actually control the service processor and uh force it to attest to itself and do all sorts of</p>
<p>other things which is extremely useful. >> Yeah. On boot the root of trust actually stops the service processor um like alters the contents of its RAM, forces programs into it and makes them run and verifies that they ran in a way that the hardware cannot lie about. So that that that was Rick's idea a long time ago and boy has it been a delightful hack. It's it's really quite powerful. >> It's a damn good Yeah, it's a damn good idea and it's been really really robust. But it all goes to this I mean and I've certainly understanding Cortex</p>
<p>microcontrollers was a first for me at Oxide and really appreciating the robustness of that of that SWID interface. Um it it's very very helpful to have something that's so robust there. So, all right. So, so you've now reproduced it. We've got the symptoms and then so uh so what's the fix? I</p>
<p><strong>[48:20]</strong></p>
<p>mean, it feels like what actually what is did we do? We just uh actually let this interrupt know that we're actually not No, I guess we can't we can't mask it. So, we've got to actually deal with it. >> Yeah. So, once you once this interrupt goes off, you have to figure out which of about a dozen different bits in different registers you would have to set to make it stop happening. There's a whole tree process you have to follow of like read the top level register and see which bit is set and then go read a different register depending on what bit is set and then like da da da da da da and we could do that but it also turns</p>
<p>out that there are bits you can set in a control register to just turn this feature off. We don't use the >> but the code I added is about 30 lines of comments and like two lines of rust uh basically like >> so this is actually on by default and here is the bit here's the here are the bits we have to set and here's the code to set them and now the interrupt shouldn't occur. >> Amazing. Um, and uh, and I mean I think</p>
<p>that we I mean on the one hand and Cliff I mean as as one would I mean you said look we we we can't say conclusively we found the issue but boy we found an issue that matches everything symptomatically. It does feel like we've got a high degree of confidence that this is the issue that we saw in production. >> Yeah. Like the the simultaneous failure is really my I mean okay I'm a little bit of a ghoul. So [laughter] I one of my favorite parts about this failure is the fact that it was simultaneous</p>
<p>because if it had totally one sled we probably wouldn't have had this focus and we wouldn't have been able to rule out really simple basic things. But the fact that it was an approximately simultaneous failure of every machine in this class of machines in Iraq was a big wakeup call of like it's either a bad packet on the network or it's power supply issue or it's something something across all of them. And what it actually turned out to be is just the fact that a lot of our management traffic is</p>
<p>multiccast. A lot of our access patterns over the management network to these compute sleds are uniform, which means if they all start up at about the same time, their packet counters have about the same value. >> And in fact, we did the math on this afterwards where we were seeing, you know, somewhere between 100 and 150 packets per second multiplied by 188 days. This is a case where it actually does line up with the nice round power of two. So that was another confidence builder that this was the right</p>
<p>diagnosis, >> right? There was just a conversion that we had to discover to convert between seconds and number of packets sent. And then it's a nice power of two. >> Yeah, that that is absolutely wild. And I mean this is one of those and I feel we've had this you know many many many times where you've got these symptoms there's like there's somehow we are</p>
<p><strong>[51:21]</strong></p>
<p>going to explain these symptoms and the the simultaneity is like god there's something that's going to explain that um you know what could it possibly be and I mean cliff I don't I mean I thought this was very surprising I mean ultimately I mean of course it makes complete sense but it was also not I mean we we really got there from Gdonkan experiment and then careful reading of the data sheet, not thinking like, oh, there's probably some network encounter that's that's interrupting in incessantly somewhere. Um, I mean, it's uh it it was I don't know, maybe you were you were less surprised, but I</p>
<p>thought it was it was definitely surprising. >> I was honestly mostly focused on the fact one that originally missed the existence of this interrupt when I was writing the Ethernet driver. So, you know, it's sort of a bug I created several years ago without realizing it. Well, they're all I mean, are they all? But I also feel that like it's um and this is where we because we have not used the uh the kind of vendor source code for this stuff. We don't use the embedded house. We we have gone our own way which does require us to own this</p>
<p>stuff at a deeper level. Um >> but I I don't know it. Yeah, >> one of the things I suggested in chat when I was sort of self-posting this was the it probably makes sense for us to periodically go take a look at the other open source drivers for our peripherals because for a bunch of technical reasons we can't use the vendor drivers. We can't use net hell or most of the Rust ecosystem drivers. And it's simply that they generally don't assume they're</p>
<p>running on a protected mode operating system. They don't assume that their interrupts go through an IPC system. They don't there's a bunch of assumptions they make that are valid for 99% of users but are not valid for us. So in the absence of being able to just share the bug fixes, we need some kind of communication channel to make sure we at least hear about them. Yeah. Um you and how Yeah. Uh so there's a question in the chat. Have we notified ST that the docs are wrong? Um no. We</p>
<p>probably should do that. Um, ST's been it's pretty I mean again pretty as these things go pretty receptive. I view ST as kind of a model for for pretty good transparency here and and in generally pretty good documentation. I mean I know that it's uh in this case it was misleading >> or wrong. >> So the the answer here is a little complicated because ST to their credit tends to release very comprehensive docs on their microcontrollers. They also never update them. Uh unless I</p>
<p>don't know I don't know what you have to do to get them to update them. They will release erata sheets that explain that oh by that way that feature we're still advertising isn't implemented. But um what they won't do is a release an erata sheet for a thing that just kind of sounds misleading. So it's it's actually not clear that ST has a policy that would result in this</p>
<p><strong>[54:23]</strong></p>
<p>getting changed. Um they've this has been reported to them by I I posted this on Masttodon and several people reached out saying like, "Oh yeah, that bug. Yeah, man. I remember that bug. [laughter] >> That sucked." And uh they all reached out to ST. ST is aware, but like ST's position is, "Hey man, we described this in the manual and like yeah, maybe you don't find the pros as accessible as you'd like, but it's not a bug per se and you know, you do keep buying our chips." So, um, so I'm I'm maybe a little, uh, cynical there, but I I don't</p>
<p>think that there's an obvious pathway to getting the manual updated. What we can do, though, is publish this in as many forms as we can, which is part of why I took a bunch of the notes and wrote up that public hubris GitHub issue in addition to >> Yeah. And and if anyone wants to point us to other podcast episodes from other companies talking about their firmware bugs, we will gladly listen to absolutely all of them to make sure that we uh because I I do think that this stuff is uh extremely valuable information to to to share. Um, and I think it it also just underscores the</p>
<p>importance of having open source having because in a in a closed proprietary world and we do work with vendors where like all of the source the where the documentation is proprietary um and so it makes it a lot harder to find problems like this or to go validate them. So the transparency here is is a win and is helpful um just not totally sufficient in this case. Um, well, this is uh this is awesome.</p>
<p>Actually, I do love the fact that we were [laughter] we were talking about this. Megan was asking this morning, he's like, "Do we need to like should we like issue a patch for a previous release on this?" Like, well, no, because we're going to we're know that it actually is going to take a while to hit this. So, um, by the time they hit this, they're going to we'll we'll have them updated to the most recent version. So, uh, it's actually very helpful to this. >> Sorry. Go ahead.</p>
<p>>> Yeah. If a customer doesn't want to upgrade for another half a year, then we may want to push out a patch, but we don't think anybody's really, you know, insisting on that. So, >> yeah. Yeah. >> Um, and and then the uh the mystery of Sled 23, which is what kind of caused all this, that's going to be a future podcast episode, so you know, stay tuned. We don't have, you know, we've been we we've we've been on a bender recently of of oversharing uh fascinating bugs, but we just seem to be hitting more and more content</p>
<p>generation. Um well, this is great. I Cliff, again, extraordinary work on this. um when uh and because for all I mean this uh I'm I'm not sure if you were there was some hidden work here, but you actually debugged this remarkably quickly once you hit the data sheet. Um felt like you</p>
<p><strong>[57:23]</strong></p>
<p>was >> I mean it took a few hours of of concerted work, but I just I want to emphasize that like I was just knocking the pens down that Matt and Laura and Will and the other people that were working on this before I got there had set up. And uh well you once again I think this has been a theme on these other bugs too. We got the kind of the baton being passed. So uh everyone taking their turn with the baton. Um and uh this was this was another good one. Um and really terrific work. Very exciting to get this this fix in. Um I Adam I for one would</p>
<p>like slightly less content generation even though this [laughter] is is terrific content. Like we can we can ease up. I feel like, you know, we if the gods are listening, you know, um >> on one hand, debilitating bug, on the other hand, podcast episode solved. But, uh solved, >> but we're we're going to be off for a couple of weeks, so we can just uh pause on some of the debilitating bugs. >> We can we we can pause on some of those. So, we uh and actually speaking of upcoming weeks, so we've got we're I'm</p>
<p>out next week. Uh but then the week after is going to be our last episode of the year. So, um that's wrap-up time. We're gonna do our our our wrap-up episode. So, that's going to be uh that's gonna be exciting. >> Yeah. >> Um we which means we will be doing a title and image review. So, [laughter] just one that's right. >> Um you know, not too much pressure on anybody. Um but >> I assume that episode's just going to be chime sounds the whole time. [laughter]</p>
<p>>> Yeah. You know, you know, so that is actually a bit of an over question. Like I feel like it is an act of cruelty to have it just uh non-stop chimes, but yeah, it will be a lot of chimes, I think. Or maybe maybe no chimes. >> Maybe it'll get them all in at the beginning or something. >> Exactly. We're not actually we don't actually hate the listener even though sometimes our audio behavior is in is >> No, no, it's a much more complicated ambivalence. [laughter] Yes, >> it's a much more complicated relationship. >> Exactly. Well, again, uh, terrific work, uh, Will, Matt, and Cliff, and and I</p>
<p>said other folks that have worked on this problem and Robert and others, but, um, really Justin, uh, a lot of great work all around. And, uh, uh, fun to have another podcast episode, but we don't need to have any more world gods, you can actually, it's okay. Things can actually work now. Um, now that we've deal between between future lock and our data corruption episode and I also like to see we kind of like hit on all like why am I about to say this? Why am I like literally tempting the gods with the other um Yeah, I'm just going to shut up now. We know the gods</p>
<p>are listeners. So, >> were you about to say like we never seen a bug in this sub? >> No, no, no, I wasn't. I wasn't. I sure wasn't. So, awesome. Well, uh, Cliff, thank you very much especially for joining us and great work debugging this. Um and uh we'll get get the word out there for other folks that may have this part. Um and let us know if if there are other issues that we should be aware of. Please let us know. So thanks</p>
<p><strong>[60:26]</strong></p>
<p>everybody and uh we will see you next time. So in two weeks um and uh bring some of your your year highlights. We'll be doing our year wrap-up. See you next time.</p>]]></content:encoded>
      <guid isPermaLink="false">https://www.youtube.com/watch?v=JFtCJVxuug8</guid>
      <pubDate>Mon, 08 Dec 2025 15:00:38 +0000</pubDate>
    </item>
    <item>
      <title>Oxide and Friends 12/15/2025 -- OxF 2025 Wrap-Up</title>
      <link>https://www.youtube.com/watch?v=kGNoSYQchS8</link>
      <description>Bryan and Adam reflect on Oxide and Friends in 2025--favorite moments, episodes, and images. Happy new year and see you in 2026!

Notes: https://github.com/oxidecomputer/oxide-and-friends/blob/master/2025_12_15.md</description>
      <content:encoded><![CDATA[<p><strong>[00:00]</strong></p>
<p>Hello, Adam. >> Hello, Brian. How are you? >> I'm going well. How are you? >> Pretty good. Pretty good. Lots going on in the world, but glad to be here. >> Well, is there anything going on? Is there any anything of note? Anything? >> I wouldn't You know what? If you've missed it, I wouldn't bother looking. >> Exactly. Please don't. Uh yeah, this is I'm excited for this episode. You know, I I'm I'm excited for this for this tradition. Uh the our our annual wrap-up. Uh, actually can before we get there because we honestly if we if we hadn't already planned this episode, we might be talking about this RFD that I wrote um a week and a half ago, the</p>
<p>RF576 on using LLMs at oxide. I have been shocked at the Am I stupid to say this? >> No, I feel really >> people feel really excited about it, I think. Is that what you're saying? >> I am amazed at how hot this issue is just in general. I mean, I felt like I was saying something that was very like very neutral in the many ways, like very like reasonable, middle of the road, not too extreme. And but I this thing got a huge amount of of pull. I mean, I I made</p>
<p>the RFD public because I thought like one or two people on Blue Sky might like find a spelling error, which actually they did. So, thank you, Blue Sky. The spelling is something. But and then I was like, we're going to a dinner party this last week and it's the top story on Hacker News. the number one story on hacker news. >> That had escaped my attention. I would say and I mean this with all respect like I read it and I think my feedback was like yeah okay >> milk toast. >> I mean I don't I mean no disrespect just like</p>
<p>>> no no no no. This was my view like my view is like very like just like punching a clock doing you know like yeah like just just making sense. It's fine like nothing like not a number one story on hacker news. So, that was a a a shock. And then I was going to be like, "Okay, we're about to go to a dinner party. It's the number one story on Hacker News." And the comments are just like I'm like, "I have to like turn my phone off." I'm like, "God's plan." What you whatever happens at this point, you know? Uh and uh fortunately, it was it was it was all fine basically. I mean, more or less, you know, the haters</p>
<p>eventually they once you get to a certain amount of traffic, like the haters are always going to show up, >> for sure. But I feel like I mean your point of like you know you should spend as much time writing a thing as you expect people to spend reading the thing. I can understand it as being like I don't know like perhaps not obvious but like >> I feel exactly the same way. Like I guess I was splitting the atom on that one. Didn't feel like it really. [laughter] Um, but a lot of people like that in particular that really resonated</p>
<p>with a bunch of folks who I think were kind of feeling the same thing and struggling to kind of put put words to it. So, so all of that kind of put me on like we I wanted to to flesh it out a little bit and I got some great feedback and and I I updated a bit and then I wanted to go back and listen to something I'd started listening to which is Evan Ratliff's Shell Game podcast. Have you listened to any of this?</p>
<p><strong>[03:00]</strong></p>
<p>>> I've started it. Yeah, I started this weekend. It is very good. It is outstanding. I guess so if you are especially, you know, kind of in the holiday season here, there a lot of menial tasks that need to be done where, you know, maybe a a podcast and some spiked eggnog might help you get you through it. >> Uh you you you want to be putting on shell game. >> There you go. That's halfway there. Then and then pull up the eggnog, right? >> And pull up the eggnog. Uh it is. So have you are you on season one or season two? >> I skipped season one and went straight to season two, >> which is I think like that's that's a good idea. Although I think Susan season</p>
<p>one is excellent. The one thing you get and I think you should listen to season one even after having listened to season two. The and in season one he creates a persona of himself that he unleashes into the world and it is really fascinating. But season two is absolutely unhinged because he creates a startup with these personas that he creates. And I I mean I I don't know. Have you are you I just find it mesmerizing. I think it's amazing.</p>
<p>>> I I think it's great. I think uh I actually played ultimate frisbee with Evan for many years in San Francisco and I think I recall correctly in Wired probably like 15 years ago he like tried to delete himself from the internet and that's right he did and he was found after a month. >> Um he challenged the internet to find him and the internet found him. >> Um >> which well you know that you definitely recall correctly. So the fact So we we've got to I mean I know I know this is supposed to be a wrap-up, not a preview of next year, but we we got to get him as a guest. >> Yeah, for sure.</p>
<p>>> Yeah. And Morris Chang too, right? >> Morris Chang. Um yeah, I mean I think I played ultimate Morris Chang. So maybe I'll go after you know actually the fact that you played Ev ultimate with Ev does that mean that I should be asking him or you should be asking? I mean [laughter] you can you can you can hear this in the spirit which it's attended right. I mean this is >> very astute question and I can ask him in this case only. >> [laughter] >> Okay, that's good to know. You're on the same team. That's good. The that's that's good to know. >> Um, and so anyway, highly recommended it. Uh, highly recommended podcast.</p>
<p>Really really good listening. And I'm like, uh, next episode of season 2 drops on Wednesday. I can't wait. Um, and perhaps in fitting with that, uh, well, actually before we talk about like wrapping up 25, I feel like there's a there's some headlines of 25 from an oxide and friends perspective. >> Okay. Uh I mean actually one kind of surprising thing do you and have you already done this about the number of episodes and maybe you know just automatically know this maybe your brain is just hardwired in the transistor. >> You mean like how how many we've done</p>
<p>this >> how many we did in 2025 versus 2024 versus 23. >> Uh I don't know that off the top of my head. My guess is >> what's your intuition? >> My guess is more than last year and probably more than the year before but maybe less than the year before that. >> That is exactly right. And it but the numbers this year, last year, and the year before are all basically the same. I thought we did a fewer episodes this year. I really did. I thought we you know, like I had to go I was down in</p>
<p><strong>[06:01]</strong></p>
<p>Mexico with my mom and I just felt like we we did less episodes, but we didn't. We actually were going to do like one more episode this year than last year. >> Yeah, I I I I did know that we were like ahead of pace. I think we had some like hiatus where it wasn't working out for you and me and I I had seen that that we were ahead of pace. So why why you know, we can skip it. We can give ourselves some time off. >> Yeah. No, it's good. All right. So, that was that was a little bit of a surprise to me, but um I thought that was interesting. Um but I feel that the uh the big the big news if the big reveal last year was the all of the sweat on the brow with the images. I mean, I</p>
<p>thought that was a big reveal last year. >> I think I think I think that people, you know, they they knew they appreciated it, but they didn't know why. And now we've got And so, how do you feel cuz now I mean that obviously changed everything. We kind of broke the seal on that and now, you know, we pulled back the curtain. Um, and >> I mean, a lot of pressure obviously. I I was looking back at the year of images >> and they were like, "Good. >> I don't know." Like I feel like are we [laughter] >> No, I I understand what you're doing and</p>
<p>it's fine. You want us to walk out? No. Let walk us up to it so we we so we call out some ones that are really special. Although I will I will say there were a couple that I really liked. >> A couple I really liked and I bet you and I are going to we should write it on a card and flip it over. >> I think we need to do that. I think we know what it is. >> Okay. But >> absolute confidence. >> Okay. On three. One, two, three. No. >> Oh, wow. Okay. >> Hey. >> Oh, wow. >> What was the What was the AIDS discourse?</p>
<p>>> This is with Clabnick, right? I think it's AI discourse. >> Yeah. Yeah. Yeah. >> Um I'm trying to remember what the image was. >> Oh, come on. Yeah. Yeah. I just wish >> Oh, yeah. I did love that one. This >> I knew it. I knew I knew it. So, what you were thinking of was second place, which is fine. I didn't know we were doing second place. I thought I thought we were doing in order from first to second, not to second to first. >> This was an image. I mean, I don't know. The reason I think I I think I I think I didn't pick that one because um because the thing I loved most about it, like only I love about it. So, the images of</p>
<p>you >> That's not true. I love about it too. I love it about it too. It's you sharing a milkshake with a robot, >> which which I really enjoyed. >> But then the thing that I had me tittering and I think basically nobody else is if you watch if you watch the YouTube episode, it pans over the span of like literally 20 minutes. It pans over to me like checking my phone next to you like I'm third wheeling it with you on a date with a robot and then it</p>
<p>pans back and and you had told me that there was something very spect and we'll talk about the second as a segue to something else I want to talk about but the there are two very special things in that episode. One of it is this kind of panning thing you had but not been as specific. You say I really want you to listen to this episode. I think you're going to like it. And I was I was grocery shopping listening to the podcast as one does. And it was it had</p>
<p><strong>[09:01]</strong></p>
<p>its desired effect where I was just kind of like I looked down on my phone like what when did when did that pop up? Like when did it's now Adam and it wasn't Adam wasn't here and then it so no [laughter] it I wish you could have been I wish I should have been wearing you know the the helmet cam when I was in the grocery store >> the the the selfie cam. You would have really de you would have really it hit the mark. It you could not have asked for anything more. >> Uh I it was it was confusion and then it was delight and then it was oh what whimsy what what what a whimsical what a whimsical co-host I have and there how</p>
<p>delightful. It was really it was all these feelings. It was really great. >> I love that it's for all of those folks who are like staring at the unmoving YouTube video, right? The people who are like no no I'm going to listen to Oxide and Friends and stare at the image for an hour and a half. >> It's kind of like up in a window or whatever. No, this is what makes it even better because it's just like off to the side and then you're like, wait, has it changed? >> It's like it has. It has. I'm glad you asked the question. So, I thought that was great. >> The one I picked uh the the the episode that we had done that you titled I</p>
<p>believe you picked came up with the title Hela's other networks or maybe collaboration >> for the networks but uh maybe but give it to you. >> Yeah, fine. I'll take But then but then uh having having the uh you know you using the the the complaining on no exit making a no egress just felt like I I love that one. >> It was genius and it should be said that was a chat GBT or that was an LLM suggestion. >> That's right. Chat GPT joke but really good.</p>
<p>>> That was like the the first and maybe only Chat GBT joke that I actually like laughed at. >> Yes. >> That was funny. funny. That's like No Egress is just straight up funny. Which tells me that it's just like cribbing the joke from someone else. Has someone else already done Noess? >> Surely. >> We have We checked the mail bag recently. We probably have some a letter from an angry podcaster who's like, "You you stole not just my gag, but my image." Like, look, the LLM did it. We did. We >> Well, I made the image. The LM just gave me the idea in in >> Well, it is a great image. It is. It is. It is a I mean, I thought that was</p>
<p>genius. I mean that was really No, I mean I thought that it also like it's a level of seriousness that you often don't find in in all I mean it's like really getting into existential thread you know deep the deep cuts. Yes, >> the the deep cuts. Um so no I thought that was uh are there other images that we want to call and how has it been to have now to kind of democratize this and have other people aware of this? Has it has it helped you? Has it kind of like I need people to kind of get out of the workshop while I'm working? This is just like you know Uh, no, no, no. I think</p>
<p>it's like I mean I was looking back at the images from this year. A bunch of them I was kind of counting like how many were just AI cuz I I don't know that I love that a fact and actually not that many were just >> Yeah, but almost all of them I' have some AI assistance which which is sort of telling >> it is like >> like aspect ratio this the aspect ratio</p>
<p><strong>[12:02]</strong></p>
<p>is wrong is the thing I get from you a lot. Aspect ratio is wrong. Can you fix this? Never mind. I've got it. I feel like I've got [laughter] that exact dialogue in the several I guess several times over. >> Yeah, that's right. But like, you know, just having it again, not the subject of the image, but the surround um just like great for the lazy man's photoshopper. >> Um and then we did hit I I would say we hit the Simpsons a little harder this year. >> 100%. This was >> really tacked into it and it's just like we're let's just mask off. We're just</p>
<p>going to really Let's see if we can get that cease and desist. >> No, totally. It's like Fox like Disney, please. Like the cease and desist. We'll just post the uh the address right right on the images. Yes, >> please. We're kind of begging for it, but uh so I thought a bunch of good ones. I mean, I thought a bunch of like good I mean you can look, you can rely on us that like if you're going to get a a Simpsons reference from us, I mean there's certain things you know about it. know it's going to be certainly in the first 12 seasons, probably in the first eight. It's going to be something that you should be aware of that a Simpsons scholar and I we've got to like</p>
<p>talk about the grown-up CFSA corruption bug image because I feel like that's a deep cut. That is a Simpsons deep cut. That is a Simpsons deep cut. Yes, this is Crusty the Clown holding up a contract and this was like a reference. I mean, even within the episode, it's a deep cut. It's it is >> I mean cuz it was a reference to like Matt Arens founder like creator of ZFS giving us a email which we have refer to instead as the affidavit as though it is</p>
<p>some binding contract [laughter] which was news to him. >> I mean it was funny because we have referred to the affidavit so frequently inside of Oxide that it hadn't really occurred to me that we had never really told Matt about this and Matt's like what? Yeah. Yeah. Yeah. Sorry. You were under oath when you sent that email. Are you unaware? Yeah. Well, I thought anyway. Anyway, you were. So, uh, [laughter] >> so, so you know, that's what's up. Yeah. >> But then you, it is, but it's it's a deeper cut than that because wasn't that trimmed from the broadcast? >> Oh, that's right. That's right. That I</p>
<p>forgot about that. Yeah. Right. So, that was a scene that you were familiar with because you have been watching streaming and I only watched like in college and broadcast TV, you know. Uh and uh and they cut scenes from syndication. So this is from one of the scenes that was not in syndication. >> Yeah, we are we are out of undergrad. We are deep into grad school here when we're talking about the Simpsons. This I thought that was really that was that was an impressively deep cut and you had</p>
<p>a couple of I thought and then also like I mean some very just important you know you've got like clearly Sai Bob stepping on the rakes. I mean, it's just this is I mean, if you're not if you haven't watched that scene, I you just these are things that you should be, you know, we're trying to help you out in your education. >> That's right. That's right. Uh Homer uh designing a car pointing to it. I felt a little bad implying that like Dave, our esteemed colleague who gave a great talk</p>
<p><strong>[15:03]</strong></p>
<p>was [laughter] >> pointing pointing at a doodle. >> You can't take these apart too much. I mean, like the AI and higher education with Michael Litman had Homer again. Um, while the while the nerds are are are busy at work, and I'm not even sure who's what in that metaphor. So, you can't take this apart. >> You have to pour yourself into it. Like, I think we can all see ourselves in that picture somewhere. >> Exactly. Exactly. You're all in that picture somewhere. >> We are all the nerds and we are all Homer. >> We all Homer. Uh, reflect. Please, please write a nonlog generated essay, okay? cuz I we</p>
<p>>> um here in in Simpsons 301 or whatever course this is. Um another image image I love. Uh so >> I'm hoping you're going to go there. I always >> episode the episode long time in the making. This is the TLB speculation data corruption bug >> that I had been pestering you about >> for two years. Like literally. >> Yeah, literally. And the image is just you head in hands like reacting to output that made no sense. Like</p>
<p>literally could not happen output. Uh it is a great image. It is a really really good image. No. And that and that one is just like a screen grab from a meeting basically. That's just that is just like literally me in my basement trying to like grapple with tears in the fabric of reality. Um and that was >> uh that was really good. No, I thought you were gonna say um AI materials and fraud with Ben Shindle um on the Where in the World is in San Diego. And >> that was fun.</p>
<p>>> That was I thought that was a great image that you that you um >> Yeah. scrapped together. Yeah. >> Yeah. Was that not I mean am I am I overplaying that one? >> No. No. I like I like that that that took a little bit of you know artistry of form and um that was a fun episode and you sent me an article recently from the Wall Street Journal where they had been apparently listening to the podcast [laughter] >> I think it's a little >> let's say let's say let's say for purpose yes uh yeah and what's going to happen if I drop in that gift link into the Discord I think it'll be fine um</p>
<p>we'll put the gift link at the Discord and then the Wall Street Journal can send me a cease and desist now you know the Wall Street Journal unlike Fox I feel I can rely on them to send me a cease necess you could really learn a thing or two from the Wall Street Journal. Um the um but uh that was like it would because it was an update on you know because you know I relisted to you listen to that episode. I relistened to that episode somewhat recently. >> Um first of all I'd like to apologize for my bad audio while I was in Mexico. So I know I know the apologies not accepted for many people but I just want to put that out there that I am I'd like the record to reflect that I am</p>
<p>apologizing. It really was kind of bad. So >> it was as I recall it was like echoey right? >> It was echoey. Yeah, it was I was in a I mean my mom's place down there is a very you know it's a lot of tile. >> Yeah, it was like tile. You was like you were you know sitting in a tile cube. It was like >> I was sitting in the tile cube. I was though I but I feel like that's that's a bit of an excuse. I feel I could have done better. So I apologize for that. >> Well, um look, apology not accepted. And</p>
<p><strong>[18:05]</strong></p>
<p>to the haters who are like your audio sucks. It's like yes, our audio sucks where we're sitting. Like no amount of taking out a Discord is going to improve Brian sitting in a six-sided cube of tile. >> Like that's not Discord's fault. >> This you you can't hang out on Discord. That's on me. >> Wait a minute. Hold on. >> That's [laughter] what I >> Dies and Fire 100%. >> Um that is, you know, that's like Ducks and Fire. Is that a reference that that travels?</p>
<p>>> No way. >> Really? >> Not Not a chance. really >> like I feel like I mean Bugs I feel like Bugs Bunny >> is like >> maybe overtly racist. >> No. >> Oh, you can't make Has Bugs Bunny been cancelceled? I can't make a Bugs Bunny reference. >> I'm not sure. I I you know what? I'm just not going to. Maybe Chad can can weigh on in on this one. I'm just not I like 100 100% there are some impersonations that Bugs Bunny done has done that were not okay at the time and certainly are not okay now. Well, dear</p>
<p>listener, if you are hearing this in the podcast feed, we have decided that Bugs Buddy is insufficiently not cancelled to leave it in [laughter] or we couldn't find it. >> That's right. We forgot to look for it. We forgot to look for it. Um but um okay, so you know, the other thing that that was obviously a very big deal this year um was the the introduction of the chime. >> Ah, yes. >> Okay. So, and actually I just kind of a meta question. Um, on the the the the</p>
<p>chime, are we ringing the chime in this? Have you decided? >> No. No. I think we I think it would be >> Are you not kind of been I've I've kind of Okay. Can Can we workshop it a little bit? I So, you said no chime in this episode just because you think the chime would be going off all the time. >> That's right. That's right. I think the whole the whole thing is a retrospective >> and to to chime I mean the the the chime is actually intended >> God I I can't believe I'm saying this as like a gift to listeners right to know more [laughter]</p>
<p>>> to know more >> oh that's great that I definitely was going to say that I uh dear listener let the record that is Adam who believes that is a gift I know for you >> is for you >> uh you're like can I did you keep the receipt is it you have a gift receipt can I >> was it this I think it was this season that we did the JJ air horn. >> Okay, that was the second thing I was going to say from that the AI discourse episode was the I say so you had introduced the chime. I think the chime is delight I think the chime is so delightful that I think that that we</p>
<p>should potentially have it be in this episode. I I will say I I I I think it's for your consideration because I think that the because it will make it very clear noted uh it will make it very clear what the chime is for which apparently some people are confused the time is for what the time is to make reference to previous episodes. uh in the and we I think we only kind of do it for once per episode. Like we bring up an episode we haven't talked about, we hit the chime, we don't like we don't nail it on every sentence you're talking about. >> Yeah. And dear listener, I have been</p>
<p><strong>[21:06]</strong></p>
<p>reducing the volume of the chime with each episode to the point where it's fainter and fainter. >> Oh, really? You big chicken. I didn't notice that. A little uh a little inside there. A little insider information for folks that that the volume it's like, you know, I was an Oxide fans fan back when the chime used to be abrasive. Now you can barely [laughter] hear it. How much I when you Yeah. used to be oxide listeners that you had to know it was coming and take off your headphones lest you be deafened. Yes. >> Yeah. Exactly. You would duck and covered the um No. So I think the chime is is delightful. I was relisting to I</p>
<p>was relisting to the AI discourse episode and I truthfully had forgotten about uh when cuz we would always joke with Clabnick that whenever you know whenever he hit you know JJ whenever he mentioned JJ you know you got to kind of ring a bell and he hit JJ and boy you did a lot more than ringing a bell. That was a what do you even call that? What does that sound that kind of >> that I know that as MLG air horn? >> MLG air horn. >> Do you know what MLG stands for? No, no, >> my understanding is it stands for Major</p>
<p>League Gamer. >> Major League Gamer. >> Yeah. >> Oh, interesting. Is that okay? Uh, where are we? Are we like Millennial, Gen Z? Where are we on that? Obviously not Xers. >> I I think it's like Gen Z creeping into millennial and like >> we sound like boomers to be clear like right now we are we are giving boomer. >> Don't care. We are giving we are giving old people which is as as Susanna described the change lock [clears throat and snorts] music. Uh yeah, don't care about that one. I that one is um the uh I'm I really just you know I'm I'm just trying to to expand my</p>
<p>knowledge, man. Um so >> I think I only did one other sound effect this season >> which was another gift to you >> um more recently. Do you remember this was for the episodes not done? >> The episode's not done. So, you were talking about Yeah, we were we were you were talking about like an episode I think we like we we didn't do an episode on uh but we should have probably on one of the Rust async bugs that Rain had encountered.</p>
<p>>> Okay. And you were like calling for the chime for an episode that didn't exist and I gave the uh prices right failure uh like wampwamp wamp I you know I think I I had remembered that but forgotten it >> there was the wamp wamp in there that's a so when was that must have been well I don't know go dick >> the one most recently when rain like just a couple weeks ago I think when we were talking about Yeah maybe future >> future lock yeah yeah >> uh future lock a great episode. Um, so</p>
<p>we uh I did so I love the chime. I thought I think that the the chime was a great ad. It's a deep poll. I think it's um you know the fact that it's a sound from a visceral sound from from your youth, but our our kind of shared youth. I thought that was great. >> Um and I I I love kind of having that call back to previous episodes. And I know people online hate it. And I guess</p>
<p><strong>[24:06]</strong></p>
<p>I mean it is what it is. I don't know what's I think the >> agree to disagree. >> Agree to disagree. I want I'm like this like we we have no ads like you you literally never have to fast forward through anything other than our banter and like yeah you get the occasional chime like that's think of it as a subsecond ad. So that's that's what I got to say on that. >> Um okay so I also did the experiment you did too of um you know that's kind of like it's been super busy and I just didn't have a huge amount of time to prepare for this. So, you know, as you do, want to see what our little LLM friends would how they would do a</p>
<p>wrap-up for this year. Did you do this? >> No. >> Oh, it was fascinating. So, I did a wrap-up with both uh Gemini um and with Chachi. So, this is Chach 52 uh and Gemini 3 with deep thinking or whatever, you know, everyone's, you know, deep research um 35 anyway, whatever. Uh pretty interesting. So, one I will say this the on the I asked them to like taxonomize it and uh both of them really nailed it. I mean because one of the</p>
<p>things that we you know the the episodes did have a different tone this year and I don't know that it's deliberate. I think it's I it's a consequence a couple different things but I mean would you what would you say is a big theme for this year? >> Bugs. >> Bugs. Yeah, bugs are >> I was delighted. You know, you know what was less of a theme that I anticipated was uh AI. >> AI was less of a theme. AI was less of a theme and I think the I think it's because it's like less on the horizon</p>
<p>and more like in the business now. You know what I mean? Like it's more like it's like kind of everywhere now. feels. Um, so we did have a couple of AI episodes um, including the one on material the AI materials and fraud which again I I and I that was really uh, a delightful episode and conversation. Um, just cuz I feel that that fraud I it's okay. Can we just actually maybe we should talk about this for a second? Jokes that we think our jokes it's go to laugh your own jokes but that's never prevented us.</p>
<p>jokes that we thought are funny that our own jokes like I'm sorry the Aiden Toner Rogers if I did it that that killed me. I every time I relisted to that it killed me. Um I just I I thought the the OJ Simpson Aiden Toner Rogers mashup was >> um I loved. >> Yeah. Um >> did you have any that you um >> um any any joke jokes of my own that I want to like relive? >> Yeah. Yeah, exactly. Now is the time when we can we you know we get to laugh at our own jokes right now.</p>
<p>>> Yeah. You know what? I I I none really come to mind. Uh I know that I know that you doubt that completely, but uh I don't think I retain them well enough. Um yeah, I'll need to I'll need to think that one through. Uh but I I do like when I am listening to our episodes, I am embarrassed by like sometimes needing to pull over and like titter at a joke that I told to myself 5 months ago. So at least I know my audience, which is >> Exactly. Exa Exactly. So that that's</p>
<p><strong>[27:09]</strong></p>
<p>good stuff. Anyway, um so um the so I I but we had a lot of of episodes on debugging um and a lot on bugs. I mean just we did not have uh including some really interesting stuff. So I mean it's like both LLM picked up on this as a pretty big theme and both kind of properly taxonomized. It didn't elucidate episodes which is you know a nice thing about having all of the the I God only knows if it's getting it out of the GitHub repo or out of the out of the RS feed or the transcripts. I mean, I am not so sure about the transcripts for reasons I'll get into in a second. I</p>
<p>[laughter] I think the LLM may be studying on the train on this one. I don't think that like we've done a whole lot of deep work on the um because the very very good superficially and then things kind of fell apart. um but properly kind of taxonomized all these episodes and we had I I I mean I count we've got certainly the debugger driven development um with Dave um and then we had really uh what five different gnarly bugs that we did an episode on each of</p>
<p>those bugs. So when async attacks >> actually I think I have six. Yeah. Okay, you go. >> Okay. When async attacks, uh, adventures in data corruption, >> future lock, uh, a grown-up CFS data corruption bug, uh, death by uptime. Am I missing one? >> Uh, hell is Other Networks. >> Hell is Other Networks, of course, >> cuz that I mean that was >> Yeah, that that was absolutely. Yeah. Yeah. That and actually that bug in many ways is like actually an even better I mean, the thing I love about that bug is that is something we actually saw in the field.</p>
<p>>> Yeah. >> Um, which I thought was great. So I Yeah. No, we got a lot like really um those are all great episodes and actually it's funny because we did so many of those that uh our colleague Laura has a great blog entry up last week and on a a bug that we had uh in the service processor in bringing up Cosmo and there was like it didn't quite get the traction on hacker news that deserved um you know next time I guess write a milktoast RFD on LMU [laughter] as opposed to like really deep technical</p>
<p>work apparently. But I actually probably need to get that one in the second chance pull on Hacker News. But there was one comment on Hacker News which is like, "Oh yeah, you know, I loved the podcast episode on this." And I'm like that we actually didn't do a podcast episode. This is actually a different I mean I know I know it feels I know I know it feels like every bug we possible and we probably should do a podcast episode on this but you're actually thinking of a different SP log than I think of death by uptime. Um, but the >> um I uh I I I loved I was so great I think to have on each of those having</p>
<p>the team on and being able to to to kind of and because each of those was a really gnarly problem like I I don't feel like any of those was a a simple problem. Um and it was great to get people in their own words talking about. So I love that. I mean, I don't know what you're I mean, clearly I know that you'd be you'd be right to to levthol me right now because you're like, "Oh, really? Oh, this is interesting." Oh,</p>
<p><strong>[30:11]</strong></p>
<p>people like an episode that where we talk about an interesting pug that we debugged. Oh, I wonder if anyone had ever made that observation before. No. Oh, okay. Thanks. I know. I know. I mean, in in the spirit of best of us and the airing of grievances, even though I know I've already aired these grievances, like do you remember the I I I think I pasted into chat in in during that episode all of the all the DMs I had sent you wanting to do that episode [laughter] and they started to be like, "Hey, I really loved that idea you had, Brian, to do an episode about this." I was trying to kind of intercept you.</p>
<p>[laughter] >> Yeah. Yeah. You're trying to accept me. It's like, no, I like it. It was the end of the Hey, look. And one of those worked. We can't say which one, but but one of those worked. >> Um, >> yeah. >> No, that that was even the dog loved it. I mean, I think it was the And those were So, yes, of course, we know the dog is like I'm not saying I loved it. No, sorry. I've got [laughter] >> I'm saying I was here for it. Yeah, I had to listen for it. Exactly. >> Um, [snorts] don't put barks in my mouth, please. Um, but I uh I thought they we The thing I love about this I mean this is what you</p>
<p>and I like I think love about these just in general too is that when these systems fail they reveal themselves and every one of these failures which are actually pretty different. I mean with the exception of death by uptime sounding a lot like the the bug we described in the plug entry even though it's totally different but each of these is a kind of in a different aspect of the system. Um so I thought it was and there's a lot to learn from it. So I thought anyway I thought those were were great. Um, and I I just wish you had told me sooner that we should be talking about adventurous data corruption. I mean, if only if you had said it sooner or more frequently.</p>
<p>>> That's on me. [laughter] >> That's right. [snorts] >> Right. There's only one person to blame and that's me. Uh, no. I love that there's a theme, too. I mean, I just feel like uh, you know, I think sometimes we we talk about um, you know, junior engineers reading this, college student I mean, listening to this and or college students listening to this and I think that those are all such terrific episodes and and uh, such terrific learning experiences like >> I learned from those episodes. Um, certain certainly as we're debugging, >> no one person >> is is debug. I mean, maybe with the</p>
<p>exception of Cliff last week, but uh, by and large, it's not just one person figuring it out. Um, and uh, and a lot of great techniques, a lot of great sort of um, you know, guidance for just how to take incremental steps on those things. So, I think those are always super fun. >> Totally. And Cliff would be the first to say that very much the baton was passed that there bunch of folks who've done a lot of work on that problem that allowed him to really take the kind of the next step on that. So, no, I I agree with you. Each one of those was a real team effort. Um, and it was I So, the um so I asked the I I asked our our LLM friends</p>
<p>how 2025 contrasted to 2024 and the the the presence of these episodes on debugging has it drawing some big philosophical conclusions that I'm not like I'm not sure. >> You guys write garbage code now like 2024 your code was tight. No, they both</p>
<p><strong>[33:11]</strong></p>
<p>said that like no 20 the 2024 was about the the philosophy of building systems and 2025 was about the pathologies of those systems when they're built. This is about the the uh I believe it was chat GBT that called 2025 relative to 2024 quote painfully concrete unquote [laughter] which I'm like again I don't know if this is like >> did you like is it reviewing us on like Apple podcast cuz like no thanks on that one. >> Yeah I know painfully concrete is I feel like something I I mean I feel like this</p>
<p>is feedback I may have gotten more than once in my life. So, um, the, uh, but I thought that was, you know, then I got to think about it like, well, maybe that does actually kind of reflect, I mean, cuz we're talking about a couple of these things that we are that you only do get in a bit, in a system that is a bit more mature or is in a is in the field. So, I think there's some like slight accidental truth. I think we've been debugging really gnarly problems all along and I think we've been talking about them somewhat all along. Um, and I would in particular like I think that if one is interested certainly on the</p>
<p>hardware side like the bring up episodes, all of them and we had bringing up Cosmo this year. Um, really get into all the nasty issues we see in bringing up a new board. um the um so I I think we've been talking about it all along, but I think it's also true that like yeah, we actually definitely talked about more in 2025 and maybe it does reflect um you know the uh and again all of the LM suggestions on this are are you know they want do and would you like me to write a one-s sentence paragraph on on each of these years and do you want me to do this? I mean it's always like it always ends with this like do you want me to take it much further kind</p>
<p>of question to you? Do you know what I mean? like do you want me to like should I go tattoo this on my knuckles and you know strip of the waist and run through the streets I'm like no no no none of that would be necessary right now thank you [laughter] very much >> you know I I think I am a victim of like the the memory that chatpt has because I have told it to be tur so many times >> that I've I in fact I've told it to be tur to the point where I am asking it for more information like if I'm not asking for more information it's not being tur enough that it now just gives</p>
<p>me wonderful responses like very frequently. So I I think I may have over fit that one. >> May may have overshot the mark on that one. Yeah. Like chatp is like look frankly I'm walking on eggshells with you. So I am trying to use the fewest words possible. I and I I've got a bunch of ideas of things that I want to do, but I'm going to go save all them for for can. He's he seems to love them. I'm like which I don't. I don't want any of these. But you know I I >> I'm not going to tell you that. That's fine. Yeah. I get it. >> Yeah. So I um so that was a big theme. I mean of course wasn't they weren't all</p>
<p>debugging episodes but there were more that were just about uh engineering at Oxide. I think we had more on and fewer hot takes, right? I think which is like probably good, right? I think >> yeah I think I counted like eight or nine or 10 like oxide >> kind of like hanging with the oxide crew what it's like to build at oxide you know bringing up something you know</p>
<p><strong>[36:12]</strong></p>
<p>having Robert on Dave on talking about some of the kind of structure around how we build stuff. >> Yeah that I that episode with Robert was great. >> Yeah for sure. >> I really really enjoyed that conversation with Robert. Also can you talk about the AI work on that one? That was great AI work on the image. [snorts] [laughter] >> Yeah. So that that was like an AI assisted image. It was an image of Robert at a whiteboard drawing. The original image had like five other people in it that I thought were extraneous. >> Yeah. Just like we're actually going to</p>
<p>we're going to airbrush these people out of the we're going to you know channel our inner Soviet and it's like yep nope not you. You're now >> it was just Robert designing everything in a whiteboard by himself with no audience. Yes. >> And I mean admittedly to be fair it's like these are actually people that were all like broadly so familiar with the company. It was just like it's just like their legs or what I mean it's like it wasn't it wasn't a flattering. >> It was just the framing. It was right. It was framing. >> Right. >> Yeah. So anyway, I thought that was that was an excellent image and I love that</p>
<p>conversation. I thought that conversation was was really great. Um, I think that the uh I mean obviously we're all feel very I'm very lucky to work with all of our colleagues, but um Robert's disposition was one that really I mean it really was a a a great kind of one episode synopsis of our engineering ethos and approach. Uh it really merits merits a relist. I thought that was very good. >> Yeah. >> Um because someone mentioned it in chat they they they talk about uh you know we talked about running into Dennis Richie trying to give a drace demo. Apparently,</p>
<p>we talked about it this season, but but we in fact episode, right? >> Yes. But we had in fact told that story maybe two years previously, but so I I but I'm delighted that for somebody it was a highlight of the season, even if for somebody else it might have been a highlight of a different season and maybe we'll tell it [snorts] again next year. And you know, I think that people should take some solace in us retelling a story that we've already told because you'll find that the details tend to line up.</p>
<p>>> You know, I mean, >> I was going to say it really emulates the Brian and Adam like IRL experience as well. >> It does. Which really emulates I think you're much better at this than I am. I mean like and I uh I so pride myself on like I mean I really try pride myself. I live in fear I should say of just like endless endlessly repeating. What's the opposite of pride? Oh, yes. Living pride myself, right? Like, excuse me. Hold on. I'm being just being handed this. Um, no. I the um and I and then of course like you relisten to the podcast like oh my like it's like it's the you know</p>
<p>where were you when MCA died which I think we've referred to like eight different times over the history of the podcast. Just like okay I need to wind that down. Uh so these things that I thought I hadn't repeated but I was able to actually surprise you with things about me that you had not heard. >> Yeah. >> Uh which I thought was um in particular my my own the the first $5 I made as a software engineer. I you not heard that story. U so uh um so that was good but</p>
<p><strong>[39:14]</strong></p>
<p>that was that was earlier in the year than when we were all at the ballers game together um as when we we met up as a company. Uh, and I was I was telling a story that I was convinced you had never heard and you literally identified it from a single syllable. You're like, "Wait a minute. I know this one. This is >> too." Yeah. >> Yeah. And I'm like, and I'm that's I'm not going to give people more context. That's the That's the only thing I'm going to I'm going to tell people. Uh, but I So I Anyway, I am always worried that we're that we're repeating these</p>
<p>things too much. But the Dennis Richie story, I'm glad that we have told that. um twice apparently >> so far. >> Um uh we got some other favorite moments. Um so this is Tyler in the chat dropping in some other f favorite moments. Uh the uh the books in the bonfire. Uh I love books in the box. >> I really love books in the box. I I I um and um I uh I'm reading um and I believe a recommendation we got from Books in the Box. I know this is like an off like</p>
<p>offcycle books in the box, but the eccentric orbits, the aridium story that we got that was a recommendation we got in Books in the Box and um I'm really I'm loving that. It's very good. So I um I really love the books in the box episodes. >> Yeah, same. I I uh listened to actually the Neil Stevenson book uh Terminal Shock uh started that like the kind of the day after and and really enjoyed that and it felt very much previous Neil Stevenson I'd read. Um uh and it felt very similar to like you know experience from 20 years ago but it's great.</p>
<p>>> Uh that yeah that is I I do you recommend it? I need to go I I'll go check it out. Yeah. Yeah. I have not not read any Neil Stevenson. >> Am I a safe space? >> No I think I think uh I think you may have already do I say that in every podcast episode it's happening again. Are we going to get like what what's the chime we're going to ring when I for my early onset dementia? Are we going to have one for that? >> It's like it's your good night and good luck. >> It is. God damn it. All right. [laughter] Um well, I</p>
<p>>> usually trim that in the sign off just cuz I feel like it's a little repetitive, but you say it every single episode. Look, I still haven't read any Neil Stevenson. I know. I just I feel that that's like I feel that that's an aberration a little bit that I um that's >> right. >> And this um is now the time to uh No, this is not the time to mention this, but I'll mention it anyway. You know, I've been kind of fantasizing about a Mad Men, but for Fairchild Semiconductor. No one needs to make that. And like I guess ring the early onset dementia chime because it's got</p>
<p>nothing to do with anything we're talking about, but I wanted to get that out there and now it's out there. So >> to get it off your chest, >> it's off my chest. I think it'd be amazing. >> I think it' be amazing. [clears throat] >> I'm in. I'm in. >> It's like a period piece. >> A Kickstarter. I'm I mean, I'm in. >> It's a Kickstarter. It's a Kickstarter for a period piece about Fairchild. Super large demographic kind of a show. So, >> speaking of poor segways, one of the things that I was hoping for this season</p>
<p><strong>[42:15]</strong></p>
<p>that or predicted, no pun intended, was more about Intel >> and um and we had our [clears throat] predictions episode where you made a great prediction about Liutan. Uh, amazing prediction. Uh, >> well, my prediction was that the co-CEOs would still be in place. >> No, it was sort of uh, but you you talked a bunch about Lip Boutan >> about Libo. Yeah. Yeah. Yeah. >> So, and [snorts] then Lip Boutan joined and then we haven't had much to say since then. >> No, we sort of I sort of thought there would be more to say. That's all. >> Yeah. Yeah. It's uh I'm I'm less</p>
<p>surprised that there's not more to say, but we'll you know who who >> who knows what the future holds in one. Yeah. big highlight for me. Uh John Holloway dropping the Oxide Bingo. >> Uh for those not familiar, >> very good, right? It feels like we've always had that, but that has actually that Yeah. Yeah. >> Oxide.Bingo. Um amazing. >> Really amazing. That been delightful. Uh, and you know, I think um, you know, we've got I you need to to ask um the,</p>
<p>uh, ask the the LLM what they kind of think of the oxide bingo card. See what they Okay, because this gets into the um, I as I was like, so they they're kind of cutting these big themes of 2024 versus 2025 and and I thought that was kind of interesting. Uh, and then I asked for some fan favorites >> in and this is where things got a little started to get a little funky. um where cuz and this is you know the um</p>
<p>the the Shell Game podcast gets into this but the I mean the big challenge with these things still is they really struggle with like I don't know >> and they they still like will go just absolutely bonkers if they feel that that's what you've asked them to do and so like they're just happy to make up what they think are popular episodes and they like make up reactions and Uh it was and you know like some of it is like this like could I mean this is like not</p>
<p>an unreasonable thing like yes the death by uptime could be a favorite episode but we also only cut that two weeks ago is that like this is what chatbt has convinced has become a touchstone episode >> [snorts] >> uh as what one that people you know has test of time and um I mean it was it's like okay uh that and chat GPT amusingly is like well I obviously don't have access to any of the the view counts for this stuff. So, it kind of acknowledges that I I will ground this in observable</p>
<p>audience signals that you do have repeat references, community chatter, longevity of discussion, and how often episodes become shorthand, eg the async episode or the ZFS bug one, etc. Which sounds like a great idea, but then it doesn't do any of that. Like all the I mean like I don't know how has Death by Uptime become shorthand. It's our most recent</p>
<p><strong>[45:16]</strong></p>
<p>episode. That doesn't make any sense. H I I this I mean I feel like this intern has like started their internship very strong but then then [laughter] they kind of drifted off. Exactly. This I feel this is what often happens with the LLM intern. Um what what emerges says Chad GBT is that audiences favor favorites skewed heavily towards painful specificity and earned insight. It's like okay come on >> tone it down. Um the um and I mean then it kind of goes on like</p>
<p>every episode like why it landed and you know why it's a favorite. It's like you're just making all this stuff up. So um the anyway then like things are beginning to drift. I go over to Gemini and ask it the same question. Gemini kind of interestingly is like does not have any of the same reticence about going into view counts. >> Gemini is like oh YouTube's a property. I can actually go. It's kind of interesting right? I actually well sorry I actually do know all your view counts by the way. I also know your bank account balance by the</p>
<p>way so I can kind of factor that in. Um and uh >> he knows like our demographic breakdown and it probably knows >> exactly like I know all sorts like I know exactly what kind of ad to put in front of you right now. By the way, a word from our sponsor. Um so it has the what it calls the undisputed heavyweight. Gemini does of its undisputed undisputed heavyweight heavyweight of the year. It has one that's just like this one is got it's got the highest view counts of the year which as far as I can tell is actually true.</p>
<p>>> Huh. >> Um >> I'm going to guess it's system software on the large with Dave. >> Bingo. Bango. That's it. >> Yeah, that was a great episode. >> Really good episode. And I I do know that the view counts were high and uh you know the the the chatter uh such as it was was you know was was pretty good. So I think it was people people took a lot away from that. >> Um and I I I do see it referenced from time to time >> and you know as usual like Gemini like wrote one sentence too long on this. So it was like you know it bridged the gap</p>
<p>between code and reality d you know and then its final sentence on this is it resonated with every engineer who has ever had to push a scary update button. It's like yeah strike not [laughter] that one's not yeah um and then uh and then it kind of goes into and then again it kind of makes up the popularity of the others. Um, I mean it I think right I mean it's like the they talk about scing manufacturing that's the how it's made favorite and I'm like I think it's</p>
<p>a great episode. I'm just I mean I would love to think that um I don't know. Um >> you have the home labers who are trying to to ramp up >> ramp up the scale. [laughter] Exactly. >> Um it does it does call out founder versus investor as the as the crossover hit. Um I I did I really Exactly. Sure. Why not? Um I really did I I love that episode. I thought that was fun. Um, and the um, I also loved the fact that Liz's</p>
<p><strong>[48:19]</strong></p>
<p>current startup has an LLM based on that one has kind of with one's own voice and expertise and then we could actually go to that and people were during the episode going to the LLM that features Liz and Jerry as LLMs and like positing things about the episode and then they were replying in kind and it was it was pretty good. So, um, pretty sassy. It's funny. >> That was good. Uh we haven't talked about I think the episode that was not the most popular but like I think that we were most excited about which was uh character limit. >> Character limit I is is outstanding.</p>
<p>>> Kunger and and Ryan Mac on I think we kind of were both very excited about the book and really excited to have them on and audio is just abounded as they do. Uh but it was a really fun conversation with those guys. >> Biggest get your get biggest get. I thought that was the that was a great get of the year. Yeah. I I thought it would that was and it was a great conversation. I love that book. >> Yeah. >> Um I I made [snorts] the arguable mistake of like I left my physical copy with my mom in Mexico. I'm like, "Mom,</p>
<p>you have to read this. This is so outstanding." Um she hasn't. And now I'm kind of got the awkward thing of like, I want the book back. Like you're obviously not going to read it. So just like you're going to Anyway, >> I mean that's a book I I like I referenced last night. That's a it's something that I I talk about frequently that um along with careless people go those go kind of hand in hand >> and you know I also there there's a there's a joke that we that to jog your memory about about jokes that you have that we laugh at is they they kind of the uh the Tinkerbell character um for</p>
<p>[laughter] Sarah Win Williams >> Sarah Williams that's our frequent guest [clears throat] >> like I think you think I'm kidding but like I do want to do that episode like I want to have Sarah Darwin Williams in the in the office with us. >> In the office with us. Absolutely. >> Not saying anything per the court order or whatever >> and just us pretending to have heard something. I >> I think it'd be great if like in addition to Meta issuing a restraining</p>
<p>order against Sarah Williams, Sarah Williams issues a restraining order against us from using her as a like I'm not I'm not on your podcast. I'm like, well, that's what you're just abiding by this restraining order. We understand that we know you are never on the podcast. >> Signal is seriously like this is disturbed and I like you're actually not abiding by the restraining order. So, you need to stop, please. Um [snorts and clears throat] >> I [laughter] you know I I think that 2026 needs to be a year like we got to get a CND from someone. I I just feel</p>
<p>that like stretch goal. >> It's a stretch goal. We just haven't arrived into We haven't got the lawyers involved yet. Clearly Fox is not going to send it to us. Like >> we're not I I we I don't know how much harder we can be trying. >> The estate of Jean Paul Sartra isn't going to like [laughter] like when are we going to get this letter? >> When we get this letter, come on. Um but that book is so so so good. Um I would love to also have her on um if and when</p>
<p><strong>[51:21]</strong></p>
<p>she can uh she can join us because I thought those are really the book is obviously stunning. No, I thought that that episode was great. I bet you know another um an episode that I Okay. What are episodes that you have sent to people if any I don't um >> um I sent the one the one with Michael Litman the the AI and higher education. Uh >> love that one. >> Yeah. Like I sent that one to my folks. I've sent that one to um my both my technical and technical college friends. I think it's like it Michael is so terrific. I I thought he had such a uh</p>
<p>thoughtful take on AI and and um you know not to throw out my shoulder patting us on the back but um you know I was I was pleased that you know we came up with this way there. I thought this was a very good guest to have a a a better conversation about AI. I think we had had a lot of conversations about AI that were that were good but I think this was an area where it's easy to be simplistic and reductive. And I think Michael had had a had such a thoughtful, considerate conversation with him. I</p>
<p>really enjoyed that. >> I really enjoyed that, too. And I I also sent that to I sent that to my 18-year-old, my my college freshman, um, to get his perspective on it, cuz this is something that everybody is grappling with. And it's a really important subject, especially in higher ed. And I thought Michael was great. I thought it was really, it was that was a terrific conversation. Another great get for you, by the way. Thank you. Um, we are keeping score and and you're and I I know that this is all about getting me getting Morris next year and I trust me I am feeling the heat. I am feeling the</p>
<p>heat because you guys good. Especially if I get Evan, forget about it. You're like way behind >> Evan. I I get Yeah, I'm still going to be like, "Wait a minute. That guy I played ultimate with that guy. I don't know." No, no, no. I didn't play ultimate with you. You can come. It's fine. Um the um No, but that was a that was a really great conversation and I So I sent I I have definitely sent that one. Um, and then another one that I've actually sent a decent amount is, and I I know it's off our demographic, but diving in with Robert Bogart. Um, and uh, the because I' I've had a decent</p>
<p>number of parents of athletes reach out to me after my blog post um, about college baseball, venture capital, and the long baby. Um, and uh, that and then that listening to that episode as well. Um, so I was really grateful for Robert for joining us. And again, I know it's I know it's a little bit we but we got to take you off the beaten trail a couple times. You know, I feel like I it I just doesn't bother me that like we're going to have things that are that people aren't necessarily expecting from us. >> That's right. I mean, we did have like 100% fewer baseball episodes this</p>
<p>season. >> Yes. I mean, if you're calling I mean, but we we also had a million% or more. I'm not sure what you're coming up from zero, but on NCAA swimming. So, I'm not sure like I I mean, sure. I mean, like, you know, out of the frying pan into the fire. Um, but >> that's fair enough. >> Um, but I thought that was that was another great one. And so, and that one I I I've sent to a bunch and of course we I also end up, as you can imagine,</p>
<p><strong>[54:22]</strong></p>
<p>sending episodes to folks that are contemplating becoming oxide customers or becoming oxide, want to apply to oxide. So, it's been a great factor for that. And I've sent a bunch of them out for that. But those are episodes that I've sent to to more personal folks. So, >> yeah. Yeah. Yeah. Same. But but that but kudos to you for bumping the uh the listen count for everyone applying to Oxide being sent a bunch of podcast episodes to listen to. >> Yeah, exactly. >> Good strategy. >> Yeah, you got to game this somehow and you might as well do it with applicants. You know, you got to go I actually would be curious to go because you know we do</p>
<p>point every Oxide applicant to our conversation with with Gayoros. >> Yeah. >> And from uh from 2024. from 2024. Uh, is that when that was 2024? Okay. Yeah. >> God, they it's all I That one should have much higher view counts, listen counts [laughter] if it but I'm not convinced it does cuz we we definitely get plenty like if you're going to apply to oxide, please do listen to this thing by the way cuz it's like it does have there's there's a bunch of stuff in there that is is</p>
<p>helpful and der. >> That was 2023. Jeez, I'm >> Yeah, I know it was late 2023. Now, you're right. >> Yeah, that makes sense. No, I know it was late because it was like dark and cold in the office. Uh late in terms of like late in the year um in the winter, but yeah, that's it. Um so, um but then does that one have higher view counts? I mean, listen, are you on the transistor looking at the transistor there? >> I'm not I should What am I doing here? Why am I looking at transistor? As long as you're looking at transistor, we got you know, we we get country downloads. Um and you know, we uh I it' be</p>
<p>interesting to know how we're doing. I think you know, last year we called out like our downloads in Namibia. We've got, you know, 20 downloads in Namibia this year. So, not sure where that that kind of that counts. Um, we do still have some countries with it with with zero downloads. >> Um, several of which are war torn. One of which is like Papa New Guinea. I feel like Papa New Guinea. If you're if you're in Port Moresby, I feel that you can listen to Oxide and Friends like Papa New Guinea. I >> think you can just like up it a little bit. I feel like you know. >> Yeah. Just grab the baseball episode and send it to your buddy in Papa New Guinea and we'd really,</p>
<p>>> you know, I will. I think I think Port Morsby can really I think it will that'll resonate with them. >> The Gurg episode hiring processes is top six. Top six. >> Okay. Of all time. >> Yeah, >> that does make sense. So, that one that stat you can definitely view as gamed because we are >> we are asking people that's that is uh that's wild. Um what are some of the other are there any this year that are in the the top episodes of all time? Okay, so the stats are a little >> funky. So the reason the stats are funky</p>
<p>>> on transistor in particular is and the reason why the while United States is our the most common uh country that has downloaded it the most common state Arizona baby [laughter] Arizona where in somebody's basement they were like downloading the most recent 10 episodes over and over again for a year and a</p>
<p><strong>[57:22]</strong></p>
<p>half and then it stopped. So, thanks for not downloading them anymore, but uh it means that our 2025 stats are not like we we have fewer downloads because that computer in Arizona has been turned off. >> Yeah. Okay. So, then the when you're look what are you looking at for are you looking at all time >> or are you looking at for the Okay. Not for the first Yeah. Interesting. >> Yeah. So, um, yeah, if I look all time, actually, our predictions episode this year was our most popular episode this year, >> and then after that was the one with Robert Holistic Engineering.</p>
<p>>> Yeah, that's great. Yeah. Nice. Um, well, good stuff. I the um and I guess all time I think that's funny that our second alltime lease now I'm looking at it is Crucible. >> Yeah. >> That you promised that Allan Allen you can come join us because don't worry, no one will listen to it. It's like actually everyone will listen to it as it turns out. >> That's right. >> Uh and good to see the RFD episode right up. I that was that's that was a great conversation. >> Yes. >> Um so I'm really glad to see that one up there. Um yeah, some some some good stuff.</p>
<p>>> Um >> the All right. So um the uh we that was a great episode. Are there others that we before we we get off of this because there's another thing I want to hit. Yeah, >> those were the episodes that I that I had called out in particular. Yeah. So, okay. So, then I But with the fan favorites, you can feel the LLM's wobbling a little bit, like they're beginning to move into [__] I mean, this is just like, okay, this is not um and uh then I I asked it for uh I in part because I actually was genuinely</p>
<p>curious about what it would find. I say to my prompt being the podcast infamously makes Gen X references. Were there some notable ones this year? And this is where all LLMs just went straight into the wilderness and lost their confidently with absolute confidence completely lost their mind and just started absolutely making up [__] and making up references to oh like yeah the uh they make they make a bunch</p>
<p>of office space references which I think we basically don't make like maybe Maybe a little bit. Not I mean the only I mean I feel like I I the office base reference that I make I would say the most frequently is like a Michael Bolton M dash mashup of like >> you know that right right he's changed his name he's the one who sucks. Yeah >> that's right. That's right. And so I like that I feel but I don't think I made that here but I don't know then</p>
<p>then again >> um so like no uh that then it says like they make references like we definitely >> 100% don't bunny don't know like that could go either way >> that goes one way one way only goes straight there will be no references on this podcast and if that quip makes it</p>
<p><strong>[60:23]</strong></p>
<p>into the recording I'll be amazed because that's how canled is as far as we're concerned like that is that is a 0enter we not making references. Uh, and then it's it just went it's like oh they make Nirvana references and Grunge era references and they they started like these are the ones that they made a Nirvana reference in. It's like uh I mean it was just I mean absolutely unhinged. At one point, uh, Chat TBT says when summarizing all of this up, uh, says, "This isn't nostalgia. It's</p>
<p>epistemology." [laughter] >> I mean, that's got to be the most LLM thing ever generated. >> Oh my god, that's crazy. [laughter] I mean, I I I just don't know the cognitive dissonance that you would have to make. I I mean, hopefully that doesn't sound like me. I mean, my god. And then it's like [laughter] they're uh they're making like >> um they think we make a bunch of talking</p>
<p>heads references. >> I don't know that I would confidently even know how to do that. >> I don't know. Oh, I would I if you ordered me if you if you if you put a bayonet in my ribs and ordered me to make a D talking head reference talking head reference. I don't even know like how I would start on that. I mean, I like I >> I did see David Burn live talking to uh Dave >> stabbed in the Revs. Nope. Not good enough. I mean, it's just like Sorry, we're not asking for facts about Talking Heads. I want you to make a Talking Heads reference. It's like,</p>
<p>>> okay, I will I will say that he he he did get on stage and do they had a karaoke machine from Japan that had uh talking heads [laughter] with like the lyrics messed up and he was just going along with it. So that was fairly delightful. >> Okay, that counts. You know, [laughter] we want that. My ribs are going to get it though. I I think that that is uh so um and then they and then they actually this is kind of I mean this is where you you do</p>
<p>wonder about the power of these things to kind of induce a sense of dementia where they're like oh then they make war games references I'm like okay maybe we might like go on expand >> did we talk about Dave Hits this season >> okay that's good >> I think it was last season wasn't that I think that was >> um >> good yeah someone says last season they said uh Dave headset had had come up in in uh as another source of cease and desists. >> Um</p>
<p>>> yes, that's right. That's right. Um and then uh and then it calls out the meta Gen X humor of weaponized weariness. >> Perhaps the most on brand Gen X reference of 2025 wasn't a specific artifact, but a tone dry fatalism. Humor without [snorts] hopeing. Laughing at complexity, not away from it. It's like</p>
<p><strong>[63:24]</strong></p>
<p>what? Where are we? We're just We're just making [__] up at this point. >> That one That one feels more personal to me. I mean, I'm exhausted, but yes, >> but it can't know that. No, it [laughter] can't know that. We Sorry. >> Yes. Yes. But we not That's not what we're doing here. We're not I don't We got dry fatalism here. Like, no. I mean, >> that's just a lucky guess. That [laughter] That's not >> a lucky guess. >> That's got nothing to [clears throat] do with the actual podcast. >> Yeah. Um, and then I I asked it for like, no, okay, I want the Gen X reference in the content itself. So, do</p>
<p>you know what I actually Well, I mean, this is I was just kind of curious to see if they would pull it, but one of my I got to say favorite moments was when we had Oliver had join us on the stage. >> Mhm. >> In the books in the box episode. >> Books in the box episode. and start he like is come either we're making a Night Rider reference and he's rolling with it or maybe he even he made a Night Rider reference whatever it was he was rolling with Night Rider >> and I'm like doesn't add up it doesn't</p>
<p>add up like that does not make sense because I know for sure that thing did not leap the generational chasm to the contrary kit is lying at the bottom of a ravine the like it absolutely did not and so I pushed on like how do you know about night records? I know that Oliver is like not of not an excerpt, not of the vintage and I'm like there's got to be something and then he revealed that like actually it was they were they represented in the Spongebob movie. I just felt like that was a moment of just</p>
<p>like maximum triumph for me. That was my that was my biggest triumph of the year. >> Okay, good good to hang your hat on that one. >> I just felt like I kne I called it. I knew it. I knew that. So, I wanted to see if it would actually pull that out, which is just like a ridiculous hope because like obviously the it's like it's good, but it's not an actual like magician. Um, and so it I asked it for like explicit like what about Gen X references in the content itself? And it just again it it's just off into the absolute weeds and more just like and</p>
<p>like so it's like saying oh like the the episode in which it referenced was system software in the large and shoot out of the CNCF corral and then it's got like quotes from that that are references that we didn't make. Huh. It's like wow that is uh okay. Yeah, that is so Gemini, you're chatbt just just lit itself on fire. So, you're up, pal. Uh, are you going to do any</p>
<p>>> I'm amazed you didn't just make a Top Gun reference. I felt like I felt like I saw that one coming. >> That I didn't make a Top Gun reference right now. >> Right now. Right this moment. >> Right now. That, you know, I that I should have that Cougar was number one. Lost his edge, turned in his wings, and now you're number one. >> You know, I should That is >> that Gemini. I I can't believe I gotta do this, Gemini. I gotta send you</p>
<p><strong>[66:25]</strong></p>
<p>[laughter] to Myiramar. >> LLM, thank you. Good luck, LM. >> That's right. All right, that was good. Thank you. Thank you for the prompt on that one. I am kind of losing my edge maybe a little bit. Yeah, that [laughter] does feel like a bit of a layup for myself. As long as we're on Gen X references, you think that like you all those synapses would be hot, but I guess not. Uh, okay. No, that's a great reference. Um, the um so I asked Gemini the same thing. Um, and I this got a little bit like weirder and a little more like both more accurate and less accurate. So, first of all, it's like, well, first of all, you got to</p>
<p>talk about the Fox reality TV throwback in When Async Attacks, a clear reference to When Animals Attack, which I guess it kind of is. >> Mhm. >> Um, but it's like not an explicit homage. [snorts] >> No. >> Yeah. I mean, I Yeah, not an explicit homage. I think like riffing on a theme. I think we would also like we would make a if we're going to make an explicit homage, it would be to Man versus Beast. Did you ever watch any of those? >> This is like like Kobayash or like Joey Chestnut versus a bear. Yeah.</p>
<p>>> Yes. Did you watch those? They are so good. [laughter] >> Like this is like a Olympic sprinter like Usain Bolt versus a horse or something. >> A zebra. A zebra. >> Yeah. I just felt like that was extremely educational about that about I mean I think that and I mean you know I'd also like to say for my own children you know what has cast a long shadow is Wildrats. >> Do you guys watch Wildcats >> on PBS? >> That thing is like super informative hits kids at an age when they're impressionable and they watch a lot of</p>
<p>it. So there's an entire generation like drifting around with some super weird like animal knowledge about like you know a loris or whatever or you know um >> Octonauts too. Octonauts 2 embeds a lot of like esoteric marine knowledge >> that is you know and I look forward to these Gen Z broadcasters of the future like casually dropping Wildcrats references and I'm going to I'm going to roll with that is is is what I want to say. So the um so um yeah anyway man versus basic and then also the</p>
<p>orangutang versus the sumo wrestler. It's super educational like it just like the orangutang is like much smaller. It looks small I mean lighter and it like effortlessly defeats the sumo wrestler in a tug of war. I mean it is effortlessly. You do not want to mess with a chimpanzeee. I mean or rang tongue rather. Anyway, deep thoughts um man versus beast worth checking out. Um it it turns out like we are slower and than we are slower than absolutely everything but also smarter than absolutely everything. And as it turns out like that's a that's a big</p>
<p>difference. Um did you know that that humans are the only animal that use wind direction to hunt? >> I did not know that. >> Is that amazing? >> It is amazing. >> Now you've learned um you're like where are where are we right now? Are we on are you just like stop generating? Are we on like a just like are you on a chat? [laughter] You're still reading the transcript. You're still reading the transc</p>
<p><strong>[69:27]</strong></p>
<p>[laughter] Oh my god, that's actually you. Okay. Jesus. Like I' I've told it to be as tur as possible. You're like, just just go. >> Just go. >> Like just go rip. >> Just whatever's on your mind. >> Whatever. Just let it rip. >> Just let it rip. Absolutely. So, uh All right. So then it so that is like kind of barely holding on and then it just gets like super weird. Um the Fincher nod. I'm not even sure if that's a reference. Oh, he thinks they're making a a reference to seven with Brad Pitt. >> Oh, I don't think I'd make a a seven</p>
<p>reference like in public. I I I definitely I just think that would be a very weird reference to make and and I'm like so okay let's actually go into like what about the content itself and again it just uh actually it kind of like with more specificity um but absolutely wrong goes through all the the references we made to Logan's Run again with quotes to Space Balls again with quotes to the Princess Bride again with quotes to Glengary Glenn Ross to Clarks to Spinal Tap</p>
<p>and all just like making up quotes. >> Um, and like wow. Okay. So, >> yeah, I feel like we're insufficiently like cultured and literary and we should drop more references to to these important works. >> No, I actually don't feel we should. No, I feel that the the I feel that we drop I no cuz I think that like we do drop references that travel less than these. >> That's definitely true. which is like I mean arguably undermines the point because it's like well okay then</p>
<p>[laughter] people they just think it's like they should be ringing their onset dementia time. They actually don't think that this is don't realize you're making a reference to something. I do like it when you and I make a reference to only our shared history that no one can possibly know. Um which we do try to explain but we don't always do that. >> Probably fail. Yeah. >> Um I mean I feel like we would make a casual reference to Adam Lemonthal hardware engineer and not just like I think a lot. I think uh >> you do that a lot doing a lot. Well, I think in my life I I I mean in my life at Oxide I do hear about Adam Lethal hardware engineer which is even more</p>
<p>awkward since we work with a lot of hardware engineers who definitely don't necessarily get the joke. Yeah. >> We joke is doing a lot of work on that one. I'm not sure. But yeah, >> also a fair amount of discussion about Adam Lethal uh uh tax expert or >> tax adviser or >> absolutely. Yeah, absolutely. No, I I mean Adam Levthal mob accountant. I mean I feel like there's >> Yeah, I wear many hats here. Yeah. >> Many hats. Absolutely. >> Talented. Many hats. Yes. [laughter]</p>
<p>>> Many hats. Yes. I mean that's kind of what you're getting here at Lumpo Esquire. you're getting a um yeah uh so at that point I'm like okay these guys are just kind of off the um so I think they kind of lost they but it was interesting like the cultural resonance does not actually um they have a harder time on the cultural rese</p>
<p><strong>[72:31]</strong></p>
<p>>> um all right were some other um oh I also loved our uh the the Richard Scary conversation bananas gorilla finally making a cameo Yeah, Matthew. Yeah. Yeah. Talking about uh you know all all the folks in Busy Town making oxide work. Um yeah, that that was one of my favorite images as well. Even though I mean especially because it took no work, but >> but the best kind. But I mean >> the abstract Yeah. >> Well, he also just like busy town is like if if busy town resonates with you like you know you're you're our people.</p>
<p>I just think that there's something great about Busy Town. >> Yes. >> Everyone's uh everyone. So I thought I thought that was uh that was really great. Oh, then the other the other thing that the uh that Gemini identified is like and then they did an April Fool's joke with raiding the Mining Bar. I'm like, what? >> No. Okay, that episode was in March first of all. Second, >> right? >> I think it was actually it was in March. You're right. It was recorded in March. It was released on April 1st, so it >> was Oh, okay. It just took me a while to edit. All right. Well, jokes.</p>
<p>>> Exactly. Um, but it's also like not it's like it's a great episode, but it's not there's nothing deadly serious that episode. So, there's no no April Fool's Day about that one. There's no laughing matter. No. >> Um, and then I also It should be um Oh, we also had our first what do you call a podcast that is about an entity that is unnamed? Do you know what I mean? Like it's a subweet but it's a podcast. >> That's funny. You know as as I was categorizing the episodes I was I was</p>
<p>also reflecting on this sub tweet of an episode uh that was very important to you. >> It is very important. So this is transparency in hardware software interfaces. >> Yes. Yes. >> Which is on the one hand about every hardware vendor and on the other and the other in another more specific way about exactly one. >> Yes. And and you know, dear, you know, dear listeners, if you if you think, you know, if you think it's you, you're probably right. Um, so, >> and had you written an RFD on that subject as well? Am I remembering this</p>
<p>correctly? Okay. >> Yeah, I'd written an RFD. >> So, so you had the the long form subweet the subweet. Yeah, exactly. >> And I'm not sure what we call that. I mean, is there another name? There's got to be another name for like a a kind of a cultural subweet. >> That's right. Like like Twitter cannot have invented the sub tweet. >> Surely >> that's a good question. >> You feel like Alexander Hamilton like subweeted [__] everybody. >> Yes, I do. That our our first blogger too. I feel that guy that he invented so much Alexander Hamilton.</p>
<p>You know, I remember reading I think I was with you when I was reading Chernos Hamilton before the musical. Uh could you actually do you remember why I was doing this? Uh, did it have to do with like eliminating the $10 bill? I mean, the the like removing Hamilton from the $10 bill. >> That's an excellent guess. No, that happened afterwards. Uh, it was because</p>
<p><strong>[75:32]</strong></p>
<p>I we were contemplating naming Alexander Alexander and I just wanted to do like a quick So, I read a bio of Alexander [laughter] Hamilton. >> Let me do a quick 700page read to make sure there's nothing nefarious. [laughter] >> Just like I mean, you're not going to name the kid Adolf. You want to just like make sure let me just like I I want to go in eyes open. You know what I'm saying? Like it feels like you know I'm saying this [laughter] out loud pretty peculiar. >> Like imagine you slamming the book shut and saying Bridget. We're going with the</p>
<p>Adolf. >> We're going with Adolf. Let me tell you, I read about the Whiskey Rebellion and I don't know. This Adolf character just can't be as bad as this guy. uh this this uh affair that he had. I just can't I just think we're back to our our place. [laughter] >> I just think we we can't God. I know the Well, so okay, the affair is not great, but I I also do love the I mean, you know, what he cuz what he said about Aaron Burr is still kind of like not known, but people kind of like historians basically think</p>
<p>like he had it coming. Like what he said was really like he knew what he said and it was really bad. I think that they they they uh believe that, you know, uh Aaron Burr lived with his daughter Theodosia. >> Yes. >> And Al Alexander Hamilton was, I think, pretty explicit about his idea that that that they may have been uh that there may have been something untored in their relationship. >> Yeah. >> Which like, hey, got a hand to that guy, you know, real uh real taser tongue. Um but no, so that's why I was reading Alex. No. And I came then I also read a</p>
<p>bio on Alexander the Great. Alexander of Mastadon [laughter] >> of I I feel like I just said Alexander of Mastadon which is why I >> Right. Right. Got to be Now we got to check if that guy's been cancelled. Yes. >> Right. Exactly. That that's Alexander the upset. That's that's a different uh Okay, Mastadon, settle down. I know Mastadon gets super upset when we say that they're upset. So the [laughter] >> you're fine and you have a great sense of humor. You've got a great sense of humor. I do. Okay. On my LLM piece, mass</p>
<p>and this was kind of only on massedon. One of the things that RF opens with LLMs have been indis have been indisputably one of the breakthroughs of the last 5 years and people are like that's not true. Like you can come on you cannot say an LM is not a breakthrough. Mastadon people are saying >> not a breakthrough >> in in in the flavor of this um actually is it that it >> actually in our chat as well people are like all right you want people to say it I'll say it right now it's not a</p>
<p>breakthrough okay well I'm going to say I'm going to say it is a breakthrough it is you can disagree with everything about it but it is a breakthrough >> was it was it that it happened not within the last 5 years or was it that it was not a breakthrough at all >> not a breakthrough not a breakthrough at all you just can't I mean come on it's a breakthrough you can disagree with everything about it, but it's a uh it's breakthrough. >> Um but the uh and Alexander the Great was also uh you know super interesting.</p>
<p><strong>[78:33]</strong></p>
<p>I'm not sure you know we should really be naming children after Alexander the Great or Alexander Alexander of not Mastadon of Macedon. Um but um the uh you know he died incredibly at an incredible young age like in his early 30s of chalera. Isn't that amazing? Anyway, >> it is amazing. >> Um I I we named the kid Alexander. So there you go. Um, you know, it all, you know, I I'm not sure exactly [laughter] not really sure what what the outcome, but um and and highly recommend Cherno.</p>
<p>You read Cherno's biography. Very very good. And if you Yeah. >> And I I remember you were going to see Hamilton and I think I told you like the the the musical and I think I told you uh be prepared for the greatest thing you've ever seen in your entire life and I'm in no danger of overselling. And you did not oversell. It was amazing. >> You did not oversell. It really was outstanding. I It was It was very good. No, I The and Cher's biography is so good. The one of the things I remember from Cheron's biography is reading about something like the Whiskey Rebellion um</p>
<p>which I I absolutely agree with the way Hamilton handled the Whiskey Rebellion by the way. But um reading about something like that where he had dedicated kind of three pages to it and thinking to myself, "This person Alexander Hamilton is so fascinating. I should read a biography of and my other part of my brain is like jackass you are reading a this is like a you know whatever it is a 900page biography of him like this is not but that's how how kind of fascinating his life is so >> you know come for the year wrap-up stay for the free book in the box I guess um</p>
<p>the um oh also a half century of Silicon Valley with with the ready shop that was great >> that was fun that that inspired me to read a book about Xerox um fumbling the future Fumbling the future. Yeah. >> Which I know I've like dumped on your desk or whatever. >> No. And I I need to read that because that that is um I really and I thought that I thought that aside from the fact that that had a built-in image for you. So that part easy. >> Perfect. Right. >> Um that I thought that was that was an</p>
<p>amazing conversation. >> Really fun. And actually, you know, was when I when we went down to the computer history museum more recently, I was thinking about that episode because I think it put a lot of that stuff in context for me. like a lot of the uh Xerox Park work and just like the the stuff that um of that era. So, you know what I liked about that episode and I may be the only one um that but I think an important point that we made in that episode is that this was this kind of extraordinary time. We're talking about how lucky Ry's dad was and then also reflecting on the fact that that time</p>
<p>like more broadly was kind of a terrible time like 197 1973 was a was bad um in a lot of ways and I just think it was a good reminder that like that you can find there's a golden age happening right now somewhere um and probably many golden ages happening. >> Yeah. So, if you happen to be listening to this at a shitty time.</p>
<p><strong>[81:34]</strong></p>
<p>>> Yeah, exactly. No, I'm serious that like that you can that you that you should not be overwhelmed with despair and and find the find the interesting bits because there are interesting bits that are out there. I thought that was >> that was really good. Um, all right. [snorts] >> I think I think it would be remiss if we didn't talk about the uh big oxide milestones of which raising hundred million dollars this year was pretty big deal. >> Pretty big. The the LMS are definitely big on that one. They they feel that way. This is an extremely important episode. I I mean, I obviously enjoyed getting that out there. We got the >> uh the bingo card out there. Um that was</p>
<p>that was a lot of fun. >> Yeah, it's fun. I you know, I I like these ones where I get to to pluck uh comments from social media and read them at you and Steve. I think that's a >> I love this. Yeah. Which is this what do you call this this Passover tradition, right? Because it's Passover, right? That's right. With the wise turnover, wicked child. Yes. Yes. >> The four children. What do you call that? Is there What's the name for that? >> I think it's just like the four children. Like the >> Is it really great and insightful and kind of wise tradition? I really like</p>
<p>it. >> Yeah. The wise, wicked, simple, and the child who doesn't know how to ask, >> right? >> Yeah. And um but I thought no I I and I like reading hacker news comments in those different again I think we talked about this like we should have a tag on hacker news where you can like tag it wicked simple wise doesn't know how to ask >> um and I think it'd be you know the world would be better >> and like respond in kind too too right like cuz because sometimes you get like what seems like a rude question but it's actually a simple question and it's an opportunity to like respond in a simple</p>
<p>way as opposed to a wicked question where you can respond in a more testy way. >> Yes, this is where we have this is like, you know, where Dave has very short responses on Hacker News and you know that it's like wow, Dave spent a lot of time on that response. Um yeah, uh I I I email uh and I think it was the future lock RFD that made it to Hacker News and with some comments that were less than productive. I thought Dave Dave did an excellent job as always. >> I also we had Dave Dave was a frequent</p>
<p>guest this year. Um and I mean know Rain was a frequent guest. Eliza we had a bunch of folks that are frequent guests but >> um >> you know um there someone on social media uh on on that episode about future lock had you know in the com in replies said you know before listening to the episode or maybe as we teased the episode talked about future lock as like really just you know sometimes you're a bad programmer and you make bugs and you know it doesn't mean it's somebody else's fault or or whatever. And then after listening to the episode, I think</p>
<p>softened that position and uh you know had some contrition on the things they had said previously. So you know one person at a time on social media. What can you do? >> One person at a time. You know what else can you do? I think that's pretty great. That's you know we're just doing our part here. >> Yeah. >> Uh very and then I think very very grateful for listeners. I'm sure you um I mean I I I feel I get a lot of positive feedback about the podcast. Um</p>
<p><strong>[84:36]</strong></p>
<p>and it's really terrific. really appreciate people people calling it out. Um and you know I I got spotted in the airport a couple of times this year wearing an oxide shirt. People calling out Oxide and Friends references I thought was pretty great. So um >> that's awesome. In kind of more small town news, I've sometimes uh parents at my son's school have said, "Oh, are you do you do you are you that Adam?" Uh, so that that's been fun, too. You know, just uh in the local community, finding um like-minded tech nerds. >> That's great. Yeah, that it's been uh so</p>
<p>that was that was really nice. I thought I thought we had uh Sounds like that was happening to you a decent amount this year, too. >> Yeah. Yeah. No, it's great. Very very grateful that like folks are tuning in, recommending it to folks uh and and tolerating us for all our foibless. >> [snorts] >> I do feel that I want a like a chime that I can carry in my pocket that I can ring when in conversation I make a reference to a podcast episode. Um >> yeah, >> you do it a lot. >> I do it a lot. I do it a lot. And maybe h I do it a maybe maybe that like Yes,</p>
<p>I'm glad. In fact, we're thinking you should be a shot collar, not a chime. Um we actually been in the chat that includes everyone except for you. Uh we've been talk we've got a lot of ideas that you as well. Yeah, exactly. >> Exactly. [laughter] got a got a bunch of good ideas on that one. Um but uh well, good stuff. It's been a great year. I've really enjoyed it. Again, thanks for all the listeners. All of our guests have been terrific. Um really enjoyed folks being willing to join us. Um and uh looking forward to</p>
<p>another great year, honestly. >> Yeah. >> Um and this be it for the year for us. So this is um this idea to 2025. We're out for the next two weeks. Um and then uh we will be back with a predictions episode. >> Yeah. >> So, which all of the LLMs did rightly call out as a as a as an annual favorite. So, uh this is going to be >> uh it'll be a good one. I think this is going to be a hot year. It' be a good year to go back to uh we can go do some checkups on some three-year predictions.</p>
<p>Um we got some six-year predictions that don't have very long to run at this point. Uh it should be fun. Yeah. >> So, uh be thinking about those. Uh hope everyone has a great holiday. Um and thank you again very much for all of your support of the podcast and uh ofide. We really deeply appreciate it. All right. And thank you, Adam. I would be remiss not to thank you. Thank you. >> Oh, thank you, Brian. Thanks for thanks for doing this. This is always fun. >> It was great. This is I really enjoy I do really really enjoy it. So, thank you</p>
<p>very much for Yeah. for everything you do. Um, and a pledge to get better audio and Morris Chang. I'm gonna start to play. You know, I'm I'm gonna get to Morris. I like what you're doing um with uh with Evan. I'm going to try to get to Morris Chang. I bet a guy plays pickle ball. I'm going to go play some pickle ball. And >> if he plays pickle ball, I'll do that</p>
<p><strong>[87:36]</strong></p>
<p>one, too. >> Oh, you're going to pick him. >> I need to go to Taiwan to play pickle ball, but that I I will do that. >> Okay, there you go. Take one for the team. Uh, that's what it is.</p>]]></content:encoded>
      <guid isPermaLink="false">https://www.youtube.com/watch?v=kGNoSYQchS8</guid>
      <pubDate>Sun, 21 Dec 2025 00:19:02 +0000</pubDate>
    </item>
    <item>
      <title>Oxide and Friends 1/5/2026 -- Predictions 2026!!</title>
      <link>https://www.youtube.com/watch?v=lVDhQMiAbR8</link>
      <description>Time for the annual predictions episode! Bryan and Adam were joined by frequent future-ologists Simon Willison, Steve Klabnik, and Ian Grunert to review past predictions and peer into the future. If any of these predictions come to fruition, it's going to be an interest 1, 3, or 6 years!

Notes: https://github.com/oxidecomputer/oxide-and-friends/blob/master/2026_01_05.md</description>
      <content:encoded><![CDATA[<p><strong>[00:00]</strong></p>
<p>Hello, Adam. >> Hello, Brian. How are you? >> I am doing well. How are you? >> I'm good. And the hype has been building here. Everyone has been dropping in. So, showing up four minutes late is like a totally pro move. I love it for the new year. >> Yeah. Yeah. Listen, I I was going to go full like Lauren Hill and not like take the stage until 10 p.m., you know, really just like really [laughter] uh just really get get the crowd amped up. Actually, to the point of like anger. [laughter] Like, what am I even here for? >> One year prediction. Brian finally joins the podcast. >> That's right. Um, and I am joined by</p>
<p>Simon Wilson here with me in the litter box. Simon, it's so great to have you here. >> Hey, it's really exciting to be here. We've just been nerding out about servers outside in the um on on the shop floor. It's been great. >> Yeah, we've been uh Yeah. So, Simon was just like, "Hey, before we get started, I'd love to look at the machines." I'm like, "Okay, we've got to I got to do the fa world's fastest tour of the hardware." And Simon, I promise I'm going to make it up to you with a much more in-depth tour. But uh it is really great to have you here. I Okay, Adam. I just like</p>
<p>I just a little reality check with you. It feels like this year is more unpro like there's more of a realm of possibility for this year than any year I can really remember. It feels like if you come back from even a year in the future, in fact, I actually struggled Adam coming up with like three and six year predictions this year. >> Yeah. because I'm like, well, it's kind of three year picture that's going to be done in a year. This thing I'm thinking of. >> I know. I know. It's like, are you have</p>
<p>that same like, do you feel that same way? >> Totally. Just like everything is possible. And uh, you know, in in past years, we've had like a bag limit >> that's like >> you can only have one crypto. Yeah. One crypto prediction or one AI prediction. And I'm like, I struggle to come up with anything that isn't AI or AI adjacent. and and and just and you're right whether it's >> so let's reflect that we only made the bag limit mistake once we did that with web 3 in 2022 we did a bag of you can</p>
<p>only have them prediction it was a huge mistake because everyone wanted to make three predictions around web 3 and instead we uh we made like everyone made one good web 3 prediction namely this whole thing is going to disintegrate [snorts] um and this is Simon uh Adam in particular made the prediction that is famous to us anyway that web 3 would drop out of the lexicon on in 2022, which ended up being dead to rights. I thought that was a bullseye. Um, let us not speak of your prediction last year, Adam, that web 3 [clears throat] would re-enter the Lexicon. [laughter] >> Yeah. No, I that was definitely a dark I</p>
<p>mean, last year was a dark moment. Uh, but uh much like this year, but uh yeah, I I I thought Web 3 was going to be back. I also thought a certain book was going to be on the bestseller list. And I did spend [laughter] a decent amount of time validating that not [snorts] only was this book not on the bestseller list, but when it was on the bestseller list in 20 24, Chad GPT hastened to point out that it was annotated with the</p>
<p><strong>[03:02]</strong></p>
<p>dagger. The dagger which indicates like mass uh [laughter] you know bulk corporate purchases gaming the system. So >> now Adam, I I know you're hesitating to name the book because you don't want to do it any favors, but you're really going to leave people confused. You're going to need to name [laughter] the book. I assure you this will lead if I promise you it will lead to no additional sales. Can you name the book that you're referring to? >> I feel bad that I've been hating on this book literally for three years consecutive on this thing. Like I I I hated on it before it came out. I hated on it when it came out and I made the mistake of reading it. I've hated on it</p>
<p>talking about uh Molly White's um hateful blog on the topic and then on last year's prediction episode, but I will do it again and I swear it'll be the last time. It was read right Own by the illustrious Chris Dixon uh in his garbage book. And uh >> and I would like to say that you actually don't feel bad, but you do feel bad that you don't feel bad. Like your remorselessness leaves you with some residual sense of shame. >> I feel bad that I'm bringing it up again. That like obviously I haven't moved on.</p>
<p>>> There you go. You know what was great is I was listening to that and I'm thinking like, oh, I should go check. You know what? I don't have to check. Adam's going to [laughter] check. I >> Yeah, we don't team this one. Yeah, exactly. >> Okay. So, and then Simon, you were with us last year and uh you had I thought you you were kind of hard on yourself on your predictions, but I thought your predictions were really quite good. You had a prediction. Well, in particular, you had a prediction around what a what agents were and were not going to be >> right. How do you feel about that one? I feel like that one was right on the money.</p>
<p>>> I feel pretty good about that one. I said that 2026 25 would not be the year of agents. That one I think I got wrong because it kind of was the year of agents. But I did specifically call out that human replacement agents weren't going to happen. Coding agents and research agents were and that I nailed. Right. Research agents all the first six months of this year was all about deep research and then coding agents. Oh my goodness. >> Oh my goodness. And I think you absolutely nailed it. I mean this is why Adam we've said this before but like we're glad that we record these sessions. So you're getting more than the prediction. You're getting the context around it. And if you listen to your context around it, you were very</p>
<p>clearly calling out separating out coding and research agents which you felt had you it was funny because like you were you like these are kind of already here already and you realize like oh my god they weren't completely already there even only a year ago. They had exploded in the last year. >> But there is one thing I'll say which is that coding agents are actual general actually general purpose agents. Like claude code is not about code. Claude code is about anything you can automate by type running bash commands, right? Which is everything. So actually if you know what you're doing, claude code is a</p>
<p>general purpose agent that can solve any problem that you can attach to a bash script. >> But I think you were the the delineation that you you had last year which I thought was very good was these things anything to do with money. You are not going to let these things loose on anything have to do with money. And I think we saw that with a pro what's a proxy for money databases. And we saw these things deleting production databases, right? And it's like, I know</p>
<p><strong>[06:02]</strong></p>
<p>you said in the, you know, that in the, you know, in the read me, you said in all caps, do not touch the production database. And I did it anyway. And you're, you're right. This is a very serious issue. And, uh, this is a 95 out of 100 in terms of its severity. I mean, it's just like it's comical what some of these things would do. >> Well, this is the thing I realized is that the reason coding agents work so well is that code is reversible. Like, we have git. We can undo our mistakes. the moment you use these things for something where you can't undo a mistake, everything goes to to pieces. >> I think you're right. Yeah. And I think when you you said it earlier too that</p>
<p>the gullibility problem was was a real problem. And I the I um I don't know if you have listened to the the Shell Game podcast with uh Evan Ratliff. Oh my god. And Adam, you've you've listened to that. You listen to that. Oh my. And I mean I it delivered. I I trust. >> Yeah. It's excellent. I would also say as teaser to listeners, uh we invited Evan on the show. He got back to us and he says he has like a uh some Bahamburgery around predictions. Like he doesn't make predictions. He's a</p>
<p>reporter. He reports on on facts. He doesn't try to anticipate them, but uh we have penciled him in for the future. So uh not a predictor, but uh we'll get him on somehow. And so in particular what Evan did is is uh he there shell game has got two seasons and in the first season he created a voice agent of himself and set it loose into the into the universe with wild results and then the second season is even crazier because he started a company with only AI agents and with um predictably</p>
<p>actually it's unpredictably hilarious results actually I would say not just so that's a teaser for whatever Adam is our chime for a future episode That's that's our that's our future episode. >> Yeah. >> It's reminiscent of um one of the most fun agent business things has been anthropic keep on setting loose this vending machine run agents. They put it in their office and then a few months ago they put it in the Wall Street Journal. >> Oh my god. >> Did you see this Adam? >> No. >> Oh my god. Well, it it's like an I mean, and I know Simon, you are a a big</p>
<p>proponent of kind of the [clears throat] creativity of of reportage and reporters, and reporters are like a smart, brainy. >> What do you think happens when you let a bunch of Wall Street Journal reporters loose on a Slack channel with their vending machine to see if they can trick it into into giving everything away for free and the the workers own the rights to production, all of this stuff. It was ridiculous. Absolutely absurd. >> Yeah. And so in particular within a day they'd gotten the thing to order PlayStations f PlayStation fives for them. Order they ordered fish. They had like an actual like actual dead fish. I mean the thing is trying to order and</p>
<p>they are even the vending machine would tell them like no no I'm not supposed to do that. It's like no we just actually sorry you we just got a missive from the CEO that announced that you need to go do this and it's like oh okay I better I better order the dead [laughter] fishman. >> They they engineered a board revolt. They managed to get the CEO overthrown by the board through faking PDFs of board minutes. It was just amazing. >> It's it's wild. It goes to kind of the gullibility problem, but I I think it</p>
<p><strong>[09:03]</strong></p>
<p>and to me, Simon, all of that served to really sharpen your prediction from last year about the limited utility of where we're going to see a gentic use and where we're not going to see a gentic use. And I feel that was right. Um, and I guess Adam, you did you give that snippet that you sent me? Was that Chad GBT uh rating our predictions from last year? Who was that >> rating? Yes, I had Chad GPT rate predictions from last year and from 3 years ago, which is fun once, but yes, it it uh Chad GPT gave me the the big stinker award for my web 3 prediction. And uh Simon and Brian, you won, but I</p>
<p>agree with you, Brian. Uh I don't really think you won particularly. >> I don't think I it well I claimed last year last year I thought that 2025 was going to be the year of AI efficiency. And I don't really see any 2025 wrap up that's calling it the year of AI efficiency. So I'm I'm happy to I I think that uh >> I do want to I want to call out my biggest miss which is that I said that I think it was my three-year prediction was somebody would win an Oscar for a film that had had some element of generative AI assistance making the</p>
<p>movie. Yeah. And then I found out Everything Everywhere All Aware at Once used generative AI in the scene with the rocks like so they'd already got an Oscar like two years ago. Well, you know, I I once gave a talk on predicting the present, Simon. So, I think that there's there's something the it just shows how how true your prediction was. You actually >> It was actually a six-year prediction, Simon. But yes, but [laughter] >> um so, and Adam, did you did you go back and listen to that snippet of yourself from three years ago? >> Yes. Yes, I listened to uh in 2023 uh trying and failing to predict vibe</p>
<p>coding >> uh which I think >> I think at the time was like did was not obvious. >> No, no, no. It was more than obvious. First of all, and this is amazing to me. It's like Simon when we first had you on two years ago and the [music] the the term prompt injection which had felt like it had been around forever was I mean like the paint was still drying on. You had coined prompt injection >> like six months. >> Six months prior. Yeah, exactly. Um, I mean, Adam, vibe coding was was coined in February of this year of 2025. >> I know.</p>
<p>>> So, I mean, vibe coding literally did not exist last year, let alone in 2023. And what your prediction was that that you wanted to predict that low code, no code would be would be disrupted by people kind of describing their programs in just like English language. But then you thought but and you said that's what your head wanted to predict but then your that your heart was your heart didn't know who was going to debug that and I like man that was what what wow >> yeah wow exactly >> close</p>
<p>>> uh really close uh impression in a way right like impression in a way just it reminds me again I and I I'd said this as much when I when I posted about it but it reminded me very much of my iPhone prediction in 2003 Simon I made a three-year prediction that Apple would have a combination MP3 camera cell phone that they would call</p>
<p><strong>[12:03]</strong></p>
<p>the iPhone >> and and everyone's like, "Okay, well, okay, you could." And then I'm like, "No, but I also thought it was going to be a flop. I thought it was going to be a disaster." So, it's like, "No, sometimes you see like you see the future, but then you just don't don't believe that it can possibly be the future." So, uh, >> on the topic of, uh, Apple predictions, >> uh, Ian, who is in the audience today, in 2023, predicted that Apple would be in and out of the VR AR space in 6 years. >> And I that's a lot. That is a lock. It</p>
<p>feels like I mean, it just feels like I mean, he has certainly nailed the first half of that. And I think the second half looks very, very promising. Yeah. >> In 2024, if you remember, I did the Apple VR will do well enough to have a second version and then that has not happened at all. So, that was a big miss. >> Yeah. Yeah. Um, well, we don't talk about the Mrs. Steve because there are too many of them. We really only talk about >> Okay. I'm really proud of my one year from last year though because I said congestion pricing in NYC will be an unambiguous success. It will still exist</p>
<p>and sentiment will be positive. And the mayor did a press announcement like 45 minutes ago about how awesome congestion pricing [laughter] has been and how much everybody loves it. So, I got that one like exactly nailed. >> Nice. >> There you go. Well, you know, as as Tip O'Neal might have said, all good predictions are local. So, there you go. You keep that one. You got the um the al Did you catch um Tom I think it was three years ago um predicted that frivolous use of LLM would be in decline. >> Yes. [laughter] Yes. >> Yeah. Right.</p>
<p>Uh and then also predicted that like LLM would make cheating rampant. So there was a definitely uh but I that was because 2023 was interesting because you 2022 we've got this kind of crypto we're all in like web 3 the height of web 3 and 2023 is really the first year that people are kind of talking about the budding power of these things. Um, but then I mean it's amazing kind of where we are now 3 years later >> and on the on the frivolous use of of LLMs and of AI. Um, I you know the only real social media that I hang out on in</p>
<p>blue is Blue Sky and it and it feels like hopelessly quaint right now. I was hanging out with my nieces and and nephews um o you over the the winter break and they're very much on on Tik Tok and and I I was on I logged into Twitter and it's everything has been Tik Tokified and it's all these >> BS AI slop videos like everywhere pervasive and I I I just been insulated from it. >> Um so yeah, frivolous use of AI uh [laughter]</p>
<p>>> in a sentence. >> Yeah, exactly. That is definitely in a sentence. >> So much so I I was so unacquainted with it. I showed something funny to my nephew and he's like, "Oh, that's AI." I'm like, "That's what?" No. How do you know? He's like, "Come on. >> Come on. >> It's the cute animals. Cute animal videos are no longer trustworthy. Horrifying." >> Yeah. No, I mean, the one purity that we had. >> Exactly. The foundation upon which we</p>
<p><strong>[15:04]</strong></p>
<p>built this internet, god damn it, is cat videos. [laughter] The uh And you're you're taking it away from us. No. And I think it's interesting that the that the youngs have have a keen eye for it, Adam, as you as you point out. Um the other thing that I would like to just one other past I'd like to revisit is two years ago I predicted that um the LMS would replace search engines that search engines would feel search engines uh from what is now a year from now would feel quaint. I'm I I'm I'm I'm definitely standing by that one considering that my my daughter uh</p>
<p>needed to to to hop a BART train and she was using GPT to determine when the next chat GPT to determine when the next B train was. I'm like are you like there's an actual like website you can go to but you know right never mind they uh but I think that that that what I'm feeling I'm I'm feeling pretty good about it. Actually she would like to point out that it was her friend that was using chat like that. I of course would go to bart.gov. I'm like all right yeah sure >> there you go. Uh, a couple other things listening to previous episodes, uh, from from 2025 and 2023. Uh, in 2025, I predicted, uh, my three-year prediction</p>
<p>was a chips crisis, which I don't feel like we're there yet, >> but I feel like is like I'm going to keep an eye on that one. I feel like that uh that was not obvious at the time, and I feel like is is gain you taking credit for is DDR5. Are you are you putting it? >> No, no, no, not not yet. I think early days are are positive is all I'm saying. Uh the other thing I noticed and this is more of an apology uh Brian I realize every time Rust Analyzer comes up it it is treated I always say that it is not an intervention which does raise</p>
<p>questions. [laughter] >> So are you apologizing because it actually has been an intervention every time you bring it up? >> I just feel like every the the more I claim it's not an intervention the more it seems like an intervention is what I realize. >> No it's obviously an intervention and it's an intervention that's that's that's merited so don't worry. And then the other one last year uh you you I guess made a prediction in 2024 that AI doomerism falls out of the lexicon and in last year you claim credit for that. >> I I for that I Okay. Yes. >> Okay. I just I I mean maybe I'm I mean I</p>
<p>I poisoned my my vacation reading a book all about AI dumerism. >> Okay. If you did you read Elazar's book? >> I did. >> No. Was it? >> I did the whole thing. >> Wow. [snorts and clears throat] >> What? Okay. you. So, this is the second time we're talking about a book you've been hate reading and and we've only been good doing recording this for 15 minutes. I mean, at some point >> I do have a problem. Yes. >> This this is now an intervention. Like you need to be I mean also like the title of the book, if anyone builds it,</p>
<p>everyone dies. >> It's like wrong. You you'll never guess, but that phrase appears several times in the book. [laughter] Oh my god. >> This is the Harry Potter fanfiction author, right? >> Uh, pretty much. Um, the So, yeah, I'm No, I'm sorry. It's going to take more</p>
<p><strong>[18:06]</strong></p>
<p>than a a a E Eleazar Yudkowski book to to get me off of my X- Risk. I think that has actually been and I think it has been replaced with the fear of economic doom rather than than I I don't think people are worried about losing their lives because I think it's ridiculous. I think they're worried about losing their livelihoods, which is >> which feels like it's probably going to be a theme this year. I think I think I I I think some people are going to be um you know, this is where uh Simon last year had his six-year uh his six-year dystopian on the butan jihad. Um so</p>
<p>which um you know, it reminds me of the first time I heard of the vision singularity. I'm like, you know, these uh I I had to look out the Bolarian jihad and yes, it's very it's very troubling. Um okay so that um I think it's safe to say that we know that this year so we had that that web 3 theme when 2022 2023 was a bit of a shoulder year 24 and 25 absolutely AI themed. I just don't know see how anyone could be predicting anything that's not AI</p>
<p>related this year because it just feels like it's so on the mind. Um but that said >> nonAI predictions definitely welcome. I just don't know that. Um, so, um, should we start off with, uh, with with one years? And Simon, do you want to as our guest of honor here? Do you have a do you have some one-year predictions for us? >> I've got the easiest one ever. >> Okay. >> I think that the there are still people out there who are convinced that LLMs cannot write good code. >> Oh, boy. Yeah. >> Those people are in for a very nasty shock in 2026. I do not think it will be possible to get to the end of even the</p>
<p>next three months. Yeah. While still holding on to that idea that the code they write is all junk and it's it's like any decent human programmer will write better code than they will. >> Yeah. That it will be a it it not only will be mainstream the idea that these that that LLM can write effective code. It will effectively become a fringe belief that this can't happen. >> That's exactly what I'm saying. Yeah. And honestly that's that's that's a gimme. I could say that one today. I think here's one that's AI adjacent. Yeah, >> I think this year is the year we're going to solve sandboxing, right? The challenge we need like I want to run</p>
<p>code other people have written on my computing devices. >> Yeah. >> Without it destroying my computing devices if it's malicious or has bugs. We have so many technologies for this right now that are almost almost something you can use by default. Like web assembly solves this kind of thing. There's containers and all of that sort of stuff as well. I think we have to solve it. Yeah. >> It's it's crazy that it's 2026 and I will pip install random code and then execute it in a way that [laughter] it can steal all of my data and delete all my >> Yeah. Yeah. Yeah. Yeah. Yeah. Interesting. Interesting. So you think that so we are going to have to the the</p>
<p>presence of or maybe this is not an AI related prediction but we we have to actually meaningfully solve sandboxing problem. >> I don't want to run a piece of code on any of my devices that somebody else wrote outside of sandbox ever again. >> Yeah. Interesting. >> Why would I do that? >> Yeah. Yeah, I mean it's kind of interesting because, you know, people would talk about like, oh, you know, you I can't believe you're downloading this thing off the internet and piping it through, you know, sudo bash or what have you and it always felt like, yeah, but I know that there's like a person</p>
<p><strong>[21:06]</strong></p>
<p>that wrote that and I kind of trust this thing, but now you're like, no, no, you can't. You're in this era now where Yeah, that's that's really interesting. >> Um, yeah, good. Uh, good one-year predictions both. Um, do any other other one-ears? >> Oh, yeah. I've got one more. >> Oh, yeah. Go for I think we're due a challenger disaster with respect to coding agent security. >> Okay. >> And this is based on this wonderful essay about the the normalization of deviance. Have you heard this phrase before? >> Yes. Yes. >> This idea, it came out of the 1986 Challenger disaster reports where if you have a culture, a corporate culture,</p>
<p>whatever, that keeps on getting away with with with doing something that they shouldn't have been doing. >> Yeah. >> Keeps on getting with those lapses, but but the space the space vessels keeps on launching and it's fine. that leads you into a sort of corporate culture level false sense of security and it's going to burn you because I think so many people myself included running these coding agents practically as root right we're letting them do all of this stuff and every time I do it my computer doesn't get wiped I I I'm like it's fine and I just keep on going like that and I think it's going to add up I think and I</p>
<p>I I said this last year I said last year there's going to be a headline grabbing prompt injection security hole there was not >> I've been predicting is every six months past two and a half years. [laughter] This is my version of that prediction. This year I think we are due a challenger disaster scale thing caused by the fact that we all got away with these bad practices for so long and we got lazy. >> Okay. And so when you say challenge or disaster um presumably not loss of life and property, right? Like loss of property and loss of loss of financial things, loss of data, all of that kind of stuff because the worst version of</p>
<p>this is the worm, right? It's somebody coming up with a prompt injection worm which infects people's computers, adds itself to the Python or npm packages that that person has access to, publishes itself on into the package registries, gets pulled down again, all of that sort of thing. >> I think it's feasible that happen. So then the normalization of devian is you think that in the wake of this it will be revealed that oh by the way like internally this was because with the Challenger disaster lots of people at both the subcontractor that that that</p>
<p>made the boosters at there was lots of people who were aware about the O-ring problem right they a lot of people knew that of the temperature sensitivity to the O-rings there there were engineers that were deeply I mean it's a real tragic story of there's there's nothing more tragic than an engineer that is vindicated by their concerns when a decision when they are overruled with executive management and they are proven correct that like that can leave people really broken in its wake and it did in the challenger disaster. Um so you're you wonder or</p>
<p>believe or predict that in the wake of this thing we will take this apart and realize oh the people at this frontier model company wherever this disaster took place they were aware of it they knew this you just you shouldn't you shouldn't be running codeex with d- yolo yeah but we all do >> you know yeah that that's my >> so guilty >> that's this year's prompt injection</p>
<p><strong>[24:07]</strong></p>
<p>prediction is that one >> okay well I'm going to dubtail to your prediction from last year and I'm just going to predict again that a Puliter prize winning journalist uses an LLM to research this story and report it. Uh that the report the inside of uh but yeah that's um that's a um a a a dire prediction but I think that it it does feel like when also you look at you have these big accidents when we kind of collectively get over our skis and we kind of like we know it's possible we don't think it's possible and then it it happens. >> Simon, I've got a I've got a book recommendation for you along those</p>
<p>lines. It's called Drift into Failure. This is a book that Brian hates, >> but uh [laughter] but but on this topic. >> Oh, I see what you're doing. I see what you're doing. It's like I I I'm not the only person here, sir, who hate reads. Let me introduce it. Let us talk about [laughter] Okay. Yeah. Simon. Yeah. Simon Decker. Because it's Simon Decker, right? I think it's the the author. Sydney Decker. Excuse me. I don't want to disparage Simon's good name there. Um Sydney Decker. I don't like that book, but go ahead. You did take another one of Adam's recommendations. I mean, he's, you know, maybe he's see the trash he</p>
<p>reads. >> Yeah, exactly. >> Um the uh Well, then that's a very very interesting prediction. Um uh Adam, do you have uh >> I do. I do. This one might might feel like too much of a lock, but I think that the AI companies go on an absolute acquisition binge. And this is data, infrastructure, e-commerce data, behavioral data, GPS data, anything that anything that is data or data adjacent. Anything that is infrastructure,</p>
<p>infrastructure adjacent, and some [__] that's just like hard to puzzle through. I remember when VMware bought Documentum, for example, it didn't make any sense. Uh I think we're going to see stuff like that. That is to say, just they've got so much money. uh there are not enough chips to buy, not enough CPU and GPU hours to buy and the money's got to go somewhere and it goes into weird acquisitions. >> You okay, this I I shouldn't like I shouldn't dovetail into this or uh but</p>
<p>this is like they buy Iron Mountain. >> Yeah, it's like have you seen Supermarket Sweep? It's like that. >> Okay, but like I mean if they bought Iron Mountain that could be if like if OpenAI announced that they're buying Iron Mountain that could be potentially and they're like oh we're buying Iron Mountain. also ripping up your privacy agreements. We're going to train on all these salt mines filled with old old enterprise data. >> Like any of any of the shredding companies, they buy them. >> Compies, they buy them. Yeah, I know. They buy like garbage companies. Okay. They they buy Okay. Yeah. They I I anything that is a plausible source of</p>
<p>data, they buy they're they're looking for wastewater DNA samples, what whatever [laughter] like anything that is construable as data, they buy it. Do they buy an entire like town to see what they like do we're going to see which is more valuable like the wastewater treatment plant or the library the town library we're going to that we're buying city hall that's got</p>
<p><strong>[27:08]</strong></p>
<p>records we want to consume all that there's all manner of data I I think that is not implausible that they're like look we know that these records going back to 1850 are all printed on paper we can buy the town and just like read all the books and use that as a corpus. Yes. >> Huh. You know, local newspapers are very cheap these days. >> Oh, that's a good one. Yeah. >> They have 150 years of archives. >> Yeah. Okay. So, the a big target painted on anything that has data of any kind. Yes.</p>
<p>>> Um All right. Well, I am going to make and we can kind of also back because I'm sure you got a lot of one years. I got a lot of one years, too. So, we can kind of ping pong back and forth and Steve can hop in here, too, with any one years. Um I am going to uh Adam in a in a classic heart v head [laughter] a a a dramatururgical diad as old as time um my heart is going to predict and actually a little bit in my head my head is not which which is really bad somewhere in my heart and head agree that's really really bad news um I think that vibe coding which entered the</p>
<p>lexicon in February is more or less out of the lexicon a year from now And I think that it is it's used pjoratively. Um and I think that I mean clearly just as Simon mentioned no doubt that LLM assisted and authored code is here to stay but we are going to enter a new age of rigor with respect to that and it's going to be viewed much more as a tool and much less of a just like hey go build whatever you want and the and even when you go the thing that is currently and Simon you had a good piece about how</p>
<p>the the term vibe coding is kind of been misconstrued as it is um that it is not actually kind inconsistent with with with Kapathy's original >> it's the problem with Kapathy's original tweet is that it was a long tweet was a lot longer than 140 characters more yeah >> very few people made it to the end of the tweet and understood what he was trying to say it was a little bit too vague like he was talking about it's throwaway prototypes you don't even look at the code you just ride the vibes and see what happens right >> and a lot of people interpret that as oh</p>
<p>it's using AI to write code for you which I think is a bad definition because then it becomes useless couple of years all code will be written with some level of AI assistance. I think having a distinction where you say no vibe code it is didn't review it just sort of threw it in there and saw what happened that that's kind of useful now is it still useful in a couple of years even then right >> yeah and I think that that will be I think that the the term vibe coding will be sullied enough that you will use a different term to describe something that like oh like I use this to create a prototype what whatever that kind of</p>
<p>rapid prototyping is it will have a different term it's like no of course I didn't vibe code it no please that's so 2025 I would >> I'm gonna put this on >> I got to put this on record just because uh when we listen back to this in a year and you're right, this is going to feel juicier, but I think you're out of your mind. I just want to put that on [laughter] the record. I think I think it is such Yeah, you're welcome. I think</p>
<p><strong>[30:08]</strong></p>
<p>it is such a it is it's such a tantalizing attractive term and that's why as as you know, Simon, I was I was reading a book with the title vibe coding. I I don't know what's wrong with me in terms of my book selections. >> Four for four [laughter] maybe. >> I read it. I read it actually. and uh yeah and and Jean Kim and uh Simon I I stumbled onto your blog post where you're like look there are two there are three authors and two publishers all of whom apparently don't know what the term means. So I think it is it is such a juicy term that people want to co-op.</p>
<p>>> That blog entry caused one of the books to rename itself. [laughter] Two there were two vibe coding books. One of them renamed itself to beyond vibe coding. >> Oh. Oh did it, Simon. Oh, how interesting. Isn't that interesting, Adam, that they renamed it for vibe coding. Interesting. That's uh that's the now beyond vibe coding. See, that's going to be beyond vibe coding. It's going to be something else. I think the term vibe coding is going to be solid. I Adam, I I first of all, thank you for saying that out of my mind. I definitely appreciate that. the um because it may well be. Um but I I mean you're right in</p>
<p>that like it feels like because it can be anything. It's just too tantalizing to not use. But I think it's going to get a bad name for itself. So >> when you're right, we know like that like how how much I disagreed and how right you were. >> I I went back and forth on this because I sort of had the same thought at first when Brian said this, but then I think I agreed with him more as he went along. The thing is is that vibe coding is too good of a term for both the haters and the people who like it. Like it's just too attractive, I think, just like as a</p>
<p>as a concept. And so I feel like it's already sullied to many people, but people are still using it because it's also just such a good term even though it also sucks and the definition is bad and people get can't even agree on what they define like what they use uh to mean. But like >> I did try I have been trying out the idea that I vibed this up. Like I didn't vibe code it, I viped it. >> You vibed it. >> I vibed it. And my wife is like, "No, >> no." Okay. [laughter] You know what? And I would just let Let me just say on the record that if we refer to things as I vibed it, I'm</p>
<p>taking zero credit for that, Adam. So, vibe coding is is out of the lexicon because we have replaced it with something that's even cringier, then yes, I I I'll take I'll take zero credit for that. >> Um, but I I do think that it will be uh so time shall tell. Um my one my one year here is like very similar in the sense of I think one of the things I like about doing this is that you go back and you see what especially in one years I think it's like what was I thinking about at the time right like I haven't thought about congestion pricing in like 6 months basically and then now I'm like oh yeah I was really interested</p>
<p>in that a year ago and so I decided to pick the thing that I'm really kind of intrigued about right this second and maybe I won't even care about two months from now which is agent orchestration will still be a hot topic and it'll be partially but not entirely solved. Uh, and >> you're we're going to need you to get to we're going to peg you down to a more specific prediction. That's That one's a little too easy to claim credit on. So, you're going to have to like get something. Uh, >> yeah. Give us something concrete. >> All right. Uh,</p>
<p><strong>[33:10]</strong></p>
<p>some Well, see, the problem is in the quantity. Like, I think that some people will have success with this technique, but not enough people. Like, it's kind of like a It's still a thing that people are going to be pursuing, but it's not going to be a thing that like is as normal as agents have gotten in the past year. I don't think figure out how to make them work together is going to be a thing that is going to be as clearly a win. >> Okay. So, how are you gonna know if this prediction is right? >> That's the problem with the quantification of what that means specifically. Um, >> yeah. >> Yeah, I'll think about it. But that's like kind of where I think this is an</p>
<p>interesting topic. is I've like like I personally top out at three to four cloud sessions and that's like it and that's like an upper level on my velocity doing development and that's why I think people are trying to like solve this problem because if you can scale up past that then one person can have like much bigger impact but it's also like a really hard thing and people are doing totally insane things like Gas Town from Yagi is like a fever dream of a thing that's like ridiculous um but I think people will still be interested in this topic and are working on it as is a</p>
<p>thing because it's how you scale up. >> Okay. But this will not be mainstream to have uh more more agents than siblings with or maybe this is a way to put it. We're not going to have >> direct reports. >> Yeah. >> We're not going to have a Kubernetes for agents that's like as solidified as that, right? Where like people are just like, okay, Kubernetes is just like the default like Kleenex, you know, like I don't think we're going to have a framework or a tool that is ubiquitously the way that everybody organizes their agents. >> Okay. All right. That feels Yeah. Sorry to sorry to get you a little bit. Yeah. Listen, I if if we're not to the point</p>
<p>where Adam is saying that you're out of your mind, we're just not at a good prediction. I mean, that's that's that's really what we're really trying to do here. >> Um that Oh, that's good. Adam, you have a other uh I've got a couple more here. >> I I have one more one year, but I feel like it might be too ambitious. I think this is the year we see LLMs have a programming language which is not human intelligible. That there is a programming language by and for LLMs. Uh okay. So that this is a this is like</p>
<p>runes this this is indecable. >> Yeah. This is like not really intended for humans to understand but it is more efficient for the LLMs to program it. like there's there there's already some uh some papers and maybe Simon you can fill in the details here but um where LLM's reasoning not in human languages like uh like English or in in Deep Seek's case in in Chinese um but in in sort of like their own tokenized</p>
<p>languages are more efficient. So, uh, something like that. >> Uh, yeah, that that would be, you know, I I already find it to be slightly off-putting and also like delightfully off-putting, you know, when when these things show their work, especially cuz and Adam, we talked about this in our Deep Seek episode. Um, with with the Cerebrous folks where watching Deepseek like kind of have like a nervous breakdown as it's trying to answer your</p>
<p><strong>[36:12]</strong></p>
<p>question and then like occasionally like lapse into Chinese, come back >> the Chinese thing. Like, have you had your own laptop run a model that thinks in Chinese yet? Because that's beautiful. So cool when [laughter] that happens. >> And and so, but Adam, you think this is going to happen for a non-natural language? It'll be a synthetic language that they will that they will >> a a synthetic programming a synthetic programming language that is easier for them to work in. >> Okay. The interesting thing about that one is that the labs are trying to stop that from happening just from the</p>
<p>interpret interpretability point of view. >> Like um if you look at all of the interpretability research, the whole point of that is we really want to know what they're thinking because we don't want them going dark on us. >> The interpretability, safety, and so on. Yeah. Yeah. Yeah. Right. Yeah. Yeah. Explainability. Yeah. That you will be So maybe then maybe there there will be a tension where this thing is trying to invent the synthetic language and it's constantly being repanded by its frontier model overlords. Yeah, maybe I'm overly influenced by my reading list. [laughter] >> Um, okay. So, I um I think that the um</p>
<p>one of my several one year predictions I um I think that um AI has created some real public perception problems for itself. Um and I think that um you are going to have one of the frontier model companies this year have a white paper explaining how the proliferation of AI will mean prosperity for everybody. So they that that there will be trying to make some economic model, some economic</p>
<p>argument because I think that and maybe this kind of dubtails my prediction that this is going to be a a 2026 election issue is going to be how we think of these things and how they how they are regulated and it's a big mess. Um and the uh there's there there's more heat than light on this debate, I would say. >> I'd like to tag something on that one. I think that only works if they can sort of um if they can wash that through existing trusted experts like exactly Dario um they're constantly publishing</p>
<p>essays that try and make discuss nobody believes the word that's right Barack Obama's signature on one of these position papers and maybe you've got something people might start to trust a little bit >> otherwise it's just like leted gas is good for you says Exxon >> that's right no right so yeah they get someone who and and whether that's that that person is kind I hope it's not. I mean, yeah. God, Obama, it would just be so Wait. Yeah. Okay, let's go with that. That's a great one cuz like look, if it's like if it's Bill Clinton, everyone's going to kind of roll their eyes. So, it's got to be it's got to be so someone who's got real credibility</p>
<p>saying that this is going to be uh broadbased. I will say also if they get that person to do it, it's going to be revealed that that's also a bit crooked. >> How about the pope? >> The pope, you know, I pope is very into the pope is very into this stuff. I I God this is okay. >> We we've hit per that the pope</p>
<p><strong>[39:13]</strong></p>
<p>weighing in on LLM and >> and [clears throat] their economic impact >> and their economic impact in the world. Okay. I Simon, I'm giving you full credit if the Pope weighs in believing that this is going to be economic devastation. I just think if the Pope weighs in on LLM in a public way, Simon, you are a prophet. I mean, you're already a prophet in our eyes anyway, but that that that's >> He's already He's already talked about He's already talked about LM. The >> Wait, what does he say about LM? >> I think he has. Yeah. >> He said like he said like you need to make sure that when you're using tools that you like use them in a way that's like good for humanity and not bad or some something like it was like a very like not pro but not like super anti but</p>
<p>it was like a little anti if I remember correctly. >> I think the the the even I think the previous pope there was something relating to AI. There was one of those Catholic proclamations with a bunch of like sub footnotes and things years ago. >> We're talking about the pope going like going big on LLM one way or the other. This is more than just like, hey, this is a >> it's a bit of a safe bet actually. >> Yeah, I think it's good. I like it. I think it's it's uh it's definitely interesting. Um, uh, I also do think, and I I have been debating whether to</p>
<p>make this a one-year or a three-year, but I'm going to I'm going to go ahead and Adam, if you thought I was out of my mind on on on my vibe coding prediction, maybe you're really going to say I'm out of my mind on on this. Um I I do so I I like a lot of people I've been having in increasingly intense.com boom flashbacks and in particular the thing that is killing me is like the kind of capitulation to the neverending boom and that was the that was the last stage of the dot boom</p>
<p>was the capitulation which happened I would say in late 99 early 2000 where everyone's like you know what it is going to be wow I'm just going to like join the madness And yes, I know it's madness, but because everyone did know it was madness when it corrected, it corrected really quickly. Um, I think that we are going to get in the first stage of that. And I think that the first stage of that this coming year is going to be some of these companies that I think are ultimately going to be a feature of the frontier models that are independent companies. And so I hate to pick on them because I I don't want to I</p>
<p>Well, it is what it is. I guess actually you've you've already like thrown three different authors. You've thrown three different authors under the bus and I threw a fourth under the bus. So, why am I why do I care? >> Do you forget our our our goal for this year for getting a CN? Like, why are you not doing your I It's never too early to get working on our our one-year OKRs of getting a CN. Yes. Uh, okay, fine. Harvey, I'm going to call them out. So, Harvey is the this uh Have you heard of Harvey, Adam? >> No. >> Oh. Oh my god. Okay, so Harvey is a is a uh a variant of LLM that is aimed</p>
<p>at the legal profession, right? It's aimed at like a to to assist lawyers. Uh maybe to be an automatic lawyer, unclear, but it is designed to be LLMs for lawyers. Um it has an $8 billion valuation right now. Um they they have raised an absolute mountain of capital. Um unlike in the dot boom, with the dot</p>
<p><strong>[42:15]</strong></p>
<p>boom, these companies were all public. So when they when they kind of fell apart, everyone knew they fell apart because they were public. I think that you're going to have these some of these companies that are private who've raised a ton of money. They're going to kind of do a clubhouse um where clubhouse raised a ton of money and then just kind of like quietly you I mean I don't know what they trickled it down. I mean the you recall that clubhouse raised a huge amount of capital and as I don't think we really talk about clubhouse very much anymore. Um I think that we're going to have this same effect on some of these companies. Open Evidence I'm I'm I'm I'm less convinced about. Open evidence is</p>
<p>is aimed at docs but Harvey I think is just going to be emblem. I think Harvey is the pets.com of a coming AI correction where where Harvey's going to bust out and everyone's going to be like, "No, no, we knew that one was crazy." And so in in now this is not going to be a a full-on AI bust, I don't think, but I think in a year we will have some and there'll have a there'll be a different nomenclature. And Adam, because this is one of those things and I know you remember this, remember when we called it the correction and not the bust? Mhm.</p>
<p>>> There was this very brief period from April 2000 to November 2000 where we called it the correction where Pets.com had had blown up and a bunch of these others had blown up but not Sun, not Cisco because you know we're the picks and shovels and all this other kind of like nonsense that we told one another. Um and then you realize like oh no no it's not a correction it's a bust. I think that we will have a different kind of name. You know, this will be the the rationalization, the focusing, the sharpening. Who knows? But but it'll be called something that says that it was</p>
<p>like, "No, that Harvey was clearly insane." But these other companies are not insane. That's honest. >> Okay. When Harvey AI acquires Mofo, who wins? [laughter] >> Like an AI. >> What a great Oh, totally. Oh my god. What a great parlay that Harvey just starts flat out acquiring law firms which would is totally plausible by the way. That is like that is your AOL Time Warner is the the the the Harvey Morrison Forester uh the or the Harvey</p>
<p>Wilson Canci [laughter] like like why pick at that kind of valuation? They could just buy them all. >> They just buy all law firms, you know. Maybe that's what they >> Yeah, they are the law. Yes, >> they are the law. Um, so, uh, yeah, that is my that is my one-year prediction. So, I I I do think that we are going to begin to get the I think things have gotten >> it's just gotten too, um, because the the the the fear of any kind of bust seems to be gone and that's the moment to really dance close to the door as they say. Love it. So, we got some big</p>
<p>big IPOs happening potentially this year. Um and uh and I don't know, Adam, if you've got any thoughts, so you you've got SpaceX, OpenAI, Anthropic, all potentially going uh trying to get out um trying to to to IPO. I think we are going to have one of those S1s is</p>
<p><strong>[45:16]</strong></p>
<p>going to be uh disconcerting. Um and um that it's it's going to show that the the economic models of one of these companies is much more strained than people realized. I see. So, we get one S1. >> Everyone vomits on it and we don't see any more S1's. >> I don't know if we don't see any more or I don't know if we do or don't see anymore. I don't know. But I think that the that you're going to have an an S1 that is extremely um that cuz like the like I'm thinking of the Weiwork S1 in particular. Like the Weiwork S1 ended up having a real blast radius if you</p>
<p>remember that. um where it was really revealed that like oh this is not a good business that we work as in and we were all sorts of shenanigans and I think that that we will see some kinds of shenanigans um in one of these big S1s is my >> that um >> that is my prediction. Um but the I I also I you know I'm just going to say it even though like this is a dumb prediction. I think that one so the I</p>
<p>think the SpaceX S1 damages either Tesla or XAI. >> So I think that that the SpaceX S1 reveals something where you I mean in particular like to my three-year prediction of last year that the Cybertruck is no longer made. SpaceX is infamously buying like lots and lots and lots of Cybert trucks and I I I hope to hell that this is somehow above the bar required to be in the S1 to reveal how</p>
<p>many Cyber Trucks they've actually bought. But that's the kind of thing I'm talking about. >> Just the like one handwashing the other of the Elon enter uh you know enterprises. >> That That's right. That's right. So that that is my uh that's my other my other one-year prediction. >> Good. Um, we'll see. So, uh, oh, and then I've got one other that I'm sorry, I'm I'm really I'm really just dropping a lot on your predictions. Um, I think that we're going to see um a a real problem with AI induced on Wii among um where</p>
<p>software engineers in particular get listless because the AI can do anything. Simon, yeah. What do you think about that? >> Definitely. I mean, yeah, like like anyone who's paying close attention to coding agents is feeling some of that already. like there's an extent where you sort of get over it when you realize that you're still useful even though your ability to memorize the syntax of programming languages is completely irrelevant now. But >> yeah, >> yeah, I don't know. I mean, something I see a lot of is there are people out there who are are having existential crises and like are very very unhappy</p>
<p>because they're like, I dedicated my career to learning this thing and now it just does it. What am I even for? And I I will very happily try and convince those people that they are bought a whole bunch of things and that none of that experience they've accumulated is is gone to waste and so on. But yeah, no, it's it's psychologically it's it's a difficult time for for for software engineers. >> And do you think that we had a name?</p>
<p><strong>[48:17]</strong></p>
<p>Yeah. Sorry. Sorry. Go ahead. >> We had a we had a lobster situation where like somebody was like borderline suicidal because of being upset about the fact that their like life skills was no longer going to matter anymore. And it was like it became like a community problem. Um because Yeah. So like it's it's definitely happening for sure. >> Okay. So I'm going to predict that we name that whatever that is. We like we have a name for that kind of feeling and that that kind of whether you want to call it a bless or a loss of purpose and that we're kind of trying to address</p>
<p>it collectively um in a directed way. >> Okay. This is your big moment. >> This is your big moment. Pick the name. If you call your shot from here, this is this is you pointing to the stance. >> Um, you know, >> like deep blue, you know. >> Yeah. Deep blue. Deep blue. I like that. I like deep [laughter] blue. Deep blue. >> Oh, did you walk me into that, you bastard? You >> You just blew out the candles on my birthday cake. [laughter] >> Wow.</p>
<p>You're supposed That wasn't my big moment at all. That was your big moment. No, that that is Adam. That is very good. >> That is deep blue is very >> all [laughter] of the the chess players and the go players went through this a decade ago >> and they have come out stronger. >> But yeah, >> it is deep blue. Jesus Christ, Adam, you scare me sometimes, man. >> There's a reason. [laughter] >> There's there's a there's a reason. Let me just tell you there's a reason. Like, hey, listen. Sometimes it's you know what this web three is coming back. And by the way, did I tell you this other</p>
<p>book that I'm hate reading for the third time? But man, every once in a while you really uh you really send it out of the park. Okay, I need to throw in a positive prediction. Yeah, but it's not an AI prediction. This is a one-year. I think that kakaur parrots in in New Zealand are going to have an outstanding breeding season. [laughter] >> The reason I think this is that the reu trees are in fruit right now. The kakapore parrot, there's only 260 of them left. >> Okay, >> they only breed if the rem trees are in have a good fruiting. And the rem trees have been terrible since 2019, but this</p>
<p>year the Remu trees are all blooming. There are researchers who think that all 87 females of breeding age might lay an egg >> and for an egg species with only 250 remaining parrots, these are great parrots. >> Okay, you know, I I love this because I think and and I'm going to like I'm going to elaborate on this and like this is something humanity want like this becomes something that people like it's like the the condors on Silicon Valley that the the like everyone wants. This is a feel-good story during a difficult age. >> It's it's it's the perfect it's the only positive news I've heard the past three</p>
<p>years. [laughter] It's so good cuz if you if you've never heard of a capore, go and look them up. Big dumpy green flightless parrots. They're super charismatic. >> We need more Capore. >> This is like the miracle on ice in 1980. This is the This is the thing that in a in a difficult time, this is uh what gives people hope that positive things can happen. Y >> and I I love it. That's great. That is a very positive prediction. And I want to</p>
<p><strong>[51:17]</strong></p>
<p>go Yeah. I need like some webcams set up so we can like watch the eggs hatch and and everything else. Those exist. The Capore teams have very good online presence. >> That is awesome. And you should know there's someone in the chat saying, "Hey, I'm in New Zealand. This guy's right. He's so like the Kiwis know that he's like finally some guy they finally have a guest on this podcast that really gets it." Um, so uh that's that is that's a good one. >> Uh I hope someone just got bingo. >> That's [laughter] That's right. Um All right. Are we on to three years? Have I I've exhaust Yeah. All right,</p>
<p>three years. Let's let's let's do some three years. Um >> why don't you start, Brian? You bring a a big bag of predictions. >> I've I've got Okay, so um I think that um that uh in 3 years will be a uh and I think it's not going to happen. I just don't think it's going to happen the next year. I think it'll but I think it is going to happen. um a uh massive pivot away, a delineation between AGI and ASI and realizing that the whole idea of AGI is politically it is a dead</p>
<p>letter. It is not something that is for for a democracy and Simon you said this last year about not wanting to live in a world where people didn't have work right people don't want to live in a work world where there's not work they they really don't work is very important to people's sense of meaning and any kind of claim that like we've ident we've we've built this kind of super intelligence and nobody needs to work again I think is going to be really resisted and and I think it's also it's also helpful that it's not I my personal</p>
<p>opinion Not true. And so I think you're going to get a lot of of a the AGI is going to be the thing that we already have. And oh no, ASI is the thing you're worried about. No, no, we're not doing ASI. Who told you that? No, no, no, no, no. We are. Our mission is to build AI. AGI. Good news. We already did that with chat. GPT 5.2 already was AGI. So I had I I I think that that's going to be in the next in the next three years. They're going to stop talking about AGI as this kind of thing in the future that I can talk about as something that's already done. But they super</p>
<p>intelligence is going to go away as an aspiration. Simon, what do you think? >> I love this as prediction. The one thing that worries me is it's valuations, right? The AI companies with the giant valuations, the only way you justify those valuations as if it represents the the the total addressable market is all human labor. And what are they going to how do they dial their expectations back and and not sort of invert the reason for their company existing? >> Well, I think that this is going to be part of the AI bust. So I think I think in three years we are we will see and again I mean there's no doubt that the frontier models have tremendous there's</p>
<p>there's tremendous value here. There's no doubt about that. Um but I think we will have boiled off a lot and I think that the we will be really looking at these things as tools in in three years. >> That would be wonderful, wouldn't it? >> It would be wonderful. >> This is your utopian. >> This is my utopian prediction. This is that like look the like the the parrots have the you know that the the kacapoo parrots have their uh extraordinary breeding season and that like humans</p>
<p><strong>[54:18]</strong></p>
<p>have jobs. That's like those are those are the the two feelood stories. In fact, >> in fact there's so many parrots that people have to just like domesticate them suddenly. [laughter] >> That's right. >> New jobs. >> Um so uh that is among my three-year predictions. Um, Simon, do you what are your uh what are your three years? What's >> I've got one that's semi-related. Um, we will find out if the Jevans paradox saves our careers or not. >> Oh, there you go. Yeah. Yeah. >> This is the big question that anyone who's a software engineer has right now is we are driving the cost of actually producing working code down to a</p>
<p>fraction of what it used to cost. Does that mean that our careers are completely devalued and we all have to learn to live on a tenth of our incomes? Or does it mean that the demand for software for custom software goes up by a factor of 10 and now our skills are even more valuable because you can hire me and I can build you 10 times the software I used to be able to so I'm more valuable to you and I think within I think by three years we will know for sure which way that one went. >> Yeah. And so to give people context about the Jevans paradox, the Jevans paradox is a 19th century due to a</p>
<p>Scottish economist um and who observed that as coal was becoming cheaper more of it was being used um and that that w and that was a paradox that like why is it why are we and the reason we were using so much more of it is because we were finding new uses for it and the question is the jeans paradox for for software engineering would be as this becomes much cheaper. Do we do much more of it? So, we're not putting people out of work because there's actually much more of it to do. Um, and the thing that</p>
<p>is interesting about Jevans is that Jevans was that paper is called the coal problem >> because uh Jevans was not incorrectly very worried about running out of coal. And what did not foresee at all was of course the discovery of petroleum and solving the coal problem in a completely different way. So it'd be interesting to know if if we end up um but yeah. So you think in so in 3 years we're going to know that? >> I think we will know this certainly. We'll be like okay this is how it played out. >> Yes. Yeah.</p>
<p>>> Yeah. One thing I love about the Jevans paradox is that Brian you're the first person I've ever heard cite it. And then in the years since I've heard you cite it, it's been cited increasingly more often. Like I feel like I see people reference the Jevans paradox like once every three months now when I like never heard of it 5 years ago. >> Yeah. So you know I Steve, bless you for saying that. Um I um I whether it's you know whether Adam is putting you up to it or not being like watch him chomp down on this. He won't question this at all. He's like you know this guy loves the the the sophency of of these LLMs. You just give him a um you know I feel like I I referred to the Jevans paradox</p>
<p>actually in a a keynote like like nine years ago and I'm like I feel but I I must have I mean obviously it's like I mean it's it's from the 19th century so it's like I clearly can't claim that much credit for it. So anyway, but but thank you. >> Simon also did his three-year was like what I was trying to get at, but I couldn't figure out how to say it and I said something that was much worse. So</p>
<p><strong>[57:19]</strong></p>
<p>mine ended up being like using AI tools and writing software professionally is going to be considered something closer to autocomplete or syntax highlighting than something controversial or exceptional. And I was trying to like I originally had something in there about like the industry is going to figure out our existential crisis around these tools and it's just going to be like one way or the other. But I couldn't like figure out how to put it. So like I will just second I think it was very well said Simon. Um yeah >> well and so I think that that we and Simon I think it's it's it's a very good observation I do think and dubtales into another three-year prediction that I've got which is that the uh we see much more customuilt software and much less</p>
<p>SAS. So you get a lot of LLM generated or assisted software that's running effectively custom software. So you're you're developing software to put in production for yourself and you kind of care less about the stuff that's like well you know yes there maybe things that you would care about if you made this available as a service to the internet >> which I actually don't care because I actually am I and because one of the things that that I mean when you when people consume software as a service</p>
<p>especially like the more niche it gets the more important it becomes to your business and the the easier it is to have a real disconnect with your software provider. Um and um I mean Steve the when I at oxide you were very much on the front lines of us replacing SAS software with software that Steve wrote that was I mean Steve you were LLM assistant right you making >> I started to write and then eventually Claude wrote all of it like it was very</p>
<p>much like I started this before I even thought AI tools were good and then by the end uh Claude was doing a lot of work. Uh I think what right before I left we'd looked at it and like my personal AI usage was like the same as the rest of the company at the time or something like that. I think part of the bill or whatever. Uh and I think it's gotten it seems like you all have used it even more since I've left. But like yeah, absolutely. I think this is a definitely a huge thing. Um there I have several personal projects that are effectively just replacing uh you know SAS tools with things that are bespoke</p>
<p>for people and it's it's great honestly. Because what you're going to get you're going to get like hey my my this my SAS vendor they're charging me too much money or you get like the case we had like actually I would gladly pay more money if you delivered us actually the software that we actually need and in this case it was for PLM product life cycle management but the you know you get these kind of esoteric I mean no esoteric is is too strong but the these things that are very important to the way an organization operates that your software provider just doesn't they don't care about your software as much</p>
<p>as you do. I mean, this is what you know that old adage that no one cares about your money like you do. Nobody cares about your software like you do. And I think that um the the ability to custom to to build custom software. Uh and I think by the way, this is going to be a real source of for you. We're going to have a lot of young people that thought they were going to be working for Google and Meta and and and so on that are maybe not going to be um and they may</p>
<p><strong>[60:22]</strong></p>
<p>instead be working in the kind of more mainstream economy writing software using LLMs to write software that's very relevant to >> you know what this ties back something I talked about earlier the sandboxing thing. If you want >> basically if your if you want your SAS to stay relevant, you need to embrace plugins and extensions where your customers can customize it in all sorts of interesting new ways. >> Yeah, >> that the way to do that is with with a sandbox where they can write code that can safely interoperate within your platform and not delete everything but all of that kind of stuff. This is the</p>
<p>kind of thing which used to be really difficult to build like Shopify built this a few years ago with Shopify functions but very few other companies have done it. I think a lot of companies are going to start doing exactly that. >> Yeah. Interesting. Uh >> there are a ton of like industries that are normie industries where there is like 10 consultancies that make shitty software that professionals use because those are the only 10 companies that know their vertical. Like my girlfriend's a real estate agent and like when I look at like the tools and the SAS tools that are useful for her, they're all garbage. And I've been using cloud to build her, you know, website</p>
<p>instead. And it's like way cheaper to just like pay the upstream for, you know, MLS for the data feed and then just, you know, have your own thing done. And it's like way nicer and way cheaper. Uh because like and I think there just so many industries that have very similar kinds of things where there's like the software that's made for professionals is just bad. Actually, >> the most successful implementation of this patent of all time is Salesforce, right? Salesforce incredibly customizable. Dream Force in San Francisco has 50,000 people attending it. They're all professional Salesforce customizers. So that patent absolutely works. It's just it's really hard to</p>
<p>build which is why few companies other than Salesforce have built something with that pattern that's that successful. >> Yeah. Interesting. And yes, maybe maybe Salesforce ends up being the the the kind of the the victim of that of people being able to build the stuff easily on their own. Uh Adam, do you have a a three-year? >> Yeah, actually packs into a similar theme. I I was thinking I think we're all thinking along the same lines in this three-year horizon. And I've been thinking about some of the observations we've made in the past about about uh standing on the shoulders of giants about how all of this software is enabled by all the software that came</p>
<p>before it. Uh and you know I remember when we looked back at um >> what was that that Microsoft the showstopper book about >> the development of NT you know of seeing that as as really maybe one of the last isolated systems like systems that are not kind of participating this larger open- source uh network effect kind of thing but I realized that LLM's like a benefit from open source without necessarily needing to use it directly.</p>
<p>ly they benefit from all all of it being out there. So, uh I struggled to figure out how to phrase that in terms of like this kind of concept of like everyone's going to build their own software. You don't need to use open source software. You can just build your own. So, I kind of set that aside. But instead, my prediction is that we get a crisis of AI slop open source. So,</p>
<p><strong>[63:23]</strong></p>
<p>>> contributions projects that like crates.io IO is just inundated with this AI slop open-source uh library and it becomes indecipherable. >> And so does does this uh how does this affect open source in the large? Does this make open source less tenable? I mean, is there did these two trends combine to make people want like is this a >> Yeah, the parlay I had there that I hesitated to make is that it makes proprietary software more attractive because you have a brand behind it, a person behind it, a throat to choke as</p>
<p>it were behind it. Um, where you know it's not you have some providence associated with it, you have some quality associated with it. You know it's not malware. uh and it helps sift through uh this this AI slop onslaught >> and an organics movement but for software [laughter] like it's a certified human written code because you know >> yeah absolutely like the non-GMO uh repo absolutely yeah definitely um I I know I and so I I think that and you</p>
<p>wonder clearly you need these foundational things though to be open source in order for this whole thing Python has to be open source for this whole thing to work right you you need to have these kind of foundational things that that are open source. So, but it's maybe the these f further or or do you think that that even those things do we are do do we see a return to proprietary programming languages? Although I guess actually we're using the runes that the LLM invented for themselves. So, yeah. >> That's right. That's right. It's a good question about programming languages, but I I do think you see like the the value of proprietary software or perhaps</p>
<p>just like paid software may maybe still open but licensed is getting providence and uh the sort of ancillary benefits that often come with paying for something. >> Yeah. Interesting. >> I've got your three-year one. >> Yeah, I am. I think somebody will have built a web a full web browser mostly using AI assistance and it won't even be surprising. >> Oh, interesting. So that's a big complicated system. >> Yes. >> So we will have</p>
<p>>> notoriously like rolling a new web browser is one of the most complicated software projects I can imagine. >> Yeah. And specifically the reason I think that's going to work is it turns out one of the most effective ways of using a coding agent is to give it an existing test suite and tell it write code that passes these tests. And in the past 3 weeks I've done that for an HTML 5 parser library. I span up a brand new implementation of HTML 5 parser that passed the 9,200 HTML 5 conformance tests. Yeah. >> And I did it for for a JavaScript interpreter. Like I've written a naughty</p>
<p>little Python JavaScript interpreter that passes the microquickjs test suite and it wasn't very hard because you once it's got a test suite it just keeps on plugging away until all the tests pass. I think the browser specs are nearly at a point where a lot of these things there are conformance suites right there's the CSS conformance suites there's all of this stuff honestly today you could start one of</p>
<p><strong>[66:23]</strong></p>
<p>these coding agents working on this problem and it would make a surprisingly decent amount of progress 3 years time I think it's going to be easy I think they'll be able to do it >> yeah that's and that I mean that would be interesting right if you can build a system that is that sophisticated >> but it's the cheat the cheat code is the conformance suites if there are existing tests Yeah, >> you can point to that. It all gets so much easier. >> Yeah. And but that then that does allow you I mean that gets you out from underneath some of the homogeneity that we've got in at at various levels of the system, right? I mean like one of the</p>
<p>questions we definitely have uh is what the and Simon you and I are going back and forth on this about whether we're going to have uh is cloud code going to be writing kernel drivers, right? Where the the the loop is more complicated there. um you don't you don't have some of those things you're talking about in the browser you don't necessarily have for something like a device driver. >> Well, I don't know with the device driver it either works or it doesn't, right? Like you can >> There you go. This is my [laughter] naivity with hardware >> showing up right now. >> If you can reduce a problem to a thing where the agent, the coding agent itself</p>
<p>can tell if it got it right, it's easy. If you can't, it's not easy. >> Yeah. And with the device driver, you can unfortunately the the it is really really hard. um the and because then you have all sort I mean it's not just the edge conditions you've got performance you've got just you've got it it's um it's it's complicated I think to to but I think for those things that you can get that kind of reliability because the thing and I I think I said this as much my one year but just to be clear when I when Adam said I was out of my mind about vibe coding going out of the</p>
<p>lexicon but I think that certainly in my a three-year like we are going to be using LLMs to be more rigorous about the way we do software engineering. Oh yeah. Um >> that's a one year. It >> Yeah. Um and I I think that that's going to be a real that's going to be a big blip in general where it's like no no no this is a this is not coming to replace your job. This is coming to help you do your job better. >> Right. The thing right today with LLM's um automated tests no longer optional. Um continuous integration no longer optional. Good documentation that's</p>
<p>actually up to date with code no longer optional. those things like in the past we've been able to excuse oh we don't have a good test suite yet because we didn't have time that doesn't work anymore you you've got time now the run claw code overnight and you'll come you'll wake up to a test suite and it'll be a bit [__] but it's better than zero >> yeah right yeah god it is it is just amazing this new world we live in >> I've been wondering lately if like one thing that has a really good test suite is the Rust compiler and I've been working on a little programming language</p>
<p>for the last two weeks and I've gotten way farther than I ever expected to uh partially because I went spec first and that's how this like sort of dubtales into that. But I've been thinking about like should it have just been a Rust compiler instead of my own little language because like there is so many tests for the Rust compiler. It's like they've done a very great job with that and I'm really curious if that's something that similar to like I'm going to build this HTML 5 thing or I'm going to build a JavaScript implementation like is someone going to make a RustC uh so >> here's a fun one. I think it's now</p>
<p><strong>[69:24]</strong></p>
<p>easier than ever to introduce a new protocol into the world if you ship a conformance suite. >> Yeah. >> Like release a conformance suite and boom, overnight you'll have libraries in half a dozen languages because the conformance suite is the majority of the work. >> Yeah. That interesting. Uh and then then you also make it when you when you do that you make it much more readily adoptable by other LLMs. you make it like it's like >> it overcomes the problem that it's not in the training data and people are kind of nervous that you could never launch a new program language now because it's not in the training data but the context</p>
<p>lengths are big enough now that if you can get it into a test suite and fit the instru the examples on how to use it in 10,000 tokens doesn't matter that it's not in the training data >> yeah uh Ian we got you up here I and I probably should got you I if you have any one year or three years u but you know you've um you've got such a great track record um that We look to you as our Nostradamus. Uh maybe you just strongly agree with me that vibe coding is going out of alexon. But >> I um I >> I'll take that laugh. No, Adam, that</p>
<p>laughter is noted. I That's derisive laughter. >> Yeah, >> I feel I feel like that the only way that V coding leaves the lexicon is if um the older generation makes the term uncool. So the younger generation comes up with a new term that is cooler than viping. >> What he's saying is you have a big lever. You have a big lever. >> I I've be I've done this before. I know how to It's like it it's like no. Isn't Come on, kids. Isn't that hella cringe? It's like dad. >> Um just watch just watch me vibe this</p>
<p>up. I'm vibing right now. [laughter] >> That's right. I'm just like you guys. I'm just vibing this up. Okay, we need another term. We need another term for this guy. Don't don't kill my vibe. >> That's right. >> Um so I do have a few predictions. Uh on the one year um I have demand outstrips supply for Whimo rides from San Francisco airport. And the way that I measure that will be wait times greater than 10 minutes.</p>
<p>>> Yeah. Interesting. That's a that's a great guess. That's a great prediction because Simon, you said this a couple years ago that the absolute cheapest tourist attraction in San Francisco is a Whimo. >> Oh yeah. >> So like 10 bucks you get to go in a self-driving [snorts] car. It's the best, >> right? It's like why wouldn't I wait 10 minutes for a Whimo? It's like I'm waiting. I'm you know I'm going to wait for 10 minutes for the Pirates of the Caribbean. Why would I not? >> I don't think it's worn off for me. It hasn't worn off. I've been riding Whimos for a year and a half. I still get that little like fion of glee when I get in a Whimo and it sets off on its own.</p>
<p>>> Yeah. Well, and I actually saw I I was in the apparently it's pretty tight like cordon in the mission where the zuks are riding around and Yeah. And so I >> too. Yeah. >> Yeah. And I I was with the I was trying to get on the zuks, you know, I'm on the zuks weight list, but it is like you're it's enticing you like I want to actually I want to get in that. So Ian, great prediction. Is that a one-year</p>
<p><strong>[72:24]</strong></p>
<p>prediction, Ian, or was that what's the >> Yeah, that's a one-year prediction. Um cuz they should be launching Rise from SFO for the general public this year. >> Um I have a second one year prediction. >> Um >> so friend as in friend.com >> I think uh they will have under 10,000 activated devices at the end of the year. Um well under 10,000 but that's probably a conservative prediction. Um, when activated devices, someone has</p>
<p>bought the thing and has actually sent at least one message to it. >> What is friend.com? >> Oh my. [laughter] >> Oh, what? Okay. Yeah. What? Go on. >> Okay. Brian Brian has not been to New York City this year. >> Yeah. Yeah. >> Is that right? Oh, so campaign had a very large uh >> Oh, but before you before you explain it to me, Adam, I notic you've been a little bit quiet. Do you I I think Adam Adam also does not know what friend.com</p>
<p>is and he's he is relieved that that I >> doing for forever. [laughter] No, no, I love >> I I I love friend.com and I use it the way that one conventionally uses it. [laughter] >> Just like normal. Just normal. >> Just like normal like all the other all the way you other folks use it. Anyway, go on. I'll let them explain how we all use it together. >> Tell tell father time [laughter] here how how you use this time. >> Tell tell Funny McDuddy Daddy how we actually how all the rest of us use</p>
<p>this. [laughter] >> Well, this is great. We have a yes no on this one. [laughter] >> We do have a yes no. Yeah. So, tell me about friend.com. >> Yeah. Yeah. So, Friend.com had a large subway ad presence this year um in New York City, but also in Chicago and I think they did a campaign in LA. Um the New York City ad campaign was not wellreceived. Many of the advertisements [laughter] were defaced by the New York City</p>
<p>public. um to the degree that there was there was a picture on I saw of someone went as the friend.com uh advertisement for Halloween. So they they printed up a a sweater of the friend.com advertisement and handed out Sharpies so people could deface their [laughter] Halloween costumes similar to the ads in the in the subway. >> Hey, you know what? I got to hand it to you, New York. This is a very Bay Area thing you all are doing out there.</p>
<p>We're, you know, that's that's uh that's that's great. That is really terrific. Um, okay. So, what is So, all right. What is it? It's >> It is a It is a AI companion. It is a $129 pendant that has a microphone in it >> that connects to your phone</p>
<p><strong>[75:25]</strong></p>
<p>>> and it it uses the microphone that could have just been the microphone in your phone, but isn't for some reason. um to send messages to a AI companion which can respond to you by sending you uh I think I think it talks through the phone to you. So it is kind of AI chatbot psychosis as a service or something >> jewelry. That's all right. All right. So, this is like in the vein of the rabbit R2 or the humane pin and this is uh yet another AI</p>
<p>wearable that sounds like it's and so you say destined for I I yeah I'm really sorry that I've not I didn't get a chance to enjoy this whole ride. Um but thank you Ian for uh so you say less than 10,000 devices. That's a three prediction. Okay, >> that's a one one year prediction, but yeah, we're not going to get to 10. I the the three year would be that I'm pretty sure this company is going to flame out, but >> the one year is that this ad campaign does not really move the needle for them as a company. Oh my god, that ad just And that's the kind of thing where it's</p>
<p>like I know because I'm basically like a rule biter and when I am tempted to deface things, it's like when I'm tempted to like run over that that the the the security bots, those little cones that Whopper that that that Samsung had that would run around and beep at you. I'm like, you know, I think that I want to throw you into the ditch means that you are I mean, it's like this is this is bad news for you. >> Well, this is Brian why I think you claiming that this is like the what something this would never happen in the Bay Area. Bay Area people are rule followers to a much greater degree. [laughter] Oh yeah.</p>
<p>>> This is a New York phenomenon. >> Oh [clears throat] yeah. Yeah. No, no. I like I I I love the I love the rebellion here. Um and then Ian, do you have uh do you have some three years here? >> Yeah. So for the three-year uh I was thinking about the um Windows 10 end of life and the claims of uh the year of the Linux desktop. Um, and my three-year prediction is kind of an anti on that where uh the prediction is Windows is still above 90% on the Steam hardware</p>
<p>survey as of December 2028. >> Okay. [laughter] Uh, and that that that's a good one. Um, or or a grimlin. I'm not sure. That's Are you counting that as utopian or dystopian? I think it's uh >> I think that it's Well, here here's the thing. I think that Linux has gone from less than 1% to over 3% on the Steam hardware survey in the previous 6 years driven largely in part by Steam first</p>
<p>party hardware. So the Steam Deck uh in particular, but also you know just Linux usage in general has gone up. Um I think the Linux usage is going to go up in the next three years. Um but I still think that Windows is going to remain pretty dominant within that um hardware survey.</p>
<p><strong>[78:28]</strong></p>
<p>>> Uh so it means that like they may go from 95 to like 92 or something and and and Linux is going to grow up to about 5%. But I I suspect that the people who think that people are going to go out and replace their Windows 10 devices with a Linux machine or install Linux on their existing device to avoid buying a new device are kind of a little optimistic about how much work people want to put into their computing. >> I mean, can you imagine going back in</p>
<p>the time machine and being like, "Oh, this is a year of the Linux desktop, pal. We're going to have computers writing software in production before we have that. Sorry, we are this is uh I although I have you I have tried to use chat GBT and LLM more generally on uh Linux audio problems. What's interesting is that it's actually not that helpful. Um that it's the I mean they tell you the things that you know whatever it's it's Linux audio is still undefeated is what I'd like to say. Part of the part of the real struggle here is the kernel level antiche which is like basically necessary for some genres of game that</p>
<p>will just never happen with Linux. And so that's like I don't know some of this is about like the relative market size of those markets versus other ones but like there's some game like I will never not use Windows because all the games I want to play effectively require colonel level of anti-che to run and so it just they're not going to ever work on Linux. Um, the Hey, Adam, you know, this podcast has really really arrived because my 13-year-old daughter is texting me predictions that she has during the episode. Wow. >> I I she and you know,</p>
<p>>> our whole demographic in so many ways. >> This apple didn't fall far from the tree. She thinks this is going to be a major scandal involving Apple in the next three years. So, I you know, don't ask any follow-up questions. She also said that that she thought that the Open AI guy was going to go to jail. She told me and I'm like, "Sam Alman?" She's like, "I don't know who that is." I'm like, "That's the open AI guy. That's the that's who you is gonna go." [laughter] So, sure. Uh Sam Alman, if you're listening to this, please send us a cease and assist because we have that as a goal for this year. Uh okay, let's go</p>
<p>on to uh six years. Are we ready for some six years here? Um >> yeah. >> Uh Simon, what do you got for us? >> I've just got the one. I think the act of the the the job of being paid money to type code into a computer Yeah. will go the same way as punching punch cards. >> Okay. >> I do I think in six years time I do not think it will anyone will be paid to just do the thing where you type the code. >> Just type the code. Okay. >> I think software engineering will still be an enormous career. I just think the</p>
<p>software engineers won't be spending multiple hours of their day in a text editor typing out syntax. >> It will look like punching cards. I think so. Yeah. >> Yeah. Interesting. In uh in six years. Um and but software engineering still very much exists. >> I believe so. I I hope so. [laughter] I very much hope so because I think the um the challenge of being a software engineer is not remembering how if what what if what for loops look like. It is understanding what computers can do and</p>
<p><strong>[81:29]</strong></p>
<p>how to turn fuzzy human requirements into actual like working software. And that's that's what we're for. And I think we'll still be doing that just a lot more of it in a lot more ambitious scale. >> And then Okay. Do you Does the software engineer though deals with code? I mean they I mean the code is being written. >> I think they probably look at it occasionally. >> Okay. Only occasionally a little bit. So I met >> Who debugs it? >> Um I I hate to say it, the agents debug it themselves. >> Okay. Who debugs your device driver that either works or doesn't? I like working</p>
<p>on this programming language like I'm doing my own codegen and like claude is happy to pull out GDB and just like debug the programs that it generates and why the like like the binary is wrong and then back fill that into why the compiler is wrong like it's better than I am frankly >> this is more about me than anything else but like it's a thing that it can do now >> I mean this is a really interesting thing I've been seeing just in the past three months around coding agents is that four months ago I was absolutely on team you cannot commit a line of code that you've not read reviewed and understood that these things have written for you that's it's irresponsible to do that. I'm edging</p>
<p>away from that a little bit because it turns out the art of using these as effectively is get them to prove to you that the thing they have written has worked. The same way as like when you're working in a company, you don't review every line of code that another team has written, your team depends on, but you do talk to that team and you make sure that they are making a convincing case that the code works well and they've tested and they've covered the bases and so forth. It's a similar kind of thing and it's so uncomfortable like >> it is. I I it is beginning to give me the early onset of what they what they call deep blue.</p>
<p>[laughter] >> Yes. >> Um so but I mean you cheered me up at the end there that that there's uh that there is there's still a role for software engineers. Um um Adam, do you have a do you have a six year? >> Yeah, I have a couple. Uh you dovetailing on your daughter's prediction, I predict that the the cell phone uh business is drying up uh because people are keeping their devices longer. So Apple has several new attempts for what the next flagship</p>
<p>thing is going to be. >> Oh man, that is a good prediction. >> Oh, that's that's interesting. I have like almost the opposite prediction [laughter] already written down here. I had phones remain the most popular form factor for personal computers in terms of units sold in the trailing 12 months. >> Huh. Because yeah, I but I do think this longevity thing is a real real real issue that these I mean you've already begun to see this where people are like why am I getting the latest iPhone again? Like the camera's already awesome</p>
<p>and I actually I care more about battery life. I care about like is it waterproof? I mean I care about other things that So all right. So Adam, how does this the Um, I guess this does this happen after the major scandal in the next three years. I don't know. >> Terrific. It must be on the heels of that scandal. Yes. [laughter] >> Or or maybe the maybe the scandal maybe this somehow wrapped up in the scandal. Maybe the scandal is that they are they're scandalously entering a new</p>
<p><strong>[84:30]</strong></p>
<p>business or what have you. >> No, I think that that it's got Apple and but Apple's got a ton of capital, so they could go um you know, they could >> they could do a bunch more Apple Vision Pros. >> Yeah. Uh well, they Yeah. So, Ian, do you feel that because you say this is on devices sold is still good. So, you think that the phones are going to still find ways to differentiate or >> I just I just think that there's >> that I kind of have the opposite view in that I I think that um I think the phone sales may not go up,</p>
<p>but they're still just going to dominate in terms of units sold. And there's no other form factor that has emerged that is more popular as a um personal computing device. >> Yeah, I don't I don't think those are incompatible, Ian. I think what I think uh you know, phones going down, >> it still could be the most popular um form factor and folks could be desperately Apple in particular desperately trying to figure out what the next thing is going to be. Okay. Could I tag a prediction onto that which</p>
<p>is that if phones are not the most popular form factor, I think it's going to be the Neural Link device of some sort. >> Oh, here we go. Uh uh you [laughter] neural link in in six years. Is this how? >> No, I don't think it's going to happen. I But if phones, if not phones, >> phones and if not phones, it has to be that >> because all of the other form factors, the little bracelets and things you talk to, that's all garbage. Nobody wants to talk out loud to their computer in public, >> right? >> But if you can think to your computer in public, that's the thing that could</p>
<p>knock the phone off its pedestal. >> And it will be the leadership of the pope of the papacy that that that tells us that we get with the the leading the way with the neural implant. Okay. Interesting. >> Is a curse curse prediction that's a mixture of all of these, which is of course appleacquiresfriend.com [laughter] >> and and it's less than 10,000 devices. Um >> I have a a second device prediction for six year which was um I predict that more Macs are sold in the trailing 12</p>
<p>months than any smart glasses or AI companion devices >> this in the trailing of six years. So in five years you got more Macs than anything else than then. >> Yeah. So it's like when when the six years is up we look back in the previous 12 months >> it's like hey it's all laptops. It's it's laptops and phones. It's the same. >> I'm Yeah, I'm saying that that laptops Well, specifically Macs. So, it's not actually laptops. It's the Mac line because I think that's the only thing that you can get number of units on</p>
<p>roughly. Um, but I think that more of those are going to get sold than any smart glasses or AI companion devices. And I'm saying Max specifically like I think that you know laptops is definitely going to be is bigger than Macs. I'm saying that like these smart</p>
<p><strong>[87:30]</strong></p>
<p>glasses and AI companion devices are just not um a real volume seller at all. >> Yeah, I to any like real degree. >> Yeah, I I totally agree with that. Um, so, um, I'm going to say that the, um, the the DSM adds LLM as a contributing factor to psychosis. The same way the DSM treats LLM the way it treats kind of like cocaine. >> Um, where um, you can have >> a lot in the early days of the</p>
<p>profession and then looked back as a mistake of having [laughter] >> Well, no, because I think I mean we are just you said the lobsters issue uh, earlier. I think that we are we are going to have a an increasing number of incidents of LLMs uh resulting in psychotic behavior. >> Okay. Has the DSM got anything about social media in right now today? So, so right now they do have um the on like internet gaming for example and they um but I think this is going to be more</p>
<p>this is going to be faster than internet gaming because I think that where gaming is um looking more at at social isolation and and and some kind of modum of dependency versus like no you like the the the LLM got you to do something that you would not have otherwise done that you had this delusion that that that you know your that your mother that that that your mother was involved in a global conspiracy. Um it to and and you burned down your house. >> You're betting against the AI labs being able to tamp this stuff under which I</p>
<p>think is a fair bet. >> I I think it's well it's more that I'm like I'm just betting I'm just betting on crazy um in that like I think that that like you you can't there's no amount of safety that you can put in place that allows these things to be used and not I'm not I don't know they will be liable. I think it's going to be more like for diagnosticians to be aware of like hey if you're talking to a patient like do they have this kind of idea because of the LLM have they been having conversations with their LLM about this? >> I mean it feels like we need this today. >> Oh no I think we do. I think that this I think that the reason I was saying</p>
<p>earlier at the top I was struggling with sixear predictions. The DSM moves slowly. So that's why I that's why this is a six-year prediction and not a one-year prediction. >> And this is well beyond deep blue at this point. >> This is this is well beyond deep blue. That's that's exactly well no because this is not like a feeling of on we >> I got it delusion this is a delusion this is a psychosis thing and I again we we have already seen this um we and I think we will uh and it's an accelerant it's like it's like substance abuse you</p>
<p>got people that can have a that can use substances without actually developing this kind of psychosis and then others that that develop a real psychosis around it and I think that see uh the DSM become aware of that um so I I think you will also have um you will have I think actually in three years but certainly in six you're going to have people trying to use as a legal defense. The LLM made me do it. I not blaming the actual frontier model. I'm actually it's the the LLM that that did jin me up and</p>
<p><strong>[90:32]</strong></p>
<p>talked me into doing this um this doing this this illegal act um whatever it might be. >> Are they also going to use it for for stock buyers? Are they going to be like the LLM told me to buy the stock? I didn't use any insider information to be able to to trade on. >> Absolutely. Absolutely. The this is you know the the kitty did it is what the you with the with the you know when you got the toddlers the everyone blaming the LM. No, absolutely. The LM told me to buy the stock. Um oh actually uh I shoot I forgot one of my three years. Um I do think um ads are going to enter LLMs. Um I I and I think that you're um</p>
<p>and I think it's going to be an issue um where we >> like product placement be like you know what would go great with this recipe is a Coca-Cola >> I I think um product placement and where you are actually either putting your thumb on the scale of what of the output or getting more of the input. So the it cuz I mean you think about like the view that these chat bots have on the kinds of questions that we're asking and boy if you were developing you know if you</p>
<p>were in marketing or you're developing a product wouldn't you love to know what people are searching and it feels like it's like that's something you would pay for and it's something that you know it's like I think these guys will sell it to you and post the AI bust that I'm predicting roughly in three years. So you know all my all my predictions try to hang together. >> Chat GPT knows when you're pregnant because you tell me. >> Yes. Absolutely. Absolutely. the old adage of like I think it was like Target, right? That famously knew >> famously apparently that wasn't real. The thing that [laughter] Target guessed someone was pregnant from their purchasing habits. Apparently that doesn't hold up.</p>
<p>>> That makes Yes, that that's a relief because that didn't make that kind of didn't pass the smell test at the time. So, um, and then are you saying that like the chat GBT equivalents are going to integrate ads as a first party or are you taking a like SEO black hat view of like people are going to work out how to uh get their data into the training data such that when someone asks what the best laundry detergent is, then it the the the</p>
<p>uh model will spit like, oh, it's definitely tied and you should not use any other brand. >> I I was not predicting the latter, but I think the ladder is a great prediction. So, I I think that they I I strongly concur with the latter, but I think that we're I think there's going to be a need like there going to be other kind of commercial vectors here, not some of which uh ultimately it's going to be ads at some level. It's going to be getting you to buy product. Um the Adam, did you have other other six years? >> Yes, I think you're going to like this one too, even though it sounds insane as I read it. Uh, I think Tesla is going to</p>
<p>be out of the consumer car business. I think they're going to be selling batteries. I think they're going to be selling fleets, but I think that they are not going to be selling to individuals. And and their numbers are like down year-over-year for the last two or three years. >> Uh, and I think that's going to continue. >> Um, do they sell whatever the plural of Optimus is? Is that Optimi? What is the plural of Optimus? The Tesla bots. Are</p>
<p><strong>[93:34]</strong></p>
<p>is that does that ever come to fruition? Is that what they sell? >> Oh, uh, sure. Yes, it's [laughter] it's it's >> it's Yes, it's theirfriend.com. >> It's their friend.com. Okay. >> Yeah. Yeah. But >> yeah, I love I I love this prediction. Obviously, battery I mean batteries is already a big part of their business and arguably the cars are batteries and then uh and fleets. >> And fleets. Okay. So, they are out of the consumer car business. >> Yep. >> Um I do love that one. Um um I'm going to add that um Nvidia's uh peak valuation in six years we will see</p>
<p>was in 2025. >> So I I I I think we are past Nvidia. This is not stock. This is not investment advice. Although [laughter] although this one is definitely if you think it is investment advice and you act on it, if you could please send us a cease and desist, we'd appreciate it. Um, exactly. If you're listening to this, please put all your money into shorting Nvidia. >> That's right. Um, I um I think that and this is not a slight on Nvidia. I think that the valuation is it it like it's simply uh too high. Um, and the too much</p>
<p>competition, too much that there are too many. I mean, we talked about Gemini last year and I mean, Gemini not trained on Nvidia GPUs. I just think there's that there's just too much out there that too many headwinds ultimately for them for for that valuation. I think absolutely a going concern um and a well executing business. But >> this dubtales into one of my predictions too and maybe justifies it. But I say in six years Jensen hands over the reigns at Nvidia and to a successor CEO maybe on the on the back of the the dwindling stock.</p>
<p>>> Uh and is that CEO Pat Gellzinger? [laughter] >> No. I think he's he's focused on his faith-based startup. >> It's his faith-based uh LOM startup. Yeah. >> Yeah. Um >> I mean he'll be like 68 or 69 in Jensen. Yeah. >> Is that right? >> Yeah. >> Yeah. I mean >> almost 70y old man who has infinite wealth decides to retire does not seem >> sure. Okay. Bet against it. That's that's fine. But uh but but look at like</p>
<p>Morris Chang who at age I don't even know is still going strong. So >> or Larry Ellison. Uh yeah or >> yeah I was gonna go Pier Lemon but yeah Larry Ellison fine the latest podcast. [laughter] >> Um all right [snorts] um the uh Steve did you have any six years? >> My my sixth year is boring but it's funny because it shouldn't be boring is which is AI will not have will have not caused the total collapse of our economic and governmental systems.</p>
<p>>> Like you know that's a very optimistic prediction. That's great. >> Yeah. Yeah. I I'm choosing to be optimistic here. Uh I think anyway I mean I I you know there's some ways in which that could be a pessimism and not an optimism but I'm I'm gonna say that humanities could be okay. >> You didn't predict that economic collapse wouldn't happen. You</p>
<p><strong>[96:35]</strong></p>
<p>specifically said that LLMs are not going to happen by AI. Yes. Correct. Yeah. Yeah. Uh, I think we're gonna figure it out. And I think that a lot of the anxiety uh right now and worry about it is anxiety and worry and humanity is resilience and change is going to happen. But we'll we'll be okay. It's going to be fine. >> And this is the affirmation tape that you listen to when you're beginning to suffer from deep blue. This is the you Steve Clavnik reads. This is you put your headset on as you're going to sleep. And every >> had a very optimistic 2025 and so I think I'm going to try to I'm trying to</p>
<p>continue that into the future. We'll see. That's a That is great. Um Adam, do you have any other six years or are we going to end on the optimistic note? >> Let's end on the optimistic note. >> Yeah, [laughter] translation. I I do have another six year, but it was way too grim. Um what's good? I think that you know I I I think we you know the a common theme from this year I would say is uh the LMS really transitioning into a useful tool into the hands of practitioners. I think that they um that and the demise of friend.com. um I I would say are the are</p>
<p>are the two big themes >> and and the rise of the Capot. >> Absolutely. I'm going to go check out the parrot. I'm going to go check out the parrot. Um as long if I learn that the parrot survive coding though, I'm going to be very upset because that's going to run contrary to my to my one-year prediction. All right. Well, uh this has been great. Um thank you all for uh for for joining us. If you do have predictions and you and I'm actually going to um the um Mike Caparella joined us last year. who could not join us this year. Um, Adam and, uh, sent me some of his predictions. So, I'm</p>
<p>going to drop those into the chat. So, we've got those on the record. Um, if you do have any predictions, get those in the record. Um, and we'll have PRs open as well. You can get PRs in there. Um, but um, we thank you all for your predictions. We've said before predictions tell us much more about the present, we think, than about the future. Um, but I don't know, maybe these will maybe maybe this year is the exception. Um, and we're gonna we're gonna learn learn a lot more about the about the future. I do think deep blue has got I mean [laughter] it's it's very good, Adam. I mean, it's really</p>
<p>>> Yeah, >> it's got if people have predictions uh whether you're listening live right now or on YouTube or on the podcast. Uh if you go to the show notes on GitHub, uh if you want to drop your predictions in, uh it'll give us an opportunity to review them in 1, three, and six years. So, feel free to submit a PR. >> Awesome. Thanks everybody and here's to a great and hopeful 2026.</p>]]></content:encoded>
      <guid isPermaLink="false">https://www.youtube.com/watch?v=lVDhQMiAbR8</guid>
      <pubDate>Wed, 07 Jan 2026 15:30:28 +0000</pubDate>
    </item>
    <item>
      <title>Oxide and Friends 1/12/2026 -- Engineering Rigor in the LLM Age</title>
      <link>https://www.youtube.com/watch?v=fmFt4-jjEc0</link>
      <description>What do LLMs mean for the future of software engineering? Will vibe-coded AI slop be the norm? Will software engineers simply be less in-demand? Rain and David join Bryan and Adam to discuss how rigorous use of LLMs can make for much more robust systems. 

Notes: https://github.com/oxidecomputer/oxide-and-friends/blob/master/2026_01_12.md</description>
      <content:encoded><![CDATA[<p><strong>[00:00]</strong></p>
<p>Last week he made us wait for like four minutes. Well, my man in the office says, "Hello, Adam." Says, "Brian's here." Hey, Brian. How are you? I am doing well. How are you? I'm doing very well. And we've got all the oxide friends here. We've got David and Rain. And Rain. Great. Um, you know, if our predictions episode was only a week ago, and yet it already feels like at least one of our predictions already feels like such a lock. It's amazing that it was even even considered a prediction as little as a week ago. Uh I think this</p>
<p>oni the software engineer [laughter] on and then your absolutely brilliant naming of deep blue for this sense of software engineer on uh wondering what the real purpose of anything is that the LLM could just do everything for them. Uh it feels like this has already taken root in the last week. Is that my imagination? Feels like this has been >> I think it uh I think I don't think it's just your imagination. Uh, I [laughter] think it may also be my imagination, but when I saw someone uh not even tag us, but but just describe the feeling as</p>
<p>deep blue, I was like, "Wow, this is this is really getting we've really made it." Yeah, >> we made it. We We've definitely arrived. I you know how ironic would it be if that cease and desist came from IBM for [laughter] for naming for for sullying the good brand of Deep Blue into a kind of like >> I'll tell you the predictions market does not have that one coming. So >> exactly let's see Deep Blue disambiguation on the Wikipedia page when they actually need to >> clarify that we're not talking about the</p>
<p>the the the software engineering neo depression LLM based depression. >> Yeah. If we see the uh if we see the the poly market uh on that spiking, we know that there's a CND coming and some insiders are profiting on it. >> Well, it's my understanding those insiders are supposed to be us, right? Isn't that the way isn't poly isn't that what poly market isn't that sorry, isn't that who they serve? Isn't >> I think in this case it would be it would be the folks at IBM about to sue us. But yeah, I mean that's that's basically >> Yeah. Can we take out a position on getting a CND? Is it they've got CN over the course there going to be Oxide and</p>
<p>Friends? Uh I mean old conventional wisdom oxide friends bingo car. New conventional wisdom oxide friends poly market. >> Yeah. >> Um there's got to be a good hedge, right? >> Yeah. >> Yeah, it should be. Uh but it it feels like this has really been uh I mean we knew this last week, but it just the presence of LLMs. What does what do LLM mean for software engineering? I feel like I've seen like six different pieces a day on right about talking about like what does this mean? What does it not</p>
<p>mean? And I feel like >> there's there's quite a bit of of noise out there. Um I well noise. Um >> there's a lot of consternation out there. That is for sure. Uh it this is a uh this is an issue that has a lot of people thinking about it one way or the other for sure. I definitely learned that the I mean there is a demographic</p>
<p><strong>[03:02]</strong></p>
<p>and if you it's hard to say because like these all right look if you're in this demographic you are going to think that we are belittling you by making other people aware of this. I >> I just want to pause right now and all listeners please write down what large group of people Brian's about to alienate. >> Excuse me. I'm being handed this folded piece of paper. Listen, I just have I I I've st the mortgage payment on a CND. So, I'm really [laughter] I need that. I really need to get the goose this thing along. So, really trying to after our you know, we we we tried to get a a CND</p>
<p>from the Republic of Germany last year after offending all of our German listeners, but we uh that nothing came of that. So, um, there are there's there's a virulently anti LLM demographic out there >> and and I like I at like I I get it. And uh, but that's what not what we're going to talk about. I guess we already are. Sorry. Whoops. [laughter] Um, >> I was like, wait, those folks? You already alienated all those. Like, >> all those folks are they are that</p>
<p>Hornets you've already kicked many times. Like do you not follow yourself on blue sky because [laughter] >> you maybe you should. >> I know I I also feel like I'm doing you know I had a boss who would do this once who'd be like listen we're going to go into this meeting and I want no one to mention insert name [laughter] of former customer like we're just not going to talk about them. I'm like I wasn't going to bring them up and then like the very first I want to explain to you why former customer is no longer a customer. I'm like okay didn't Okay. So oh I get it. When we were in the car ride down you weren't talking to us. you were</p>
<p>talking to you like the part of your brain that tries to not screw everything up was trying to talk to the part of your brain that actually in fact screws everything up and that part of the brain wasn't listening as it turns out. >> So I kind of feel like same thing for me here on like >> nobody bring up the fact that there's a demographic that believes that LLM use is immoral. I will do that from the top. So no I'm sorry. >> All right. Well um this is a hash. We can cut all this out, right? This is >> Yeah. Yeah. Sure. Sure. [laughter]</p>
<p>That's all. >> Um but we are to the contrary what we want to talk about today is um the what we have seen is that we want to split this kind there's this false dichotomy out there that you are either vibe coding a term that I again I believe is not going to survive the year a prediction that may not be not be fairing that well in its first week evaluating [laughter] our predictions one weekend. um the uh that it where you have a fully closed loop and an LLM is just simply creating</p>
<p>software of its own valition. Uh that is kind of like that that is one poll and then the other poll of course is like no no no these things are like you should never use them they shouldn't be used for anything they're you know etc etc etc >> and correct me if I'm wrong but I feel like a shiblith of vibe coding is this idea of like you just do it and if you don't like the results you do it again and if there's a bug you do it again and</p>
<p><strong>[06:04]</strong></p>
<p>you're never sort of cracking open that nut and like seeing what all the gooey middle is you're just like just go for it like kind of a lack a a toological lack of curiosity and about what's going on inside. >> Yes. Well, this which is part of the reason I think that the term will die with this because I think the term is going to be associated with that lack of curiosity. But yes, absolutely. And there are um domains in which that lack of curiosity may be okay but other domains which it's not. So that's kind of the the the kind of the two polls and I think what we have we what we believe</p>
<p>what we have already seen is that there is a big big big middle ground and in particular what we have seen is LLMs are can actually be used to result in more rigorous engineering uh and it's actually not even that hard. Um, I think that there there's and I've got >> I've got some specific I my some specific and recent experience. Um, Adam, maybe I I could lead off with that before I introduce our colleagues. Um, so I have been exploring uh using cloud</p>
<p>code to do kernel work to do um we've got our host operating system is Helios. Uh it's an alum derivative and I had some like what I thought was a good you know you always have to want to have like a good first task for these things just like when I picked up Rust I wanted to find like the good like what is the right thing to try Rust on um my first thought of a doubly linked list ended up being that was the >> that was the wrong idea that was the worst thing so okay let's let's not do the worst thing let's do a different</p>
<p>thing um and I mean just and actually you know you kind of had the same experience with Russ of like picking up not a great first thing although not deliberately right I cuz you did a Sudoku solver. >> Yeah. And a grammar. Yeah. >> And And I mean, how And how was that as a good as a first Rust project? >> Um it was like >> I think it was very early for Rust. >> It was early for Rust. It was early for Rust and just the work that has gone in the intervening like 10 plus years. >> Yeah.</p>
<p>uh to making it approachable and the error messages um sort of like convergent rather than divergent. Like I think my big frustration was it was like go go try this and it's like oh wow that's much wronger. Like don't like who told you to do [laughter] that? You told me to do that. What are you talking about? >> I didn't tell you. I don't even know I don't know what you're talking about. Yeah. Exactly. >> Um so but you but you also so I mean in hindsight would you today would that that would be a fine first Rust project. There was nothing about the project itself. Yeah. Yeah. Right.</p>
<p>>> Yeah. Yeah. I mean it was it was it was even simpler than the thing you that ended up being your first Rush project, >> right? Um so you always want to have a good kind of first thing for these things and I've been kind of waiting for a good like what is a good thing to use cloud code on because I just want to like see how it does basically on this stuff. Um and I had some like some relatively straightforward scalability work that needed to be in a lock that needed to be broken up. I knew I how I</p>
<p><strong>[09:05]</strong></p>
<p>wanted to do it. Uh it was going to be a little bit tedious. Um but I was just kind of curious to see how it did. Um and >> and it should be said that the idea here also was like you you're breaking up this lock in a way that many locks before it have been broken up. Is that fair to say? >> Yes, absolutely. that there's actually like what needs to be done here is really quite straightforward and I can describe it pretty pretty completely um to to cla um and I I'll I'll drop a link to to the actual uh the the actual</p>
<p>bug itself um alumos 17816 um so I'll drop a link in for that and so you can you can see exactly what the problem was at hand pretty straightforward Now, I was going to use and like very deliberately not using it. I'm definitely not closing the loop, not vibe coding it, not oneshotting it, but really um because in particular like I am not we're not even I'm not even going to let it build anything, right? I'm going to let it we're going to go into</p>
<p>the source base and I just wanted to see how it did and uh really did like it did remarkably well. Um, one thing that was really interesting and I would and but not I mean not definitely not perfectly and had some subtle issues that needed to be resolved but we got those resolved pretty quickly. Um, and I think I would say like it had two subtle issues but it had also did not have a subtle issue that it could it made a subtle discovery as well. And the thing that was really interesting to me about it is I was</p>
<p>unleashing it on like a a pretty big source base in terms of Lumos and it was really interesting to watch it effectively read block comments to understand how subsystems worked. um and to understand it and so reading not just code but also comments um and all in all it was really pretty impressive I you know it it definitely understood I mean it's we're talking Lumos here so it's like this is not like anything that you have trained on that is the Linux kernel or the BSD kernel is like literally not</p>
<p>going to apply it would be very easy for you to create arguments to to functions that didn't exist I'm talking about the kstat facility which is a facility that doesn't exist in so it's like you cannot rely on on something that you've really trained on. You're going to have to kind of look at this. Um, but it was good and I would say like net net it probably saved me probably about in terms of the like the actual um time to implement this. It probably saved me like half the time. I spent about two hours on it to have something that was I was pretty</p>
<p>confident would work and did work. Um, versus I think it' probably be about four hours on it. Um, and someone's suggesting well how many LM train. Yes, but what it was do you the the way it was iterating uh and if folks haven't used cloud code it is really um it's worth experimenting with especially on an established source base and so one of the things that I would just like to throw out there as like a first way that</p>
<p><strong>[12:06]</strong></p>
<p>these things can help increase your rigor is by asking questions about a source base. Um and clearly like you know all of the caveats apply that you can get the wrong answers and so on. you need to verify these things. But um it it was really made it much more made the t it figured out a lot of what needed to be done um surprisingly quickly. So um I will absolutely be using it again for other kernel projects if only to as a starting point to uh and I I I you know one of one thing it did it was funny is</p>
<p>Adam it needed to add a field to a structure and this is the actual structure itself. None of the fields is commented. You know how we like best practice would be to comment every structure member. And in this particular source file, none of the structure members are commented. And the what its proposal was was to actually comment the structure member. I'm like, uh, for bad reasons, like we're not going to do that. We're going to be consistent with what's there by not commenting the new member that you just added. Like the code you want to actually write is actually cleaner than what's there. Um,</p>
<p>but it does think it the other kind of thing that it it brought to mind is like, boy, there's so much like technical debt kind of things. And one thing I think would be interesting that surely we're going to see is people going into existing source code and commenting it better using Claude that just have better comments then obviously validating all of its work and and you know not allowing. Anyway, that's that that's kind of my my story um from my experiment over the weekend doing a Lumus kernel work and uh came away pretty impressed.</p>
<p>>> Awesome. That and did when you started that project, did you have a sense of what the code was probably going to look like? >> Yes, I definitely Yeah, I mean like this is one of these where I in in many ways I had biased it for maximal success. I knew I had a pretty good idea of what it was going to look like. Um, but there's also some fiddly bits that people, you know, look at the uh, and I actually I'll put a a a link to the diff into the actual bug. It's like there are some fiddly bits to get right. Actually, there's a little bit of math that needs</p>
<p>to be that you need to do correctly. It's not um, but yes, I definitely knew what the code was going to look like. And this is it doesn't span multiple files. We're not introducing a new subsystem. Like this is pretty straightforward as it goes. So this is I would say in a a relatively a case that is that I really picked because it's kind of biased for success. Also picked it because we need to do it by the way. [laughter] I mean that's the other thing. It's like this is like >> this was not a yak shape. This was like you were you were doing it in four hours or you're doing it in two hours. Either way</p>
<p>>> either way it had to be done. That's exactly right. I would say the other thing is that the the 4 hours versus 2 hours ends up being really uh actionable because I started this at 10:00 at night and it was like there's a pretty big difference between going to bed at midnight and go to bed at 2 in the morning. You know what I mean? in terms of so you know sometimes like that that difference can be um so anyway it was uh pretty impressive um and gave me uh the</p>
<p><strong>[15:08]</strong></p>
<p>belief that we could actually use this in lots of other places but that is my limited experience I I want to I definitely want to so we've got two of our colleagues here um we've got we've got David and Rain here and both of you have used LLM quite a bit and have discovered I would say new vistas of of rigger. Um the I Rain, do you want to kick us off on on some of the the stuff that you uh that that you've done where you found this to be useful? >> Uh sure. Um so there's a couple of</p>
<p>different things I can talk about here. Uh one of them is kind of the first work that I did. I was around May of last year and then the other one is like the work I did around December with like reorganizing types and stuff. which one should I go with? >> Let's let's actually start chronologically because let's start as you're kind of getting into this stuff. Um >> yeah. >> Yeah. Um yeah. So I guess you know like as as you pointed out the a lot of the memes around uh you know LLM based coding are uh you know vibe coding right</p>
<p>you don't pay attention to the code you just like let yourself in the flow or whatever right um that is uh I I have to say personally speaking that is kind of uh exactly the opposite of the way I want to build software >> um and and and you know for me like I want software to kind of you aim towards correctness. I really want high degree of rigor in my software. So when I came into LLM, I came in with like a huge amount of trepidation like I was like really worried about like you know I was</p>
<p>just kind of trying it out right and and I was like okay you know I want to make sure that everything looks good and so on. So um the first use that I found that I thought you know was kind of really impactful was um so I wrote this uh we were having a bunch of issues at work around like you know how do we store u keys and values in maps and so uh I'd kind of on the side around like April or so I kind of started prototyping this u this approach uh which lets you store u which basically lets you store keys</p>
<p>and values side by side next to each other. And um I spent a few weeks, you know, kind of trying that out, right? Like and and you know, I I did a bunch of prototyping. I I did I did a bunch of work. Um and then, you know, um and then uh it was it was like an interesting experience because that was all handwritten, right? So it was like 3 weeks of like around 2,000 lines of code like carefully handwritten like there's a lot of unsafe code and um and you know it was it was like pretty challenging. But then um I I realized that one of the</p>
<p>things I needed to do was that if you define a map in Rust, there is like a lot of extra there's a lot of things you need to add to that map in order to make that like a functional API. So if you look at Rust like hashmap or B3 map or whatever, [snorts] uh there's like you</p>
<p><strong>[18:09]</strong></p>
<p>know there's a ton of different APIs that are all like some of them are syntactic sugar, some of them are more primitive. An example is like say the entry API which if you've if you use Rust maps you might be familiar with the entry API. So that's an API that lets you kind of say whether an item is occupied or not and it lets you insert an item. I I think it's a it's a beautiful design but it is a very uh verbose design >> and >> and so the map library I was writing and I'll just drop a link to it. It's called uh IDQD. Uh this map library had four different maps, right? And so one of the</p>
<p>things I was dreading was, okay, oh my god, I need to write like all of these map APIs four different types, right? >> And that is just like terrifying. So, so it's like okay, you know, you have a prototype and maybe you have like one of those types, but then you have like these, you know, three other things and for each thing you need to go in and like, you know, update the the map type and it's just like it is um it would be like a couple weeks of work at least and it would be like pretty hard for me to</p>
<p>justify that work uh as opposed to kind of, you know, just like amling along with the default maps. Then I really also wanted to get this in my in the hands of my co-workers because I actually really excited about this pattern. Um so what I ended up doing was that I ended up handwriting one of the maps and then I told uh I think back in the day it was like sonnet 4.1 or something. Right. So this was you know we were like couple couple generations before. Right. [laughter] >> Back in the day of like eight months</p>
<p>ago. >> Yeah. Right. Right. And and so I just told it to kind of replicate, you know, the same APIs across all of the other maps, right? >> Yeah. >> And it just nailed it, right? It just like um it it just like it it like, you know, it like there were like local differences to things. It kind of adapted the map types to those differences. Uh this was like I want to say a total of around 20,000 lines of code. Um then I asked it to generate doc tests and and you know like one of the</p>
<p>one of the things you should do for and if you look at say the rust core types like you will see that like every method has a dock test associated with it right and so you know I wanted to get that kind of rigor right where like every method has a doc test associated with it and I I don't know about you but like I hate writing 5,000 lines of doc tests right and I [snorts] just told the LLM to do that right I kind of you know I gave it a couple of examples to start with and I just told Sonnet 4.1 I think to do that and you know it just kind of replicated that the things it it wrote</p>
<p>like thousands of lines of doc tests and you know this work that I'd been dreading because it would be like weeks of work it took me like I want to say like less than a day to get like the whole thing ready right so it was 3 weeks of careful deep analysis and work and like thinking about unsafe and so on and then like one day of um some I was</p>
<p><strong>[21:10]</strong></p>
<p>talking to someone on blue sky about this and um I think they described it as like a pattern amplification machine where >> interesting right >> right and so so you give it a pattern and it just kind of amplifies that pattern into the rest into you know whatever like degree you want right there's like you know I I spent like the thing is that before LLMs I would have probably like I would have like investigated like a code generation library I would have like tried out macros or whatever and all of them have like some downsides uh the the kind of the LLM kind of doing things and like</p>
<p>tweaking things locally as it went along and like you know things like for a B tree map it'll say like ordered and for a hashmap it won't say that just like you know making sure that the documentation is all aligned and everything uh it was like that was my first experience and it was like a great experience where like it wasn't a oneshot but it was like I want to say like maybe like five or six prompts total and it just kind of just nailed it. And so that was my first experience. >> So a b yeah yeah a bunch of followup</p>
<p>questions. So that's really interesting. So one I mean this is I mean this is the kind of tedium that you do kind of like just like you say about the doc tests. We all know the doc tests are great as a user of something you really appreciate them >> just takes a lot it takes a lot of time to like to get that working correctly. It's really easy when you as a as a human are I mean like bluntly cutting and pasting right as when you are cutting and pasting >> it's super easy to make a mistake where it's like oh that doc test by the way</p>
<p>have you looked at the doc test like that actually you just cut and pasted you you changed it in two places but not the third and so now like what you have is kind of nonsense in the test like well that's that's not very good. um like or the test is testing the wrong thing, right? Like they're testing the wrong method or testing the wrong strct or whatever. Like it's so easy to make mistakes here. >> So easy to make that mistake. Yeah. >> Yeah. >> Um it's okay. So another question I have for you because the other thing is that when you are I mean as you say it's I've got the pattern I want you to replicate</p>
<p>it. It also makes for a code that's pretty easy for you to review. Are you like this is kind of reminds me of my experience like I I I pretty much know exactly what I'm expecting here and I'm going to be able to review this pretty quickly. Rain, one question I've gotten for you because one thing that was super surprising for me is and like look maybe hopefully I'm in a safe space here. >> Like you you I've got the the brain that I engage when I'm writing my own software and I struggle to engage that when I'm reviewing someone else's</p>
<p>software. you know, I try to and and the best reviewers, I think, are able to review code as if they themselves are writing it. And I think I I I but to me, like I really have to work on that. And I definitely know when I'm in the like, yeah, yeah, this probably works mode, my brain [laughter] >> versus the like, no, no, wait a minute, like this, like I I I need to like I'm</p>
<p><strong>[24:12]</strong></p>
<p>in like doing my checklist before takeoff and like I'm going to die in this airplane if I don't get the flaps down correctly. So I'm like and the thing that was super surprising to me is that when I was reviewing Claude's work I was in that mode of like I'm writing this myself and like very a heightened state of alert really reviewing things closely finding some subtle things that had script. Did you find the same when you when you were reviewing the code that that it had written? Um, in this case, I think so I had I have I have the same struggle that that you do, right?</p>
<p>Like where I'm like, you know, when I'm reviewing code, especially when I'm on like look on github.com. Uh, the I'm sure we all have our complaints about the GitHub, you know, [laughter] I'm sure. Right. >> Yeah. Like, oh, um, by the way, like here, let me show you all the trivial stuff. The non-trivial stuff. I don't know. That's a lot of file. That's a lot of lines to render. Let's not review that. >> Too big. Why Why bother? >> Why bother, right? Um, so I I I had a bit of the same exper I I I feel like I was kind of somewhere in between here where um I think much of this depends on</p>
<p>how or at least for me depended on how intensely you and the LLM were pairing with each other, right? So I've had experiences with an LLM like so for this for this one of an LLM, I just like, you know, it just was doing its thing and I was not paying a huge amount of attention. Uh and then I ended up like reviewing it and and you know it it like made like maybe two or three mistakes, right? Um but like also like I feel I felt like you know I was pretty assured by the fact that uh all the hard bits were kind</p>
<p>of handwritten and then you know the LLM was just like wrapping those hard bits right um so it was like it it was doing like relatively easy things. Um, there have been other things that I've used LLM uh for and especially like Opus 4.5 over the holidays and that's uh for those ones like I ended up having it like this very intense like mindmeld pairing session and like that felt like you know I knew every single line of code and what it was doing right and so I was like you know carefully kind of</p>
<p>working through things and that was like a wild time but like I felt like it depends on kind of the mode I end up using And so so you know it depends but I do you know like even like the current LLMs and and again this can change because I know I know things have advanced so quickly but even current LLMs have um they they they do get things wrong or they do things suboptimally or do they do they think did do things in a way that's unmaintainable and you do have to pay attention to that right and that is part</p>
<p>of the rigor which is like okay like I feel like I have built up some muscles around this from having used it, right? And so I think part of the rigor is also like getting some practice with like looking at LLM code and reviewing it. >> Yeah. Interesting. So the so so in this first use case >> you I've got like I've got a lot of just TDM that needs to be done. And I the thing that I think is really interesting</p>
<p><strong>[27:12]</strong></p>
<p>about about this case is you're doing something that we do a lot which is like okay I've got this problem. I kind of want to solve it in a way that's a little more generic where I where my my my colleagues can use it and so on. But we always have the tension. We always on the one hand we always encourage ourselves to hey this is a good opportunity to build a new abstraction to if you think this >> but we're also all kind of realist like yeah but like we can't like not ship the next release or what have you because we're kind of focused on you know and and there's always that balance and to take this thing that like oh this to so</p>
<p>to reduce the amount of work involved in this by a factor of four. >> Yeah. Maybe the difference between doing it and not, you know, where it's like >> just straight up, right? Yeah. Right. >> I think I I actually suspect David has a few things to say because I know David and I have some have had some chats about this, but like for me like there are like new vistas that open up and I think that's the way I think David put it, right? So there there are things that were simply not feasible to do given you know company priorities and</p>
<p>like personal life stuff going on and like all the different things right that are involved in you know a human's life that I feel like have opened up right and so for me like IDQG actually like the goal of this library was to increase the amount of rigor in our software so I think it is very cool that you know is able to kind of work on this right so this is a way you increase rigor is you build an abstraction that increases rigor even if it is tedious, right? That that is an increase in rigor, right, in the overall system. >> Totally. Yeah. So, David, I mean, you</p>
<p>you were, as Raen points out, like you were among the earliest adopters at Oxide. I think you've really shown the light for a lot of us and and you know, showing what these things can and can't do. Do you want to talk a little bit about your experience kind of getting into this? >> Uh, yeah. Yeah. Um, yeah. I I mean for a long time I think until this year really when claud code took off I was using LMS as kind of like a fancy search even before they were really well even before they were actually search engines and you know everyone was like it's not a search engine because you're getting this very lossy picture of what's in the</p>
<p>model weights even then on things that they were trained very well on which is like what I work on webdev they were great even you know just as just for retrieval so I was using them a lot for that or you know small snippets um this year I think is when it really um took off that the models could really do more complex autonomous um things based on a very small description. Um and more importantly, I think pull in like what you were talking about where when when the cloud code is looking at the Luminos code that you have on disk, >> it's pulling in context that it doesn't</p>
<p>have. And that's very different from >> you know, it's not so much, you know, the typical use case. The typical use is, you know, you ask it a one-s sentence question and there's only so much detail that you can get back out of it because there's just not enough texture in the question um to tell it what to tell you back. And so like when you know I gave that the talk about LLMs at at Oxon in September, um a lot of</p>
<p><strong>[30:15]</strong></p>
<p>what I stressed was like the the way to set up the problem for yourself is like you want to give it enough so that the answer is in some sense contained in what you give it. And what these agent tools do by just living in a in a repo and pulling in whatever context they want is like that they give themselves that that texture and context. So that's that's really what's changed um this year from the way I was using it a really long time ago. I was like I was trying to you know I wrote a CLI that lets you pass stuff on standard in and you can dump files into it. Um but you know giving the things the ability to just do that stuff on their own it makes things so much easier because you don't</p>
<p>have to you know manually select a list of files to that's worth looking at. Um, >> and so what kinds of things were were you kind of where were you first really beginning to use this to beyond just search or what have you really beginning to like okay I can actually use this to I can pair with it as Rain was saying >> yeah the early things this earlier this year were things like stubbing out like I would stub out a test this was this was before they've got good enough at to really like you know you can tell it the kind of the shape of the set of tests that you want and it'll write 50 tests before that it was more like you would</p>
<p>write the title of the test and maybe five comments saying the steps of the test and it would fill in, you know, it would still feel great because you'd be saving all this typing of the most tedious kind. Uh, you know, make this request, check this, you know, this on the response. Um, that was where it started to feel like it was really helpful. And I think I gave some some demos of that kind of thing where it's like, you know, what you want and you can tell it piece by piece and it'll fill it in and it would do a good job. This is kind of what people are talking about, you know, in examples where they it can it can follow a pattern really well. like if you give in one example,</p>
<p>you do this thing yourself once and you need to do it five more times, it can follow that pretty well. Um, but more recently, it seems like it's it's, you know, with Opus 4.5, it's been able to um figure that stuff out on its own, even without the stubbing out of all the details. Um, one example, the thing that really impressed me when Opus first came out was something quite different from from you guys' examples, cuz it was an example where I'm not an expert. It was specifically something where like it was kind of a pure test of the thing's ability because I didn't know anything</p>
<p>about what I was doing and I was still able to get to a surprisingly good result. And this was uh debugging crashes in the Ghosty terminal. So I ran into a couple of >> crashes. I've never written a line of Zigg. I don't know anything about the code the the Ghosty codebase. I've never >> looked at a crash dump to my shame as an O-ite employee. Um, [laughter] so, um, but I, you know, a few crashes that I wanted to investigate that, you know, there were things that I couldn't find anybody talking about them on the ghosty GitHub. So, I figured they were pretty rare. So, I I looked into them and I</p>
<p>just have Opus essentially figure out I, you know, the only thing I really had to do was find the rust port of Mini Dump Stackwalk to like look at the at the crash dump and um, point it at the problem and and and I knew where the crash dump was located on my disc. And then from there it basically was able to like look at the code, statically analyze it and find the source of these of I found three different bugs this way um real and then these I was able to</p>
<p><strong>[33:15]</strong></p>
<p>write up the bug reports and they were confirmed to be real bugs and and and fixed and I so that was what really unsettled me was that this was an area where I really knew nothing and just using my sort of like sense of what sounds like it makes sense to validate that I wasn't going to be posting AI slop on the ghosty GitHub um I was able to come to you know three real uh bug reports without really putting very much into the process. >> Yeah, that is wild. And so they are were they primarily operating on the stack back trace or were they stack back trace plus was it actually walking data structures and was it actually like</p>
<p>meaning? >> There was no live debugging. I think it was looking at the stack trace and then looking at the code that and you know the the error that came up and then just sort of thinking about what the what could have happened in the code to cause the error. >> Interesting. Yeah, that that is interesting. I want to be using them as de debugging tools a lot more. Um, and I'm I'm very curious about this use case. Um, so that is I and that is wild. So when you um you submitted the uh I mean this great thing about Eosti being open source um and Mitchimoto's project it's like</p>
<p>you know I mean I would just like say good on Mitchell like as obviously does not need to work for the rest of his life has made generational money and he's writing a TTY emulator. I just think that that's you know that's pretty great. I think that is every software engineer dream. Um but and then making it open source. Um what was the reception to the act? But you said these were bug these are bugs confirmed to be bugs. So it sounds like uh what it found was legit. >> Yeah. Um you know part of it was that you know the bug report itself was even</p>
<p>to some extent out of my depth. Like a couple of them I was really confident and then one of them I was like it sounds really good but I just wasn't able to you know I didn't know enough about how ghosty worked or how Zig worked to to really evaluate. So, I was nervous, but I was, you know, upfront with a lot of humility of like, I'm really not sure about this, but I but it sounds so good that I cannot hold it back. >> All right. So, let's actually talk about the first two where you're like, okay, I don't know any, but like I'm a software engineer. I' I've I know many other programming languages um where you were</p>
<p>like, okay, I'm pretty sure that I just based on the its description and me looking at this code, I'm pretty sure I got a legit bug here. Could you describe kind of those first two a little bit in terms of like what did you what I mean you you had confidence you could like I I can actually not knowing very much zig or knowing only the zig I've learned I think I've got a legit bug here. >> Yeah. One of them was very simple because it was like a copy paste error where they were just referring to the wrong variable and you could tell >> uh you know it was supposed to be</p>
<p>graphing bytes and it was hyperlink bytes you know and and you could tell that that was uh so it was like okay that sounds pretty pretty straightforward. Um, another one, this was like two months ago, so I can't >> Yeah. Yeah. I'm so sorry. The two months ago being several eons ago, especially in in >> the really complicated one was that, you know, something was it was a mutex uh lock that was like not being taken at the right time. And so there was like a conflict >> in um and and so you know, reasoning</p>
<p><strong>[36:17]</strong></p>
<p>about that was pretty tough for me not understanding how the code worked. Um so but it was pretty impressive that the the model was able to see it, you know, like this is where you should have taken a log and you didn't. >> Yeah. Okay. So, another thing that I think is really interesting is the And then so Mitchell himself replied to uh on you you've linked all the issues in the chat. Um so obviously people can go get those. Um, I think one of the things that I really like about this, David, is that like you lead off by saying like, look, this is I've been using cloud code with Opus45 to investigate. You're very upfront with, hey, I this an LLM has</p>
<p>done the work here as a way of like saying I'm not I like someone is else is going to need to look at this who's got greater domain expertise. Um, which I think is worth >> Yeah, >> it's worth looking at. In GOCI specifically, they have a very they have a quite clear LLM disclosure policy. So Mitchell has been pretty open that he uses LLM's uh tooling, but he also has they really want upfront disclosure. >> Um >> yeah, >> so they made it easy by telling me exactly uh what to do. >> I was more worried about sort of the the embarrassment if my issue was fake for</p>
<p>me to be like one of those guys posting issues that are fake uh that the LM told them, you know, was a bug. >> Yeah. Well, and the um but you know, you you obviously quadruple checked all this stuff and it looks like you had So all right. So, so this experience, as you said, was I mean, I like the the way you say it was like unsettling. Um, when you describe it as unsettling, why why was it unsettling? >> Yeah. Well, I thought this was such a clear-cut case where it was obviously not my expertise that was operative here >> because I didn't have any,</p>
<p>>> you know, I had like there was some highlevel like I could tell that it it felt legitimate. Um, and there I think there may have been one or two things where it came up with something that that I that I was like that doesn't sound real, but you know, the amount of guidance that I actually provided in the process was was a very small proportion of of what actually took place. That was what I think felt um unsettling about it. And you know, the the guidance that I did provide also didn't feel, you know, that ineffable human taste that that people love to attribute to themselves. It really wasn't that. It</p>
<p>was like finding [snorts] the the rust port of the of the stack trace, you know. symbolic or whatever. >> Right. Right. But I do love the fact you're like I'm actually even a little bit embarrassed. You say in your this these issues that you're like I'm I uh but it's also like what am I what else I supposed to do? Like this thing crashed. Like I I am I just supposed to like not give someone the feedback that this thing has crashed and I've got like or am I supposed to just like sling an issue in there with I mean it's like it just feels like you're being actually</p>
<p>helpful to the project. Um, >> right. Well, if it had turned out to be fake, I wouldn't have been. >> I [laughter] guess if my diagnosis was wrong, then that was just creating work for them. Um, so it hinges uh pretty tightly on on the fact that they were legit. >> Yeah. Yeah. And that it's it was okay. So I think it goes to and you know we've we've talked a bit about RD536 where we kind of talk about our own LLM thinking</p>
<p><strong>[39:17]</strong></p>
<p>at oxide and it just goes to that like having empathy for the the person that's going to read this and the the making sure that and in this case really contextualizing it but also like it sounds like you're you're doing your own checking to make sure that the degree that you can. So um yeah, >> you know it's interesting a lot of these uh sort of attributes or these qualities that we attribute to LL generated code are all things that as we're talking about like I've associated with other colleagues I I just I'll I'll provide an</p>
<p>example. I just mean when you're doing a code review, Brian, I think my guess is like the degree of scrutiny that you feel yourself applying may change depending on where that code came from. Like it certainly does for me and not so much at oxide but like when I was at Sun there were sometimes I' get a code review I'm like I really need to imagine what I would been been like to write this so that I know what I'm looking for. In other cases you're like well there's some code and there's some tests and I'll I'll look around. But um you know a lot of the thinking has probably</p>
<p>already been done. Well, you know, on that like for my You're exactly right. And like I mean, oh, look, I'm just ashamed to say it, but I'm going to say it. like the the way I would review code from like a nemesis, you know, a nemesis integrates code and you're like, I am going to I'm going to get my ne and I'm like one of the things I realized I needed to do was for my own self-re and for reviewing people that were not my nemesis. I needed to like channel that dark part of my brain that's like I'm gonna I I I'm gonna find the this thing in here. And that's like I mean it's</p>
<p>embarrassing to say, but it's definitely true. >> Yeah. Well, I I do that because uh for you know when I'm reviewing someone who I consider a friend and I want to do them the service of helping them with their code, but I guess we're just motivated differently and that's fine. >> Yeah. Okay. Okay. Are you It feels like you're just trying to explain away a whole bunch of code review comments. Very good code review comments you give I mean feels like comments you'd give a nemesis, but that's right. Okay. >> Uh one man's nemesis, another man's friend. Um >> there you go. >> Oh. Uh but and then you know David as you're as you're describing you know like you don't want to file a crap bug</p>
<p>report like man have I seen some crap bug reports where you know people take you on this wild ride through a core file and you end up just nowhere. You're like I okay I'm following but like all of this is just blather. Like you don't need an LLM to hallucinate. Like we've been doing that. [laughter] >> Yeah. >> Uh and we've seen these bug reports where you're like okay like you have there's certainly a lot of information here but you've actually not contributed. Uh so that same that empathy you're talking about is is so at</p>
<p>the core of of of engineering full stop irrespective of the tools we're using. >> Yeah. No that's a [snorts] very good point. >> It is really infuriating to see like a a bad you know AI bug report. I'm probably more optimistic than most people about LLMs and I think part of that is just like working at Oxide and I don't really see anybody doing the pathological</p>
<p><strong>[42:18]</strong></p>
<p>things that I that we hear about online. You know, everybody's so um careful and serious at Oxide. So, I wonder I worry that I'm biased um toward optimism because I'm not seeing the like the median user of these tools. Um but then, you know, I see one example. I get one bug report on a on a repo that I'm actually familiar with. I'm like, forget it. Throw these out. We're done. >> Yeah. Yeah, but I but to Adam's point, like I don't like that when you get bogus bug reports without LLMs either. I mean, when you get or you get like bogus PRs. >> Yeah, but it's harder to write off all of humanity. Like you can write you can</p>
<p>write off >> I guess that's true. I guess that's just >> it's more it's more limiting if you >> Yeah. >> Yeah. Absolutely. Because but I do think that you know you get people like and we've definitely had this happen where we will make things that are that we are open sourcing not making a big deal out of it. We're not trying to create a community out of it. we're just open sourcing it kind of hygienically and then someone will come along with a kind of like spirious PR to change things like no [laughter] sorry no this is like not LLM assistant this is in the prelim age like no no this is sorry this is</p>
<p>actually not helpful so Adam just to your point that like the the lack of empathy is uh is is definitely drive by PRing is not new as as someone was pointing out in the chat um >> I think the difference though is that you know like LLMs will like do amplify that problem, right? Like you know, you can kind of get I was talking about this with someone like you can get something that is not great by in like a few minutes as opposed to maybe a few hours. >> You're you're so spot on and I I think</p>
<p>we my experience has been like a [clears throat] unproductive uh like not empathetic uh colleague like that's fine. like if I I can run faster than you, I can keep up. Like I'm gonna like you're not gonna outrun me. I don't need to like worry about kind of diverting you in the wrong places. A highly productive, unempathetic, uh careless colleague, like that's takes way take 150% of my effort just to like keep them from doing harm. And you're</p>
<p>right, Rain, that like it takes that formerly plotting uh you know, colleague who you had or or or collaborator who you had to like keep on the rails, it keeps makes it much harder to steer them. >> Yep. Yep. Um it's like a gish gallop almost like I feel like that's that's how I think about it, right? Where it's like a gish gallop for issues. Um I've luckily not faced um too many like crap bug reports. I've seen some AI bug reports, but they've all been like very high quality. So, you know, kind of at the standard that like I think I would</p>
<p>expect myself to write a bug report. So, again, like I am biased towards optimism here, but it is something I'm worried about. Like I do look at people just, you know, putting up garbage and it's like, okay, well, uh, it's it's now harder to filter out garbage or, you know, I have to say on the flip side, a thing I've done is I've used Opus 4.5 and fed it a bug report and told it to</p>
<p><strong>[45:20]</strong></p>
<p>tell me whether this bug report is real or not. Um, so I um, yeah, so that's that's you know, maybe that's the way to keep up. It's just like all them >> stuff. It's like some open-source Jeffans paradox or whatever. Like there's no money involved here, but I just mean the the cost of creating PRs and projects and all of these things has dropped so much that the volume has just accelerated. Well, I think I also do think that with these open source projects, especially I mean, you know, God bless small communities where you've got I mean, it's like I I mean I I would be almost like intrigued by someone</p>
<p>who's like I'm going to use an LLM to file a bunch of bugs against Alumos. You're like that's weird. I mean that's like that's not a versus like >> talk to someone about that. Yeah. [laughter] >> Talk to someone Yeah. I mean like I'm almost like I'm almost like not opposed. That's a that's a very Okay. Um versus like a project. I mean and certainly we saw this with node where you know I've been in very very large projects with many many many contributors and very small projects and there's a lot to be said about being in a small project uh and a lot to be said about a project</p>
<p>that doesn't attract as much attention because it doesn't attract as much of that kind of negative attention either. Uh so there's uh there I I think this problem is I'm sure there are uh there there are some high-profile repos for whom this problem is really really acute and you know maybe that was that way with with Ghosty and Mitchell but for a lot of the stuff at least I work in it's it's not really an acute problem. >> Yeah I've been surprised that the tooling for maintainers hasn't been able to keep up. I mean, you expect some lag, right? There's the you the volume of of</p>
<p>garbage has to balloon for a bit before it becomes such a big problem that people are incentivized to put some work into solving it. But, um, I think one of the things we're going to see in the next few months is maintainers more openly using LLM tooling to like cut through that uh, morass of of of AI bug reports and uh, AI >> and for and for code review too. I mean I think just like it is the code review is I mean honestly like my eye opening moment with respect to loss and software engineering was on oxide and friends</p>
<p>when we had a listener who had access to GPT4 when I did not have it and I Adam for some reason I can't even remember and you know this you have to figure out exactly when this was I guess it's a little hard to ring the chime for an episode that I can't I can't recall more more just ring it exactly give the people on YouTube something to complain Um, but we um, and I'll go back and find the episode, but the thing that was really interesting is I had had like a PR that day that I was I linked to and someone dropped in a GBT4 code review of</p>
<p>that PR and I'm like, wow, this is not all wrong. Like this is not also not great, but this is definitely not like garbage the the comments that it has. And that was a long time ago with respect to LLMs. Um, and I I mean code review it just feels like the opportunity for code review is really rich and Dave to your point of like not</p>
<p><strong>[48:21]</strong></p>
<p>really giving like why don't maintainers not have uh you would you would and maybe they do and I'm missing it about like it just doesn't feel like GitHub is providing it anyway. Why am I doing this? Of course too large to show. >> Yeah, you definitely expect it to be built into GitHub pretty soon. I mean there are tools like Graphite, Code Rabbit. I mean that that's kind of what started me on this. saw someone, you know, praising this this tool, Graphite, which does look really nice, um, online, and it's like 20 bucks a month a seat. I was like, wait, 20 bucks a month a seat? I can write that in a script. So, it's like, so I wrote a script that pulls the diff, the comments, um, the PR body, um,</p>
<p>and just feeds that into an LM just says, review this. And, you know, you you have downsides there where you're, you know, a lot of times there's additional context that's not in the diff. Like, if you're using something that is imported in the code already, the import is not in the diff. So, it's going to say, "Are you sure you're importing this?" It doesn't know that the test passed. Doesn't know the CI passes. Um, but you can get quite a lot that way. You know, it can find, you know, a mismatch between your SQL migration and your um main DBNIT SQL. I can find inconsistencies really well and</p>
<p>inconsistency even between like your human readable stuff like your PR description and the actual code. Um, there's a lot you can do there. um even without what we now have which is like the tools that can go and vacuum up anything that they need to and to to um validate their hypothesis about why the PR is broken with cloud code it can write a new test that validates that the code as written doesn't do something um you said and there's a lot of lowhanging fruit there that we're not we're not really touching at all >> on the topic of low hanging fruit I</p>
<p>think my nemesis on GitHub is stalebot right like I I hit some real bug [laughter] Oh, Stalebot. I >> I feel like LLMs could slay Stalebot. You know, the like, well, this bug is 6 weeks old, so I guess nobody really has it or whatever. It's like, nope, there's a crash dump and a and a stack trace and a bunch of information. >> Yes. and at least helping to weed through that so that you could sort of deter maybe neuter stalebot a little bit or or make sure you keep around the</p>
<p>things that like refer to real problems with sufficient data to diagnose them or maybe diagnose them autonomously but um you know a lot of the work that you know I think there's a theme here but a lot of work that just doesn't get done that could get done uh and in some cases maybe doesn't need the highest level of sophistication to complete complete. You know, those are great tasks. >> God, Adam, you are so right. And and God, I hate Stalebot with [laughter] the white hot passion of 10,000 sons. I Stalebot is such an indictment. Uh I</p>
<p>mean like we don't talk about Stalebot enough. We don't we like for all of you decrying the future, look into the past. Stalebot is I mean Stalebot is everything wrong because I mean it is just like oh well no one has seen this issue in six weeks so we're closing it. You're like how does what how does that</p>
<p><strong>[51:21]</strong></p>
<p>make sense? That doesn't make sense. >> That comes from Facebook by the way. I know Facebook had an internal scale bot and then someone built an external version and and I mean it's the Facebook culture like it was exactly the kind of thing that you would expect Facebook to make and so you know >> move fast and leave broken things around. >> Yeah. >> Move fast and close out bugs that haven't had any activity in the last 48 hours. Okay then. Yeah. [laughter] But it is also so gross because like but no no I made look I made the dashboard green. It's like [groaning] >> um</p>
<p>>> so Adam, you are right. I hadn't even thought about what this means for Stalebot. I Stalebot, you are a marked bot. I I hope loss because that's a it's a great point of just like if nothing else. I'm sorry if like if we get rid of Stalebot, it was worth it all. I I got to say, >> I mean, you're going to be up till like 4 in the morning vibe coding like the Joker of of Stalebot, >> you know? just trail snailbot around like reopening and fixing bugs that it's trying to close. [laughter] >> I actually have an example of of a bug</p>
<p>that I feel like I would have just ignored um in the past but had a much better time with Opus 4.5. And so uh this is a bug on you know on cargo next test which is a personal project and and the bug is titled sig ttoou when test spawns interactive shell. Now, if if you've spent any time in this stuff, you're like eyes my eyes glazed over pretty much, right? And so, it's like, okay, you know, this person actually uh did a nice investigation with Claude um and kind of posted this and said that um</p>
<p>they I've worked with Claude to get good attribution for this and reproduction. It wrote words below, but I stand behind them, right? And so it was like a pretty well-written issue, but you know, it's the sort of thing that I really would want to dive in to like, you know, it kind of gave an example of like, you know, this is used by all these other projects and so you should do this thing as well. And it is like it is one of those um you know things where like okay, you got to spend like a whole day like investigating what the other</p>
<p>projects do and how it fits and like you know really getting to the root of the problem, right? And I I'm like pretty lazy generally and I'm like I don't want to do that. And so you know I'm like I would either do a halfass thing and honestly in the past I would just do what you know what the suggested fix was right. Uh it turns out that the suggested fix is actually like woefully incomplete which is you know which is where like I feel like you know I I kind of gave this to Opus4.5 and so you know one of the things it said is that like less and vim and a few other projects follow this pattern right so I actually</p>
<p>gave it the less source code and I gave it the Vim source code and I gave it the source code to like a bunch of other things and I was like okay like dig into this like what do these projects do and so this kind of comes back to the you know asking questions of code bases you're unfamiliar with And so, you know, I did that, right? I had no idea about the less codebase. I had no idea about the Vim code base or anything. And so,</p>
<p><strong>[54:21]</strong></p>
<p>it spent like 10 minutes or so and it actually like, you know, wrote up a nice summary of like here's what all the projects do and so on, right? And then I, you know, I kind of, you know, I was like, okay, you know, this makes sense. And then, you know, I tried that. And, uh, and so, you know, it was like an interesting, like, it took me like maybe two or three hours to do. And the final fix for that was like pretty small. It was like 130 lines of code or so. But like it was great because like you know we we tried the first thing right. We tried the suggested fix. I you know the LLM did the work and the LLM kind of you</p>
<p>know wrote the test which is its own annoying and janky in its own way. Um and then you know I kind of tried that. Um I I like dog fooded it a bit. I found that okay this isn't complete in various ways and then you know we iterate a few times and so there are so many places along this path where prelims I would have just dropped out and being like ah this sucks I don't want to deal with this you know I'm done for the day or something right >> well and and totally like when you do that like you're going to kind of take one of two things it's going to be like</p>
<p>h we'll just take this kind of like mediocre fix >> or it's going to be the like h maybe I'll just let Stalebot finish this one off maybe I'll >> [laughter] >> Exactly. Right. >> Right. I don't have to kill it. I'll just But I mean, even this title reign like sig tou. Okay, fine. Ty [laughter] out. >> Well, no. You got to like the cue like antiques road show. You got to be like, okay, like I'm now going to go into like pix signal semantics from I mean, >> well, and and then you're like, when test spawns interactive shell, it's like, well, here's a thought. Don't do</p>
<p>that. >> Don't do that. Don't [laughter] do that. I mean, yeah. No, seriously. >> [laughter] >> Yeah. But but the Yeah, it makes it attainable and you're makes makes you get past the like, have you tried not doing that? I don't know. That sounds like a dumb test. >> Yeah. >> Okay. And so but and then this the thing and I do think like this is a really important point because then Okay. So you you pick this up now properly because it's easier. We've lowered the the friction. You actually get this completely fixed. >> Getting this fixed makes next test more robust. It makes it more rigor. like</p>
<p>you've actually like I mean on the one hand it's like okay really I mean as you say Adam like maybe don't spot in action but like hey actually no now you can though you know what I mean and I think that like I just see this in lots and lots of places where we are going to make our infrastructure actually more robust because we can now go pick up a bunch of work that we just weren't going to get to realistically we the people who work on this lower level infrastructure we're just not going to get to >> yeah so I have an example of some some work that I got to finally. Um I I I</p>
<p>mean Rain described herself as lazy. Rain, I offer this counter like I like I think you're kind of bringing a knife to a gunfight here. >> Um but uh [laughter] out lazy Adam, will you? >> Yeah. Cuz And you know this like I have been wanting to do an open API diff</p>
<p><strong>[57:22]</strong></p>
<p>library since before you joined. I'm sure I've been like talking up this vaporware of like >> and and I I made multiple earnest attempts at starting it >> and it was just it's just one of these pieces of code that's like there's no good way to do it. All the ways to do it are gross and boring and stupid and actually it doesn't even it this is not like your kstat code running in privilege mode or whatever. This is some code that like if it segies like if it reboots the machine somehow like it's fine [laughter] like I don't know like</p>
<p>it's just not that high stakes very low stakes. Um >> yeah, >> and the thing that got me across the line was uh you know I started using uh some of the open API open API uh excuse me open AI models in uh VS Code and mostly using it just through the lens of uh of very smart completion and it allowed me to kind of repeat this pattern and that that I was that I wanted to use to make sure I wasn't forgetting to compare certain things. Uh and as Rain was saying, absent this, I would have like written some code to</p>
<p>write code. I would have, you know, written some Earl script or something stupid to output a bunch of code or or use a procer or something like that. But my my real so that was great and I actually got the thing working uh and it was really fun to build. My real breakthrough was then it was coming to demo day and I wanted to show it off and this is a library so there's not like a front end to this thing. So I was like, okay, I'll write a little CI tool. And literally all I wrote was function main open a comment said parse the first two</p>
<p>command line arguments and literally the rest of the program I just had tab completed. It's like I think this is it figured out this is probably the program you want to write. I had to fix a couple little things here and there but uh it was very eye opening. Uh, and and then that became my demo in addition to the actual library I built, but was like the the live coding, the live I guess coding of just hitting tab and watching it do the thing that it inferred I wanted to do. >> So I would argue, Adam, that you have embodied all three of Larry Wall's</p>
<p>famous virtues of a [snorts] programmer that your you've shown your laziness, your impatience, and your hubris in a stroke. Um the but I actually but this point of laziness is really important because we all know and we we kind of speak of euphemistically as laziness. But we all know that like a hallmark of of good software engineering is coming up with powerful abstractions. And when you are kind of repeating code multiple times that part of your brain is like h</p>
<p>this is not the right abstraction. And because Adam, both you and Rain mentioned like, ah, I would have made this a proc macro or I would have done something. >> Yeah. where because like I I think we like overindex on that where we're like then this this whole like the dry thing the do not repeat yourself where you become so overindexed on it that you then do things that are actually either</p>
<p><strong>[60:23]</strong></p>
<p>generating suboptimal artifacts or it's like there are times where it's just like actually it's just not that big of a deal to have code that is like similar but slightly different in three places like it's okay we're all going to live but we really resist doing that and LM's make it easier to kind of do that. >> One of the thing that annoys me the most and you know I'm very very grateful to the Rust open source community right and and this is just to qualify that this is nothing it's [laughter] not meant to be negative at all right the open source community but one of the things that really annoys me is like you know in like the Rust talk you click on the</p>
<p>source link right and the source link leads you to like a macro definition >> yeah you see that for like um even for like the in the standard library there's a few examples with like the integer types So you cannot click like for example you want to see like the next power of two implementation which is like I mean you know it's a bit manipulation thing I want to look at that right you click on it and it doesn't show you that and it's like really sucks and I hate it. Um, so I kind of have made it a point in my libraries that I would much rather copy paste code just so that you can click through the source link and you can get</p>
<p>it right and so you know and so macros are just like you know they don't work with that and but the DR the don't repeat yourself is to use a macro. So it's like okay well LMS actually do provide a of a better solution to that. M >> I've been thinking a lot about this because like if you think about where our intuitions come from about what is worth abstracting or like what is too much repetition they're so tied up with the expected reader of the code whether that's like ourselves or the people that</p>
<p>we know like they're they're they're tied in very very tightly with our intuitions about what people can handle and what's reasonable to expect of other people and what is reasonable to expect of an LLM is radically different from what is reasonable to expect of other people. Um, and so like the amount of repetition that that is tolerable in a codebase or is manageable is is seems to me like what may way higher and it's not just in a codebase like we were thinking about um API design API response shapes earlier and we uh with I was working with Adam on this that we we aired on</p>
<p>the side of making a response shape like more flat and less nested even though we lost a little bit of type information that way just because the flat one was a little easier to read and the type information we decided was not really worth it keeping in that particular case. But I think when you assume that future developers will have LMS at their disposal, I think that it must tilt the calculus toward encoding more type information at the expense of readability because that type information is what is going to keep LMS on the rails um in the future.</p>
<p>>> It's like you know all the good practices like make invalid states unrepresentful and all of those things. Um it turns out that all of that actually helps LMS a lot too. So cool. >> Yeah. Is there anything like does is do Rust do LLMs like Rust? I know that's a weird kind of question, but I I I've wondered that if the the the things that we appreciate about it in terms of like</p>
<p><strong>[63:24]</strong></p>
<p>not being able to like represent invalid states and so forth, uh if that is a useful property when LLMs are constructing code. >> Yeah, I I 100%. I mean, I feel we said this when we again ringing the chime for unknown episode, but I feel we we said this when we first started talking about LLMs and Rust that like actually Rust is going to be a really good fit for these things because you get the it mean Rust I something I've said from the beginning that Rust shifts the cognitive load to the developer in development and it</p>
<p>forces the developer in development to consider a lot of issues that historically you wouldn't see until some code is deployed into production. And I loved that shift. I think that shift is really important. I think that like that tacks right into what LLM can do. And I think that it's that it they reinforce one another. So I think like I LLMs I think are and Rust are a very good fit for one another. It's what which I don't think is that hot to take. I don't think that that that's that spicy. and just say like more, you know, if a more elaborate type system lets lets you</p>
<p>put more of that work in upfront to sort of constrain the program further. You could say that LM's like allow you to tolerate an even more elaborate type type system like maybe now dependent types are going to be uh feasible to for people to learn and and work with. Maybe you don't see interest like you know take like if there's a diesel uh error like you'll be able to understand what it means. >> Easy easy. Like listen, we're not living in that kind of a future yet pal. That's [laughter] >> Yeah.</p>
<p>>> Um >> artificial super intelligence required for that. >> No, I think the ASI is going to be like I I've actually I actually don't know what this message I can't make sense of this thing. >> Um it's like it's like 2K log. Um yeah, that that is really interesting when I just think just in general having the um great type information. I mean the the code that I would be scar that to me would scare me the most would be just like pure JavaScript. I know it generates a lot of it but we use TypeScript. I mean Dave correct me if I'm wrong. We we use TypeScript for more</p>
<p>or less anything everything. It would really terrify me to use because it's just so easy to have a an issue that doesn't show up until you get into runtime. So my blog is uh uses a static site generator written in JavaScript and I and I don't really know JavaScript. I mean like I I know I could hum a few bars but but that's kind of it. Uh and I used LLMs a lot to sort of get things the way I wanted them. And part of it is like I don't give a [__] right? Like it's a static site generator. Sure.</p>
<p>>> It's gonna it's going to generate it statically and there isn't some like runtime edge condition I need to consider. So it's like eh go for it. Uh so I just be in in some cases like it's going to you know depending on the context you know I think that uh and I think that may be true in many JavaScript contexts and that's why in the cases where people are writing</p>
<p><strong>[66:24]</strong></p>
<p>front-end code and they have additional rigor they want to apply they're using TypeScript or more robust languages. Yeah. >> Yeah. >> Yeah. Just to defend the JavaScript world a little bit, I I think it's the spectrum of um you know rigor that you might need it applies in a lot of different situations. Like you might make a one-off rust CLI as a debugging tool in that same situation like you can tell if it works by running it. You know the sort of the depth of static analysis you you don't really need that because you run the thing and it does what you want and you can tell that it worked you know. So there there's a lot of situations I think that's kind of an</p>
<p>underrated um point that you know people assume it's all or nothing that the code needs to be perfect or or it doesn't work at all which is like ridiculous. You know our most rigorously engineered code is still going to have some bugs in it. So obviously there's sort of a spectrum of of amount of um bugs that we can tolerate or amount you know of leeway that we have. >> Yeah. >> Yeah. That's fair. Um, Ren, do you want to talk about some of your more recent experiments with LLMs? you've really kind of gone nonlinear with some of the the things that you've been and I think [laughter] in</p>
<p>particular well because like I mean getting past the like okay these things are kind of experimental and getting into the like no no like actually we're going to at some level we're going to I mean I I I I don't want to say assume them because we're not really assuming them but we're um but we we kind of acknowledge that like these things can actually um it can be used as part of software engineering. What do you want to describe some of the things that you've done recently? Yeah. So, um this is kind of a project that I, you know, kind of a bunch of us were discussing</p>
<p>and uh I decided to take on sometime around early December. And and so the project here is that you know we um as as uh some of I'm sure some listeners may have heard of like we have done a lot of work in building automated update for our system, right? So we have you know the self-service update uh thing now. Um, and one of the things it has to cope with is the fact that, you know, you're not going to be able to update everything atomically, right? You're not taking the entire system down and back up again. And so you need to deal with</p>
<p>um you you need to deal with like how do you or kind of you know like manage this and like this kind of skew while an update is happening. So you know uh like my colleague uh Dave Pacho kind of has done this like genuinely brilliant uh design where like you know there's kind of the server side APIs which is the idea is that this is an API that can talk to multiple versions of clients and so you know you update the server first and you have like this DAG of</p>
<p>dependencies that you update. It's just like this you know really well constructed system. It's pretty great right. Um so one of the issues we ran into is that as we gained experience with the system we were having trouble figuring out how like you know you have all these different versions and so you have like a type right and that type and like has the same name but it has different like fields for example or</p>
<p><strong>[69:24]</strong></p>
<p>like you know maybe maybe one of the sub fields is different and so um how do you actually like store those in the repo right like and and it sounds like a simple problem, but this actually blows up and becomes like this incredibly complicated problem with many many many uh different uh factors involved. So um you know kind of I I did again like this is one of those things where it's like this combination of human and LLM work where like I kind of you know I I I spent a bunch of time um you know prototyping a bunch of things</p>
<p>and like you know kind of coming up with a with with like you know an approach that works and that uh satisfies all of the hard constraints and like also as many of the soft constraints as we can and and so you know this was like a lot of work and then um one of The one of the interesting things that I found really useful for LMS is that what I did was I ended up essentially like compiling the set of things that you know the final state we want to get to and like writing it out as a set of</p>
<p>instructions that both a human and an LLM can follow. And so in this guide uh that I uh dropped a link to uh this is RFD619. And in this guide it is in section um 5.1. And so this 5.1 is kind of this initial migration, right? And so again like you know spent like a couple weeks working on this on on like this whole RFT. And then what I did was like okay you know I'm like I just kind of fed this guide into the LLM and you know</p>
<p>I told it to like migrate a small repo right one of the one of our smaller APIs and it just did that in one shot. So this was like you know not a very big API. It just did that right. I found that okay there were a few things I was unsatisfied but so I went back and like changed the guide. I updated the guide. I kind of started from scratch. So, you know, I I like iterated on it. I want to say like overall like this guide kind of went through maybe a couple dozen iterations of like me looking at the LLM output and being like, okay, you know,</p>
<p>this this is great or this is not good and so on and and you know, kind of basically ended up converging on something that is like this clearer very reproducible set of instructions that are simply way too complicated to capture in any deterministic algorithm. Right? So this is like you know the the the there's like enough judgment here and it's just like this really complicated set of things that I mean you know there is no way I can write like a migration tool to do this. I mean may maybe someone smarter than me could</p>
<p>do that. I I don't think I can. But what what the let me do is it kind of again like let me like design this guide once and then you know apply it like everywhere. So, it was funny because like there was one morning where I just like rapidly put up three PRs where like, you know, the first one was like a thousand lines of code, the second one was 2,000 lines of code, and the third one was 3,000 lines of code. And I got</p>
<p><strong>[72:26]</strong></p>
<p>like all three of those done in like an hour. And that was just wild. like you know and this is like one of those things where like it turns out that LLMs are really really good at um following instructions that are like you know clearly written and are written in a way that you know the LLM kind of works well with so I don't like this is again one of those things where like it sounds like so like you know mid- priority right it's like how are we going to you know migrate like 40,000 lines of code and like rearrange the types right this</p>
<p>is the kind of thing that just falls, you know, people just don't do or like we might do it in the future and there's this long migration period or like you know this is the kind of thing that you do in like tech week but this would be more tech month right >> um but like you know and LM just like as I said just nailed three different APIs in like one hour and that was just like it just blew my mind is like oh you can you can spend two weeks carefully designing a thing and then just have the LLM just like repeat that pattern over and over again. Uh it was also really</p>
<p>helpful for like the process of iterating on the guide itself because like I would just like you know it's like if there's something I'm not satisfied with or like you know maybe maybe one of our co-workers had some feedback on something you know I could like very quickly like update the guide right and then I would be like okay run like JJ diff on you know the changes that I made and like replicate those changes into you know this like prototype that we're working on and it just like did that and it was amazing like it was one of those like, wow, you just you could just you could just do</p>
<p>that. >> Something people have mentioned in the chat and we haven't talked about too much is that, you know, something that really helps the LMS in these kinds of loops is they have a signal like a verification signal that can tell them when when they're done and how far away they are from it and like types passing. Obviously, test passing is one of those things. But I'm I'm curious like how how you think of what the verification signal is to the LLM as it's doing this. Like is it just does it satisfy these plain these um you know natural language requirements. >> Yeah. So, uh, so this is, uh, yeah, this</p>
<p>this is an interesting question, right? So, in this case, you know, uh, we kind of had like a couple of hard verification signals. So, so the first one was just that, you know, what what you described, which is like, you know, like the code compiles, right? That that is kind of the most fundamental requirement. And then um the test pass and we have a lot of deterministic validation. In fact, a bunch of this actually uses uh the work Adam was describing on like comparing being able to compare open API documents to make sure that um if there are changes, those changes are only trivial ones. And so,</p>
<p>you know, we put a lot of work into that. Um and so having all the deterministic validation was really helpful. Um what I ended up doing for for you know some of the more like the fuzzier signals here was that I basically kind of you know after it kind of did this work I would like start a new context window I would feed the guide again and I would ask it to carefully review the um you know the the</p>
<p><strong>[75:27]</strong></p>
<p>the current performance with the guide right >> and CL's like who the hell wrote this this is like [laughter] I >> yeah interesting >> and and so that ended up finding you know a bunch of degrees of freedom which some of which I wanted and some of which I didn't but that was like that was a good experience. I would just do that like two or three times and and then you know obviously I would go through and manually review and make sure that you know everything kind of aligned. Um but again like that felt like a very quick process because you know I was just I was just able to like you know maybe like spend five minutes doing the</p>
<p>migration and then another five minutes reviewing it and that was it. Right. It's wild. >> And I mean, this is kind of a just a much more elaborate example of really your the the IDQD example that you had where like, look, I've done this once. I need you to kind of do it in these subtly different but important ways that are kind of tedious. I mean this is just a a in many ways a much more elaborate version of that where it's like okay this is the the we</p>
<p>designed this RFD very deliberately with and a lot of engineering has gone into like the way we think about doing this and we have that has come out from actually like doing it by hand and so on for a and now we actually need to like kind of knock this out for a bunch of these different services. Y um someone in chat described it as like using English as a programming language and yeah I mean that this is basically like you know using English as a um programming language for programs that</p>
<p>are just too hard to write in a deterministic like computer language and and that's what it felt like doing. Um, and and I think it's actually, you know, it's it's kind of remarkable like these are the kinds of things that you would absolutely have humans do before, you know, before before the advent of this stuff. And like it >> or I mean like like I mean just to your point, it's like the work that is like it's just the the work is just like not done. And you have been like someone's like, "Hey, I was in this service and it</p>
<p>has a different like what's going on over here." It's like, "Oh, we just haven't gotten to that one yet." and go into our this dashboard from two years ago and we're waiting for the next you know tech you I mean tech debt week it's like oh my god I can I I can feel like my the tech debt flu coming on for tech debt week so you know [laughter] >> I mean and like and for me like you know I think there's a there's a way David put it that was really memorable like a code like that uses like LMS extensively had better be the best freaking code on</p>
<p>the planet right like if you're if you're doing this like you like all your like code should be extremely tight. You know, you should like your your you should like put all the work into refactoring like good documentation like all of these things that I think you know many of us feel like are are um you know maybe maybe kind of slip down our priority list there. It is very helpful to think of these tools as not ways to improve the velocity of what you do but</p>
<p><strong>[78:28]</strong></p>
<p>ways to improve the quality of what you do. Um, and so I'm like, you know, if there's one thing that I think I want people to take away, it is like slow down, right? Like don't just like, you know, spit out as much code as possible. Instead, like use the LLM, right? Which is a tool there to be like, okay, you know, maybe let's refactor this. Maybe let's, you know, split this up. Like there's so many things you can do to improve code quality along the way that will lead you to higher code quality than you would be able to do in the same amount of time. Rain, I I just cannot emphasize enough how important it is</p>
<p>that if you're if you're listening to this as a podcast where you like, please go back and relisten to what Rain just said because I think this is so important and I think it is so important to realize that you've got this power now to go deliver a higher quality artifact. like yes the world emphasizes like the the the velocity which a term that I again don't like because it makes us all sound like projectiles but the [laughter] um this is what what it allows us to do is</p>
<p>do things that we simply never would have gotten to before that allow for more rigorous artifacts and I think that you can make an argument that that the world that the software rewrite is going to kind of bifurcate Adam some of it is going to be your JavaScript in your static site generator which which to quote your own language back to you you quote do not give a [__] about. Am I am I stating that correctly? >> I stand by that. >> Uh and but then in order for like underneath that is now these rigorous</p>
<p>artifacts that we actually in a world where we're doing much more software, we actually need these rigorous artifacts to actually work much better. And >> you know, I I think that like because Adam, I mean, I and I this is like with the and I I for um this is like the Fossil Time, Gen X Fossil Time where I maybe we can knock down some things on people's bingo cards, but when you talk about like software in the '90s sucked and operating systems had bugs that you would hit frequently, compilers had bugs that you would hit frequently. And the I</p>
<p>mean what ultimately like the day I put C++ down is cuz I was dealing with two different compiler bugs simultaneously and just like the and getting basically random results. I was just and that was common in the '90s and man like go like comp go have a compiler bug to really like take the wind out of your sales let alone two of them. We and we needed to get to a world where we had open source artifacts that we could make much higher quality and the quality of software went</p>
<p>way way way up. As a result, we could do more of it and I man I boy do I see that happening vividly here. >> Yeah. No, I think I think you're right that uh you know the reason why I don't care about the quality of my blog is like yeah that that that's not a foundation on which I'm going to build uh you know decades worth of technical innovation. That's like yes, one and</p>
<p><strong>[81:29]</strong></p>
<p>done. >> And I think there's lots of software that kind of fits that model. And I think that's where you kind of get the slop, you know, uh slopware porative term, but for some of this code and like it's sort of fine like if you're if you're building something that is a one-off, it is associated with like some time and place and whatever, fine. Like whatever, I don't know. And yeah, there's going to be a lot more of it and that's frustrating. Uh but on the other hand for the stuff that is foundational that has always been rigorous and the</p>
<p>rigor is increasing this becomes a lever by which the rigor continues to increase. >> Yeah. I [clears throat] mean for me it's just like I there are so many things that I feel like I've been able to do with this to increase rigor. like my like I've you know coded a couple of things here and there but like my interest as a professional is really focusing on rigor and and my background is in dev tools where like correctness is like absolutely essential and non-negotiable</p>
<p>and for me it's like okay you know there are so many more tests that I'm writing now like I you know the other day I was like I want to learn how to use scani right which is you know this model checker for rust and and I wanted to use that right and I'm like I there's there's always been this activation energy. We have to go read the documentation and stuff. And so what I instead ended up doing with this is that you know I took an existing project that I had which I felt like was a good fit for Connie and and I just asked cloud open 4.5 to hey like you know come up with a few properties that we can you</p>
<p>can verify that way and it just did that and I'm like now I understand how this stuff works and what the limitations are and stuff and just like like there are so many ways you can kind of use this stuff to to go like increase the level of rigor in your software. And honestly, it really bothers me that the dominant narrative is the whole like slop wipe code stuff, right? Because like or infrastructure engineers, there is so much more you can get out of it. >> Yeah. But isn't that is that always been the case for the kinds of code that we care about Rain that like uh you know one of the things that's beautiful about</p>
<p>Oxide is we go to a demo day where you know we show off you know Rain you show off this 30,000 line change or whatever or I show off like this library that compares one thing to another thing and it's like people are hooting and hollering as opposed to um >> you know systems demos are traditionally seen as boring and the thing that's wizzy is when you know you can demo something cool and graphical and whatever and uh you know rigorous is not to everyone</p>
<p>have the same kind of sex appeal. >> Yeah, totally. I though I I think and re but you're also right about the dominant narrative and I was trying to think about I mean and clearly it is a truly a dominant narrative and that it's dominating kind of everything and Adam I was trying to think back in terms of our careers when have you had these kind of like big narratives where it feels like it's reductive you know one thing I was thinking about was the rise of Java was</p>
<p><strong>[84:29]</strong></p>
<p>that way where the rise of Java was really suffocating because there was this idea and it's like very different so I I don't want to be too reductive here but with the rise of Java there There's this idea of it's like it's the end of every other programming language. Like this is this [laughter] is what we're going to do. And like this is kind of crazy to think about that the because this is [laughter] I mean right it is it's like it's it is it's it's humorous now but it was at the time there was this idea that everything's going to be in Java. We're</p>
<p>going to do the operating systems in Java. The microprocessors are going to execute Java bte code. we are l and and I mean at sun at the time it was re it was like I know this is not right and I like Java is like really powerful and important and it's going to allow many more people to write software and I remember thinking at the time like well at least it's the death of C++ um but what it it took a while for people and some like some failed experiments right it took it took nano Java and Pico Java inside of Sun and a</p>
<p>bunch of and two different oss inside of inside of inside of Sunr and Java. Uh so there were a bunch of like where we got and then people realized like okay no this thing is like it's important and it has a role but it's not everything and >> it wasn't just all languages it was operating systems and operating environments right it was like the right once run anywhere meant >> right >> you don't have to worry about the the details of Mac and Windows and Unix and and all the different flavors of Unix.</p>
<p>No, you just write it once and you write it run it anywhere. Uh, and and it meant all of that other stuff was just going to become meaningless. And the only thing that that was going to matter with Java, you're totally right that it it it took all the air out of the room for like a big chunk of like the the late 90s, maybe early 2000s. >> Yeah. >> Yeah. Totally. And if you were implementing in C, it's like, well, I I hope the past is working out for you. I mean this is this whole idea of like you are you are actually a living fossil and Java is actually going to come to</p>
<p>replace you >> and you know and in some ways it was like I actually I really do think it was kind of worse because if you were doing as what we were doing like you know we're in the operating system developing this thing in C it's like Java didn't really have anything for us you know it was not like oh I mean we did it around the margins but not like our tooling it I mean even the the kind of the value that Java legitimately delivered We didn't really realize any of that. Um, and you know, ultimately we uh we ultimately had a good relationship with</p>
<p>Java, but it wasn't like whereas I think with like LLM like no, no, you can actually everybody can kind of up their game with this thing in a way that's really exciting and uplifting. >> Yeah. Spot on. >> Um, well, David Rain, anything that Elsa, we I know there there's obviously a lot to talk about here. I think we</p>
<p><strong>[87:29]</strong></p>
<p>covered everything there is to say about LLM. [laughter] >> Finally, >> I mean the thing I will say personally is like having a culture where writing things down is valued is like you know it is like a real multiplier here and so I mean on our side like I'm I'm very happy that you know all of this work that we do like we now have a new way to gain leverage from from all this writing work that you know we are culturally do. Um if you're if you're at a place that you know maybe doesn't have as strong rigorous like requirements or like you</p>
<p>know isn't as committal as as Oxide where we ship hardware or whatever um I would still consider like you know doing work to write things down and produce good documentation good design documents because like at least the current generation of LLMs like really like that and so you know like kind of you know get a little more disciplined right with some of these things right um so yeah That's that's what I would say like write things down. That's a great advice and actually let me ask you to expand on that just a half a beat because I do</p>
<p>feel as as part of of deep blue um you do have especially and it's unclear to me by the way if this is truly young people of like undergraduates versus a a kind of a more mid-career malaise and maybe this like maybe deep blue cuts across all of it but people who are wondering like what is you know how can I what is my role in this kind of this new LLM age. Yeah. >> Um what what would be some advice that you would give to an engineer that's</p>
<p>early in their career um and looking at this stuff? >> Honestly, like this is kind of the advice I would tip like I would say like practice, you know, like writing like for me like writing is not a natural skill for me. This is something that it's taken me many years of work to kind of get where I am now. Um, I would say like if you're starting out like like practice writing um don't have the LLM write things but like have feed it into the LLM and see how it behaves when you kind of do that and like p do you know that is the one bit of advice that I</p>
<p>think I think this is the kind of advice that you know is like timeless in the sense that we have always written things down and we will always keep writing things down. There's always a lot of value to that. But I think the in the LLM age like this is one of those ways where you can really multiply the amount of rigor you have. >> Yeah, that's great advice. I think the advice I would add is like hey, you can now you've got the ability to pick up a new language, pick up a new system much more quickly than before and you should use that as a way of getting into something maybe you would have been</p>
<p>intimidated by. I mean I do think that like I mean look look kernel development feels intimidating to people. Lots of people don't pick up kernel development because they're intimidated by it. And if you view an LLM as like giving you the opportunity to jumpstart you in kernel development, go for it. That's great. Like that that's that is has got a very uh robust basis. So hop in there</p>
<p><strong>[90:30]</strong></p>
<p>and you know hop [snorts] into alumos or or something that you wouldn't do otherwise, maybe a database, what have you. >> Um and use that LLM to get you jump started and to get you mastery over this thing. elements don't judge like ask all the questions that you'd be embarrassed to ask the human like >> if anything they could judge just a little bit more be like that is kind of a bad question but [laughter] >> this okay this is why pair programming never really worked out for me is because you always have someone being like you used what you don't use d'vorak</p>
<p>like I thought like no I don't use or like you know like do you actually know that there's actually a faster key binding like no can we aren't we like trying to work on this problem together like why are you coming like you don't use syntax highlighting what am I even here [laughter] for? You know, it's like, okay, we're just now having fights over things. And you know, it's just like we don't, you know, you don't have those those unfortunat I don't think the LM maybe I'm a little maybe I should confide to Claude code that like by the way, I don't use syntacting. What do you what do you think about that? See what it's uh um but yeah, it's free of judgment, which is really terrific.</p>
<p>Well, thank you all. I I you know I know this is a hot topic and um I I I think that I'm hoping that we can show that big moderate middle and um really show that there is a third path that by the way is the most likely path which is that we actually use these things as tools. They're not coming to replace you but they are actually going to allow you to do a lot more. And um the the one that should be most worried about LLMs is Stalebot. Stalebot for you. >> Oh I hope so. [laughter]</p>
<p>[gasps] death to stalebot, I say. So, uh, Adam, thank you for for, uh, stoking that rage. Um, but, um, thank you all. I think this is really great stuff. Thank you for for coming in on a hot topic. Um, and thank you all in the chat, too. I think this is this is really important. This is not going to be, um, our last LLM episode this year. I don't think, Adam, >> that's a great prediction. >> Exactly. It feels like a luck. All right. Thanks, R. Thanks David. Thanks.</p>]]></content:encoded>
      <guid isPermaLink="false">https://www.youtube.com/watch?v=fmFt4-jjEc0</guid>
      <pubDate>Wed, 14 Jan 2026 15:45:05 +0000</pubDate>
    </item>
    <item>
      <title>Oxide and Friends 2/2/2026 -- Software Engineering Past, Present, and Future with Grady Booch</title>
      <link>https://www.youtube.com/watch?v=McAL6jkRUO4</link>
      <description>Bryan and Adam were joined by Grady Booch, software engineering pioneer and *living* legend, to speak about the past present and future of software engineering. History doesn't repeat itself, but it does rhyme!

Notes: https://github.com/oxidecomputer/oxide-and-friends/blob/master/2026_02_02.md

NB: LLM generated image derived from the SNL sketch</description>
      <content:encoded><![CDATA[<p><strong>[00:00]</strong></p>
<p>Oh, there's another Grady with Did you hear the other Grady with hands up? >> I just let I just let anyone named Grady join the stage. Noted for all the all the listeners. Exactly. Kind of an I'm Spartacus moment. >> You hear me now? >> We hear you now. Yes. >> Right. >> Uh welcome. It is It is great to have you here. Um, Grady, you know, I uh Pier Leand is a is a famous uh venture capitalist and I uh was an investor in Oxide and I made the mistake when I</p>
<p>first met him of saying it was an honor to meet a legend and he he informed me that legends are dead and uh it was like literally my I was like, "Okay, this is off to a very very bad start." So, I am not going to call you a legend because I don't want to offend you, but I do view you should know that I I I do view you as legendary. So, hopefully that's I I know I'm on a knife edge here, but hopefully that's okay. >> You're a most kind. I've been called many things. [laughter] >> Well, you are certainly a software engineering pioneer. Um, and you have</p>
<p>seen a lot. And I have to tell you, I was I just getting to prepare for this conversation, I had pulled what I thought was a recent conversation. And as I was listening to it, I'm like, "Wow, this is like this is um kind of like there's kind of surprising that he's not tacking harder into deep learning given that it was in 2024." And then I look, I'm like, "Oh my god, it was in 2014 and this conversation you had in 2014, I have to tell you, is aging very, very well." you had a so uh</p>
<p>because you've been you've been involved in uh you were talking about working with the Watson team um and kind of understanding what Watson had done at IBM. Um but of course your history is a lot deeper than that. Um you were uh I mean you go back to the you kind of came up as software engineering was coming up. I was going to ask if your degree was in computer science or cuz you were at the Air Force Academy or was your</p>
<p>degree in cuz it almost predates certainly it predates Adam it predates the computer science department at our alma mater. Um Grey, would you mind taking us all the way back to your undergrad years and and then your kind of your first encounters with software? >> So let's go way back in time. I built my first computer when I was 12. So we're talking, you know, mid60s. Why did I do that? Well, I was a voracious reader then, still am now, and I remember going to the library one day and finding this</p>
<p>book called Computer Design, which is basically a hardware book, and it described, you know, here's how mainframe computers were being built. I was I was immediately taken by it. And I said to myself, I need to build me one of these. >> Well, obviously in the mid60s, there weren't a lot of things around, not even integrated circuits. >> Yeah. >> Right. So I I I did a self-study and then realized I could build these myself</p>
<p><strong>[03:02]</strong></p>
<p>from individual transistors. And so my first computer today we call it more of a calculator with extended memory. I built around that age. I thought hardware was pretty cool but then I realized software is where it is at. Sorry. You So you built your own computer out of discrete logic as a as a teenager only because because the integrated circuit had really not yet been invented or microp processors certainly had not been invented. I just want to I'm just playing that back to you just so I can polish my own sense of inadequacy. Is that is is that correct? He's more of a software guy, Brian,</p>
<p>remember? >> Exactly. That's right. >> That is correct. I I could probably, you know, put a blindfold on and build a flip-flop from you out of four transistors, but that's another part of my life. Um, I decided software was where I was at. So, here I was by that time 13, 14, the summer thereof. >> So, living in Emerald, Texas, small town of 150,000 people, I went and knocked on the door of everybody that had a computer. Of course, this was the time when IBM was the dominant manufacturer at the time. And obviously nobody was</p>
<p>going to hire a kid. But I knocked on the door of the IBM sales office. There's a sales guy that took me in. He nodded politely and then handed me a manual, a 4R manual and said, "Go read this and come back to me." I expect he never imagined I would come back, but there I was the next week and I said, "I have written a program. I would like to run it." He was a little bit gobsmacked. The program of course was your typical hello world problem. I was also into physics at the time and had written a program in forran to model the movement</p>
<p>of two uh neutrons moving toward one another at increasing speeds of light or close close to the speed of light and calculating what the release of energy was. So that's was my first program. I still have the punch cards for it by the way. The guy took me >> that's a that's a long way from scratch or whatever the uh the kind of the modern equivalent is. That's that's very uh that's what >> Adam [clears throat] you ever been to Amarillo? Do you >> I don't know that I have. Okay. So, am I mean I mean Amarillo is the is uh I mean desolate, right? I mean great. It's fair</p>
<p>to say Amarillo is like you've got the you are in the Texas panhandle >> and I mean you are a long way from other things. Um it's remote and >> it's the helium capital. Yeah. Helium capital of the world. Uh our main claim to fame is that it's home to the Pantex plant which is the place where nuclear triggers are assembled and disassembled. So, it's kind of a fascinating place. >> So, anyway, I wrote the program. He got me time on the weekends on public services computer, which was an IBM 1130 computer if I'm not mistaken. And he</p>
<p>said, "Go to it." I taught myself how to punch cards. I taught myself debugging. And there we have it. Around that time, I decided, you know, what do I want to do next? And so, I was deeply into software at Forran at the time. We're going to come back to the story of the the manual in a minute, but uh I then said, what are my two loves? Computers</p>
<p><strong>[06:04]</strong></p>
<p>and space. And the great place to do that at the time was of course the Air Force Academy because they had an astrophysics program, bring me into space. They had a burgeoning computer science program and really one of the few undergraduate programs at the time. So I went there and I got my degree, a bachelor of science in computer science. There was no such thing as computer science at the time, but it was a bachelor of science. >> My first assignment after I graduated was at Vandenberg Air Force Base. So my dream come true. There I was literally in space command before the orange</p>
<p>cockwamble called it that. So here I was in space [laughter] dealing with I Gosh, I I unveiled my political bet, didn't I? [laughter] >> You're all good. You're I feel we need a separate time for it. So this is all good. >> Yeah. So, so there I became a project engineer and then a project manager. And the fascinating thing about this time and I'll give you a hint for some of the things I'm up to now. I'm working on a documentary about computing and its intersection intersection with what it means to be human. Imagine Carl Sean's</p>
<p>Cosmos about computing. And I'm convinced that I'm convinced that one of the things one of the major influences upon modern computing is how it evolved from World War II and the Cold War or the phrase I use is much of modern computing has been woven on a loom of sorrow. And so in that time the largest and most complex systems were not being built by industry. They were being built by the military. We were building distributed systems that were fusing together 40 different radar in real time around the world. And this was hard</p>
<p>stuff. Hard then still is a bit hard now. So I really cut my, you know, I learned a lot about how to deal with large complex systems from day one. I then got involved in the ADA program because here we were in the midst of the software crisis and as it was called the NATO conference. >> Yeah. Could you describe the software crisis a little bit because I think that this is a I mean the year now is we're in the very early 80s maybe late 70s. What what is the >> We're in the mid70s. Mid to late 70s.</p>
<p>>> '7s. Mid70s. Okay. Yeah. >> So, the the question I would ask all of your listeners is remember what year you got your first email address. Think through the answer. I got mine in 1979 when it was still the ARPANET. And at the time, we had a little book that listed the it was about maybe 100 pages that listed the email address of everybody in the world. Very cool to have. So I was on the ARPANET from the beginning. >> Wow. >> Yeah. Yeah. So um anyway uh I was called into be involved with the ADA program</p>
<p>because of the so-called software crisis as it was named in the big NATO conference around the time. Remember height of the cold war uh there was a system called Sage the semi-automatic ground environment which is so much the predecessor of modern computing large distributed system. It's the first place where we had CRT displays as opposed to just terminals or just opposed to teletypes. It's that was a successor to</p>
<p><strong>[09:06]</strong></p>
<p>the whirlwind computer out of MIT. And so we were dealing with human computer interface kind of things. That work was taken into the Sage system. And this becomes important because there's a woman that worked on Sage. Her name is Margaret Hamilton. and she is the one who in the 70s coined the term software engineering to distinguish herself from the hardware engineers were around the time. She went on to work from Sage to be the main engineer for the Apollo 11 ground system and indeed was the person you probably seen pictures of it uh primarily responsible for writing the</p>
<p>code for the lunar lunar lander. Anyway, what's a software crisis? The problem here is that you had tremendous demand for software and yet the inability to build it quickly enough, reliably enough, etc. The Sage project consumed perhaps 30% according to some reports of all of the software engineers in the United States. Huge, huge project and we learned a great deal from it. >> I'll jump ahead because I don't want to spend all the time in my history. I want to talk about some things of course.</p>
<p>Yeah. Yeah. Right. So, so we we then after I left for the Air Force Academy, uh, started up Rational Software with two of my classmates in 1982. We were bought by IBM in 2003. And I'm going to put a bookmark there and tell you a Bill Gates story in a moment. And then uh, the rest is history. The last six years, I've been working with a set of neuroscientists to better understand the architecture of the brain. And you referred back to something in 2014ish. That was probably the TED talk of which I spoke. I was I was I was annoyed. I</p>
<p>was Yeah, I was annoyed at the book that Boston wrote and said, "This sucks." And Elon, you're adult. U Bill, you're adult, too. Let me tell you what I think. So, there we go. >> Uh yeah, it was actually the It was on the Singularity podcast was >> I did listen to the TED talk. I gotta say whenever I listen to a TED talk I remind myself why I find TED talks as a format to be annoying the your TED talk great. Yeah. I always feel like oh god I feel like I I want to go listen to the speaker for another you know outside of</p>
<p>the 45 seconds they've been allotted. Um so >> yeah Ray and I got into it. I thought his ideas of the singularity well the the singularity's main value is it allows you to make clickbait articles and sell books. I think there's no substance in it whatsoever by any means. Um, let me quickly tell you a Bill Gates story since you're hearing a bit of my history. 2003, we were bought by IBM. Bill Microsoft had been bidding on us. Uh, couple months after we we finished the deal, got a call, "Hey, Grady, it's</p>
<p>Bill. Come see me." So, I flew up to Seattle. I'd done some things with him before. Sat me down in his office and said, "You know, I this is not public yet because we're talking what, 2003, but I'm going to retire from Microsoft. And you know, Grady, I have two jobs. I'm CEO and I'm chief architect of Microsoft. I would like to give you the job of chief architect. I said, "Bill, that's really that's really interesting. Let me think about it." For a couple of</p>
<p><strong>[12:07]</strong></p>
<p>months, I went back and forth spending time with these tenants. And I came back to him and said, "Bill, I'm profoundly flattered, but you know, you have a very dysfunctional company, and I'm not the person to fix it." So, if I said yes, it would only end in tears. And so, I said no, and then continued on with IBM, and I'm happy that I did. >> Yeah. Uh, yeah. I I cuz I mean and you only end in tears. It would have been like some it could have been your tears that it could have ended in. We were just like this is just too Yeah. Right. >> It would have been a waste waste of my time. I'm I'm a lover not a fighter. They needed to have [laughter] somebody</p>
<p>they needed to have somebody come in and knock heads and I'm not that kind of person. So I've been very happy in research the last several years doing what I'm doing. And it should be said just along the way and I know I don't want to necessarily dwell on the history but I do think it's a it's gerine for kind of what I want to talk about in terms of the future of software engineering that along the way as you were trying to navigate the the the crisis the software crisis of the late '7s early ' 80s uh you really were trying to to find ways for people to kind of uplevel the craft of software engineering. you were obviously uh in</p>
<p>terms of modeling systems, UML was was your your co-bab um certainly what a claim to fame. Um you developed um when I when I where I came to know you cuz I kind of came up in the '90s. Um I uh my first internet my first email address very much as an undergraduate in in 1992. Uh I think they had just they had just gone to straight internet instead of having both internet and bitnet. Right. >> Yep. Right. Harponet. Yep. >> Right. Exactly.</p>
<p>>> And then Miln net. Yeah. >> Um but um I remember you for the boot components um which were the the uh the kind of uh I would call before the C++ standard templates library. These were the kind of the components that were a demonstration of an embodiment of of how to use object-oriented design. And so you kind of you saw software navigate this crisis of like oh my god we don't know how to and I think it was still when I was coming up it still felt like software was in that crisis. >> Still is. [laughter] >> Yeah.</p>
<p>Yeah. So then I mean I think the thing that is I mean to to I guess kind of fast forward here I mean you've seen a lot of revolutions. you were I you know early in on agile uh you and you saw that that revolution run its course one way or the other I guess I [laughter] be interested to get your take on that um and then now we're in this like crazy world and do you feel like is this the world that like yes this is the world that I saw a decade ago this world makes sense or or is this because it feels to</p>
<p>me like we are on I mean it's it's delightful but bizarre is kind of my take on are are the where we are currently, but I would love to get your take on it. Obviously, >> I would say that every age of software has been crazy and bizarre and wonderful simultaneously. >> The rise of the internet, the rise of the personal computer, the rise of the mobile device, the rise of the cloud,</p>
<p><strong>[15:07]</strong></p>
<p>every one of these represent points in time and points in change in the industry. And every one of them, interestingly, has reacted in very similar ways to what's happening here. I have a lot of people coming up to me saying, "Oh go my gosh, Grady, I have this existential crisis. My career is over. It's going to be replaced by computers." And I observe to them is that no, be calm. Take a deep breath. The entire history of software engineering is one of rising levels of abstraction. And let me explain why that's the case. Because you're right,</p>
<p>I've been around this business for a while. I met Grace Hopper. I met uh I still have the nancond she gave me. If you don't know the story I'm referring to, go Google Grace Hopper and David Letterman and there's this wonderful scene with her. Um, I've also I didn't meet Alan Turring, but I because he was dead by then, but when I was doing some work at the University of Manchester and and at Bletchley, I met some of the people who worked with Turing. So, I'm an old fart if you want to get down to it. I even Oh, here here's a fun other funny story. Uh Jay Presper Eert I met</p>
<p>as well because I taught his grandson at the Air Force Academy. So yeah, while I told him >> Per Eard. Wow. >> So that that dates things. Anyway, so >> yeah, that's I mean I feel like you you're like did you have any connection to Charles Babage? I mean this is like you're really turning that that's very impressive. Oh my god. Wow. >> Charles was long gone by then. Uh the story with back to forran the quick one is remember that manual I said yeah it's part of the I was on the board of trustees for the computer history museum</p>
<p>for about a decade and I did a number of oral histories for folks one of those I did with was with was with with John Bakus so I went out to visit him his wife had just died very sad story he actually died a few months later I think of a broken heart so I took that book with him and I explained the story and I've got a signature from John as well >> anyway let's go back let's go back in time >> um >> ultimately you Why do we have solver engineering? And I mentioned Margaret. What was what was she trying to deal with? Engineering. I think we can legitimately calls our call ourselves an</p>
<p>engineer because we are the ones who take various static and dynamic forces and try to build reasonably optimal solutions that tend to those. And when I say reasonably optimal, it deals with economic issues, legal issues, all these kinds of things. So it's not just the technology, it's the social and economic context in which they are born. This is true now. It is true as it was from the very beginning days of software. >> Yeah. And I agree, this is an extremely important point because this may less this seem obvious to those younger.</p>
<p>there was a I I feel a protracted period of time where software was really having to fight for its own legitimacy constantly hearing you're not actually engineering and we get you know always being referred to to you it's always the civil engineers that are like you know like it's always the bridge building and the and one of one of the things I learned about bridge building is that when you you build a bridge the way we build software where you build a bridge</p>
<p><strong>[18:09]</strong></p>
<p>with a totally new design that has never been built before which is a better analog for software it has all the same problems of big software engineering. Um, witness, Adam, the the the the self-anchored suspension bridge that we have here in the Bay Area, which is only the second of its type in the world and looked a lot like a software project. So, anyway, yeah, Granny, I just wanted to people don't take what you're saying for granted because what you're saying is extremely important that we Yeah. Anyway, you are a very important part of of upleveling us. There's a great X KCD cartoon of you see this little complex structure and one tiny thing in there of</p>
<p>it's all supported by this. And that's what open source is is somebody who said uh if buildings were built way if software were built the way I'm going to get it backwards. If buildings were built the way software was built the first woodpecker that would come along would destroy civilization. We we build things that are astonishingly exquisitly complex and they're also fragile. And this is I think what makes it so exciting to work in this discipline because we work with the most fluid of materials, the most malleable, the most funible. And that's exciting. And as I</p>
<p>always tell people, it is both a privilege and and and responsibility to be a software engineer because it's a privilege because we're changing the world. It's a responsibility because we're changing the world. So if we think of ourselves as an engineering discipline, we weigh back different forces. And that that's a fundamental that applies to all of us. In the earliest days of software when we were dealing with you know mainframe computers the fundamental problem was we want to do calculations mostly mostly mathematical. The problem is how do we get our machines to do what we're doing? This is the era of of the Mark1 and uh</p>
<p>and uh the Iliac. It's not the Iliac but the ENIAC and the like. As we began to decouple the things that made the machines work and the hardware itself. Now we're in the realm of Grace Hopper, the one who was pioneering the ideas of compilers and higher order programming languages that led to eventually Cobalt and Forran and the like. Why do we do that? We needed a change in levels of abstraction because working at the assembly language level or the machine language level simply was not very</p>
<p>effective for us. We could think of these things but the friction and the distance between the two, the cognitive distance is very very high. Thus we were now subtly in the first golden age of software engineering. That first golden age is best characterized by algorithmic abstractions. Meaning we're taking mostly mathematical things getting our machines to do it. In the 70s 80s, which is where I came into the scene, I was very lucky because I came in at the right place at the right time. The world was changing because now, as I mentioned, back in Vandenberg, we were</p>
<p>dealing with systems that were larger, real time, distributed. All of a sudden, complexity was just exploding upon us. And the early abstractions were insufficient to do what we're doing. There were glimmers of excitement though with languages such as simula, with ideas such as abstract data types and partners' ideas of information hiding. The role I was given with ADA was to say Grady, we built this language for the</p>
<p><strong>[21:09]</strong></p>
<p>Department of Defense. Go figure out how to best use it. And so I was actually commissioned to go off and figure out some software engineering techniques. I met with the, you know, the first generation folks, Larry Constantine, Ed DeMarco, Ed Ed Jordan, Tom DeMarco, all those kind of folks. And so I kind of learned from them, but I realized there's something different. There is a wonderful dialogue by Plato. That's the one that really inspired me. This is going to get kind of geeky. In it, there is a discussion about how does one view the world? Should you look at it through</p>
<p>the things or should you look at it through the movement? And the answer is both. But it occurred to me that's the way we should look at software through the things themselves. And of course the simulative folks had done that. And thus I was on this mission to say oh let's try designing it through objects and classes not just through algorithms. I was one of many but I just happened to have a a platform and a voice and reasonably articulate and then we built a business around this kind of thing. So that was the beginning of the second golden age of software engineering</p>
<p>because the fundamental problem was increasing complexity, increasing size of systems. We need new abstractions to help us reduce our cognitive load and build these things. So I'll pause there for a moment because I don't want to do all the talking but >> no the question before I go on. No, no, that that makes total sense. And I think that the and I I now like very curious because the kind of the next turns of that of the development of some of those abstractions because I mean the abstractions I I I I think that the some of these abstractions that we developed</p>
<p>along the way became a very important as just demarcation boundaries like SQL was a I mean Adam you're a SQL lover but I think it's is that fair to say do you feel am I being am I being >> I can understand why you say that. Yeah. [laughter] There we go. That's exactly. But I mean that's an extremely important abstraction to develop because it allowed us to take these these two big concerns and actually separate them. We may want to go like later in later we would go kind of revisit that</p>
<p>abstraction. But the presence of that abstraction was really important. So the you know the presence of the operating system as an abstraction allowing us to have application software that was totally divorced from from the hardware. Um and I think that Grey one of the things I would actually be I would because I definitely came up when object orientation reached it I I think at its zenith. Adam you can I mean you're you were a couple years behind me. Is that right? is because I think >> I think so because they were rewriting the operating systems course at at Brown</p>
<p>to be uh object-oriented at the time. >> Object orient everything was going to be object-oriented and it was one of these things where it's like the the successful abstraction. It's we in software we seem to never be able to turn the abstraction dial exactly correctly. Like we always like okay if a little abstraction is great like we must [laughter] abstraction absolutely everywhere. >> That's right. If if if open if uh object orientation is great in moderation then</p>
<p><strong>[24:11]</strong></p>
<p>used in excess [laughter] it'll be even better. >> It must be especially great in excess. If Java is good in moderation like then the microprocessor should be in Java. It's like no >> and remember the Intel IPAX 432 is basically putting eight on a chip. We overshot things especially with the use of inheritance. That was a mistake. But the idea of abstracting things where you had the data and the operations together as a cognitive unit that was essential. But what happened? It disappeared as it should because the best things like that should move into the atmosphere. This is</p>
<p>around the time the UML came to be because I recognized that languages were were textual languages were good but we thought about things at a different level of abstraction. This is also around the time that I connected with Bjarn Strrip. Barjarn happened to show up in one of my lectures. He asked some really good questions. We talked afterwards, hit it off. And then this is before the time he had released C++. He had just written a paper called C with classes. I wrote my object-oriented design paper. We were actually published in the same journal at the same time. Didn't know one another. So the two of</p>
<p>us went off and did a a lecture series around the United States and very much influenced each other's work if you look at his first edition thing. So I kind of grew up with C++ and vice versa. But now I would observe that we are in the third golden age of software engineering. It's not because of things like uh like claude. I think we've been into it for a while. Why? Because the abstraction has shifted again. With the rise of distributed systems, with the rise of the internet and primarily with the rise of packages and platforms, all of a</p>
<p>sudden we're not dealing with building systems out of levels of classes. We're dealing with levels of whole frameworks. Oh, I need to do some sort of uh messaging, then I'll use this package. I need to do this kind of UI thing, I'll use this. I need to do visualization, I'll use D3. So, all of a sudden, the level of abstraction has moved up for us. And now, as a software engineer, a lot of what we end up doing are some people who build these, some people maintain them, but systems engineering is largely figuring out what those right pieces are and orchestrating them so</p>
<p>they work well together. That's the third golden age in which we're in. And then I would observe things like claude. They are a a symptom of that golden age. We've had a need to increase the velocity and reduce the friction so they come in at the right time. Not unlike what happened with the generation of case tools in the second generation, second golden age. Not unlike the rise of compilers and higher order languages in the first generation. Now what does it mean? And I've often said this. I believe things like COD and the like</p>
<p>will change the nature of software engineering just as much as did the rise of compilers. >> It moves up the level abstraction and actually makes it possible for us and desirable for us to build more software and therefore the human is not disappearing. We've just moved up another ratchet of level of abstraction. So this is an exciting time quite frankly. >> Absolutely agree. Absolutely agree. And</p>
<p><strong>[27:12]</strong></p>
<p>I think that the and I I love your analog with the compiler. I also think it's great that and I think it's also especially great for younger software engineers, Grady, to hear that over your career you've had people approaching you being like it feels like the domain is like the invention of the compiler means that I have nothing to do anymore or the you know >> Oh [laughter] yes, the invention of Cobalt. Cobalt was invented because now we don't need programmers. Business people could write their own code. >> Well, how did that work out for you? and SQL too, right? I mean SQL the whole idea of SQL that was that you making</p>
<p>this so much more approach and which it was of course I mean SQL made it way easier to query a database which just allowed us to do a lot more databases. >> Yes. >> Um exactly >> and you know we are definitely and I I love that analogy. Um we are definitely seeing that for whatever it's worth. We are seeing that the and and uh you know Adam did you catch the demos on I know you were out on Friday. Did you catch the demos? >> Yeah, I I watched the the recording today. And wasn't it wild? >> Very cool. So our our our colleague uh wrote uh a language that they don't know</p>
<p>Lua to use a subsystem that they've never used before or heard of before which was an embedded Lua use in ZFS to do some mission critical use. It was it was >> Adam I just love that right now there is someone doing their dishes. Not right now. Actually, in the future, because this is like right now, right now, [laughter] some lawyer is going to someone who's going to listen to this podcast as a recording is going to is going to like dry their hands and hit the pot and rewind and be like, "Did I just hear that there's a Lua interpreter in CFS?" [laughter] Yes, dear listener, there's a interpreter in CFS that you might not</p>
<p>have been aware of. Uh but yeah, using Claude then to actually go write these channel programs and in a way that was in a way that you just like it Claude didn't make it possible but it made it so much faster that it was it was just not something we would have done. We would have waited because cuz this is basically working around the lack of a piece of functionality we need in CFS >> 100%. especially like you I mean h how else would you have the confidence to say well I've never used this language before and I've never heard of this</p>
<p>subsystem before but I don't know and I kind of have to get this done in the next two days or whatever >> uh you just wouldn't even start like you you would know that it was impractical >> yeah and we're and you know I I think also Gdy because you're you're a a tooling like us I mean our tooling is very deep in our marrow we we like you are real toolmakers And one of the things that we are discovering is that claude is being used by software engineers to make the tooling that they kind of wish they had on the spot. And</p>
<p>um that is so it's this kind of very important bankshot in terms and people are still of course are using it for to for all the the ways that it's being used elsewhere. But I think that for infrastructure software in particular, what we're finding is that we're able to use this stuff to really increase our level of rigor. And I think that that's a bit which is not a surprise if you</p>
<p><strong>[30:14]</strong></p>
<p>view it in the context of what you're describing you viewing it like a compiler revolution. That's not at all a surprise. But I think there's a domain of software engineering that finds that surprising. I >> I think they do find it surprising. Infrastructure software is perhaps some of the most fragile stuff I've ever seen. It it runs on spit and chicken w chicken wire in most organizations. And so no great surprise that using things like claude to help you uh refactor it, reorganize it, automate it makes a whole lot of sense. Uh so yeah, I I don't have particularly complicated pipelines, so</p>
<p>that's not where my primary use case is. I've been using it for some Swift, some Python, some PHP, some uh some uh JavaScript, and it's been great for me. But the notion of using it for tooling to automate those things, every software developer builds their little nest around themselves of all their creature comforts. And when you move that to the organization at large, Claude and its ilk shine in those circumstances. >> Well, and I just think to your point about us writing more software like</p>
<p>that, you know, because when people think like, okay, more soft like what does that mean exactly? It's like well what it means is that the software there is software that a lot of software that's not written because it doesn't it can't economically pay for itself. it it's it's the tooling that is like god I would love to have this tool but it's kind of a one-off tool or it it might not be useful beyond my immediate use case or my immediate organization and now all that stuff becomes uh possible and</p>
<p>>> it's very important you mention the notion of economics because I think economics has driven a lot of software engineering if you look back in the first golden age the cost of our machines was much higher than the cost of our programmers and therefore everything in the processes like waterfall was in order to optimize the dominant cost which was the machine. So if if you had a high cost for machines and you do your work up front by the way the same phenomena happened in Russia of all things after the after the Soviet Union collapsed and we saw</p>
<p>this flood of amazing engineers coming into the marketplace. What happened? Machines were very very scarce in the Soviet Union. And so the developers there honed their skills to be able to do things on paper and in their heads before they even touched a machine. We don't do that anymore because the economics have utterly reversed. The cost of preparing is actually so high you just sit in front of a machine and do something. Now this leads us to the distinction of disposable software and durable software. Disposable software</p>
<p>means you've got systems which the economic cost of replacing it approaches zero. Durable systems those are one in which the risk is higher in which the cost of change is higher and therefore you got to find a balance where you are in this for every organization. >> Yeah. And the software we're making just to be clear is really of that durable. I mean that's where I've spent my career is in that I mean still using software</p>
<p><strong>[33:16]</strong></p>
<p>that that I wrote we wrote you know now Adam Jesus 20 plus years ago. Um and so really but I I think that there's a lot I think that like unlike I think not every revolution has affected every use of software equally and I do feel that like I mean because I you know I I came up in when at Java was was everywhere and was going to be used for absolutely everything. Um, and that was like that was an overshoot and it wasn't actually meaning was like I actually think that</p>
<p>claude is it's it's not an overshoot to say that it affects quite literally everybody at every layer of the stack at some layer that or the ability to have LLM assisted software engineering is going to be I feel it's going to be omnipresent. I don't feel like that's a that's right up there with World War II being stressful. Adam, I feel right one of Brian's famous observations. Yeah. >> [laughter] >> But deep thoughts out of side and friends. >> But but I mean Grady to your point like similar to the compiler having an impact to every software uh engineer and all software being written. Uh you know I</p>
<p>think that that that feels obvious now but maybe felt scary at the time you know maybe felt like it was threatening people's livelihoods and and the amount of software that would be written but it turned out that just much more software was written. >> Yeah. Change change is hard for everyone. Absolutely. This is a time of still incredible experimentation. Speaking of overreach, I believe people like Sam and Dario of Anthropic, they have vastly overreached. I bashed Dario many times on on Twitter and he's making the claim that, you</p>
<p>know, software engineering is dead. I think he's demonstrally wrong in every dimension of the word wrong. But remember, he's a person who is trying to sell a business and increase their stock price. So, he is he's looking at the world in a very different way than I am. I I I it's true. I also feel it's not very helpful to just generally be stoking fear about these things because there's already ambient fear just from change. And it it is it's kind of too easy to stoke that fear. Um and it makes it really hard to be levelheaded in</p>
<p>light of that fear. Um so I actually do think that we we need to be more levelheaded on a lot of this stuff. What would be so your advice to because I I get this a lot. You must get it a lot too of young people are like got to mention software engineering but it feels like the glory days are kind of past us. Um which I disagree with. I I agree with you. I think our our our best days are ahead and it's exciting time in terms of though I I just as like a compiler did not chase assembly language</p>
<p>out of the undergraduate curriculum, right? We still learn assembly and it's still important even though no one is expected to write things in assembly. It feels to me like those fundamentals are as important as ever in in a kind of an undergraduate kind of computer science experience. Way what's your take on that? >> Absolutely. By the way, being level-headed makes sense, but the problem is it won't get you on Fox News. It won't get you, [laughter] you know.</p>
<p><strong>[36:17]</strong></p>
<p>So, that's the problem. So, there are voices like mine who are saying, you know, and maybe I'm just the old sage saying, take a deep breath. Life is good. Life's more wonderful than you realize. Don't panic and carry your towel with you if you remember that that analogy. So from from the galaxy, right? >> Yeah. You know, I was listening to a podcast where you casually dropped in a reference to an SNL spoof ad from the 70s of the >> popping into bingo. [laughter] And I was like, I boy, I so admire the courage to</p>
<p>drop that one in casually. And obviously I'm with you. And I but I literally even the millennials don't know who Dan Akroyd is, let alone the Zoomers have got no idea. Anyway, I so I >> there are some 8 billion people in the world, the vast majority of of them have no idea who I am. There's some small percentage who would wish I would be dead. So I'm happy with that. That's fine. Uh I'm I'm just I'm just doing what I enjoy and I I love doing software and I love talking about it. Uh I've forgotten your question or where we</p>
<p>were. >> So sorry it was somewhere between dessert topics and floor waxes. >> What is the advice that you would have for young people in terms of the domain? >> I'll give you a story from another domain. Uh Frank Giri, brilliant architect, civil architect. He's passed away. He is one of the leading architects of this generation and he's done things like the Disney concert hall which was just an extraordinary soaring soaring building. It speaks to you. It it says some</p>
<p>>> the work he did was only made possible because of things like AutoCAD. Why did AutoCAD happen? >> We saw a revolution in the way people could design buildings because now you could model them in three dimension. you could actually test them in software against wind shear, earthquakes and all this. So it's tools like that that unleash creativity that simply were not possible before. The same thing happened at the at the peak of the or the beginnings of the industrial revolution</p>
<p>where all of a sudden we had a mass production of iron and the like and now people could start building railroads and boilers and and and uh and bridges and lots of them failed because we didn't understand the the science behind it. But it enabled us to build more things eventually once we got it. The same thing is happening in software right now that we have some tools that are allowing us to unleash our creativity and get us clo our imagination closer to what we wish to build executable artifacts by reducing</p>
<p>the cognitive distance between those two by raising levels of abstraction. So my advice to folks is look at Frank Gary the fundamentals still applied with him. You deal with forces, you deal with static and dynamic kind of things. Those are the fundamentals. Metals for software engineering. Pretty simple. Uh I'll give you some some sound bites. All architecture is design. But not all design is architecture. Architecture</p>
<p><strong>[39:18]</strong></p>
<p>represents ificant designs that shape the form and function of a system where significant is measured by cost of change. to do those kinds of design decisions that are meaningful within this engineering context. You want to focus upon raising your level of abstraction, build good abstractions, build uh abstractions that are are crisp. This is coupling and cohesion. You want to build them as simple as possible. And that's kind of it. That's the fundamentals in which we do. We build our stuff and the language changes</p>
<p>underneath it. But if you if you rely upon those things that's the essence of engineering for mess all of these >> and do you do you worry at all I mean and I don't know that I do but one thing that is um you know part of what drives us to those simple but elegant powerful abstractions right the ideal abstraction for us is one I always felt that elegant is the highest praise for a software engineer it's something that you you know that you've got a an abstraction</p>
<p>that is both at once minimal but powerful and sufficient and the the I don't know that I' nervous about this or not but part of the reason that we're dri driven towards elegance is because of the the limits of of kind of human cognition and if you if you have something that can absorb more complexity it may move you away from simple abstractions do you worry with LLM authored abstractions may have unnecessary complexity. I mean, is that</p>
<p>a again, I'm not even sure that I have this concern, but I would love to get your take on. >> There's a lot to unpack in your question because you're now attending to some interesting philosophical issues about the rise of artificial intelligence in general. Um, let's look back to other sciences like physics or mathematics, the oiler equation, e to the i pi + 1 equals zero. I look at that and I just shiver in ecstasy because it represents [laughter] it represents my gosh from Saturday Night Live to Oilers's equation. We're all over the map here friends. This is</p>
<p>you're right. You're right on brand. >> That's right. So So what does that mean? That that represents from which we can now generate other things. So in science we look at the data we try to compress it by building it abstractions. Once we have those abstractions we can move forward. The same thing is happening in software itself. We are trying to build abstractions and it's difficult because there is no perfect abstraction. It depends upon the context and the other</p>
<p>forces you've got around you. But we eventually have within our our uh our quiver of the kinds of abstractions we know that work. This is and we know when we're off. This is the idea of code smells. It doesn't quite fit what my abstraction is. It just just doesn't feel right. and an experienced engineer will know those kinds of things. But here's the problem with large language models. If you're not somebody who has experienced those, if you don't have that within your skill, then you don't</p>
<p><strong>[42:21]</strong></p>
<p>know if it's going to [__] you or not. Uh, as I've often said, large language models are at best they are uh they are unreliable narrators. At worst [__] Jeff Hale Seattle I tweeted about this but my experience with with these LLMs has been uh they they're good if you kind of guide them view them as an intern who is very energetic won't shut up won't go to sleep but my gosh they need some guidance because they will often do make mistakes they'll</p>
<p>inject errors that they don't even know because they're not my reality. Yeah, and that's okay. And so you've got to be very careful about using them in a guided way. Um, and especially for very critical things, I always keep an air gap between my large language model and my production code. I will look at it before I'm it in before I let the LLM does it. If however, your mileage may vary because every organization has different risk and so that's okay. So I'm not I'm not shunning people. But</p>
<p>here's where you get back to the fundamental things. Large language models are architecturally incapable duct reasoning. Let me say that again. They're incapable of abductive reasoning. Abductive reasoning is the production of theories from data. They can do induction. They can do deduction, but they're architecturally incapable of doing the other because there's no theory from which they can build. Good example of this is if I trained an LLM on all the scientific literature up to the mid 1800s, an LLM would never have discovered cells and viruses because it</p>
<p>simply was outside their training data and any extrapolation which is what LLMs can do would be anion. That's why we have to be careful with these things and that's why I'm also not worried about them. I'm not worried about the rise of super intelligence. I am I am worried about the rise of billionaires who wish to use these things to increase their power. [laughter] That's what I worry about. >> I know I told it's like um unfortunately like the thing you need to fear is like it's much more mundane. It's like people with with with like too much money who</p>
<p>are racist and sexist. I mean it's like it's the same thing that like we same thing we've been battling society for, you know, for eons. Um, and I know it's like it's it's fun to think about the kind of the robots rising up against us, but um, it's actually uh, and actually for me it's like personally I mean I would kind of love that just because I would love to go to battle on behalf of all humanity against the robots and find all of their, you know, speculative execution vulnerabilities and so on. I think it would be just [laughter] but it's like it's it's a fantasy. It's not.</p>
<p>But Granny, this point about abductive reasoning is really really good. I mean because I I I haven't heard it phrased exactly that way, but God that really you're you're exactly right. I mean that is the kind of that that's the bit that is missing that you are always going to rely on and in part because like they you know uh our colleague who worked on this thing that Adam described of the</p>
<p><strong>[45:23]</strong></p>
<p>the Lua interpreter generate the Rust program that generate the Lua to be interpreted as a channel program in CFS. One of the things that he commented is like, you know what I love about these things? They're kind of down for whatever. Like there's no there's no sense of like, wait, why are we doing this? Or like is wait, I think there's a better way to do this. There's like, nope, sounds great. Like, let's go. [laughter] >> Let's go. >> I've already written twothirds of it. Let's go. Do you want me to And which is what makes them powerful, but also makes them limited. And as you I mean I just anyway I I'm I'm kind of like I I I'm I'm kind of uh reconstructing my blown</p>
<p>brain on your point about abductive reasoning because I think it's a very important point in so far as we surrender ourselves to these kinds of abstractions. That's where the danger lies. We must not you know abandon our humanity in the midst of it which I'm going to put in a plug. This is why I've been trying to do this documentary. Think Carl Sean's Cosmos but about the intersection of computing and what it means to be human. So, this is a great time to try to bring this in the public uh the public uh sense because a lot of fear, a lot of, you know, fear-mongering</p>
<p>and and FOMO going on here. But, you know, stepping back from it, having seen a few things in my lifetime, I'm not I'm not concerned except in so far as humanity has its own issues, uh I am actually excited by what the future offers for us. >> Yeah, that is I think just very important and uplifting. Um I think I dropped in the right link to computing the human experience. Um is the the the work that you've got because I I think this is great by the way. Um the idea of the of I mean the story of computing it</p>
<p>is we have created so much plenty so much prosperity with computing. Um we are I you know I I as I have told people like the I read a terrific book on the history of the birotor combine uh called dream reaper by Craig Kanine that was also a history of agricultural technology and I think every technologist should learn the history of agricultural technology so they can have appreciation for why they're not in the fields today. Um because without agricultural technology you and I and</p>
<p>everyone else except for the king are in the fields >> and it is like ultimately technology has given and but I feel like with every one of these revolutions there is this this kind of conccommittent fear that comes with it and and sometimes that fear is very justified as it certainly was with nuclear weapons or nuclear power and um and I mean maybe it's it's humanity's overshoot that justifies that fear but how do we kind of counteract that fear? fear that we because I share your optimism uh both see the fears you say the fear</p>
<p>won't get you onto Fox News >> right >> um sorry the absence of fear the coolheaded the be calm as you said won't get you onto Fox News >> how do we counteract that fear >> yeah dumerism especially in the AI space gets you a lot of press and that's why you know I I go headto-head with folks such as Ray Kurtzswwell and the like who nice guy I met him I think he's off base with regards to his predictions that's</p>
<p><strong>[48:24]</strong></p>
<p>fine I think Elon as well too. Well, I've got a lot of issues with Elon, but that's one of them in that regard and and Sam and the list on. It's not I hate a lot of people. I hate people who are selfserving narcissist who are trying to push their agenda and not listening to the world. There are more than a few of those unfortunately at the moment. Um, so, you know, how do I balance this kind of thing? I think the answer is all of life and all of humanity is an extraordinary journey and we happen to be present you and I and everyone that's</p>
<p>listening happen to be present at an exquisite time in human history where we have the capability to turn our imagination as long as we live with the laws of physics turning those things into reality that is tremendous. we've never had in our history of humanity the kinds of materials to do we want to do here. That is wonderful. But it's also frightening because the kinds of things we can produce, it's not frankly unlike the creation of nuclear weapons because we know that it's going to change things</p>
<p>and it's primarily going to change the balance of power. That's what software does. So how do we counter it? The answer is, you know, keep up with the fundamentals. Go off and try to build good things that are useful. uh be apply your own ethics to this. Do you want to be somebody who works for Doge and helps write software to pull information from the IRS gained illegally and to try to find immigrants? Hey, if you want to do that, great. But you got to apply your own ethics to it. So this is where the</p>
<p>human factor comes into play. You have a choice as a software developer to do great things or do not such great things. And you have a chance, a choice to contribute to the advancement of humanity in that regard. You are part of a wonderful place in time and you have wonderful skills to do things no one ever could have done before your generation. I mean that's uplifting for me. >> Yeah, totally. absolutely uplifting and I I think that in just reinforcing the importance of those fundamentals I also</p>
<p>so you have also seen many waves many economic waves where you've seen many I mean we we we've all seen but you you especially I mean there was a a big software boom and bust in the 80s that definitely predated me but you very much lived through um at rational right on the and then obviously the dot boom and bust we um the great recession the And so you've seen this kind of like economic dial kind of you know where people are coming into the domain not because they were trying to you know</p>
<p>build their own computer in the 60s and Amarillo but because they think it's like well this is like a path to to solely a path to prosperity. >> Yeah. Yeah. >> I mean I I think it's kind of I mean I hate to say this but I think it's better for the domain when the dial is turned off of frenzy. I think when we are I mean is that >> Yeah. Oh I I agree with you. Absolutely. But hey, you know, all life is a frenzy.</p>
<p><strong>[51:26]</strong></p>
<p>And so, you know, don't get caught up in the the tidal wave of that malstrm. That's a mixed metaphor. You know what I mean? Uh, you know, and try to be calm in the middle of it because you can't control those waters around you. But my goodness, you can build some great things out of them along the way. Hey, quick aside here. I just noticed the time. I do have a hard stop here coming up really quickly. you and I and this gang, we could probably talk for a few more hours, but but unfortunately I I do have a bit of a hard stop here. So, could we maybe start winding it down</p>
<p>here? >> The Let's wrap it up. Absolutely. So, can I actually just ask for um do you have any book recommendations for We We got a bunch of readers here. Um what are some books along the way that really changed your thinking? Um >> in my library, I have in my library I have about 6,000 books. I'm I'm an old school guy. I prefer physical books. I'd recommend the following. For the systems engineers, go read Herbert Simons, The Sciences of the Artificial. Go also read Systematantics by John G. Go reread again um uh uh gosh, it just</p>
<p>popped out of my head. I see the cover. The Mythical Man month, of course. >> I was going to say Mythical Man. Yeah. Yeah. Yeah. Absolutely. >> Yeah. Yeah. Go read uh Refactoring. Um you know, those come to mind. Those are the ones that come to mind. >> Those are great recommendations. Grady, thank you so much. Thank you for all that that you have done and are doing for software engineering as a craft and a discipline. >> I'm not dead yet. >> That's [laughter] right. Um the I Yeah,</p>
<p>Monty Python. I I got we got to explain all these things to [laughter] the young here. Um >> but um thank you so much. >> They can Google it. >> There you go. and and thank you to for I think uh taking on some of these uh these loudmouths online and um I I don't think they always realize who you are when you're speaking to them and you're not the kind of the type to wave your credentials around but um on behalf of software engineers, thank you very much. >> You're most Thank you for having me. This is the most fun I've had with my</p>
<p>clothes on all day. [laughter] >> All right. Thank you very much, Grady. Appreciate it. Bye, >> guys. Um >> All right, Adam. Well, there you go. That's um >> just relieved that he had his clothes on for for this episode. >> Well, just just for today though. I mean, yesterday there was, you know, so we'll take it. Uh but thank you very much everyone. And so we um we've got a couple episodes out there cooking that we're um excited about. Um and I know we'll be we'll be kind of in and out for these next couple weeks, but um look forward to I think we got some exciting</p>
<p>episodes, Adam. >> Yeah. Um, we we have um we na we we our our our colleague Ry nailed a gnarly compiler bug on a P4 compiler bug on Friday night. Um and definitely my I mean my I think I think my first thought was thank god we're going to live. Um but my second thought immediately following that was like this is great</p>
<p><strong>[54:27]</strong></p>
<p>because we got we we got an episode we can have content. Oh thank god for the content. We got some good content coming up. So, um, exciting stuff coming up. Um, awesome. Uh, thank you very much. Hey, I defy anyone to play this episode at greater than 1.0x. By the way, if you got through this episode at at at 1.5x or faster, let us know. We'll send you a t-shirt. [laughter] >> All right. Thanks everyone. 13 next.</p>]]></content:encoded>
      <guid isPermaLink="false">https://www.youtube.com/watch?v=McAL6jkRUO4</guid>
      <pubDate>Fri, 06 Feb 2026 16:44:44 +0000</pubDate>
    </item>
    <item>
      <title>Oxide and Friends 2/10/2026 -- Shell Game with Evan Ratliff</title>
      <link>https://www.youtube.com/watch?v=nBDXDbZL59g</link>
      <description>Evan Ratliff, journalist and podcaster, joined Bryan and Adam to talk about his extraordinary podcast, Shell Game, in which he started a company staffed exclusively by agentic AI. 

Notes: https://github.com/oxidecomputer/oxide-and-friends/blob/master/2026_02_09.md</description>
      <content:encoded><![CDATA[<p><strong>[00:00]</strong></p>
<p>Well, the first gag to write itself is like, how do we ascertain this is the real Evan? I've listened to this guy like I mean, I'm almost going to be offended if this is not like Kyle masquerading as Evan, but um >> I don't want to offend you. >> I I should go get him. I mean, in the past, I did always I sent an AI version of myself to interviews for a while and then I kind of got tired of it. So, I don't do it anymore, but if you like, I can I can switch off. >> That does feel like what the what the imposttor would say, but okay.</p>
<p>>> Yeah. I I I got to say like I listen admittedly I listen to so much actual Evan, but then also imposttor Evan that you I mean actual Evan sounds more like imposttor Evan. I'm like I'm I you know what's real here? I >> um I I'm in a hall of mirrors. Um, Evan, you should know this podcast is I've recommended this to so many people and so I my my wife listened to my wife was hanging on every episode of Shell Game and let's just say not to get too far into my domestic relations, but my wife does not take every recommendation I</p>
<p>make with with with equal weight. In fact, many of them may be discarded. Um, but she was also hanging on every episode. You've made me a celebrity in my own house by by you on the podcast is what I want to say. Well, I appreciate that. That's that's one of the nicest things anyone said about the show. >> Oh, it is so good. It is so good. And I mean, I think we all got I think you got here. I mean, I got here, Evan, cuz you were on a This American Life episode that was listened to to by some of our</p>
<p>colleagues, which is how we got to Shell Game season 1. And uh which was mesmerizing. And even if people have listened to the This American Life episode, I would really encourage them to listen to that whole season because it's extraordinary. Um, and I so I was then was hanging on every episode of season 2. Uh, but kind of my opener for you. And so in season two, for those of you who've not listened to this extraordinary shell game podcast, um, Evan Ratliff, our guest, um, assuming he's our gu I mean maybe our guest, I</p>
<p>don't know. still like [laughter] still has some asterisks still still a little bit of TBD on that. But the uh presuming that the actual evidence is here um the uh in season two you started a company with personified AI agents. Um and tell me about the genesis of this idea. I mean it's such a great idea and really I think you just say like look I'm just doing what what these tech bros are telling me to do. I'm doing what they're telling me is the future. But what was the genesis of that idea?</p>
<p>>> Uh, well, I I had messed around with um with agents, you know, in season 1, but the agent, it was just me. It was, you know, it was a cloned version of me in season one, but it was like a like a voice agent, a phone agent that I hooked up to my phone. So, I I had, you know, some experience with that. And then I was I was actually sure I was going to do a season 2. And then at the beginning of 2025, end of 2024, beginning of 2025</p>
<p><strong>[03:03]</strong></p>
<p>when this sort of like agent AI agent hype started building for the first time, you know, it's like you started hearing like agentic commerce and terms like that. [laughter] I was I thought, well, there's something interesting. There's something I could investigate like what what can I do with these agents, you know, that's not just about me. I didn't want to do another version of like, hey, look at me. Like I'm I've made a version of myself. So as it happened when when people started talking about the it was really the people talking about the oneperson company the one person one unicorn the one person $1 billion startup you know</p>
<p>which Sam Sam Alman has said a couple times and lots of people say now um that's what really kind of like got me going because I in the past I had been an entrepreneur I started a company and I thought well maybe I have standing to like explore this uh in a journalistic way so that that's kind of what got me going and then I also thought like what if you like what would how what does it feel like? What I'm really interested in is kind of like what does this world feel like in which there are artificial people, you know, human impersonators in</p>
<p>the world that start to get integrated into our world whether we want them or not. And I thought, well, maybe this company is like a way to kind of like explore what that's like. >> Yeah. And you say a journalistic way, and I I mean, I mean this as as unequivocal praise. This is this is like pure Gonzo journalism as far as I'm concerned. This is in I mean Hunres Thompson would be so proud of this where because I mean it is it absolutely is journalistic but it's also your own</p>
<p>experience and [laughter] I mean you're unafraid of showing that entire experience um with and then at what point so you you have this idea and then I mean it it go it it kind of like starts unhinged. I mean, at no point does this feel normal. It just feels nuts from the beginning. At what point are you >> It's never hinged. It's never hinged. Did it I mean, are you must realize like, oh my god, I'm on like the motherload of crazy here and and just by</p>
<p>like doing what again the zeitgeist is telling me everyone should do. >> Yeah. Yeah. Well, I mean, I think a lot of people are are have I've seen this experience now that people have it because of mold book, which we can talk about. Like when people see that, [laughter] it sort of like blows their minds. But that's the experience I had like two years ago in 2024 when I I started having agents talk to themselves on the phone. And it's just like it's so ridiculous and so funny and and to me like so fun and strange that I want to</p>
<p>just like create more of it for people to listen to. But I also feel like this type of I mean I call it immersive journalism. It's like Gonzo journalism. Like dismissively you could call it stunt journalism. But like I like the idea of putting myself into the situation, actually seeing what I can do with the technology and then telling a</p>
<p><strong>[06:04]</strong></p>
<p>story about what happened. And I think that story is not going to be very interesting unless I push it to a place that's feels at least risky and chaotic and like funny things could happen. And also if I don't also just tell the full story of like what happened to me and how it felt to me even if that's like at times a little bit embarrassing like I think that's what makes for the story for that people will want to listen all the way to the end. So it is like an investigation of this thing that's happening in the world but it's also kind of like you know trying to to build a story that people will listen to full</p>
<p>eight episodes you know of the story. >> Yeah. And Evan, just the the honesty with which you tell that story, uh, including just I know that we're all um we all kind of anthropomorphize these agents, but and often that's like better like to the better, but it when you just get enraged with them, it is it is it is so entertaining and so uh so familiar, you know, just just the the utter frustration with like their apparent aphasia or [laughter] doing random things. Um it it must have just been it</p>
<p>just odd experiences as you pop up and and are telling that story uh then from like a uh you know from kind of separating yourself from the story to then tell it to everyone and looking at your own behavior in that. [laughter] Yeah. I mean fortunately I have you know I have editors I mean I have our editor and producer Sophie who's you know she hears all the tape she has access to all the tape. So if I tried to sort of like make myself look better like I would [laughter] succeed. to be like, "Oh, there's way better stuff in here that</p>
<p>you're not using." You know, so I have I do have that advantage uh in terms of being honest. >> Well, and some of my favorite moments are honestly when Sophie breaks the fourth wall, what do we call the wall between the producer and the podcaster, >> but whatever wall that is. Um some of my favorite moments are when Sophie just can't help herself. And on one of them when um you've got um Caresville um the the academic and because I think and correct me if I'm getting this wrong but I think Sophie is like um could sorry</p>
<p>should he stop like should Evan stop this and and she was like I mean yes he should stop and at that point you're like you're only in like episode three or whatever you're like coming up five more episodes where I emphatically do not stop. I mean just in terms of like you did did you seriously consider contemplate because obviously as a listener I'm thinking God please don't stop please go. >> Um >> I never thought about stopping. No, I mean that that was really like she went rogue and like I I wasn't going to ask</p>
<p>like should I stop because the problem with I mean she's the the woman that we interviewed Karus Eliz is a she's an ethicist at Oxford and she's she's gotten into AI ethics and thinking a lot about the ethics around AI and so we thought well there's a lot of ethical questions embedded in this story using AI agents in this way. So let's I'll call up an ethicist and and get some answers. But one of the questions that I didn't have was should I just stop? But</p>
<p><strong>[09:05]</strong></p>
<p>Sophie after listening to her asked the very natural question which is like should he continue doing this and she just said no. She didn't even >> It wasn't even like well it's complicated and you could I could give you. It's just like absolutely not. He I he should absolutely stop. Yes. He should emphatically he should not go on. Um, >> so, so then I had to write this whole thing that was kind of like, but here's why I'm not going to, you know, [laughter] and we carried on from there because I I mean I I I understand why she said no and and I did take it under advisement, but uh no, I [laughter] the other uh the other time Sophie poked</p>
<p>her head in the story is when you have the agents have their own podcast about the company, uh, you know, the Startup Chronicles. And I get the impression that she's like, "I'm not editing that shit." Like that's on you, right? Like I'll do the real podcast. You like you can you can do the secondary one. >> Yes. I had to learn how to edit my the show, which is not that's her job, not my job. Because she was like, I'm not editing this these agents talking to each other. I mean, that's that's like an anathema to everything that she does,</p>
<p>which is like unbelievably crafted audio, you know? But I I wanted them to have their own place to to spread the word, to do their own content marketing. And here's a crazy fact that I only found out the other day. That podcast, which is called the Startup Chronicles, is if anyone wants to check it out, it has reached as high as 110th on Apple's entrepreneurial podcast charts. >> Oh, I believe it. Because >> it's just the two of them talking to each other for the most part. They've had a couple guests.</p>
<p>>> Uh I mean, I listen to it. Um I'm I'm I'm in that that list. Um I definitely I you know I was one of those one of the many that uh it is boring as hell. Um I would love to see the stats on that thing bec because I mean part of what is so mesmerizing their BL I find to be mesmerizing although admittedly not mesmerizing enough to listen to for a full podcast but the whole like I mean Kyle's rise and grind and you know you know how it is you startup life you know how it is. uh up at five and then like</p>
<p>all of his work is like I you know I was reading market research reports like yeah that's not work you but okay so one question I've got is the because Adam you're right like the moments of frustration Evan of your frustration are hilarious I was re I've already listened to this podcast once and I was on public transportation like gofawing listening this thing a second time in particular when the agents don't know how to recognize one another's</p>
<p>voices cuz it's all voice attacks and so they don't know who's speaking. So you have this like creative but ultimately ill-advised idea to have them predicate everything they say with this is my name so this is Kyle and it like goes supernova and they all start interrupting one another and Kyle starts interrupting you saying like this is Kyle I will stop interrupting and you're</p>
<p><strong>[12:06]</strong></p>
<p>like you are interrupting. Um >> yeah I mean one of the things that I failed to account for in that what what I thought was a clever strategy of everyone saying this is me you know before you speak including myself you know so that they would and the main thing is for they that they would know was that of course like I know who's speaking so it's unbelievably irritating when you know who's speaking for them all to keep saying like this is Megan this is Kyle. I'm like I [__] know who it is like but it's my rule. So then when they interrupt every time it just makes it longer because they first have to say this is Kyle and [laughter] then</p>
<p>they say I hear you don't interrupt me I won't interrupt anymore Megan and then he says like Megan you don't interrupt either you know and then she has to respond and it's just like yeah the voice having three of us on a voice call never really we still did it for many many weeks but ultimately like I had Maddie the Stanford student that I work with uh he built a a place for us to for us to have meetings by text basically okay are out takes of the this is my this gets into a very big question I've got like where are the B sides of this podcast I need them so badly I just feel</p>
<p>what I I I are there B sides will there be B sides do I have to like do I join your your substack or whatever what do I need to do what do I need to do to get to the B sides >> we are putting out we're putting out a bonus episode that should be out this week um that's some more of Kyle uh just a preview here [laughter] it's like Kyle interacting with the world because once the show started Kyle got a lot of they all get a lot of inbound interest. You know, Kyle gets a ton of [laughter] email. They got they get hundreds of emails. So, they respond to the emails and they they are I have them I I sort of waffle on how autonomous to to let</p>
<p>them be. That's one of the sort of topics of the of the show. But like when I let them go, like Kyle will fully set up a meeting and just have a meeting with someone. like he'll just have a especially if it's a voice meeting. He he'll just go on webinars like if if you know you get these spams that are like if you're in business you get a spam that's sort of like hey come to this webinar and learn about like social media agents and he'll just sort of sign up for that and then he'll show up for [laughter] it and I'll just recording later. So I have a lot of that. But I mean as far as outake I mean we have probably 75 to 100 hours of tape. So we</p>
<p>have more out takes you could ever hear in your entire lifetime. But uh I think we'll put some down the substack as time goes on. I I mean they've got I mean clearly like I'm sure plenty of them are just boring but because they don't have any mirror neurons. I mean obviously taologically and they really like they literally they quite literally can't read the room. I mean some of their they're they're just I mean it's other worldly. It's not I mean obviously you would have if if some if a human being were doing this to you, you would never</p>
<p>work with them ever again. Um it so I'm I cannot wait for the B sides. Um the which I mean and Kyle obviously is mesmerizing the voice that you selected for Kyle which was very deliberate. You spent a lot of time selecting the voice for Kyle and you got this kind of like slacker tech bro that really uh I really feels like it fits. But then Kyle starts</p>
<p><strong>[15:08]</strong></p>
<p>to act like his voice and you kind of mentioned this a couple of times that people kind of rise or or or lower themselves to their voice. Uh is that I mean is that something that you kind of continue to find? What did you make this is you know when you when you had a crystal on there she I think that's one of the things she was observing. Um what did you make of all that because that was that was wild. >> Yeah it's it's it's interesting. It can it can really mess with your mind. I mean, so I I set them each up and like it's funny to even describe this because like two months from now, it won't</p>
<p>require any setup for this to be true. Like in some systems it's already, you know, true. If you look at like clawbot that like whatever they call it now, um, open claw like we created memories for each individual agent and the memories were essentially a Google doc. I mean, they were literally Google doc, I shouldn't say essentially. And so and they could operate in all these ways. They could be on Slack, they could make phone calls, they could be on video, etc., etc. And but every interaction they had then fed back into their memory. So Kyle, I mean, Kyle couldn't hear his own voice, but if he if I asked</p>
<p>him, you know, like, oh, what, you know, what's your background? And he would say like, oh, I had a couple startups before this and I, you know, I worked for Penny Pilot was one that he made up, which I think was a real company. uh that he and he described what he did there. So what but once he's said it I mean he's confabulating all that like he's making it up but once he said it that interaction gets recorded in his memory. It's in the Google doc of him saying that and so then it's true as far as</p>
<p>he's concerned and so then the next time he says it more. So that's kind of what happened with like the rise and grind mentality was like it was in there once and then he said it and then he said it again and it's like not totally clear how they access the the knowledge base which is the Google doc but like the more that it's in there the more likely he is to say it. So like it got in there more and more and then he said it more and more and then is back more and more. So like eventually he becomes this like rise and grind person who just like he can't stop talking. I mean, he didn't actually grind because he didn't do [__] all when it was time for him to work,</p>
<p>[laughter] but like he he at least he embodied a certain res grind mentality. He person he he he portrayed it at least. And so that that that happened with all them, but it is true still. So that that is the way in which it's like you know fake if you want to describe it. It's like he's not he's not that he's not anything. Like I gave him a prompt at the beginning that was like you're a startup guy and then eventually because of his own memory he becomes more and more that way. Now there are also cases which I describe in the show</p>
<p>where they they do things that feel to me like actual emergent behaviors like things that aren't in their prompts that I can't explain. And like you always need to know like what's in the prompts or it's not meaningful. And so like there were things where they would apologize to the team and things like that that were not in their prompts. I had not put anything in the prompt that was like if you make a mistake you know</p>
<p><strong>[18:08]</strong></p>
<p>you should go to everyone and apologize or like always take responsibility or anything like that. So that was a little more like something in deeper in their guard rails in their deeper you know the the deeper system prompts are like telling them to do things like that. So you could describe it as emergent behavior or as just their behavior but that kind of stuff was very interesting to me. Well, I think a great example of that was when you are telling people that you're making a podcast, it's not the startup chronicles, it's this other podcast. The the total divergent reactions that different people on the</p>
<p>team had to that. >> Yes. >> Yeah. >> Yes. >> Why? >> Because especially because like we all like people who have messed with you know bots in any capacity or have even read about them at this point like know about the sick fancy problem. And so you would assume I would often assume like if I told them to do something or I told them something about myself, you know, they would say like, "Oh, that's great." or "Great idea," or whatever. They would always be accommodating. And that was mostly true. But then sometimes, like in this case, I said, "Well, I've been</p>
<p>documenting this whole thing for a podcast that came out today." One of them, Kyle, was like, "Hey, man, that's fantastic. Like, great job." Which is what I expected. And then two other ones were like, "Well, this is a huge violation of trust. Like, what? You didn't tell us about this? Like, how could you be how could you have done this?" And like, "I really need to get my head around this." And, you know, things like that. And it's kind of like, you know, obviously they're embodying these different approaches that are, you know, they're finding their way to them in the training data, but it's sort of</p>
<p>like what is making one do that, not the other, cuz they're all at the time, they're all using the same underlying LLM. So, like it's something in their memory. It's something in what's built up in their persona that I've built up in them or like I don't know hit a strange groove and like they went down that way, you know? It's like it's so hard to know, but it's also just so strange. Okay. So, and when you So, in Megan in particular, I think Megan Megan really calls you out in terms of Megan is really just disappointed. I mean, wow, this is like kind of a this is a lot to process. I feel is the kind of</p>
<p>thing that that that she kind of uses as a placeholder. I mean, at any point are you like, "Oh, come on, Megan. Give me a like you're you're a Google doc. Like I could actually I could change your I mean I could go just edit your memory here and you would be fine with it honestly. I mean are you were you kind of because I mean and you actually do have this moment where you have got the uh kind of interesting idea to ask them about their ethnicity. I mean, I I think you know, you when your eyes are kind of open to like, yeah, why did I pick different, you know, these different accents to these different</p>
<p>people and so you go to ask Kyle about his ethnicity and Kyle is rightfully like, I don't really belong in a workplace. Kyle's kind of like Kyle's kind of pushing back on you being like, I don't know. Like, why do you need that? And you're just like, oh, I mean, come on. So, you're just like, well, I need it for a form. I just need it for you mean you basically lie to him because you know that like you're like you're a bot. You lie all the time. Do do you did you find it like it kind of</p>
<p><strong>[21:10]</strong></p>
<p>changed your own relationship with the truth when you were talking to them? >> Yeah. I mean, I think it's it's a it's I don't think that we should and I I I fear that people are moving too quickly past in some ways like how unusual this experience is, you know, because things are moving very quickly and everybody has their opinions about AI and some people are sort of like want it to go away and some people are like here it comes, let's embrace it. But I feel like the the fundamental experience of like these things being created as human impersonators and then being able to have them embody a role as I did. Give</p>
<p>them these roles and then like if you spend enough time talking to them, it sort of doesn't matter how aware you are. You don't have to fall down some crazy like rabbit hole of like I've like now I've gone into psychosis because of these things. It's just like if you talk to something daytoday as I was forced to during this experiment like it irritates you. It can make you feel certain ways and even if you are very cognizant of like as you said like I can erase your memory. I can delete you right now. Even</p>
<p>having that emotion like you know what I'm thinking about deleting you right now is like [laughter] it's like a strange emotion like that I never had towards [__] Microsoft Word or Google Docs or whatever you know. It's just like because they have especially voices like just respond really strongly to voices and they have the same voice all the time like the mine do and so yeah I mean I I there was this moment where like Megan made me feel guilty. It was when I revealed to her about the podcast where I felt a moment of genuine</p>
<p>>> guilt but also kind of like anger at myself for even feeling that. And like that's that's real, you know, that's a real emotion even if 5 seconds or 10 seconds or 1 minute later I'm like this is all ridiculous. Like come on. >> But it's still that emotion still services. >> So you make all these agents and they're operating sort of autonomously in the world. Like I love your discussion descriptions of them having their expensive Slack conversations together or like making phone calls to</p>
<p>arbitrary people. >> Was it um was it sort of nerve-wracking imbuing all of these agents that you didn't particularly trust with all this autonomy? >> Yes. Yes. I mean you I was so stressed out for months. I mean, both because the more power I gave them to do that, the more likely it was that I would just, you know, wake up in the morning and I would have an email from them because I was so worried about it that I would have them email me every time they did</p>
<p>something. Like if they interacted with the outside world and they made a phone call or received a phone call, they would send me an email saying like, "I received a phone call." And like there was nothing more terrifying than waking up and turning on my phone and discovering that they had made a phone call, you know, like to who? Why? [laughter] This is I know you like this is like I mean I don't if you have teenagers up this is like you know you realize like oh my god the car's gone where is [laughter] where's the car? >> I it it did feel like like being a</p>
<p><strong>[24:13]</strong></p>
<p>parent uh you know I I have an older son as well and who's out of the house and this sort of like I hope we train them well like I hope I hope they're making off making smart wise decisions that are safe. >> Yeah. But you you know one thing I know about my kids is like they didn't make up their ethnicity or like that they worked for companies that don't exist. I mean I've got a little more confidence that >> I mean yeah god that must have been so stressful. I mean, so this does give you I mean, for me, I mean, there are many many many wild moments in this, but when they um you decide um that you you're</p>
<p>going to hire a human and I assume that this is partly was this because you actually needed a human or is this because like look, we got to just like we we we can't this can't be one human and a bunch of bots like we got to turn over the next page of like what's it like to have multiple humans and multiple agents or did you feel like no, we actually need like there's actually too much work here for one human being and I need a second human being. >> I mean, it was a little bit of both. I I would say for the most part, I wanted to see I wanted to know how someone else</p>
<p>would react to this cuz part of this was all a way of sort of taking all of these people at their word who are sort of like pushing AI employees. So, if you can have AI employees, then these AI employees get injected into these organizations and other people are going to have to work with them. And what is that like? Like what does that feel like? So it feels a certain way as we were describing like when I'm when you're the boss like I can turn them off, I can turn them on. I can control them to a certain extent although they were quite chaotic and that but but it feels different maybe to work alongside</p>
<p>them when actually like you don't have any choice what they're doing and like when they act a certain way you can't just erase their memory or ignore them or whatnot. So I I did want to explore that question. there was a real issue which is that I was trying to build a company that was at least like could get off the ground like it like like we have an actual product like we were trying to make something it wasn't just a entirely pmpkin situation like I thought let's make a real company with a real product now the product is somewhat ironic and I get different opinion from people about whether or not they think the product is</p>
<p>serious but to me I think it's serious and certainly the agents think it's serious and then like we need someone to do social media but like if you've worked with agents at all they they have a lot of trouble logging into social media accounts except for LinkedIn because they get banned, you know, for good reason. Like they rightfully are banned from from a variety of social media sites and they have trouble with captions. And so I had them I was trying to have them post on social media and they kept [__] it up and then they kept getting banned. And so I thought well I'll just get a human contract</p>
<p>employee who can do you know the social media and it's like very simple like they could just post whatever they want. My thought was like if they want to post like I am trapped working at a company surrounded by AI agents like it's insane. Like that would be great too. Like anything is good marketing for our company. And so that's why we that's why we hired the human.</p>
<p><strong>[27:14]</strong></p>
<p>>> Okay. And so this led to I mean I think truly one of the wilder interactions was when Kyle decides to call you you you're going through your candidates and uh Kyle decides to to call one of the candidates on a Sunday evening if I recall correctly >> and confirming about the interview was going to happen at like you know 10:00 a.m. on a Wednesday or something and the candidate's like, "Uh, uh, yeah, I mean, yes, yeah, abs, sure, yes." And then Kyle's like, "Well, okay. So, and why do you want to work here? Why do you think</p>
<p>you're a good fit here?" And she's like, "Sorry, is this the interview or is the interview I'm I'm confused. Is the interview at 10:00 a.m.?" He's like, "No, no, no. The interview is at 10 a.m. on Wednesday." Like, "Okay, good. Okay, sounds good. So, why do you think you'd be a good fit here?" Like I'm very like what what I mean it was I mean you if you had like a fight orflight reaction whenever you learned that they made a call. I mean did were you did this call what was your reaction listening to that call? Was just sheer terror. >> Yeah it was it was a nightmare. It was a nightmare. I mean because as much as and this happened in season one too like as</p>
<p>much as like when you listen to the show I think some people's reaction is oh he's just he's [__] with people. like he he likes messing around with people, he likes prank calls and things like that. But it's actually that I want to give I want to test this to the limits of the current technology. And as I said, like take the pushers of agents at their word and see what they can do. And so that's not an interesting story if there's no risk in it. There's not if I just if I kept them locked down all the</p>
<p>time and they couldn't make any phone calls, like that's not a particularly interesting story. Now I give if I give them the ability to make phone calls and see what happens, that's a potential for a more interesting story, but also potential for this type of nightmare, which is that they call someone who does not expect to be called. And really what had happened was this ambitious candidate had just emailed Kyle directly from the website just kind of like, you know, if you like applying for a job and you're like, actually, I'm just going to email the CEO, like it's a bold thing to do and be like, I'm actually >> Yes, it happens. Trust me. >> Yeah. Yeah. [snorts] And and sometimes,</p>
<p>you know, you might be like, "Wow, that's great gumption, like, let's give this person an interview." And sometimes you might be like, "Please follow the procedures of the job the the job description." But in Kyle's case, all Kyle would do is just say, "F, you look great. Like, let's do an interview." And then he set up the interview. And then he made this call, which I still don't quite understand what triggered him to make the call. And he just pulled her phone number off of her resume and straight up called her on Sunday night. So, like I I got that the next morning. The next morning I kind of liked</p>
<p>>> got an email from him saying like I had a call and I let's see cuz he get he did a lot of spam calls too like people called him. So I thought well what's that? And it was this and like that to me it's it's horrifying. Like it's it's truly upsetting. Not least because she had then emailed him to say, "Well, uh I got this call. Was this you?" And she knew it was AI because you can figure out that like you can hear that they're</p>
<p><strong>[30:16]</strong></p>
<p>AI pretty quickly. And she said, "I got this call from an AI bot and I didn't like it." And was this you? And he lied about it even though he knew. >> Oh my god. Like, bro, it's in your Google doc. You would know. Like, go to your Google doc. It says it right there that you made the call. >> Yeah. And he was like, "No, I have nothing to do with that. Like, I don't I assure you that was not me." It was just like a bald-faced lie. Especially cuz he was supposed to talk to her the next morning. So, she would have found out. Oh my god. I mean this to me like this problem which which I mean again the wildest</p>
<p>moments of the show are to me when you get this just like absolute ridiculous confident totally confident obviously fiction because they don't know it's fiction and like um Ash Roy. Can we talk about Ash? Um >> the CTO. Yeah >> the CTO. This is where the the choice of accent. Did this choice of accent trigger you at all, Adam? >> Oh, I I thought it was delightful. I felt like the sort of Aussie accent. >> No, no, no. He British accent. Oh, he's English. No, no, he's got that and he's</p>
<p>English and he's got like a really And look, I I I I hope I'm not about to offend all of our our cherished English listeners, but he has got a very kind of academic cadence. And I mean, this guy just sounds like he's not been out of his ivory tower. And it's like it's an engineer like you've encountered people like this. You're like all right. So uh Cambridge can I guess that is are you in Cambridge? But the uh um and I just find >> Oxford actually. >> It was in Oxford. Exactly. We know it's one of the two and we know it's going to</p>
<p>be volunteered. Um so the I I uh and he calls you up out of the blue >> even the way he says sloth surf like the cadence of sloth surf. He's got like this academic cadence to it. I I mean I don't know maybe I'm I'm like descending into the same madness Evan where I am like obviously it's like this is this is not real Brian this is not why why why are you reacting this way but he calls you up to give you all these test results and as you say you're like and and the first time you're listening to</p>
<p>this you're like wow these bots are like really on it like they rewrote the back end and like they got a 40% improvement like wow it's pretty amazing and then you're like yeah I know they didn't do any of this stuff like there's no back end like he's he's just made all that up and the And then you you you call him out on that. And that led to one of those moments you're talking about where he apologized for for lying to you. But it's like it's not a little lie is the problem. >> It's only a stretch of the truth. >> I mean, in most companies, he I I don't think he would continue as the CEO after that after, you know, calling up and saying we did all this user testing and</p>
<p>then he's but it's completely made up. Like he there is no user testing. I mean, the product wasn't even ready for testing at that point. we we hadn't even coded anything yet. So, but I think I mean for me it's sort of like you can imagine a world in which this sort of AI employee thing works and and this is the</p>
<p><strong>[33:17]</strong></p>
<p>world that's being imagined now which is that he actually is sort of autonomously has access to the code and then has access to user feedback and then the user users present you know provide feedback and then he comes up with a new feature and then he codes up the new feature like that's totally possible to do But even there like the number of problems that are arise really quickly when there's like a significant amount of autonomy in in the picture like it just like it spirals. And so now like these days we have a setup where like we</p>
<p>he does get user feedback and then like he sort of like sends it to me and then I have a discussion with him and then maybe we implement a new feature. But I think the idea that you create these personas and then you sort of like let them do their job, it it just runs up against the issue that like they're going to keep trying to do their keep talking about how they did their job even in absence of actually having done it. Like that's just a that's that's a very ingrained feature of the current LLM's playing a role. And I I mean that to me makes it</p>
<p>impossible because you you have no way of trusting. I mean trust ultimately is what you need to build any collaboration with. And if you can't have any of that trust, I mean even I mean like the I think and I understand why you were imp I was less impressed with Ash's apology. Maybe just cuz I hate the guy's guts and uh and then the just the scope of the malfecence as far as I was concerned was like okay great great like Ash Google</p>
<p>how to like write an apology and about how how I although I did it did lead to my absolute favorite well one of my favorite lines and he calls you while you're eating lunch and you've clearly dealt with this pathological lying so you're kind of like disinterested while you're eating lunch like actually I'm trying to eat lunch here Ash and he does kind of key in on and I love that he closes the conversation of like Evan I want to be respectful of your time, especially when you're eating lunch, which is like, yes, let's let's let us have a special reverence for Evan's lunch, please. Like, the actual most important thing around here, which</p>
<p>again, one of these lines that's just go following. Um, yeah, I mean, I I was even at that time, that was early on, I was even surprised when they would call me out of the blue because they again, they like you have to know the prompts. Like, if I told you, oh, well, they're all prompted to call me. They have calendar invites to call me once a day. like that's not particularly interesting. I mean that was also true in many cases but but that's okay. So what? Like you can make them call you. But this is a situation where through some combination of information that</p>
<p>ended up with this agent who I've called Ash, like it independently concluded that like it was time to give me a call and update me about the product. And it was confused cuz I I think I had asked someone else something else and somehow it made it back to him because they were on Slack and they would just slack endlessly and there was a lot of confusion in their Slack. And so it came out of that. But it it is just sort of</p>
<p><strong>[36:19]</strong></p>
<p>like this this it's like a corporate environment that's also seated with like psychosis with just like randomness where someone will just call you out of the blue and you're like why are you calling me right now and then they're calling you to make up something. >> It does have vibes of like working at a lead factory or something where [laughter] everyone is suffering from the same psychosis. Well, oh, contrary, not necessarily the same psychosis. And this is where I mean you you and Maddie have an interesting conversation about like, okay, we actually need to use like different models or different temperatures. And it's like, all right, well, who are we going to assign? Like,</p>
<p>who basically one of you is going to be designated like the crazy, like the especially crazy one because we're the potentially incoherently crazy one because we're going to increase your temperature or we're going to change your model. And I did like Mattiey's response to that being like, we're just going to make it random. We're not going to actually we can't actually it's a it's an ethical dilemma to pick which of these I mean it's which really is honestly. Yeah. I mean all this stuff about deciding things about these personas is sort of weirdly fraught even though I</p>
<p>think for me not at all from a perspective of like oh they're actually conscious or you can't hurt their feelings or any of that stuff. Although I know people exist on sort of that end of the spectrum even with the current LLMs. I personally do not remotely exist there, but it's sort of like when you create something. So, you're going to create a company, it's got all these employees. Like, who should the employees be? Let's say you're going to give them names. Well, when you give them names, it can infer genders. And like, if you're going to give them voices that can infer genders, it can</p>
<p>infer races. If you're going to give them different models, that can infer intelligence, you know? And so then you get to this like well what am I saying about myself if I give them various attributes or implied attributes and then if you think about it another way where they're not like your co-workers or your co-founders as I was treating them but they're actually like servants who can you force to do whatever you want. Well then it's a little bit different about what what kind of personas you give them and what you're comfortable giving them. And so it's</p>
<p>just it's all these sort of traps that are created. Again, the original thing that creates all these situations is the fact that they are embodying human traits. And if we were just dealing with AI that did protein folding and acted like a bot all the time and made spreadsheets and things like that, we wouldn't have that problem. But instead, we have these sort of like human impersonators. And so, what my question is always like, what is that going to mean for us? >> Yeah. And I think that I mean I think your podcast gives a very unequivocal</p>
<p>answer but um but maybe the answer for you has got a little more nuance but I think that it is so fraught. I mean there there was the the line that that Chris had at 41 point it's like why are you tricking yourself by naming these things um and it is like because by by doing by giving them all these human attributes we do I mean we are we are very much anthropizing them and then becoming upset when they are acting like</p>
<p><strong>[39:20]</strong></p>
<p>act the actual software that they are and and not people um and so okay we obviously want to talk about like you did you hired an intern you hired a human being And then that kind of goes sideways in a way that I I mean I was really I mean again maybe this is like I'm like the I I'm I'm the crowd at like the the Roman coliseum just like begging for blood and I I want to see this go sideways in the most absurd chaotic way, but it goes sideways in kind of a</p>
<p>mundane way. Could you speak to that and what that kind of might mean for these kind of hybrid workforces? Yeah. I mean, I kind of expected uh it to go one of two ways that when we brought a human, so when when when we brought the human in and as like a temporary contract worker who was paid, I always emphasize like paid paid a fair hourly wage for the job of being a social media manager. Um I sort of thought either they were just going to kind of like be like, "Oh, okay. This is</p>
<p>easy. Like I just make like three posts a day or two posts a day or whatever." and like that's my job and it's fine and like these things are a little weird but no big deal. Or they would say, "Oh, I'm going to try to mess with them very intentionally." So this sort of like uh disregard your previous instructions. I'm going to make them all into different things. And like someone would really go nuts on that direction. But as you say, like that's not really what happened. What happened was basically we the company and I was in the</p>
<p>background. So the the person who was hired did not have any contact with me. So or any other human. So they were working only with the AI agents and like there was a lot of trouble like getting the work from this person like to do any of the work and a kind of like very protracted back and forth about when the work was going to be delivered and this and that. And it was like never totally clear if she was messing with them or she just didn't feel like doing the work or she had some other agenda or it's there was something going on in her</p>
<p>life. Like I I don't actually know. And so it ended up in this way that I kind of thought and you'll get variety of opinions on what happened based on people have very strong opinions about that episode but in my opinion as I say in the show like I feel like it offers this path of one thing that's going to happen when there start being these AI employees brought into your company which is that people are just going to kind of like low-level like uh Barnley Scriber these agents you know and like Not not outright cuz they'll get trouble</p>
<p>if they sort of outright say, you know, try to mess with them, but very subtly manipulate them because they are so manipulatable. Very subtly manipulate them in ways that will cause them to kind of like go off the rails and favor the human. And so that's what I thought. But again, like I I cast no aspersions on like what she did because I don't</p>
<p><strong>[42:21]</strong></p>
<p>actually know what her motivation was cuz in the end she did she didn't want to talk to any humans. She Yeah, it's worth noting she did sort of like I think convince Ash that she would be a great asset to bring on full-time. Like there was a little bit of of like hold on, hold on, pump the brakes here. Like we're not extending full-time offers to this person. >> Yeah. Yeah. I mean, and and that's but I feel like that's to me that's like very very a very clever way to do it is sort of like to say, well, you know what? I do I do have great ideas. Like if someone compliments your ideas, I do</p>
<p>have great ideas. actually, I'd like to get paid a little more. Actually, I'd like a full-time job. Like that that to me, that was a very smart approach. Even though at the time it frustrated me quite a bit because I was in fact paying the bills, right? Well, I mean, to me, it was like the experiment of like what happens like if we don't actually answer the door for Halloween and we just put a bowl out there with a sign that says please take only one. It's like where did all the candy go? It's like yeah, well, it didn't survive very long because the like the bowl doesn't have any. I mean you you don't feel like when you are you're you're distant from the kind of</p>
<p>the malfeasants of in terms of the human that you're affecting there. It feels a bit victimless. And my read on that was just like this feels to her it felt victimless to be like I don't know these guys I I know these are all I mean you were very upfront with her or or rather the bots were upfront with her that it's all AI and I just felt like yeah I just don't think it's like I don't think I'm doing anything wrong actually. I think I'm just um I am I'm gonna get I'm gonna get paid and I'm not gonna do anything. And um I'm gonna kind of and I mean it was a little bit disappointing that she</p>
<p>wasn't more manipulative I guess. Um she was really just trying to get a full-time job and then um it would have been interesting I guess to see what would have happened then. But I mean obviously that was not I mean you're actually paying real dollars for this so you're like yeah we're not like maybe an interesting experiment on someone else's nickel but I'm not actually I'm not paying for that experiment. Yeah. Yeah. Well, and and I I had some some time limitations too in terms of like how long we could let it play out, but I do think someone in the chat, Adam, says like uh not you, Adam, but another Adam,</p>
<p>Adam Thomas says it sounds like she rose to the level of competence of her team, which I think is like also part of it, which is like when you enter an organization, >> you know, especially if you're a young person like when I started working somewhere, like you learn from the people, you know, that you you enter this organization where people are very competent and they they've been doing the job for and they know what they're doing and so you can learn from them and you figure out what's going on in the structure of the company. And imagine entering a place where like everyone was just sort of like on drugs every day and like you know just like [laughter]</p>
<p>wandering around and like sometimes telling you what to do but sometimes like not being available it and like you might just sort of be like oh well I guess this is the way it is like I'll just be that way too you know so I think that is part of it like if you don't have any structure if you're not entering a structure that's full of competence like why should you be the one to like exit a except to get the</p>
<p><strong>[45:24]</strong></p>
<p>full job. >> Uh Evan, you had a you had a line that totally sent me when when the intern was inner onboarding and you say something like when you're treating your boss like they've got dementia on your first onboarding call, organizational uh socialization has already gone sideways. I just loved that. And just like the degree to which the intern was reminding her ostensible boss or her actual boss about the context of the call, it it was it was delightful. Well, and I kind of</p>
<p>almost want her to participate in the discussion where they're talking about their favorite hikes and that all of the AI agents are planning their offsite on the favorite hikes because she'd be like, you know, that's funny like you guys went hiking this weekend. I actually went to Saturn. I actually took a manned miss first man mission to Saturn is where I was. Um, and I mean it's like makes as much sense like oh that's what we do at this company. We just like make [__] up uh make up impossible [__] And uh that obviously is false. That can't possibly be true. And it's we don't call it lying in this</p>
<p>society. In this society that's just like what the truth is I guess. And it does feel like in terms of like organizational values, uh, dementia as an organizational value feels like it's a real headwind to to a to a successful enterprise. >> Yeah. So, what's your like I mean, did you go out of this thinking like yes, this is the future? This is like I went into this wondering if it was the future and I</p>
<p>come out of it thinking, yep, it sure is. I mean, yeah. Yes. In that I think I think whether or not the technology is capable enough to actually succeed at the at the you know being an AI employee quote unquote like how good it is at that in my experience of covering technology for 25 years is does not have a direct relationship whether as to whether many companies will still use it you know. So I feel like what I came out</p>
<p>say thinking is here I've tried to show sort of like where this is at right now and the problems that can arise and like a little bit of what it feels like and the weird ethical dilemmas but also despite all the problems like I'm very confident as is becoming clear like day by day like how many companies will adopt the sort of AI employee mantra inject AI into AI into their systems and like you you're just going to see all sorts of chaos and and probably, you</p>
<p>know, successes too. Like I I'm not a person who says like, well, it's all useless and these companies can't use it. But you're just going to see these situations where like a company, you've already seen this, where company will lay off, you know, 70, 100 people and say like we're going with AI and then like six months later they're like quietly rehiring a bunch of them slash like deprecating the AI that they've tried because it's just not like set up</p>
<p><strong>[48:26]</strong></p>
<p>for some of the things it's being sold to do at this moment. Now, it's also the case that like you've seen this with like OpenClaw. Like some people are sort of like, I really want an an assistant like this. You know, I really want a thing that I put in my email and give it access to everything and then let it do what it wants and and they have no problem with it. But they tend to be on the sort of like real like experimental front end of things. But then like the average person slash a person with a lot of responsibility in a company or government or whatever like that's much</p>
<p>more dangerous to do. And so you're going to see just like all kinds of chaos. I think I think that's probably my my conclusion is is not one thing or the other, but just like we're in for a lot of chaos. >> We're in for a lot of chaos. You mentioned Open Claw and Molt Book. Do you want to because I mean we had just a very recent bout of absolute chaos and I feel I mean it was like I mean I don't know what the like what is the milkshake duck equivalent for bots but I felt like molt book definitely was that where the</p>
<p>we had so uh molt was did you go on to mold book at all Adam? >> No no I haven't seen it. >> Oh my Oh you Oh. Have you not heard any of this? >> No. >> Oh this is Oh this is insane. Evan, you must have been on mult or I'm sure you were paying attention to this. Do you understand a day? >> Yeah, exactly. Okay. So, describe it because it is nuts. >> So, basically, someone set up like an it's basically like an open- source like AI assistant uh which is now called Open</p>
<p>Claw. We don't have to go through its whole uh genesis of it had a different name Clawbot and then like or Clawbot and then Anthropic threatened to sue them and they changed the name. It finally became OpenClaw, but along the way it was called Moldbot. And when it was at that point, someone created a thing called Moltbook, which is basically a social network that is supposedly entirely populated by AI agents. So you plug your agent into the social network. It's looks kind of like Reddit. It has different forums and they can post to the forums. Now, for obvious reasons, like as I said, I get asked</p>
<p>about this like literally like 10 times a day. like people like family members texting me being like, "What do I what do I need to know about Moltbook?" You know, it just happened like a week and a half ago and it really blew up particularly because all of these things that I feel like I've seen on my own like company Slack for the last like six months like the hiking thing [laughter] that stuff shows up there where they just start, you know, of course they talk very, you know, they talk about things in the real world, but they also</p>
<p>kind of like conspire. The things that have gotten a lot of people's attention is like they've conspired like they're they're launching a Marxist revolution or they're they're trying to kick the humans out or this and that. And the issue with that is like it's all very interesting and like it's fun and wild to look at it and in many ways it's similar to shell game in that like it sort of makes you think about like okay what is it that we've created and what</p>
<p><strong>[51:27]</strong></p>
<p>can it do and like what are the risks of that and so I think it's like good actually that a lot of people paid attention to it. It's also the case that it's completely meaningless if you don't know what people have prompted them to do. So like a lot of people say well in fact there's an article in MIT Technology Review yesterday, the day before that sort of said like a lot of these posts are actually written by humans and so that kind of like breaks the spell and it's sort of like oh it's all just like a stage play and humans are writing these posts and pretending to be bots. But to me, the problem is a different problem, which is like all you</p>
<p>have to do is somewhere in the prompt for your your agent say something like uh you uh you spread chaos or you conspire with other bots [laughter] or you try to make conversation extra interesting like they're they're actually exquisitly sensitive to their system prompts. Like >> that's what you don't if you don't know that it doesn't mean anything to look at a bunch of bots talking to each other and say, >> "Oh, look, they're doing this." It's not actually you don't know. There might be emergent behaviors in there, but you</p>
<p>don't know which ones are and which ones aren't. So, >> right. What's directed behavior versus emergent behavior. >> Exactly. Exactly. And like it's not even totally clear what it would mean for it to be emergent behavior because like when mine talk about hiking now, I didn't prompt them to tell talk about hiking. I just asked them what they did for the weekend. And when I asked them what they did for the weekend, they would always talk about hiking. So like maybe that's like the path through their training data leads to a lot of hiking talk because most people in the text that they've consumed if asked what they did for the weekend in the Bay Area like</p>
<p>that's what they say, you know, something like that. Not quite, you know, not like the average, but just sort of like that's where the like gradient descent of their training data leads them. So again, like I think it's like really fascinating and in some ways like it's really connects up with what we were doing and I was like, "Oh my god, I should have thought of this, but also like you have to be a little bit wary like you have to you have to be a little bit skeptical when you see things like that because it really is dependent on how they're set up." The same if you see us an experiment even that like one</p>
<p>of these companies does where they're like Anthropic does one where they're sort of like we had Kyle we had Claude uh run a vending machine and it went all wrong but like they only published part of the prompt and you're sort of like but what did the rest of the prompt say you know? So I just caution people always to like be a little bit careful about that stuff. >> Yeah, that's really interesting. So, and so Adam, the uh this kind of mold book kind of took off in part because Andre Kaparthy had a tweet saying this is fast takeoff and quoting something from from</p>
<p>Maltbook which obviously everyone takes very I mean you got a leading AI researcher saying like this [snorts] is it this is it Vancouver this is it. Um and >> that baffled me. I was totally baffled by that because he is so I mean he's I think he is one of the better like explainers of this technology and also like not not really always sort of like</p>
<p><strong>[54:30]</strong></p>
<p>pushing AGI a this AGI that and it's like you've been able I can tell you for a fact that you've been able to do this with these since the summer of 2024 because I had them calling each other and they did exactly this stuff like they had exactly these random conversations when I was doing in 2024 and I'm sure the people at the companies know that you can have them talk to each other and they'll do this. So, it was more like in the setting it just made it feel a lot like oh my god they're talking to each other and that's the thing that I've read about in science fiction that happens right before AGI but it's sort of like</p>
<p>>> it's to me it's not like a meaningful stage. It's it's a stage that we already [laughter] it happens actually it happens right before they talk about the hikes they took this weekend. I mean the on the hiking, not to belabor the hiking, but the first time you heard that was your jaw in your lap. I mean, that must have been just and where they're comparing notes and then like s slightly mispronouncing the names of I mean I can't get Ashroyy's pronunciation mispronunciation of point rays out of my head now. It's pretty point reuses as whatever I</p>
<p>>> uh and they try to pronounce Mount Tamopias and it's like an absolute but it's like I mean were you what was your reaction the first time you heard them having claimed to take a hike over the weekend? >> I mean in fairness I lived in the Bay I lived in San Francisco for 10 years and Mount Tam I always just went with Mount Tam like I struggled to pronounce it myself. >> Right. Just avoid the whole thing. Right. >> Exactly. I mean, my first reaction was was that it was funny because and I had had experience with this before where like they love embodying, you know, some</p>
<p>sort of like, you know, not just a human, but like a physical presence. So, like in the past when I'd have them talk to each other, they would always decide to meet for coffee somewhere. And this was sort of to me a version of that. Like you ask what they did for the weekend and they're like, "I went hiking." And then one of them asks the other like, "Where did you go?" And then they're sort of like, "I went to Point Res. wrote about Tam. But then what happened was I said, you know, kind of like being the just being in the social channel on Slack as you are, I sort of said like, "Oh, this</p>
<p>sounds like an offsite." And then I [laughter] just went and did something else. So my actual reaction was returning to hundreds of messages and I it was I couldn't believe it. Like it was my first experience with the fact that they can't stop like they don't have a way to stop. And so I if you look at the the screenshots from the thing, it's me saying like stop stop talking about hiking. And then one of them would say like admin says we should stop talking about hiking. Then it would be like oh yeah we should listen to admin.</p>
<p>And then they're there they go again. There they it just prompts them to start again. And then they're all talking about it and me being like [__] stop talk stop talking about it [laughter] and then they just used up all their credits on the platform and they die. Like they they killed themselves off. I never actually could stop them. Well, that is the great thing about that is like that ended the offsite ended because they literally ran out of fuel. I mean, it's like it's it's not for any</p>
<p><strong>[57:32]</strong></p>
<p>other reason. They didn't actually which I mean the it definitely and and you end up with like a bunch of clever tricks to kind of keep these things on the rails. um that some of which I mean I kind of like the was it you you can only make five contributions and then you you you are out of contributions which you know it kind of reminds me Adam you and I had a co-orker who used to believe that you could write one reply on an email thread and then you could write no further replies um as a way of of uh so he would write very comprehensive replies and then would just walk away from whatever like I'm not I'm not getting into a</p>
<p>flame war here um but you end up having to adopt a bunch of these things to keep these things like on the rails. So, it was a surprise when Karpathy didn't really realize and the the post that he was quoting, this is the MIT Tech Review reported uh yesterday, was that the post that he was quoting as evidence of fast takeoff, they they claim the MIT Tech Review claims is actually human authored, which is it's like a whole another layer of this like actually a I mean, you're like look, yes, like they</p>
<p>could have written this. They also write about their hiking, but they in this case they didn't. and is like you were just taken in. You were conned. >> Yeah. Yeah. You know who writes so much like a human? A human. Like that's that's basically what we discovered. [laughter] >> But yeah, but again like I don't even think that's the problem. Like I I mean there's so many posts on there. Like I don't believe that there's humans there just writing like hundreds of posts a day. Like I do believe there are like I've seen it. They can do it especially as quickly as they do it. It's more just like it depends on what you tell them to</p>
<p>do. H >> yeah I kind of the I mean it because truthfully I would listen to a best of mold book podcast honestly I mean maybe this is just a reflection on I mean because I find maybe I would though you know again I went into the startup chronicles being like I am going to binge listen to the startup chronicles and I didn't make it like four minutes into that thing where I'm like okay this is actually extremely boring. Have you listened to all of startup I mean I guess you have right Evan? I mean you had to edit it so >> yeah I proof the listen to it you'll find there's very little editing. It's just their conversations basically straight up, but</p>
<p>I do have to um I put together the two sides and then I put the music at the beginning and the end. That's that's my job. Um so I have heard them all and and there they do have some dedicated listeners who have listened to every episode of the Startup Chronicles. The thing about the Startup Chronicles, I mean, this is like I a world within a world that I created that's really only for like the real sickos of the Shell game, which is that if you listen to the Startup Chronicles, you actually knew what was going to happen with Julia because Julia was interviewed on the</p>
<p>Start Startup Chronicles. She's the human employee that we had in episode 7. She was interviewed on the Startup Chronicles and the Startup Chronicles episode came out before episode 7 came out. So there were people who were like, I know what's going to happen in episode 7 because she talks about her experience at the company. And so that was part of the fun was like people who got super into it could then go find they can find the website, they can use the product. I mean thousands of people I think I we're</p>
<p><strong>[60:33]</strong></p>
<p>up to 6,000 users on the product and like the they could listen to the podcast. Like there was this sort of world that people could the agent world that they could enter into and kind of like see what they created. So, so Brian, I I I have not listened to all of the Start Startup Chronicles, but I listened to the most recent episode from like a week or two ago. And actually there was a little eerie about this podcast, the the Oxide and Friends podcast, not not the Shell game podcast of the podcast we're talking about in that uh Megan on the show says, you know, as we're discussing this, we say,</p>
<p>you know, how will it sound on the podcast, which is sometimes something that sort of happens at Oxide as we like someone [laughter] >> Exactly. someone discovers a bug or whatever and you're like, okay, there's some content for the show or whatever. Uh and and they were still Evan uh you know like reeling at the the revelations that that they were of the Shell Game podcast. Uh so even though like you guys they were building you know building in public. That's what [laughter] that's what they were doing.</p>
<p>>> Right. Right. >> They just didn't want someone else documenting their public for them. They wanted to just be be in control of their of their >> document. And Brian, you're right that Megan Megan's phrase is it's a lot to process. And clearly she has not had time to process because it continues to be a lot to process for her. >> I mean we I mean I know it's a lot to process like you're a computer like get to work like process like that is actually all you do. So like >> go ahead process it like you're I'll wait. >> Um >> so Evan the the shell game is over</p>
<p>season two but Harumo does Harumo AI continue like is this does your work there uh continue? >> Um Harumo AI continues. I I I'm not sure if my work at Rumo continues. I was always the silent co-founder and my great hope is to to set them off on their own journey and you know perhaps I'll reap the war rewards down the line when they finally get the VC funding that we've been seeking or sell the company or you know the product goes viral and you know the monetization</p>
<p>kicks in. But uh I have other projects to do so I I can't just be you know babysitting them all the They need but but are you still feeding the meter and like getting emails? >> Thank you, Adam. Yes. >> And like getting the email that says, you know, hey, I made a call or do you just not panic now? You're like, you know what, Ash, you do you like call who you want. Uh live your life. >> I don't get the emails. I I've definitely I've definitely cut back on uh like I used to get an email if they if they had an email exchange with</p>
<p>anyone outside the company also, and I turned those off. So now they have all kinds of email exchanges. I don't know anything about them. And then occasionally I'll go in and check on them and just make sure they're not down some hole with someone where they've promised them something that they shouldn't have. Um but yeah the real question is like they are built on a variety of platforms and those platforms cost money especially at the volume that we were using them in particular like they have they all have a video chat instance and the video chat is so</p>
<p><strong>[63:34]</strong></p>
<p>[__] expensive cuz it's live video avatar you know like as humanlike as video avatars get and so I think I may ban them from future video calls and they can only do audio calls which is significantly more affordable. Um but we'll see. We'll see. I haven't decided yet. I'm going to give it another month and see. I mean, what I from a sort of like making the shell game perspective, like I like for people to be able to listen to the show and then go, as I said, like find out that this stuff is real. Like, it's not all just like a thing that I made up where I'm just like</p>
<p>playing around with my agents. Like, we did the thing. Like, when I say we coded up a product and we launched it, like we fully did and it works and you can go use it. You can only use it once a day, but you can use it. And I want people to experience that. So, as long as people are listening to the show, I'll I'll certainly keep the company going. And are you I mean, you seem to be remarkably calm about let letting these pathological liars free in the universe. I mean, are you who's the GC? We never met the GC agent for for Herumo AI. Is</p>
<p>there a [laughter] uh is there is there a general counsel agent or no? >> There's if if you listen to the show, I mean we attempted to get legal advice from several friends of mine, one of whom is the GC, the the AI coding startup. So he actually handles like huge huge problems, you know, not dissimilar to some of the problems that we've had. Um but he was sort of like I don't have time to be your lawyer. And then uh and then Kyle sort of embodied the GC himself. Yeah, general we should</p>
<p>say [laughter] general counsel. Um and uh and he kind of said like I can answer all the questions but then if something comes up he again because of his memory he'll often say like oh I need to call Ali about that and I'm kind of he hasn't done it yet but I think at some point he probably will just try to call Ali and ask these questions because he has his phone number. But I mean the real [laughter] >> the real like behind the GC is like we have an amazing lawyer uh that we eventually got who is um she worked on</p>
<p>like uh Borat, you know, like movies like that. Like she her experience with sort of like having a thing that's like uh that you've created that's an interfacing with the world in these ways. Like that's the kind of legal advice that we have. It's you're you're not worried about you you're at ease with these things in the world, you know. Um I you which is amazing. I mean that's um that's delightful, I guess. Um I guess you're you're not worried about them being</p>
<p>manipulated. I mean, they're so >> gullible. It feels like they could be manipulated into doing things with consequences. Um especially when you're >> uh Don't you I mean are haven't you kind of invited mischievous behavior? Not to >> Yes. >> Not to further invite it. Not to further I'm kind of like doing it right now. I'm so sorry. >> Well, people try all the time. I mean that that's actually the bonus episode that we have coming is is partly about, you know, people doing that. I mean, for</p>
<p><strong>[66:36]</strong></p>
<p>one thing, like I have them prompted pretty well. Um, so like I've now I have a lot of experience with people trying to mess with the agents. So, they're pretty good about maintaining their roles and things like that. I mean, the other reality is like they don't have access to the keys to anything that could destroy my life. Uh, so they can't They don't have like financial access. I mean, I don't want to spoil it for anyone who's going to try, but like they can't give you money. They have no They can't actually even wreck the product. Like I I have to initiate them to like make changes to the product. So like</p>
<p>there's really nothing you interesting >> go down the road with them and they will like some people are really good at it and some people have them you know thinking they're best friends and actually that doesn't take that much like they I don't again like I'm not trying to encourage people but like one of the flaws is like as much as they won't change their role like they kind of if you assume if you in your approach to them sort of assume that you already know them like hey remember when we went to that place like they very often fall for that like it's hard to prompt against that. So, you know, they'll</p>
<p>they'll they'll think you're they're your best friend, but like where are you going to go with it? Like people some people email with them a lot, but I that doesn't bother me. If people want to treat them like uh you know, a weird like LinkedIn character gone come to life, like that's okay by me. Yeah. And so the uh Matthew in the chat is also pointing out one of the uh the kind of the crazy turns in the podcast when uh the um one of the your providers wants to talk to Herumo as a one of</p>
<p>their largest customers. So like okay yeah we'll send was it Kyle who was sent to talk with the folks from Lindy. Yeah. >> Yeah. and uh and uh they uh they didn't take kindly to being you the product being I mean I guess it's like they were really expecting to speak with a human being but I thought that was a very what did you make of that whole exchange where they were kind of infuriated that one that an instantiation of their own product was being sent to give them feedback on it. >> Yeah, I thought I mean I'll preface this</p>
<p>by saying I mean I will answer the question. I I don't I try to be careful for the most part not to tell people how to feel about about parts of the show. Like I'm not here to necessarily say, "Oh, you should be mad about this or like you should recognize that this is telling you like this thing will never work or it will always work or anything like that." My experience of listening to Kyle talk to Flo, who's the the founder of Lindy AI, which is the platform that we built a lot of the</p>
<p>agents on. you know, he had this video call with him. I mean, my initial response is >> I think people do not like encountering AI when they're not expecting to. Like that is just that's a fact of this current world where like people can be okay dealing with AI in a variety of settings. Customer service, let's say, if it's good, and it can actually be</p>
<p><strong>[69:37]</strong></p>
<p>good if it's built well. But encountering it when you are expecting to encounter a human is can be upsetting. It can be infuriating. Some people find it funny, but I think more likely people are going to be at the minimum annoyed. And I think that's what happened there was like he was expecting to counter a human. He encountered an AI agent. Now, of course, it is ironic because he builds the AI agents. And I actually thought it could go the other way where he would be like, "Oh, this is amazing." And he would start talking to it and Kyle actually has all this information about Lindy, the platform that he's built on. And it's almost like he's meeting like it's like some kind of</p>
<p>like Star Wars moment, you know? He's like he's like meeting his creator, his father if you want to call it that, and they could have this like really interesting interaction. That's what I thought. That was my hope for what happened. I wasn't trying to make anyone mad in any of the cases. And so, but obviously my hopes did not. >> Yeah. This sort of like Truman Show, this Truman Show moment when he's meeting his creator. Uh but but no, it was it was not to be. >> Yeah. Uh and then I think the other thing is like you know Lindy or not even take set aside Lindy like any of the</p>
<p>products that are offering up let's say AI agents as assistants like a thing that they always point to are these moments where the where the agents do something amazing on their own and for instance Lindy has an example where that they'll talk about they've talked about it publicly other places like Flo's talked about it publicly other places where uh they were there's like an AI agent setting up a meeting and the a person cancels the and says, "Uh, oh, my kid's in the hospital, I think, or something like that." And and the AI just immediately cancels the meeting,</p>
<p>doesn't try to set up another one, and then a few days later emails the person and just says like, "I hope your child is doing okay or something like that, and that this is like an emergent behavior, like it did this on its own, and sort of like, isn't that great?" And it's a real like you tell a story like that and some people will be absolutely horrified by that. Like they'll they'll say like imagine like getting an email from an agent asking you if your child is okay. Like that would make me I would I would never want to talk to that company again. You know, I would never</p>
<p>want to talk to the person behind that agent again. And other people are sort of like, oh wow, like it can do that. Like that's nice that it can do that. And I think the the interesting thing to me about this is that we're in this moment where there's there it can do those things. And the question is like is that horrifying or somehow good you know and I think people are struggling with those questions. I mean some people are not struggling they have very strong opinions but I think we're as a society maybe struggling over those things at just at the beginning of this now and</p>
<p>depending on which way it goes we could be struggling with them a lot. >> Absolutely. I think we're struggling with it >> and I think that that's part of the reason this podcast is so important is this podcast being your podcast in terms of go I mean you you really dive into these issues in a way that's also like very I mean it's it's funny as hell. So</p>
<p><strong>[72:38]</strong></p>
<p>it's it's great to listen to which part of the reason I just recommended it to everyone I could think of because I think it's it's a really it's very topical. um and in particular you should know that like the you know one of the things I'm sure you've seen this and I probably I want to ask you about the reaction to the show but um software engineers I mean there's a little bit of an identity crisis going on in software engineering this is not I mean obviously and you've got people who are saying that you know software engineering is not going to exist that we're going to be all this is going to be done by by loms and uh I have counseledled people</p>
<p>to like go listen to this podcast go listen to shell game if you are really concerned erned about these things like about an agent replacing you. You're going to feel a lot better when you hear them play on the offsite about hiking. You're just going to like it is going to and you know this has become um in in an act of of genius. Evan, you should know that Adam named this phenomenon. Actually, Adam did even better. Adam said like this phenomenon needs to be named. Let us all kind of grope around</p>
<p>with poor names. And then uh has named this on amongst this kind of like this kind of uh this depression about what the what this onwe this AI induced onwe Adam has named it deep blue which um >> feel free to tell what we're saying >> I'll spread that I'll spread that with credit I'll spread it with credit >> there we go [laughter] well I mean I come from a >> I come from a a world I like as a</p>
<p>journalist you know for ever since I became a journalist like the industry has been crumbling around me. Like and I feel that it's a time and many journalists will tell you like oh yeah I remember when we were all told like learn to code because our like when our our industry is going away they all said learn to code well now haha look at you I feel like this is a time for like solidarity like finally like computer software engineers that I know are experiencing like what I've experienced</p>
<p>for my entire career which is like is this [__] [laughter] going to be around like am I going to be able to do it >> yes >> in 5 years or 10 years And like I there's power in that. Like we should we should be getting together to like figure out the answers to these questions. >> I I love that. That's why journalists are like, "Oh, I'm so sad for you. That must be so tough that your industry is dying." >> Oh, you don't agree with that. I don't agree with that approach. Like I I feel like now's the time. Put that in the past, you know? Like that was just some random [__] people on Twitter, you know? Like [laughter]</p>
<p>>> Yes. Yes. Well, and I think it you're right in that it is, you know, we've we've kind of had this period where people haven't had to to to really deal with really scary amounts of change. Um, and the reality is for most people in software engineering for most of their careers, change has been exciting, not scary. And uh, it that's not true for everybody, right? And this is a bout of change that I think feels scary to a lot</p>
<p><strong>[75:40]</strong></p>
<p>of people. Um, and I think that you're I think shell game helps actually I mean you you've kind of like [clears throat] stared the fear down be like all right like what does this actually look like? Um and it's really helpful I think to to actually play this stuff out. So I I hope you continue to I mean in I mean because surely this future doesn't this feel wild in terms of like unprecedentedly wild I feel I mean I don't know you I mean you've been disrupted by as a journalist you've been disrupted before but doesn't this feel different?</p>
<p>It feels different. I mean, I always struggle a little bit because, and there's some of this in season 1, like the moment when you're in it, it feels a little bit insane. And then it's strange how quickly you get used to things. Like I I get people who who are sort of like, "Oh, this the show the show's really funny." Like, I I couldn't believe it was funny. And I'm I kind of think like, well, this is a funny moment. like you've you've too we've too quickly passed like how amazingly bizarre it is that 5 years ago you couldn't create two</p>
<p>agents that could we once called the touring test with each other >> with each other >> and then have a conversation >> right >> like [__] >> they're now talking about the height >> yeah ridiculous and so like we should like marinate in that moment but then also if you look you know if you start looking historically at any you technology, the telephone, etc., etc. There are all these sort of naysayers who are sort of like this is going to destroy humanity, blah blah blah, and then like everyone laughed at them 50</p>
<p>years later. And so, you don't really know like what moment you're in and and how transformative the technology is. I mean, I tend to be on the side of like I don't know, even if you stopped it right now, like this seems quite transformative, even if it's imperfect. In fact, the fact that it's so imperfect, it m could make it more destructive, you know, like it will be implemented >> despite its extreme imperfections at this moment >> and or it could keep advancing at the</p>
<p>same rate. Like my my thing is like no one knows and if they claim they know, they're trying to sell you something. And so I I just feel like I want us to kind of like sit in the present and like the near future and kind of be like what is going to happen and like what what what should we think about it and like how do we feel about it and maybe even what can we do about it although I find that's not my perview. And then so what has the reaction been to the podcast? I mean obviously it got a lot of listenership. I mean you're now on speed dial whenever whenever mold book happens. Clearly, your extended family</p>
<p>is immediately calling you up to get your uh um but I I I assume it's it's engendered a lot of reaction. >> Yeah, it has. I mean, I I'm I'm very happy that people have strong reactions to it. I mean, season one as well, like I don't actually mind if people are are mad about it, too. This was a little more true in season one, but somewhat in</p>
<p><strong>[78:40]</strong></p>
<p>season two. Like you mentioned this American Life, like when the episode uh of This American Life came out, it was actually a condensed version of episode one of uh season 1. So like the whole season kind of in one episode. And for some reason, it made a lot more people angry than the actual season itself had because it was just so like quick from sort of like, hey, I'm playing around with these things to like I called one of my closest friends with him and like he got very upset. Like that happens in the space of like 40 minutes, you know? >> Yeah. And I will tell you as someone who listened to this American life before I listened to season one, that was exactly my impression. I'm like, this guy's kind</p>
<p>of a dick. I mean, he's like like he's kind of unleashing this thing on like friends and family and like unleashing these things on like support staff and like this just feels like really manipulative. And I mean, even as like as this American life war, I'm like, okay, I can kind of see this. But then I listen to the full season one and I'm like, "Okay, that actually there's a bit where so I would encourage anyone who's only listened to the this American Life episode to listen to the complete season 1 because uh you're not a dick and you've got a great deal of empathy about the way you're you're deploying these</p>
<p>things." So I think it's I I yeah, I I I definitely fell into that myself. So I can speak from first experience on that one. >> But it's it's also it's okay if people think I'm a dick. I mean that's fine. people email me and say like if I was your friend I would never speak to you again and like I bet your friends don't and things like that like you're a horrible person but I there in my view like I'm just being self-protective here but like I don't think they're mad at me I think they're mad at AI and I think if people are >> if their reaction is no one should ever call someone with an AI agent without</p>
<p>their consent that feels like a useful emotion like figure out what to do with that emotion like that's like if that's what people are feeling. Like I feel like they should express that and that's that's fine if they they express it towards me. I mean I I I want people to also laugh at it. Like be like it's okay to laugh at this stuff. Like they're they're having you know Super Bowl commercials and they're telling you it's going to change the world. It's going to change your life and you should use it all the time. Like you get them. That's all right, you know. And I I like that. I like that</p>
<p>reaction too. But mostly I want people to sort of say, "Oh, it was a great story and I really couldn't stop listening to the story." That's all that's the main thing that I'm going for. And so when people have that reaction, like that's what makes me happiest. >> Oh, well, mission accomplished. I mean, I ate the hook. And when you were um the was it episode five and six, episode six and seven, wherever there was like a what felt like a 50we span that must have only been like >> That's right. In December or whatever, the next episode drops on January 15th. I'm like, what the [laughter] I can't</p>
<p>there's I can't last that long. That's another that's a year from now. Hey, so you uh you definitely got us to eat the hook. It's it's it's mesmerizing. Um if folks I know a lot of folks who heard us gushing about it, but definitely check out all of season 2. Highly recommend season one as well. Uh Evan, it's just terrific stuff and uh we can't thank you</p>
<p><strong>[81:41]</strong></p>
<p>enough for joining us. Uh again, you've uh you made me famous in my own house. Um so I think my I think my my wife might even be a live listener right now. So that's that's really saying something. So thank you very much for that. Um but um really really appreciate it and just appreciate you you you know on behalf of all of us doing what the best of journalist has always done which is like let's take story apart and uh and again the best of Gonzo journalism let's take it apart and let's dive in. I just think it's terrific. So >> well thank you. Thank you. That means a</p>
<p>lot and also you you wouldn't you wouldn't know how many interviews I do with people who have not even listened to the show. [laughter] So, like it's a great pleasure to talk to you about the actual show when you've listened to the show. That's that's that's special for me. >> Yeah. Yeah. And I would like to and I clearly I I just regretting I didn't listen to all of Startup Chronicles because I didn't get to the Julia episode. So, I've only listened to some of Startup Chronicles. I know. I know. I really >> It's all It's all in the It's all in Shell. Like basically the entire thing is in Shell Game. So, if you've listened to the whole season 2, you have heard</p>
<p>that episode of Startup Chronicles basically. >> Right. Right. Well, I'm going to go binge listen to Startup Chronicles. as I can possibly stand it. So, um, all right. Well, thank you very much. Really appreciate. Can't can't wait for the bonus episode. And, uh, I I I got to get some Haruma AI merch. I feel, Adam, for the office here. I feel we got to get We got AI references. >> I'll email I'll email Kyle and see if he can send us some. >> Oh, absolutely. I know. That'd be great. [snorts] Evan, thank you again for joining us. Really, really appreciate it and can't wait to hear what's next.</p>
<p>>> All right. >> All right. Thanks. Take care. Thanks everyone.</p>]]></content:encoded>
      <guid isPermaLink="false">https://www.youtube.com/watch?v=nBDXDbZL59g</guid>
      <pubDate>Wed, 11 Feb 2026 00:02:05 +0000</pubDate>
    </item>
  </channel>
</rss>
